/share/home/conradb/git/ifg-ssl/S1_C1
/home/conradb/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/share/home/conradb/git/ifg-ssl/S1_C1/training/dino_S1_train.py:106: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  fp16_scaler = torch.cuda.amp.GradScaler()
Using cuda
Commencing training
Epoch 0/501
  0%|          | 0/29 [00:00<?, ?it/s]/share/home/conradb/git/ifg-ssl/S1_C1/training/dino_S1_train.py:157: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(fp16_scaler is not None):
  3%|▎         | 1/29 [00:58<27:31, 58.97s/it]  7%|▋         | 2/29 [01:07<13:10, 29.28s/it] 10%|█         | 3/29 [01:08<07:04, 16.33s/it] 14%|█▍        | 4/29 [01:09<04:16, 10.25s/it] 17%|█▋        | 5/29 [01:10<02:45,  6.88s/it] 21%|██        | 6/29 [01:11<01:51,  4.86s/it] 24%|██▍       | 7/29 [01:12<01:18,  3.57s/it] 28%|██▊       | 8/29 [01:12<00:57,  2.73s/it] 31%|███       | 9/29 [01:13<00:43,  2.16s/it] 34%|███▍      | 10/29 [01:14<00:33,  1.78s/it] 38%|███▊      | 11/29 [01:15<00:27,  1.52s/it] 41%|████▏     | 12/29 [01:16<00:22,  1.33s/it] 45%|████▍     | 13/29 [01:17<00:19,  1.21s/it] 48%|████▊     | 14/29 [01:18<00:16,  1.12s/it] 52%|█████▏    | 15/29 [01:19<00:14,  1.06s/it] 55%|█████▌    | 16/29 [01:20<00:13,  1.02s/it] 59%|█████▊    | 17/29 [01:21<00:11,  1.01it/s] 62%|██████▏   | 18/29 [01:22<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:23<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:24<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:24<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:25<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:26<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:27<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:28<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:29<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:30<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:31<00:00,  1.09it/s]100%|██████████| 29/29 [01:32<00:00,  1.09it/s]100%|██████████| 29/29 [01:32<00:00,  3.19s/it]
/home/conradb/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/share/home/conradb/git/ifg-ssl/S1_C1/training/dino_S1_train.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(config.model.checkpoint_path, map_location="cpu")
Epoch loss is 9.34443187713623
saving checkpoint
Extracting features for train set...
/home/conradb/git/ifg-ssl/dino/knn_evaluation.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels).long()
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0061, 0.0380, 0.0200,  ..., 0.0251, 0.0120, 0.0271],
        [0.0077, 0.0332, 0.0184,  ..., 0.0232, 0.0139, 0.0260],
        [0.0051, 0.0287, 0.0190,  ..., 0.0286, 0.0175, 0.0260],
        ...,
        [0.0062, 0.0267, 0.0189,  ..., 0.0294, 0.0134, 0.0272],
        [0.0084, 0.0363, 0.0214,  ..., 0.0363, 0.0120, 0.0250],
        [0.0092, 0.0308, 0.0246,  ..., 0.0272, 0.0163, 0.0249]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9855, 0.9849, 0.9849, 0.9847, 0.9847, 0.9847, 0.9847, 0.9846, 0.9846,
         0.9846],
        [0.9852, 0.9850, 0.9848, 0.9846, 0.9846, 0.9846, 0.9845, 0.9845, 0.9844,
         0.9843],
        [0.9851, 0.9848, 0.9848, 0.9846, 0.9844, 0.9844, 0.9843, 0.9842, 0.9842,
         0.9841],
        [0.9865, 0.9861, 0.9859, 0.9858, 0.9856, 0.9854, 0.9854, 0.9853, 0.9853,
         0.9853],
        [0.9856, 0.9854, 0.9853, 0.9852, 0.9851, 0.9850, 0.9849, 0.9849, 0.9847,
         0.9846],
        [0.9842, 0.9841, 0.9837, 0.9834, 0.9833, 0.9833, 0.9832, 0.9832, 0.9830,
         0.9830],
        [0.9833, 0.9832, 0.9829, 0.9828, 0.9827, 0.9826, 0.9826, 0.9826, 0.9824,
         0.9821],
        [0.9858, 0.9857, 0.9851, 0.9850, 0.9850, 0.9848, 0.9847, 0.9847, 0.9845,
         0.9845],
        [0.9844, 0.9842, 0.9842, 0.9840, 0.9840, 0.9840, 0.9839, 0.9839, 0.9839,
         0.9839],
        [0.9856, 0.9854, 0.9852, 0.9852, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851,
         0.9850],
        [0.9836, 0.9832, 0.9832, 0.9830, 0.9829, 0.9828, 0.9827, 0.9825, 0.9825,
         0.9824],
        [0.9851, 0.9850, 0.9849, 0.9848, 0.9846, 0.9845, 0.9845, 0.9842, 0.9840,
         0.9839],
        [0.9855, 0.9855, 0.9853, 0.9852, 0.9851, 0.9850, 0.9849, 0.9849, 0.9849,
         0.9849],
        [0.9836, 0.9836, 0.9835, 0.9835, 0.9834, 0.9829, 0.9829, 0.9828, 0.9828,
         0.9828],
        [0.9833, 0.9831, 0.9827, 0.9827, 0.9827, 0.9826, 0.9826, 0.9826, 0.9826,
         0.9826],
        [0.9837, 0.9834, 0.9833, 0.9832, 0.9832, 0.9831, 0.9830, 0.9830, 0.9829,
         0.9828],
        [0.9847, 0.9845, 0.9842, 0.9842, 0.9841, 0.9841, 0.9841, 0.9840, 0.9840,
         0.9839],
        [0.9859, 0.9858, 0.9857, 0.9856, 0.9855, 0.9854, 0.9854, 0.9853, 0.9853,
         0.9851],
        [0.9851, 0.9848, 0.9845, 0.9844, 0.9844, 0.9843, 0.9843, 0.9842, 0.9842,
         0.9840],
        [0.9826, 0.9820, 0.9820, 0.9815, 0.9815, 0.9815, 0.9813, 0.9812, 0.9811,
         0.9811],
        [0.9833, 0.9833, 0.9831, 0.9831, 0.9830, 0.9830, 0.9829, 0.9828, 0.9828,
         0.9828],
        [0.9844, 0.9844, 0.9843, 0.9842, 0.9842, 0.9841, 0.9841, 0.9840, 0.9840,
         0.9839],
        [0.9864, 0.9861, 0.9858, 0.9858, 0.9856, 0.9856, 0.9855, 0.9855, 0.9854,
         0.9854],
        [0.9839, 0.9839, 0.9838, 0.9838, 0.9837, 0.9837, 0.9837, 0.9836, 0.9834,
         0.9834],
        [0.9858, 0.9855, 0.9853, 0.9852, 0.9852, 0.9851, 0.9851, 0.9851, 0.9850,
         0.9849],
        [0.9845, 0.9843, 0.9842, 0.9842, 0.9841, 0.9841, 0.9840, 0.9840, 0.9840,
         0.9839],
        [0.9850, 0.9846, 0.9846, 0.9845, 0.9844, 0.9844, 0.9844, 0.9843, 0.9843,
         0.9842],
        [0.9831, 0.9830, 0.9829, 0.9829, 0.9828, 0.9828, 0.9827, 0.9827, 0.9826,
         0.9825],
        [0.9850, 0.9846, 0.9845, 0.9843, 0.9843, 0.9841, 0.9841, 0.9840, 0.9840,
         0.9840],
        [0.9840, 0.9839, 0.9839, 0.9838, 0.9836, 0.9835, 0.9835, 0.9835, 0.9835,
         0.9834],
        [0.9847, 0.9846, 0.9843, 0.9842, 0.9841, 0.9840, 0.9840, 0.9840, 0.9840,
         0.9839],
        [0.9842, 0.9840, 0.9839, 0.9839, 0.9839, 0.9838, 0.9837, 0.9837, 0.9837,
         0.9836],
        [0.9845, 0.9840, 0.9840, 0.9840, 0.9838, 0.9838, 0.9837, 0.9837, 0.9837,
         0.9836],
        [0.9857, 0.9856, 0.9856, 0.9856, 0.9853, 0.9853, 0.9852, 0.9850, 0.9850,
         0.9850],
        [0.9834, 0.9831, 0.9831, 0.9828, 0.9828, 0.9828, 0.9828, 0.9826, 0.9825,
         0.9825],
        [0.9854, 0.9850, 0.9849, 0.9848, 0.9846, 0.9845, 0.9845, 0.9845, 0.9845,
         0.9844],
        [0.9829, 0.9829, 0.9826, 0.9825, 0.9824, 0.9822, 0.9822, 0.9821, 0.9821,
         0.9821],
        [0.9843, 0.9843, 0.9842, 0.9840, 0.9839, 0.9839, 0.9839, 0.9838, 0.9838,
         0.9838],
        [0.9866, 0.9864, 0.9861, 0.9861, 0.9860, 0.9860, 0.9858, 0.9857, 0.9857,
         0.9856],
        [0.9842, 0.9842, 0.9842, 0.9842, 0.9841, 0.9840, 0.9840, 0.9839, 0.9839,
         0.9838],
        [0.9840, 0.9839, 0.9839, 0.9838, 0.9838, 0.9836, 0.9836, 0.9836, 0.9835,
         0.9835],
        [0.9845, 0.9845, 0.9843, 0.9843, 0.9842, 0.9842, 0.9842, 0.9841, 0.9841,
         0.9841],
        [0.9838, 0.9838, 0.9835, 0.9831, 0.9830, 0.9830, 0.9830, 0.9830, 0.9829,
         0.9829],
        [0.9836, 0.9835, 0.9835, 0.9835, 0.9834, 0.9834, 0.9833, 0.9833, 0.9833,
         0.9833],
        [0.9859, 0.9858, 0.9857, 0.9857, 0.9856, 0.9855, 0.9855, 0.9855, 0.9855,
         0.9854],
        [0.9859, 0.9857, 0.9857, 0.9856, 0.9855, 0.9854, 0.9854, 0.9854, 0.9853,
         0.9853],
        [0.9859, 0.9857, 0.9857, 0.9857, 0.9856, 0.9856, 0.9855, 0.9855, 0.9855,
         0.9855],
        [0.9787, 0.9784, 0.9780, 0.9779, 0.9778, 0.9777, 0.9775, 0.9773, 0.9772,
         0.9771],
        [0.9846, 0.9844, 0.9843, 0.9843, 0.9843, 0.9843, 0.9842, 0.9842, 0.9842,
         0.9842],
        [0.9840, 0.9838, 0.9836, 0.9834, 0.9833, 0.9833, 0.9831, 0.9831, 0.9829,
         0.9828],
        [0.9825, 0.9824, 0.9822, 0.9818, 0.9817, 0.9817, 0.9817, 0.9816, 0.9816,
         0.9815],
        [0.9855, 0.9851, 0.9850, 0.9849, 0.9849, 0.9847, 0.9847, 0.9846, 0.9846,
         0.9846],
        [0.9855, 0.9854, 0.9854, 0.9853, 0.9852, 0.9850, 0.9849, 0.9849, 0.9848,
         0.9848],
        [0.9839, 0.9838, 0.9835, 0.9835, 0.9835, 0.9835, 0.9834, 0.9833, 0.9833,
         0.9832],
        [0.9845, 0.9837, 0.9837, 0.9836, 0.9835, 0.9835, 0.9834, 0.9834, 0.9834,
         0.9833],
        [0.9838, 0.9837, 0.9837, 0.9837, 0.9836, 0.9836, 0.9835, 0.9835, 0.9835,
         0.9835],
        [0.9862, 0.9860, 0.9857, 0.9857, 0.9857, 0.9857, 0.9856, 0.9856, 0.9856,
         0.9855],
        [0.9858, 0.9854, 0.9854, 0.9853, 0.9853, 0.9853, 0.9851, 0.9850, 0.9850,
         0.9850],
        [0.9847, 0.9847, 0.9846, 0.9844, 0.9844, 0.9843, 0.9843, 0.9843, 0.9842,
         0.9841],
        [0.9852, 0.9842, 0.9842, 0.9841, 0.9840, 0.9840, 0.9839, 0.9839, 0.9839,
         0.9839],
        [0.9843, 0.9842, 0.9840, 0.9839, 0.9838, 0.9838, 0.9838, 0.9838, 0.9838,
         0.9838],
        [0.9855, 0.9850, 0.9850, 0.9846, 0.9845, 0.9845, 0.9845, 0.9845, 0.9845,
         0.9845],
        [0.9852, 0.9851, 0.9849, 0.9848, 0.9847, 0.9845, 0.9845, 0.9845, 0.9845,
         0.9844],
        [0.9837, 0.9836, 0.9836, 0.9835, 0.9835, 0.9833, 0.9833, 0.9832, 0.9832,
         0.9832]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1300184.0000, 1289765.6250, 1289715.2500, 1286137.2500, 1285460.3750,
         1285379.5000, 1285296.1250, 1285187.1250, 1284497.2500, 1283931.5000],
        [1294614.8750, 1290958.1250, 1288156.5000, 1284998.3750, 1284966.5000,
         1284737.3750, 1282610.8750, 1281998.2500, 1281324.7500, 1279681.0000],
        [1293289.5000, 1287874.0000, 1287163.1250, 1284410.2500, 1280500.1250,
         1280409.8750, 1278492.8750, 1277170.6250, 1276161.3750, 1275385.1250],
        [1319298.0000, 1312363.6250, 1308936.3750, 1307173.6250, 1302791.7500,
         1299510.8750, 1298927.2500, 1297186.6250, 1296877.5000, 1296324.7500],
        [1301868.8750, 1299015.1250, 1296652.3750, 1294529.6250, 1293769.3750,
         1291753.6250, 1289346.2500, 1289079.5000, 1286223.1250, 1283756.2500],
        [1276149.1250, 1274615.3750, 1267426.2500, 1261850.7500, 1261265.8750,
         1260002.3750, 1259698.3750, 1259494.2500, 1255913.8750, 1255324.7500],
        [1260903.8750, 1258390.7500, 1253232.6250, 1252458.3750, 1249617.7500,
         1248902.8750, 1248248.0000, 1248138.5000, 1245110.3750, 1239319.6250],
        [1305930.1250, 1304910.3750, 1294377.7500, 1291915.0000, 1291915.0000,
         1287654.2500, 1286224.3750, 1285225.0000, 1282825.0000, 1281905.3750],
        [1280795.7500, 1276897.8750, 1276101.7500, 1274233.7500, 1274226.5000,
         1272971.7500, 1272412.2500, 1271706.2500, 1271389.7500, 1271264.8750],
        [1302645.1250, 1299057.2500, 1295699.3750, 1295521.3750, 1294126.0000,
         1293668.2500, 1293546.0000, 1293146.5000, 1292784.0000, 1292038.2500],
        [1265525.1250, 1258480.8750, 1258431.6250, 1255225.3750, 1253319.8750,
         1251936.5000, 1249014.8750, 1246763.2500, 1246091.6250, 1244698.5000],
        [1292877.6250, 1291820.1250, 1289819.7500, 1287697.2500, 1284972.6250,
         1282409.1250, 1282399.3750, 1277766.3750, 1272681.7500, 1272065.2500],
        [1300938.0000, 1300677.5000, 1297234.8750, 1295493.0000, 1293912.5000,
         1292474.5000, 1290609.7500, 1290356.1250, 1290257.7500, 1289491.3750],
        [1266465.6250, 1266073.2500, 1264093.3750, 1263953.5000, 1261557.0000,
         1254355.3750, 1254048.0000, 1252426.1250, 1251985.5000, 1251975.8750],
        [1261286.5000, 1257701.0000, 1250380.6250, 1250285.2500, 1250120.6250,
         1248731.3750, 1248628.8750, 1248406.2500, 1247617.2500, 1247468.5000],
        [1267095.1250, 1262935.3750, 1260145.5000, 1259011.3750, 1258653.7500,
         1256872.5000, 1254935.7500, 1254764.6250, 1253082.1250, 1252157.5000],
        [1285320.7500, 1281623.0000, 1277782.2500, 1277726.1250, 1275991.0000,
         1274954.5000, 1274329.7500, 1272645.3750, 1272555.5000, 1271101.1250],
        [1308936.3750, 1307080.1250, 1304147.7500, 1302647.5000, 1301100.6250,
         1299675.7500, 1298368.6250, 1297407.0000, 1296763.6250, 1294376.6250],
        [1292945.3750, 1287933.0000, 1283272.7500, 1280043.5000, 1280043.5000,
         1278745.2500, 1277967.5000, 1277275.3750, 1276307.3750, 1274079.3750],
        [1248936.2500, 1237863.2500, 1237221.2500, 1229321.1250, 1228878.1250,
         1228141.1250, 1224494.5000, 1223083.6250, 1222210.2500, 1221004.5000],
        [1260288.3750, 1260242.7500, 1257368.7500, 1256375.1250, 1255346.2500,
         1254537.2500, 1253932.0000, 1252285.1250, 1251991.3750, 1251658.3750],
        [1280749.2500, 1280107.0000, 1279703.0000, 1276936.8750, 1276510.6250,
         1275332.8750, 1274800.2500, 1273804.8750, 1273526.7500, 1272261.8750],
        [1317350.5000, 1312755.3750, 1306934.2500, 1306217.7500, 1302673.6250,
         1302315.8750, 1301648.0000, 1300765.6250, 1299959.5000, 1299281.5000],
        [1271049.1250, 1270775.1250, 1269948.8750, 1268838.7500, 1268119.0000,
         1267323.5000, 1267166.3750, 1266878.7500, 1263343.7500, 1262418.7500],
        [1305592.6250, 1300868.6250, 1296579.3750, 1295315.0000, 1295071.7500,
         1294208.7500, 1293528.8750, 1292999.6250, 1291842.3750, 1289787.7500],
        [1282957.0000, 1279385.7500, 1277798.0000, 1277634.8750, 1275174.6250,
         1275039.6250, 1274123.2500, 1273481.8750, 1272657.3750, 1271332.7500],
        [1291206.7500, 1284471.5000, 1283472.2500, 1282592.5000, 1281102.3750,
         1280138.7500, 1279910.3750, 1279269.7500, 1278339.2500, 1277494.7500],
        [1257623.0000, 1254548.0000, 1253006.7500, 1252617.2500, 1252442.8750,
         1251547.3750, 1250461.7500, 1249815.5000, 1248669.3750, 1245786.2500],
        [1292187.2500, 1284393.1250, 1282187.7500, 1278634.3750, 1278388.1250,
         1275253.7500, 1275003.2500, 1273915.3750, 1273322.7500, 1273255.8750],
        [1272769.1250, 1271705.0000, 1271075.7500, 1270301.3750, 1266546.6250,
         1264672.1250, 1263769.1250, 1263519.6250, 1263446.1250, 1262215.3750],
        [1285910.3750, 1284206.8750, 1278311.2500, 1276732.2500, 1274592.3750,
         1274005.3750, 1273528.0000, 1273348.1250, 1272804.3750, 1272280.0000],
        [1277525.1250, 1273633.6250, 1271954.8750, 1271688.1250, 1270750.8750,
         1269194.6250, 1268381.5000, 1267341.6250, 1267283.5000, 1266739.8750],
        [1283063.6250, 1273379.7500, 1273156.3750, 1273002.1250, 1269864.1250,
         1269643.7500, 1268662.1250, 1267153.1250, 1267009.2500, 1266561.0000],
        [1304789.7500, 1303687.7500, 1302502.1250, 1302149.6250, 1297440.2500,
         1296919.5000, 1294586.5000, 1292006.2500, 1291245.0000, 1290981.3750],
        [1262778.7500, 1257798.1250, 1256992.2500, 1252333.0000, 1252241.0000,
         1251540.2500, 1251483.0000, 1247932.5000, 1246870.2500, 1246696.5000],
        [1298521.0000, 1291285.6250, 1290083.0000, 1287568.2500, 1285041.2500,
         1282436.0000, 1282429.8750, 1282202.3750, 1281982.3750, 1280075.2500],
        [1254233.3750, 1253682.1250, 1247706.3750, 1245545.1250, 1244029.1250,
         1241039.3750, 1240421.7500, 1240114.1250, 1239029.0000, 1238544.6250],
        [1278762.3750, 1278117.3750, 1276423.0000, 1273190.3750, 1272304.3750,
         1270976.3750, 1270784.8750, 1270434.7500, 1269588.0000, 1269440.3750],
        [1320900.7500, 1318543.2500, 1313005.7500, 1311753.0000, 1309966.5000,
         1309310.8750, 1306622.7500, 1304899.3750, 1304065.7500, 1303429.1250],
        [1277812.7500, 1277231.6250, 1276328.1250, 1276123.6250, 1275701.3750,
         1272988.8750, 1272848.0000, 1271706.2500, 1270873.3750, 1270082.1250],
        [1273016.7500, 1271929.3750, 1271115.7500, 1269848.3750, 1269837.5000,
         1265985.0000, 1265668.7500, 1265581.8750, 1265155.8750, 1264157.2500],
        [1283265.5000, 1282551.0000, 1279638.3750, 1278116.2500, 1277047.6250,
         1276168.6250, 1276098.0000, 1275904.5000, 1275359.6250, 1275065.2500],
        [1269912.5000, 1269516.6250, 1263666.6250, 1257551.0000, 1255822.8750,
         1255772.6250, 1255564.1250, 1254477.5000, 1253911.7500, 1253037.8750],
        [1266202.3750, 1264391.1250, 1264062.0000, 1263841.5000, 1261777.2500,
         1261635.3750, 1261466.8750, 1261187.7500, 1260790.8750, 1260390.6250],
        [1307511.5000, 1306336.1250, 1305184.3750, 1304372.8750, 1302534.5000,
         1301754.6250, 1301041.0000, 1300577.0000, 1300358.7500, 1298549.3750],
        [1308372.2500, 1305484.2500, 1305263.8750, 1302123.3750, 1301047.2500,
         1299629.8750, 1299430.2500, 1298743.8750, 1297871.0000, 1297695.2500],
        [1307797.0000, 1304268.5000, 1304160.2500, 1303815.8750, 1303079.8750,
         1302055.1250, 1300512.5000, 1300427.0000, 1300324.1250, 1300268.2500],
        [1181072.6250, 1176096.7500, 1168451.0000, 1167350.5000, 1165629.6250,
         1163863.3750, 1160468.6250, 1156297.2500, 1155901.3750, 1153890.2500],
        [1283744.1250, 1280994.8750, 1279271.1250, 1279071.0000, 1278238.1250,
         1277921.1250, 1277297.3750, 1277072.0000, 1276806.6250, 1276360.8750],
        [1273051.8750, 1270090.6250, 1265793.1250, 1262763.1250, 1260900.3750,
         1260696.0000, 1256832.8750, 1256638.7500, 1253061.6250, 1251878.0000],
        [1245446.5000, 1244694.8750, 1241704.7500, 1234159.6250, 1233039.6250,
         1232764.5000, 1231610.5000, 1230502.2500, 1230103.3750, 1228579.2500],
        [1301775.8750, 1293468.3750, 1291068.8750, 1289985.8750, 1289459.3750,
         1286160.6250, 1285584.2500, 1284868.5000, 1284000.0000, 1283372.0000],
        [1301783.2500, 1299738.8750, 1298153.2500, 1297196.6250, 1295621.5000,
         1292018.5000, 1290602.2500, 1289134.7500, 1287751.2500, 1287089.5000],
        [1270969.0000, 1269888.3750, 1264868.7500, 1264749.3750, 1264668.5000,
         1263708.8750, 1262497.0000, 1260048.1250, 1259932.7500, 1259692.3750],
        [1282104.6250, 1267398.5000, 1267224.3750, 1265883.6250, 1265017.1250,
         1263913.7500, 1263130.5000, 1262214.1250, 1261558.2500, 1261264.7500],
        [1269498.5000, 1268675.5000, 1267736.8750, 1267647.3750, 1266396.8750,
         1265312.6250, 1264609.5000, 1263878.8750, 1263616.1250, 1263573.8750],
        [1313767.3750, 1309625.6250, 1305339.8750, 1305256.5000, 1304952.7500,
         1303955.0000, 1303342.1250, 1302775.5000, 1302117.2500, 1301228.5000],
        [1307206.0000, 1299006.5000, 1298426.8750, 1297504.6250, 1296948.0000,
         1296272.7500, 1292629.8750, 1292433.8750, 1292018.5000, 1291320.0000],
        [1286094.3750, 1285794.0000, 1284933.5000, 1281476.2500, 1281008.2500,
         1278607.5000, 1278607.5000, 1278211.2500, 1277405.7500, 1275719.6250],
        [1295264.3750, 1277683.5000, 1276213.6250, 1275126.1250, 1273317.8750,
         1273104.2500, 1272374.6250, 1271807.0000, 1271571.6250, 1271512.2500],
        [1279053.8750, 1276373.1250, 1273322.7500, 1270843.0000, 1270191.1250,
         1270060.2500, 1269800.0000, 1269499.6250, 1268942.8750, 1268865.3750],
        [1300224.8750, 1292531.1250, 1292393.1250, 1283707.2500, 1282915.5000,
         1282608.3750, 1282529.0000, 1282074.0000, 1282049.6250, 1281788.0000],
        [1295850.1250, 1293875.5000, 1288967.6250, 1288715.6250, 1285559.7500,
         1282973.1250, 1282535.1250, 1282218.2500, 1281565.5000, 1280972.8750],
        [1267470.8750, 1265291.0000, 1265178.7500, 1264122.2500, 1263846.2500,
         1261498.1250, 1260809.0000, 1259727.2500, 1259491.7500, 1258921.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1300184.0000,       0.0000],
         [      0.0000, 1289765.6250],
         [1289715.2500,       0.0000],
         ...,
         [      0.0000, 1285187.1250],
         [1284497.2500,       0.0000],
         [1283931.5000,       0.0000]],

        [[1294614.8750,       0.0000],
         [1290958.1250,       0.0000],
         [1288156.5000,       0.0000],
         ...,
         [1281998.2500,       0.0000],
         [1281324.7500,       0.0000],
         [      0.0000, 1279681.0000]],

        [[1293289.5000,       0.0000],
         [1287874.0000,       0.0000],
         [1287163.1250,       0.0000],
         ...,
         [1277170.6250,       0.0000],
         [      0.0000, 1276161.3750],
         [1275385.1250,       0.0000]],

        ...,

        [[      0.0000, 1300224.8750],
         [1292531.1250,       0.0000],
         [1292393.1250,       0.0000],
         ...,
         [1282074.0000,       0.0000],
         [1282049.6250,       0.0000],
         [1281788.0000,       0.0000]],

        [[1295850.1250,       0.0000],
         [1293875.5000,       0.0000],
         [1288967.6250,       0.0000],
         ...,
         [1282218.2500,       0.0000],
         [1281565.5000,       0.0000],
         [1280972.8750,       0.0000]],

        [[1267470.8750,       0.0000],
         [1265291.0000,       0.0000],
         [1265178.7500,       0.0000],
         ...,
         [1259727.2500,       0.0000],
         [1259491.7500,       0.0000],
         [1258921.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[10300601.0000,  2574952.7500],
        [10289628.0000,  2564418.5000],
        [11544695.0000,  1276161.3750],
        [10435030.0000,  2604360.2500],
        [12925994.0000,        0.0000],
        [12631741.0000,        0.0000],
        [11245932.0000,  1258390.7500],
        [12912882.0000,        0.0000],
        [11470736.0000,  1271264.8750],
        [12952232.0000,        0.0000],
        [12529488.0000,        0.0000],
        [11552110.0000,  1282399.3750],
        [10361344.0000,  2580101.0000],
        [12586934.0000,        0.0000],
        [12510626.0000,        0.0000],
        [12579654.0000,        0.0000],
        [12764030.0000,        0.0000],
        [11709404.0000,  1301100.6250],
        [12808613.0000,        0.0000],
        [11063933.0000,  1237221.2500],
        [12554025.0000,        0.0000],
        [11489929.0000,  1273804.8750],
        [10430929.0000,  2618973.0000],
        [12675862.0000,        0.0000],
        [10370693.0000,  2585102.7500],
        [10206911.0000,  2552674.5000],
        [11537859.0000,  1280138.7500],
        [12516519.0000,        0.0000],
        [11511288.0000,  1275253.7500],
        [12670021.0000,        0.0000],
        [12765718.0000,        0.0000],
        [12704494.0000,        0.0000],
        [12711495.0000,        0.0000],
        [11673806.0000,  1302502.1250],
        [ 8765858.0000,  3760808.2500],
        [12861624.0000,        0.0000],
        [12444345.0000,        0.0000],
        [10182316.0000,  2547705.5000],
        [13102496.0000,        0.0000],
        [12741696.0000,        0.0000],
        [12682296.0000,        0.0000],
        [12779215.0000,        0.0000],
        [12589234.0000,        0.0000],
        [12625745.0000,        0.0000],
        [13028220.0000,        0.0000],
        [13015661.0000,        0.0000],
        [13026709.0000,        0.0000],
        [10493120.0000,  1155901.3750],
        [11503033.0000,  1283744.1250],
        [10093973.0000,  2517733.2500],
        [11107910.0000,  1244694.8750],
        [11606372.0000,  1283372.0000],
        [10348748.0000,  2590341.0000],
        [10118478.0000,  2522545.0000],
        [11392486.0000,  1267224.3750],
        [12660946.0000,        0.0000],
        [13052360.0000,        0.0000],
        [12963768.0000,        0.0000],
        [12807858.0000,        0.0000],
        [11481762.0000,  1276213.6250],
        [12716952.0000,        0.0000],
        [11562595.0000,  1300224.8750],
        [12863234.0000,        0.0000],
        [12626356.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 50.0
Top1 accuracy for validation set is 50.0 size is torch.Size([64, 1])
Epoch 1/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:04, 60.16s/it]  7%|▋         | 2/29 [01:01<11:23, 25.31s/it] 10%|█         | 3/29 [01:02<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 9.818002700805664
Epoch 2/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.55s/it]  7%|▋         | 2/29 [00:58<11:01, 24.51s/it] 10%|█         | 3/29 [00:59<05:57, 13.74s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.68s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.89s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 9.730634689331055
Epoch 3/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:12, 60.44s/it]  7%|▋         | 2/29 [01:02<11:38, 25.87s/it] 10%|█         | 3/29 [01:03<06:16, 14.48s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 9.626294136047363
Epoch 4/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:23, 58.71s/it]  7%|▋         | 2/29 [01:02<11:47, 26.21s/it] 10%|█         | 3/29 [01:03<06:21, 14.66s/it] 14%|█▍        | 4/29 [01:04<03:50,  9.24s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.24s/it] 21%|██        | 6/29 [01:05<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 9.458866119384766
Epoch 5/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.48s/it]  7%|▋         | 2/29 [01:00<11:19, 25.18s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 8.987320899963379
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0443, 0.0128, 0.0143,  ..., 0.0071, 0.0189, 0.0147],
        [0.0330, 0.0084, 0.0122,  ..., 0.0059, 0.0240, 0.0074],
        [0.0392, 0.0151, 0.0141,  ..., 0.0091, 0.0209, 0.0115],
        ...,
        [0.0343, 0.0168, 0.0142,  ..., 0.0088, 0.0136, 0.0140],
        [0.0406, 0.0112, 0.0122,  ..., 0.0101, 0.0180, 0.0110],
        [0.0377, 0.0121, 0.0114,  ..., 0.0079, 0.0191, 0.0117]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9882, 0.9881, 0.9881, 0.9877, 0.9876, 0.9876, 0.9876, 0.9876, 0.9876,
         0.9875],
        [0.9896, 0.9895, 0.9894, 0.9891, 0.9891, 0.9891, 0.9890, 0.9890, 0.9889,
         0.9889],
        [0.9868, 0.9867, 0.9865, 0.9864, 0.9863, 0.9862, 0.9861, 0.9861, 0.9860,
         0.9860],
        [0.9847, 0.9845, 0.9844, 0.9842, 0.9842, 0.9841, 0.9841, 0.9839, 0.9839,
         0.9838],
        [0.9777, 0.9761, 0.9757, 0.9751, 0.9751, 0.9749, 0.9748, 0.9746, 0.9745,
         0.9745],
        [0.9827, 0.9826, 0.9822, 0.9819, 0.9819, 0.9819, 0.9818, 0.9817, 0.9816,
         0.9816],
        [0.9823, 0.9822, 0.9819, 0.9818, 0.9816, 0.9816, 0.9816, 0.9816, 0.9816,
         0.9816],
        [0.9824, 0.9823, 0.9823, 0.9819, 0.9817, 0.9817, 0.9816, 0.9815, 0.9814,
         0.9813],
        [0.9903, 0.9898, 0.9898, 0.9898, 0.9897, 0.9897, 0.9895, 0.9895, 0.9894,
         0.9894],
        [0.9807, 0.9802, 0.9801, 0.9798, 0.9797, 0.9795, 0.9795, 0.9795, 0.9795,
         0.9795],
        [0.9905, 0.9900, 0.9900, 0.9900, 0.9899, 0.9899, 0.9898, 0.9898, 0.9898,
         0.9897],
        [0.9852, 0.9848, 0.9846, 0.9846, 0.9845, 0.9845, 0.9845, 0.9844, 0.9843,
         0.9842],
        [0.9812, 0.9811, 0.9803, 0.9800, 0.9799, 0.9798, 0.9795, 0.9794, 0.9794,
         0.9794],
        [0.9914, 0.9912, 0.9911, 0.9911, 0.9910, 0.9910, 0.9908, 0.9908, 0.9908,
         0.9908],
        [0.9909, 0.9908, 0.9906, 0.9906, 0.9906, 0.9906, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9900, 0.9898, 0.9896, 0.9895, 0.9895, 0.9894, 0.9894, 0.9894, 0.9893,
         0.9893],
        [0.9892, 0.9892, 0.9889, 0.9889, 0.9888, 0.9886, 0.9886, 0.9886, 0.9885,
         0.9885],
        [0.9850, 0.9849, 0.9849, 0.9849, 0.9849, 0.9848, 0.9848, 0.9847, 0.9847,
         0.9847],
        [0.9871, 0.9868, 0.9864, 0.9861, 0.9860, 0.9860, 0.9859, 0.9858, 0.9857,
         0.9857],
        [0.9913, 0.9910, 0.9908, 0.9907, 0.9907, 0.9906, 0.9906, 0.9906, 0.9905,
         0.9905],
        [0.9905, 0.9905, 0.9904, 0.9904, 0.9904, 0.9903, 0.9903, 0.9903, 0.9902,
         0.9901],
        [0.9867, 0.9858, 0.9856, 0.9856, 0.9856, 0.9855, 0.9853, 0.9853, 0.9853,
         0.9853],
        [0.9885, 0.9884, 0.9883, 0.9883, 0.9880, 0.9880, 0.9880, 0.9879, 0.9879,
         0.9879],
        [0.9897, 0.9895, 0.9891, 0.9891, 0.9891, 0.9890, 0.9889, 0.9889, 0.9889,
         0.9888],
        [0.9872, 0.9865, 0.9861, 0.9861, 0.9861, 0.9860, 0.9860, 0.9860, 0.9860,
         0.9859],
        [0.9882, 0.9882, 0.9880, 0.9876, 0.9875, 0.9874, 0.9874, 0.9874, 0.9872,
         0.9872],
        [0.9879, 0.9878, 0.9874, 0.9874, 0.9871, 0.9871, 0.9870, 0.9870, 0.9870,
         0.9870],
        [0.9896, 0.9894, 0.9892, 0.9891, 0.9890, 0.9888, 0.9888, 0.9887, 0.9887,
         0.9886],
        [0.9893, 0.9893, 0.9890, 0.9889, 0.9889, 0.9889, 0.9888, 0.9888, 0.9888,
         0.9888],
        [0.9903, 0.9900, 0.9898, 0.9898, 0.9897, 0.9897, 0.9897, 0.9897, 0.9897,
         0.9897],
        [0.9900, 0.9899, 0.9899, 0.9898, 0.9897, 0.9896, 0.9896, 0.9896, 0.9895,
         0.9895],
        [0.9900, 0.9900, 0.9898, 0.9898, 0.9897, 0.9897, 0.9896, 0.9896, 0.9896,
         0.9896],
        [0.9856, 0.9846, 0.9845, 0.9843, 0.9842, 0.9841, 0.9841, 0.9839, 0.9839,
         0.9839],
        [0.9875, 0.9873, 0.9872, 0.9871, 0.9871, 0.9871, 0.9870, 0.9870, 0.9870,
         0.9870],
        [0.9901, 0.9896, 0.9895, 0.9894, 0.9893, 0.9892, 0.9891, 0.9890, 0.9890,
         0.9889],
        [0.9884, 0.9882, 0.9878, 0.9878, 0.9876, 0.9876, 0.9876, 0.9876, 0.9875,
         0.9875],
        [0.9877, 0.9877, 0.9877, 0.9875, 0.9875, 0.9875, 0.9874, 0.9873, 0.9873,
         0.9873],
        [0.9869, 0.9866, 0.9865, 0.9865, 0.9862, 0.9862, 0.9861, 0.9861, 0.9859,
         0.9859],
        [0.9799, 0.9792, 0.9792, 0.9791, 0.9791, 0.9787, 0.9784, 0.9784, 0.9781,
         0.9781],
        [0.9904, 0.9901, 0.9901, 0.9899, 0.9898, 0.9898, 0.9898, 0.9898, 0.9898,
         0.9897],
        [0.9896, 0.9893, 0.9893, 0.9892, 0.9892, 0.9891, 0.9891, 0.9891, 0.9891,
         0.9891],
        [0.9898, 0.9896, 0.9894, 0.9893, 0.9892, 0.9892, 0.9891, 0.9891, 0.9891,
         0.9891],
        [0.9902, 0.9901, 0.9901, 0.9900, 0.9899, 0.9898, 0.9897, 0.9897, 0.9897,
         0.9896],
        [0.9903, 0.9897, 0.9897, 0.9895, 0.9895, 0.9892, 0.9891, 0.9891, 0.9891,
         0.9890],
        [0.9855, 0.9853, 0.9851, 0.9850, 0.9849, 0.9849, 0.9848, 0.9848, 0.9847,
         0.9847],
        [0.9811, 0.9808, 0.9806, 0.9806, 0.9805, 0.9805, 0.9804, 0.9802, 0.9802,
         0.9802],
        [0.9829, 0.9827, 0.9826, 0.9824, 0.9824, 0.9823, 0.9822, 0.9822, 0.9821,
         0.9820],
        [0.9907, 0.9900, 0.9898, 0.9897, 0.9897, 0.9897, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9854, 0.9849, 0.9843, 0.9843, 0.9843, 0.9842, 0.9842, 0.9841, 0.9840,
         0.9840],
        [0.9898, 0.9892, 0.9892, 0.9891, 0.9890, 0.9890, 0.9889, 0.9888, 0.9888,
         0.9887],
        [0.9892, 0.9892, 0.9891, 0.9891, 0.9891, 0.9891, 0.9890, 0.9889, 0.9889,
         0.9887],
        [0.9872, 0.9871, 0.9870, 0.9865, 0.9864, 0.9864, 0.9863, 0.9862, 0.9862,
         0.9862],
        [0.9864, 0.9863, 0.9860, 0.9857, 0.9856, 0.9855, 0.9854, 0.9853, 0.9853,
         0.9853],
        [0.9882, 0.9879, 0.9877, 0.9877, 0.9876, 0.9876, 0.9876, 0.9876, 0.9875,
         0.9875],
        [0.9902, 0.9899, 0.9898, 0.9898, 0.9897, 0.9896, 0.9896, 0.9896, 0.9896,
         0.9895],
        [0.9904, 0.9903, 0.9902, 0.9901, 0.9900, 0.9899, 0.9899, 0.9899, 0.9899,
         0.9899],
        [0.9837, 0.9836, 0.9833, 0.9833, 0.9831, 0.9830, 0.9830, 0.9830, 0.9830,
         0.9830],
        [0.9856, 0.9855, 0.9851, 0.9850, 0.9849, 0.9848, 0.9847, 0.9846, 0.9846,
         0.9845],
        [0.9875, 0.9874, 0.9872, 0.9870, 0.9868, 0.9868, 0.9865, 0.9865, 0.9863,
         0.9863],
        [0.9891, 0.9891, 0.9890, 0.9889, 0.9889, 0.9887, 0.9886, 0.9886, 0.9884,
         0.9884],
        [0.9895, 0.9890, 0.9890, 0.9889, 0.9889, 0.9888, 0.9888, 0.9888, 0.9888,
         0.9887],
        [0.9851, 0.9848, 0.9848, 0.9847, 0.9846, 0.9844, 0.9844, 0.9843, 0.9842,
         0.9839],
        [0.9865, 0.9864, 0.9861, 0.9861, 0.9857, 0.9857, 0.9856, 0.9856, 0.9855,
         0.9855],
        [0.9880, 0.9879, 0.9879, 0.9876, 0.9876, 0.9875, 0.9875, 0.9874, 0.9874,
         0.9874]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1351300.6250, 1351030.0000, 1349527.2500, 1343019.1250, 1340410.1250,
         1340345.0000, 1340201.7500, 1340168.5000, 1339855.5000, 1338988.1250],
        [1378716.3750, 1376456.6250, 1375582.6250, 1370375.3750, 1370366.1250,
         1370255.1250, 1367611.3750, 1367337.5000, 1366336.3750, 1366151.5000],
        [1325146.3750, 1322569.6250, 1318979.7500, 1318600.0000, 1316614.6250,
         1314253.6250, 1312699.1250, 1312204.7500, 1310856.3750, 1309755.5000],
        [1286625.6250, 1282743.0000, 1280185.1250, 1277140.2500, 1276631.2500,
         1275762.2500, 1274596.0000, 1270981.2500, 1270727.8750, 1269854.3750],
        [1163199.8750, 1137697.6250, 1130668.0000, 1121931.1250, 1120924.7500,
         1117306.7500, 1116273.6250, 1113353.1250, 1112209.1250, 1110992.1250],
        [1249136.3750, 1247269.8750, 1241534.2500, 1235995.8750, 1235141.6250,
         1235141.6250, 1233407.7500, 1232930.2500, 1230449.3750, 1230010.6250],
        [1242255.5000, 1241417.0000, 1235669.3750, 1233849.0000, 1231046.8750,
         1231014.0000, 1230712.3750, 1230535.1250, 1230166.7500, 1229723.2500],
        [1243995.8750, 1242896.6250, 1242070.6250, 1236262.3750, 1231686.8750,
         1231324.0000, 1229798.3750, 1228089.5000, 1227589.6250, 1224630.0000],
        [1393421.8750, 1383145.3750, 1383092.5000, 1382517.5000, 1381278.7500,
         1380778.2500, 1377563.7500, 1376456.6250, 1375459.2500, 1374679.1250],
        [1215080.2500, 1205637.1250, 1203670.2500, 1199963.6250, 1197912.3750,
         1194336.2500, 1194036.7500, 1193993.3750, 1193896.6250, 1193228.5000],
        [1397556.7500, 1387955.0000, 1387706.1250, 1386622.7500, 1386084.6250,
         1385122.6250, 1384260.3750, 1383842.0000, 1383616.2500, 1382048.2500],
        [1296217.2500, 1287836.0000, 1283893.5000, 1283701.2500, 1282449.5000,
         1282362.6250, 1282357.7500, 1280902.0000, 1278041.8750, 1276289.1250],
        [1223596.8750, 1221685.8750, 1208009.1250, 1202075.6250, 1200290.8750,
         1199683.2500, 1194840.8750, 1193159.0000, 1192724.5000, 1192648.2500],
        [1414591.8750, 1410588.1250, 1409531.2500, 1409450.5000, 1407159.2500,
         1407077.3750, 1404065.2500, 1403603.5000, 1403394.6250, 1403353.1250],
        [1404275.6250, 1402295.0000, 1400187.6250, 1399661.6250, 1398424.7500,
         1398227.3750, 1394885.7500, 1394715.3750, 1393764.7500, 1393674.3750],
        [1387671.7500, 1382654.6250, 1378450.7500, 1377727.8750, 1377540.1250,
         1376206.0000, 1375968.5000, 1374849.6250, 1373391.0000, 1373163.1250],
        [1372165.6250, 1370941.2500, 1366293.5000, 1366199.6250, 1363826.3750,
         1360726.6250, 1359749.7500, 1359169.1250, 1358793.2500, 1356955.6250],
        [1291837.5000, 1290417.6250, 1290404.1250, 1289921.8750, 1289005.6250,
         1287614.8750, 1287400.1250, 1286801.0000, 1286602.2500, 1286244.0000],
        [1330538.5000, 1325576.1250, 1318279.3750, 1312208.3750, 1310567.6250,
         1309666.7500, 1308327.2500, 1305879.0000, 1305540.2500, 1303776.0000],
        [1412965.8750, 1407078.7500, 1402499.6250, 1402011.5000, 1400846.0000,
         1399361.2500, 1398870.2500, 1398370.0000, 1398115.3750, 1397927.3750],
        [1397187.6250, 1396781.3750, 1394504.0000, 1394305.8750, 1394305.8750,
         1393758.0000, 1393673.1250, 1392290.1250, 1392166.6250, 1389560.1250],
        [1323377.0000, 1306017.2500, 1303553.5000, 1303194.2500, 1301849.1250,
         1300897.1250, 1297994.7500, 1297746.0000, 1297668.0000, 1296469.3750],
        [1357830.7500, 1356394.1250, 1354231.7500, 1354194.2500, 1348676.7500,
         1347487.6250, 1347305.1250, 1346991.6250, 1346849.0000, 1346391.8750],
        [1381444.7500, 1377094.7500, 1369921.8750, 1369398.0000, 1369378.5000,
         1367024.6250, 1365689.0000, 1364863.5000, 1364683.8750, 1363615.8750],
        [1332234.6250, 1319430.1250, 1312830.6250, 1311967.0000, 1311630.3750,
         1310652.6250, 1310627.6250, 1310566.2500, 1309400.7500, 1308830.2500],
        [1351735.0000, 1351523.5000, 1348436.3750, 1341187.6250, 1338261.7500,
         1336935.0000, 1336664.8750, 1336258.2500, 1333018.8750, 1332448.1250],
        [1347103.3750, 1344726.2500, 1337553.5000, 1336022.5000, 1331199.6250,
         1331007.8750, 1328887.3750, 1328867.1250, 1328455.2500, 1328321.0000],
        [1379039.8750, 1374589.8750, 1371944.3750, 1370031.6250, 1367732.6250,
         1363116.5000, 1362802.0000, 1362373.1250, 1361444.5000, 1359962.5000],
        [1374141.6250, 1373199.7500, 1367092.5000, 1366389.8750, 1365239.6250,
         1364896.0000, 1364414.5000, 1364112.6250, 1363870.7500, 1363346.5000],
        [1393006.0000, 1386364.8750, 1384111.1250, 1382805.0000, 1382318.5000,
         1382265.7500, 1381990.2500, 1381964.0000, 1381110.1250, 1380726.8750],
        [1387961.6250, 1385973.6250, 1385452.8750, 1383331.2500, 1380613.6250,
         1379295.0000, 1379199.0000, 1378457.3750, 1377659.6250, 1377428.3750],
        [1387579.1250, 1386737.8750, 1382678.3750, 1382445.0000, 1381726.7500,
         1380941.5000, 1379831.8750, 1378862.3750, 1378698.0000, 1378588.7500],
        [1302824.0000, 1284423.7500, 1282032.5000, 1279080.7500, 1276249.0000,
         1275370.5000, 1274474.3750, 1272375.8750, 1272217.0000, 1271836.1250],
        [1338187.6250, 1334644.6250, 1332327.5000, 1330727.5000, 1330128.6250,
         1330124.7500, 1329814.1250, 1329441.3750, 1329393.1250, 1328623.7500],
        [1388485.8750, 1380084.5000, 1377592.5000, 1375471.1250, 1373023.0000,
         1371987.6250, 1368887.6250, 1367861.8750, 1367821.3750, 1366561.8750],
        [1356317.7500, 1352686.7500, 1343609.6250, 1343523.8750, 1341046.8750,
         1340540.5000, 1340017.7500, 1340003.6250, 1339439.0000, 1338737.8750],
        [1343379.1250, 1342693.8750, 1341581.6250, 1339467.1250, 1339096.6250,
         1338810.6250, 1336293.8750, 1335450.5000, 1335045.5000, 1334219.5000],
        [1326480.2500, 1321750.0000, 1320524.1250, 1319033.8750, 1313783.7500,
         1313721.1250, 1313037.1250, 1311472.7500, 1307770.8750, 1307770.8750],
        [1201723.8750, 1189243.1250, 1188141.2500, 1188003.1250, 1186629.6250,
         1180108.8750, 1174649.6250, 1174594.7500, 1170623.6250, 1170498.7500],
        [1395519.0000, 1389248.7500, 1388929.6250, 1385636.6250, 1383991.1250,
         1383785.1250, 1383719.1250, 1382882.8750, 1382607.2500, 1380890.1250],
        [1380175.2500, 1372762.5000, 1372564.7500, 1371850.2500, 1370984.5000,
         1370082.6250, 1369509.1250, 1369204.7500, 1369039.0000, 1368849.7500],
        [1382611.1250, 1378722.8750, 1374566.3750, 1374375.0000, 1372184.0000,
         1370789.6250, 1370381.7500, 1369507.7500, 1369215.3750, 1369069.0000],
        [1391686.1250, 1390147.3750, 1389377.3750, 1387977.5000, 1385612.8750,
         1382447.6250, 1382327.7500, 1380773.0000, 1380467.5000, 1380075.2500],
        [1392461.3750, 1380949.5000, 1380750.6250, 1377323.2500, 1376644.3750,
         1371884.3750, 1370313.8750, 1370244.6250, 1369406.0000, 1368355.0000],
        [1301640.5000, 1297045.6250, 1292645.8750, 1290855.8750, 1290025.1250,
         1288884.0000, 1287737.7500, 1287476.1250, 1286700.3750, 1286561.7500],
        [1221190.7500, 1215985.6250, 1213556.2500, 1212337.0000, 1210764.5000,
         1210430.8750, 1210017.6250, 1206813.8750, 1206614.7500, 1206327.1250],
        [1254155.6250, 1249241.1250, 1248112.2500, 1245071.2500, 1244065.8750,
         1242865.7500, 1241771.0000, 1241146.0000, 1238831.7500, 1238328.5000],
        [1400544.2500, 1386335.8750, 1383640.0000, 1380807.2500, 1380807.2500,
         1380371.5000, 1376619.3750, 1376083.8750, 1375054.1250, 1373156.6250],
        [1299280.3750, 1290415.2500, 1278877.0000, 1278461.2500, 1278350.2500,
         1277476.3750, 1277268.1250, 1275713.5000, 1273503.7500, 1272987.6250],
        [1383506.7500, 1371324.5000, 1370950.5000, 1370383.1250, 1366797.7500,
         1366792.6250, 1366344.2500, 1362890.2500, 1362881.2500, 1362149.7500],
        [1372364.5000, 1372342.2500, 1370393.6250, 1370172.7500, 1368883.6250,
         1368741.3750, 1367753.6250, 1365969.0000, 1364948.1250, 1361731.3750],
        [1333433.3750, 1330161.6250, 1328207.0000, 1320124.8750, 1318162.3750,
         1317814.2500, 1316037.1250, 1314844.1250, 1314281.2500, 1314088.1250],
        [1317040.3750, 1316589.5000, 1310472.6250, 1305274.0000, 1302538.2500,
         1301119.2500, 1299180.0000, 1298004.6250, 1297472.5000, 1296844.0000],
        [1351795.6250, 1345429.2500, 1342690.1250, 1342275.2500, 1341188.8750,
         1340997.0000, 1340302.7500, 1339691.8750, 1339293.3750, 1339133.7500],
        [1392173.2500, 1385159.6250, 1382947.5000, 1382454.2500, 1380430.6250,
         1380354.3750, 1379685.7500, 1379093.7500, 1378613.7500, 1377915.8750],
        [1395303.5000, 1392307.3750, 1390882.0000, 1388312.3750, 1386796.0000,
         1386235.3750, 1385615.5000, 1384849.2500, 1384593.1250, 1384507.2500],
        [1268434.7500, 1265423.7500, 1260222.2500, 1259853.3750, 1257781.2500,
         1255784.5000, 1255764.2500, 1255609.7500, 1255007.6250, 1254429.6250],
        [1302550.7500, 1300511.3750, 1292650.7500, 1290815.2500, 1290393.0000,
         1288229.0000, 1285844.2500, 1284488.6250, 1283469.8750, 1283078.2500],
        [1339419.8750, 1337600.7500, 1332100.0000, 1329077.5000, 1325308.1250,
         1324677.6250, 1320491.3750, 1318993.6250, 1316702.5000, 1315945.5000],
        [1369330.1250, 1368650.0000, 1367820.1250, 1366438.1250, 1365700.6250,
         1361148.5000, 1359819.8750, 1359690.1250, 1356527.3750, 1355239.5000],
        [1377638.5000, 1367801.8750, 1366762.6250, 1365255.3750, 1365110.8750,
         1364660.3750, 1364210.2500, 1363045.0000, 1362868.2500, 1362388.6250],
        [1293276.0000, 1287516.6250, 1287244.1250, 1286518.8750, 1284977.5000,
         1280148.5000, 1279776.2500, 1278339.2500, 1277392.3750, 1271318.1250],
        [1319086.6250, 1318158.6250, 1312944.5000, 1311469.0000, 1304978.8750,
         1304016.0000, 1302858.7500, 1302575.5000, 1300918.1250, 1300570.8750],
        [1347548.0000, 1346978.8750, 1346903.0000, 1340976.6250, 1340976.6250,
         1338311.5000, 1337773.0000, 1337117.3750, 1336792.2500, 1336683.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[      0.0000, 1351300.6250],
         [1351030.0000,       0.0000],
         [1349527.2500,       0.0000],
         ...,
         [1340168.5000,       0.0000],
         [1339855.5000,       0.0000],
         [1338988.1250,       0.0000]],

        [[1378716.3750,       0.0000],
         [1376456.6250,       0.0000],
         [1375582.6250,       0.0000],
         ...,
         [1367337.5000,       0.0000],
         [1366336.3750,       0.0000],
         [1366151.5000,       0.0000]],

        [[1325146.3750,       0.0000],
         [1322569.6250,       0.0000],
         [1318979.7500,       0.0000],
         ...,
         [1312204.7500,       0.0000],
         [1310856.3750,       0.0000],
         [1309755.5000,       0.0000]],

        ...,

        [[1293276.0000,       0.0000],
         [1287516.6250,       0.0000],
         [1287244.1250,       0.0000],
         ...,
         [1278339.2500,       0.0000],
         [1277392.3750,       0.0000],
         [      0.0000, 1271318.1250]],

        [[1319086.6250,       0.0000],
         [      0.0000, 1318158.6250],
         [1312944.5000,       0.0000],
         ...,
         [1302575.5000,       0.0000],
         [1300918.1250,       0.0000],
         [1300570.8750,       0.0000]],

        [[1347548.0000,       0.0000],
         [1346978.8750,       0.0000],
         [1346903.0000,       0.0000],
         ...,
         [1337117.3750,       0.0000],
         [1336792.2500,       0.0000],
         [1336683.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12083546.0000,  1351300.6250],
        [13709189.0000,        0.0000],
        [11848981.0000,  1312699.1250],
        [10223538.0000,  2541709.0000],
        [ 9021355.0000,  2223201.2500],
        [12371018.0000,        0.0000],
        [ 9852717.0000,  2483672.5000],
        [ 9886124.0000,  2452219.5000],
        [ 9672277.0000,  4136115.5000],
        [ 9603822.0000,  2387933.5000],
        [13864815.0000,        0.0000],
        [12834050.0000,        0.0000],
        [10805118.0000,  1223596.8750],
        [12669462.0000,  1403353.1250],
        [ 9793496.0000,  4186617.0000],
        [13777624.0000,        0.0000],
        [10915301.0000,  2719520.0000],
        [11599647.0000,  1286602.2500],
        [13130360.0000,        0.0000],
        [12605080.0000,  1412965.8750],
        [12541345.0000,  1397187.6250],
        [13028766.0000,        0.0000],
        [13506353.0000,        0.0000],
        [13693116.0000,        0.0000],
        [11827543.0000,  1310627.6250],
        [12058033.0000,  1348436.3750],
        [12004590.0000,  1337553.5000],
        [13673037.0000,        0.0000],
        [13666704.0000,        0.0000],
        [13836663.0000,        0.0000],
        [13815372.0000,        0.0000],
        [12435412.0000,  1382678.3750],
        [11488060.0000,  1302824.0000],
        [11975225.0000,  1338187.6250],
        [13737777.0000,        0.0000],
        [13435924.0000,        0.0000],
        [12047228.0000,  1338810.6250],
        [13155344.0000,        0.0000],
        [ 8289880.0000,  3534336.7500],
        [11082643.0000,  2774566.2500],
        [13715023.0000,        0.0000],
        [13731423.0000,        0.0000],
        [13850892.0000,        0.0000],
        [13758334.0000,        0.0000],
        [11616927.0000,  1292645.8750],
        [12114039.0000,        0.0000],
        [12443589.0000,        0.0000],
        [12427084.0000,  1386335.8750],
        [11525065.0000,  1277268.1250],
        [13684020.0000,        0.0000],
        [13683300.0000,        0.0000],
        [11878947.0000,  1328207.0000],
        [ 9143237.0000,  3901298.0000],
        [12083505.0000,  1339293.3750],
        [13818829.0000,        0.0000],
        [13879402.0000,        0.0000],
        [11332527.0000,  1255784.5000],
        [12902031.0000,        0.0000],
        [ 9287777.0000,  3972540.0000],
        [10893214.0000,  2737150.2500],
        [12292980.0000,  1366762.6250],
        [11555190.0000,  1271318.1250],
        [11759418.0000,  1318158.6250],
        [13410061.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 50.0
Top1 accuracy for validation set is 50.0 size is torch.Size([64, 1])
Epoch 6/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:13, 58.36s/it]  7%|▋         | 2/29 [00:59<11:03, 24.57s/it] 10%|█         | 3/29 [01:00<06:06, 14.08s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.01s/it] 21%|██        | 6/29 [01:03<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 8.276934623718262
Epoch 7/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:12, 58.32s/it]  7%|▋         | 2/29 [01:00<11:26, 25.41s/it] 10%|█         | 3/29 [01:01<06:09, 14.23s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 7.869884967803955
Epoch 8/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:34, 56.93s/it]  7%|▋         | 2/29 [01:00<11:21, 25.25s/it] 10%|█         | 3/29 [01:00<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:01<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.04s/it] 21%|██        | 6/29 [01:03<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 7.7065019607543945
Epoch 9/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:25, 56.63s/it]  7%|▋         | 2/29 [00:59<11:22, 25.27s/it] 10%|█         | 3/29 [01:00<06:08, 14.15s/it] 14%|█▍        | 4/29 [01:01<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.04s/it] 21%|██        | 6/29 [01:03<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 7.734726428985596
Epoch 10/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.48s/it]  7%|▋         | 2/29 [01:00<11:15, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 7.79423189163208
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0376, 0.0120, 0.0118,  ..., 0.0083, 0.0139, 0.0107],
        [0.0393, 0.0135, 0.0109,  ..., 0.0048, 0.0170, 0.0117],
        [0.0335, 0.0152, 0.0138,  ..., 0.0093, 0.0131, 0.0114],
        ...,
        [0.0427, 0.0151, 0.0147,  ..., 0.0089, 0.0194, 0.0234],
        [0.0379, 0.0112, 0.0132,  ..., 0.0053, 0.0174, 0.0160],
        [0.0389, 0.0206, 0.0161,  ..., 0.0060, 0.0204, 0.0167]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9897, 0.9894, 0.9894, 0.9894, 0.9893, 0.9892, 0.9891, 0.9890, 0.9890,
         0.9890],
        [0.9899, 0.9897, 0.9897, 0.9895, 0.9895, 0.9894, 0.9894, 0.9893, 0.9893,
         0.9892],
        [0.9865, 0.9860, 0.9858, 0.9858, 0.9857, 0.9857, 0.9856, 0.9856, 0.9856,
         0.9855],
        [0.9842, 0.9841, 0.9838, 0.9836, 0.9835, 0.9835, 0.9835, 0.9833, 0.9833,
         0.9832],
        [0.9767, 0.9757, 0.9754, 0.9747, 0.9741, 0.9734, 0.9728, 0.9727, 0.9724,
         0.9722],
        [0.9811, 0.9810, 0.9805, 0.9805, 0.9805, 0.9803, 0.9803, 0.9802, 0.9802,
         0.9801],
        [0.9794, 0.9794, 0.9791, 0.9789, 0.9789, 0.9789, 0.9789, 0.9787, 0.9786,
         0.9785],
        [0.9850, 0.9838, 0.9830, 0.9830, 0.9829, 0.9826, 0.9824, 0.9822, 0.9819,
         0.9818],
        [0.9901, 0.9897, 0.9897, 0.9897, 0.9897, 0.9897, 0.9896, 0.9896, 0.9896,
         0.9895],
        [0.9817, 0.9812, 0.9812, 0.9811, 0.9811, 0.9810, 0.9810, 0.9809, 0.9808,
         0.9808],
        [0.9904, 0.9904, 0.9903, 0.9901, 0.9899, 0.9899, 0.9899, 0.9898, 0.9898,
         0.9898],
        [0.9843, 0.9841, 0.9837, 0.9837, 0.9837, 0.9836, 0.9836, 0.9836, 0.9834,
         0.9834],
        [0.9803, 0.9802, 0.9799, 0.9799, 0.9798, 0.9798, 0.9796, 0.9795, 0.9794,
         0.9793],
        [0.9908, 0.9905, 0.9904, 0.9902, 0.9902, 0.9901, 0.9901, 0.9901, 0.9901,
         0.9901],
        [0.9912, 0.9911, 0.9908, 0.9908, 0.9906, 0.9905, 0.9905, 0.9905, 0.9904,
         0.9904],
        [0.9901, 0.9896, 0.9895, 0.9895, 0.9895, 0.9894, 0.9893, 0.9892, 0.9892,
         0.9891],
        [0.9897, 0.9892, 0.9892, 0.9890, 0.9890, 0.9889, 0.9889, 0.9889, 0.9886,
         0.9886],
        [0.9865, 0.9865, 0.9861, 0.9861, 0.9860, 0.9860, 0.9859, 0.9858, 0.9858,
         0.9857],
        [0.9888, 0.9883, 0.9881, 0.9879, 0.9879, 0.9877, 0.9877, 0.9877, 0.9877,
         0.9876],
        [0.9907, 0.9902, 0.9900, 0.9900, 0.9899, 0.9899, 0.9898, 0.9898, 0.9897,
         0.9897],
        [0.9899, 0.9895, 0.9894, 0.9893, 0.9891, 0.9891, 0.9890, 0.9890, 0.9890,
         0.9889],
        [0.9877, 0.9873, 0.9867, 0.9866, 0.9864, 0.9864, 0.9863, 0.9863, 0.9863,
         0.9862],
        [0.9877, 0.9874, 0.9873, 0.9872, 0.9872, 0.9872, 0.9871, 0.9870, 0.9870,
         0.9870],
        [0.9907, 0.9906, 0.9905, 0.9904, 0.9904, 0.9904, 0.9904, 0.9903, 0.9903,
         0.9903],
        [0.9856, 0.9854, 0.9853, 0.9851, 0.9849, 0.9848, 0.9848, 0.9847, 0.9847,
         0.9847],
        [0.9880, 0.9880, 0.9878, 0.9877, 0.9874, 0.9874, 0.9873, 0.9873, 0.9873,
         0.9873],
        [0.9860, 0.9859, 0.9857, 0.9857, 0.9856, 0.9856, 0.9856, 0.9856, 0.9856,
         0.9855],
        [0.9883, 0.9882, 0.9881, 0.9881, 0.9880, 0.9879, 0.9879, 0.9879, 0.9878,
         0.9878],
        [0.9900, 0.9899, 0.9896, 0.9896, 0.9896, 0.9895, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9901, 0.9900, 0.9898, 0.9898, 0.9898, 0.9897, 0.9896, 0.9896, 0.9896,
         0.9896],
        [0.9893, 0.9892, 0.9890, 0.9890, 0.9889, 0.9889, 0.9888, 0.9888, 0.9888,
         0.9887],
        [0.9899, 0.9899, 0.9898, 0.9898, 0.9898, 0.9898, 0.9896, 0.9896, 0.9895,
         0.9895],
        [0.9855, 0.9849, 0.9849, 0.9849, 0.9848, 0.9847, 0.9846, 0.9846, 0.9845,
         0.9845],
        [0.9875, 0.9870, 0.9869, 0.9869, 0.9867, 0.9865, 0.9864, 0.9863, 0.9863,
         0.9863],
        [0.9902, 0.9902, 0.9901, 0.9900, 0.9898, 0.9898, 0.9897, 0.9897, 0.9896,
         0.9896],
        [0.9870, 0.9870, 0.9868, 0.9866, 0.9865, 0.9865, 0.9863, 0.9863, 0.9862,
         0.9862],
        [0.9877, 0.9877, 0.9877, 0.9876, 0.9876, 0.9876, 0.9876, 0.9876, 0.9875,
         0.9875],
        [0.9867, 0.9866, 0.9866, 0.9864, 0.9863, 0.9862, 0.9861, 0.9861, 0.9859,
         0.9859],
        [0.9806, 0.9805, 0.9804, 0.9803, 0.9801, 0.9799, 0.9799, 0.9798, 0.9796,
         0.9796],
        [0.9897, 0.9895, 0.9895, 0.9895, 0.9894, 0.9894, 0.9894, 0.9894, 0.9894,
         0.9894],
        [0.9873, 0.9872, 0.9871, 0.9870, 0.9870, 0.9869, 0.9868, 0.9867, 0.9867,
         0.9867],
        [0.9894, 0.9891, 0.9890, 0.9890, 0.9890, 0.9889, 0.9889, 0.9888, 0.9888,
         0.9888],
        [0.9904, 0.9898, 0.9896, 0.9895, 0.9895, 0.9894, 0.9894, 0.9893, 0.9893,
         0.9892],
        [0.9901, 0.9900, 0.9897, 0.9894, 0.9894, 0.9894, 0.9894, 0.9894, 0.9893,
         0.9893],
        [0.9833, 0.9832, 0.9831, 0.9830, 0.9829, 0.9829, 0.9828, 0.9827, 0.9826,
         0.9825],
        [0.9780, 0.9780, 0.9778, 0.9766, 0.9766, 0.9764, 0.9763, 0.9763, 0.9763,
         0.9762],
        [0.9760, 0.9750, 0.9749, 0.9749, 0.9747, 0.9745, 0.9745, 0.9745, 0.9743,
         0.9741],
        [0.9881, 0.9880, 0.9880, 0.9877, 0.9876, 0.9876, 0.9875, 0.9875, 0.9875,
         0.9875],
        [0.9846, 0.9845, 0.9841, 0.9838, 0.9838, 0.9838, 0.9838, 0.9838, 0.9838,
         0.9836],
        [0.9883, 0.9880, 0.9877, 0.9877, 0.9874, 0.9873, 0.9873, 0.9873, 0.9873,
         0.9872],
        [0.9884, 0.9884, 0.9881, 0.9881, 0.9881, 0.9880, 0.9880, 0.9880, 0.9879,
         0.9879],
        [0.9858, 0.9858, 0.9857, 0.9856, 0.9856, 0.9856, 0.9854, 0.9853, 0.9853,
         0.9853],
        [0.9830, 0.9826, 0.9826, 0.9824, 0.9823, 0.9822, 0.9820, 0.9818, 0.9817,
         0.9817],
        [0.9868, 0.9859, 0.9857, 0.9857, 0.9854, 0.9853, 0.9853, 0.9853, 0.9852,
         0.9852],
        [0.9899, 0.9884, 0.9884, 0.9883, 0.9883, 0.9883, 0.9883, 0.9882, 0.9882,
         0.9882],
        [0.9902, 0.9898, 0.9897, 0.9897, 0.9896, 0.9895, 0.9895, 0.9895, 0.9895,
         0.9895],
        [0.9811, 0.9805, 0.9803, 0.9802, 0.9798, 0.9798, 0.9798, 0.9797, 0.9797,
         0.9797],
        [0.9813, 0.9802, 0.9800, 0.9797, 0.9797, 0.9795, 0.9795, 0.9795, 0.9794,
         0.9794],
        [0.9863, 0.9855, 0.9852, 0.9852, 0.9852, 0.9851, 0.9851, 0.9848, 0.9848,
         0.9848],
        [0.9867, 0.9866, 0.9866, 0.9865, 0.9865, 0.9864, 0.9863, 0.9863, 0.9863,
         0.9861],
        [0.9860, 0.9856, 0.9855, 0.9855, 0.9853, 0.9851, 0.9850, 0.9850, 0.9850,
         0.9848],
        [0.9817, 0.9804, 0.9804, 0.9803, 0.9802, 0.9801, 0.9799, 0.9797, 0.9796,
         0.9795],
        [0.9839, 0.9832, 0.9830, 0.9830, 0.9828, 0.9826, 0.9826, 0.9825, 0.9825,
         0.9825],
        [0.9868, 0.9868, 0.9867, 0.9866, 0.9866, 0.9865, 0.9864, 0.9864, 0.9863,
         0.9863]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1382025.8750, 1375458.0000, 1375281.0000, 1374669.8750, 1373810.1250,
         1371298.2500, 1368698.2500, 1368511.6250, 1368083.6250, 1367602.2500],
        [1384397.7500, 1381759.7500, 1381389.3750, 1378297.0000, 1378155.0000,
         1375408.1250, 1374494.2500, 1373292.7500, 1373177.6250, 1372388.1250],
        [1319031.2500, 1310355.1250, 1306842.0000, 1306138.0000, 1305337.3750,
         1303707.6250, 1303498.7500, 1302611.5000, 1301867.7500, 1301351.2500],
        [1276420.6250, 1274306.7500, 1269860.5000, 1265552.8750, 1265069.0000,
         1264335.7500, 1263733.0000, 1260126.1250, 1259876.2500, 1258833.7500],
        [1146978.2500, 1131604.3750, 1126914.3750, 1114346.3750, 1105849.5000,
         1093986.8750, 1085801.5000, 1083451.5000, 1078426.0000, 1076049.7500],
        [1221109.2500, 1220190.7500, 1211181.5000, 1210968.8750, 1210586.7500,
         1207686.6250, 1207533.5000, 1206893.2500, 1205805.0000, 1204412.0000],
        [1192997.5000, 1191504.5000, 1186981.5000, 1184275.8750, 1184069.1250,
         1183699.8750, 1183688.6250, 1180316.0000, 1178978.3750, 1177039.2500],
        [1291748.7500, 1269332.6250, 1255615.7500, 1254477.5000, 1253049.7500,
         1248734.8750, 1244042.1250, 1241171.8750, 1235862.7500, 1234465.7500],
        [1389377.3750, 1382264.3750, 1381166.7500, 1380946.7500, 1380935.0000,
         1380748.0000, 1379939.6250, 1378880.6250, 1378713.6250, 1377100.0000],
        [1232970.2500, 1224188.7500, 1222583.2500, 1222006.2500, 1221423.7500,
         1220773.8750, 1220536.5000, 1218379.1250, 1217152.7500, 1215667.8750],
        [1395378.0000, 1394461.3750, 1393161.3750, 1388390.5000, 1386260.5000,
         1385875.8750, 1384612.8750, 1383925.1250, 1383731.0000, 1383542.3750],
        [1278419.7500, 1274376.0000, 1267999.2500, 1267405.6250, 1267196.5000,
         1266610.6250, 1266278.5000, 1265737.5000, 1262188.8750, 1261996.2500],
        [1207063.7500, 1206248.8750, 1201216.2500, 1201159.0000, 1198850.6250,
         1198676.8750, 1196133.7500, 1194011.6250, 1192646.0000, 1190423.3750],
        [1403145.7500, 1397822.1250, 1395957.0000, 1391958.2500, 1391820.1250,
         1389898.2500, 1389698.0000, 1389173.2500, 1388732.2500, 1388566.6250],
        [1410546.5000, 1408691.2500, 1402551.7500, 1402484.8750, 1400048.7500,
         1397867.3750, 1397592.8750, 1396938.5000, 1395750.7500, 1395601.6250],
        [1390207.1250, 1380241.1250, 1378261.5000, 1377297.1250, 1376505.2500,
         1375686.2500, 1372864.5000, 1372483.6250, 1371591.2500, 1370094.3750],
        [1382016.6250, 1371592.6250, 1370751.7500, 1368373.2500, 1367191.5000,
         1365871.2500, 1365295.7500, 1364765.8750, 1359927.6250, 1359065.2500],
        [1320015.3750, 1318787.2500, 1312746.6250, 1311584.1250, 1310838.7500,
         1309789.2500, 1308136.2500, 1306545.3750, 1305642.3750, 1305266.3750],
        [1363086.6250, 1353590.0000, 1349973.8750, 1346598.6250, 1345814.1250,
         1342588.8750, 1342587.6250, 1342475.0000, 1342349.5000, 1339755.7500],
        [1400814.0000, 1391806.8750, 1386973.2500, 1386851.5000, 1384589.1250,
         1384556.1250, 1382474.0000, 1382435.7500, 1382061.5000, 1381869.0000],
        [1385319.5000, 1376967.3750, 1374753.7500, 1374183.6250, 1370272.1250,
         1368928.1250, 1367861.8750, 1366968.5000, 1366670.0000, 1366520.2500],
        [1342788.6250, 1334351.8750, 1323995.6250, 1320736.8750, 1318036.6250,
         1317995.1250, 1316524.1250, 1316220.3750, 1316122.5000, 1314386.5000],
        [1342518.5000, 1336381.7500, 1335420.0000, 1333448.6250, 1333410.3750,
         1332896.8750, 1330534.6250, 1329005.2500, 1328962.1250, 1328789.7500],
        [1400999.6250, 1398332.7500, 1396241.8750, 1396015.5000, 1395878.5000,
         1395591.0000, 1394307.1250, 1393657.0000, 1393510.8750, 1393419.1250],
        [1303378.1250, 1299224.6250, 1297903.2500, 1293004.6250, 1289993.1250,
         1287756.1250, 1287387.7500, 1285910.3750, 1285671.3750, 1285296.1250],
        [1347871.8750, 1347415.6250, 1344731.3750, 1341849.0000, 1336335.8750,
         1336282.3750, 1335626.2500, 1334853.3750, 1334028.6250, 1333947.2500],
        [1310766.3750, 1308473.2500, 1304569.5000, 1304426.5000, 1303276.2500,
         1303256.3750, 1303164.3750, 1302725.7500, 1302052.6250, 1301574.7500],
        [1354792.3750, 1352726.7500, 1349859.3750, 1349302.0000, 1348049.2500,
         1347171.5000, 1345625.5000, 1345601.1250, 1345290.5000, 1344710.8750],
        [1386403.2500, 1385116.0000, 1380066.0000, 1379418.6250, 1379385.7500,
         1377220.8750, 1376838.7500, 1376127.1250, 1374731.5000, 1374027.6250],
        [1388675.3750, 1387538.1250, 1384178.5000, 1383552.8750, 1382638.8750,
         1380877.0000, 1378820.1250, 1378775.5000, 1378749.2500, 1378520.5000],
        [1373465.6250, 1372287.2500, 1368442.5000, 1368296.2500, 1366082.3750,
         1366043.3750, 1364413.2500, 1363011.2500, 1362820.1250, 1362071.7500],
        [1385834.8750, 1384602.3750, 1383628.1250, 1383333.8750, 1383043.7500,
         1382987.0000, 1378750.6250, 1378407.3750, 1377559.7500, 1377180.1250],
        [1300783.0000, 1289866.5000, 1289861.5000, 1289575.0000, 1287110.3750,
         1286689.3750, 1283626.6250, 1283582.5000, 1282755.2500, 1282511.7500],
        [1339554.0000, 1329757.0000, 1327248.5000, 1326718.1250, 1323781.0000,
         1319534.6250, 1317473.6250, 1316133.7500, 1315826.2500, 1315294.2500],
        [1392235.7500, 1391159.3750, 1388540.1250, 1387523.6250, 1383712.6250,
         1383695.5000, 1381073.2500, 1380961.2500, 1379137.1250, 1378696.6250],
        [1329545.2500, 1329473.0000, 1324584.1250, 1321728.5000, 1320070.7500,
         1319125.6250, 1315392.2500, 1315118.6250, 1314793.8750, 1313278.7500],
        [1343162.5000, 1342177.8750, 1342065.2500, 1341255.3750, 1340867.7500,
         1340757.8750, 1340750.2500, 1340052.2500, 1338032.0000, 1338023.0000],
        [1323643.3750, 1321889.8750, 1321694.5000, 1317732.5000, 1316003.2500,
         1313767.3750, 1312153.3750, 1311657.8750, 1309063.6250, 1308112.6250],
        [1212456.1250, 1211202.1250, 1208752.5000, 1207150.0000, 1203938.8750,
         1200794.7500, 1200147.8750, 1198666.5000, 1196252.5000, 1196049.3750],
        [1380509.7500, 1378183.8750, 1378040.6250, 1377131.5000, 1376261.0000,
         1375738.7500, 1375653.5000, 1375639.1250, 1375370.2500, 1374635.7500],
        [1334496.8750, 1333577.0000, 1331525.8750, 1329891.5000, 1329416.0000,
         1327529.5000, 1325755.6250, 1323596.7500, 1322935.3750, 1322579.6250],
        [1376245.3750, 1368857.5000, 1367276.2500, 1367228.0000, 1366829.0000,
         1366267.3750, 1365428.5000, 1364156.8750, 1363026.7500, 1362899.3750],
        [1395674.8750, 1382789.2500, 1378929.3750, 1377708.2500, 1376569.6250,
         1375885.6250, 1375187.8750, 1373189.2500, 1372678.6250, 1371481.3750],
        [1389523.0000, 1388098.0000, 1381024.5000, 1376283.3750, 1375379.2500,
         1375076.3750, 1374899.3750, 1374844.2500, 1373663.5000, 1373499.7500],
        [1260262.0000, 1258546.8750, 1256293.6250, 1255795.3750, 1253064.1250,
         1252847.8750, 1250988.8750, 1249983.6250, 1247790.8750, 1246470.7500],
        [1168370.7500, 1168151.3750, 1165100.6250, 1145546.2500, 1145533.2500,
         1142014.2500, 1141269.6250, 1140751.6250, 1140477.5000, 1139732.7500],
        [1136592.6250, 1120087.0000, 1118849.6250, 1118627.7500, 1115206.3750,
         1111878.2500, 1111748.8750, 1111069.5000, 1108022.0000, 1105401.3750],
        [1349780.8750, 1347767.7500, 1347512.0000, 1341713.3750, 1341439.6250,
         1340759.1250, 1339193.7500, 1339075.0000, 1339075.0000, 1338614.0000],
        [1284679.7500, 1282771.1250, 1275015.3750, 1270594.6250, 1270076.0000,
         1269869.0000, 1269717.6250, 1269261.2500, 1269227.3750, 1266136.0000],
        [1354186.5000, 1349115.5000, 1342140.7500, 1341769.6250, 1337209.2500,
         1335128.3750, 1334177.5000, 1334024.8750, 1333840.2500, 1333388.8750],
        [1356654.1250, 1355402.3750, 1350848.3750, 1350547.0000, 1350258.5000,
         1348973.8750, 1347846.1250, 1347708.6250, 1346109.3750, 1345982.2500],
        [1307290.7500, 1306599.1250, 1304599.3750, 1303507.5000, 1302828.8750,
         1302763.0000, 1299099.5000, 1297762.1250, 1296551.0000, 1296455.7500],
        [1255826.5000, 1247482.7500, 1247286.5000, 1245220.8750, 1243554.6250,
         1240477.3750, 1238172.6250, 1234587.0000, 1232651.6250, 1232005.2500],
        [1324657.3750, 1307527.6250, 1304916.6250, 1304608.1250, 1298632.5000,
         1296975.2500, 1296478.0000, 1296463.1250, 1296215.8750, 1295336.0000],
        [1385044.7500, 1356764.1250, 1355525.1250, 1354323.5000, 1354062.5000,
         1353325.3750, 1353250.6250, 1352157.8750, 1351807.2500, 1351660.2500],
        [1391304.0000, 1383425.0000, 1381277.3750, 1381160.1250, 1380220.1250,
         1377957.8750, 1377868.5000, 1377176.2500, 1376632.6250, 1376429.1250],
        [1221324.7500, 1211031.2500, 1207201.8750, 1205358.8750, 1199207.5000,
         1198480.2500, 1198402.5000, 1198043.7500, 1197846.1250, 1196994.2500],
        [1224648.7500, 1205235.8750, 1203356.8750, 1197908.8750, 1196860.6250,
         1194596.0000, 1193869.2500, 1193489.1250, 1191993.2500, 1191499.0000],
        [1316776.6250, 1300956.6250, 1295984.7500, 1295511.5000, 1295056.8750,
         1294069.2500, 1293188.3750, 1288861.8750, 1288611.2500, 1287661.6250],
        [1322669.1250, 1322369.1250, 1321408.3750, 1320469.8750, 1319705.7500,
         1317818.0000, 1316300.7500, 1315733.5000, 1315603.0000, 1313013.3750],
        [1309419.5000, 1301941.0000, 1301259.3750, 1300145.5000, 1296797.1250,
         1292592.8750, 1292106.0000, 1290855.8750, 1290821.3750, 1288401.0000],
        [1231593.0000, 1209838.8750, 1209138.6250, 1208033.3750, 1206491.6250,
         1204985.3750, 1200395.1250, 1197753.6250, 1195435.8750, 1194220.0000],
        [1272042.2500, 1259383.6250, 1254436.7500, 1254408.0000, 1252415.5000,
         1247449.3750, 1247449.3750, 1246665.6250, 1246395.7500, 1246061.8750],
        [1325730.3750, 1324970.7500, 1324175.0000, 1321797.8750, 1321693.2500,
         1318737.0000, 1318244.0000, 1318126.0000, 1316366.0000, 1316087.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1382025.8750,       0.0000],
         [1375458.0000,       0.0000],
         [1375281.0000,       0.0000],
         ...,
         [1368511.6250,       0.0000],
         [1368083.6250,       0.0000],
         [1367602.2500,       0.0000]],

        [[1384397.7500,       0.0000],
         [1381759.7500,       0.0000],
         [1381389.3750,       0.0000],
         ...,
         [1373292.7500,       0.0000],
         [1373177.6250,       0.0000],
         [1372388.1250,       0.0000]],

        [[1319031.2500,       0.0000],
         [1310355.1250,       0.0000],
         [1306842.0000,       0.0000],
         ...,
         [1302611.5000,       0.0000],
         [1301867.7500,       0.0000],
         [1301351.2500,       0.0000]],

        ...,

        [[      0.0000, 1231593.0000],
         [      0.0000, 1209838.8750],
         [1209138.6250,       0.0000],
         ...,
         [      0.0000, 1197753.6250],
         [1195435.8750,       0.0000],
         [1194220.0000,       0.0000]],

        [[1272042.2500,       0.0000],
         [1259383.6250,       0.0000],
         [      0.0000, 1254436.7500],
         ...,
         [1246665.6250,       0.0000],
         [1246395.7500,       0.0000],
         [1246061.8750,       0.0000]],

        [[1325730.3750,       0.0000],
         [1324970.7500,       0.0000],
         [1324175.0000,       0.0000],
         ...,
         [1318126.0000,       0.0000],
         [1316366.0000,       0.0000],
         [1316087.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13725438.0000,        0.0000],
        [12398266.0000,  1374494.2500],
        [13060740.0000,        0.0000],
        [11394381.0000,  1263733.0000],
        [ 5564220.5000,  5479188.0000],
        [ 7262297.0000,  4844070.5000],
        [ 8289825.5000,  3553725.5000],
        [11279768.0000,  1248734.8750],
        [13810072.0000,        0.0000],
        [ 8560278.0000,  3655403.7500],
        [12486178.0000,  1393161.3750],
        [11416212.0000,  1261996.2500],
        [ 9591620.0000,  2394810.5000],
        [13926772.0000,        0.0000],
        [14008074.0000,        0.0000],
        [13765233.0000,        0.0000],
        [12292835.0000,  1382016.6250],
        [10491222.0000,  2618129.5000],
        [13468820.0000,        0.0000],
        [13864431.0000,        0.0000],
        [10974763.0000,  2743682.0000],
        [13221158.0000,        0.0000],
        [12002406.0000,  1328962.1250],
        [13957954.0000,        0.0000],
        [12915525.0000,        0.0000],
        [13392942.0000,        0.0000],
        [13044285.0000,        0.0000],
        [12133269.0000,  1349859.3750],
        [12409917.0000,  1379418.6250],
        [13822326.0000,        0.0000],
        [13666934.0000,        0.0000],
        [13815328.0000,        0.0000],
        [ 9016224.0000,  3860138.5000],
        [10580292.0000,  2651029.5000],
        [12465662.0000,  1381073.2500],
        [13203111.0000,        0.0000],
        [13407144.0000,        0.0000],
        [13155718.0000,        0.0000],
        [ 8430258.0000,  3605153.0000],
        [13767164.0000,        0.0000],
        [13281304.0000,        0.0000],
        [13668216.0000,        0.0000],
        [13780094.0000,        0.0000],
        [12407216.0000,  1375076.3750],
        [ 8762246.0000,  3769798.0000],
        [11496948.0000,        0.0000],
        [11157483.0000,        0.0000],
        [13424930.0000,        0.0000],
        [11458121.0000,  1269227.3750],
        [10725676.0000,  2669306.0000],
        [12152484.0000,  1347846.1250],
        [11720906.0000,  1296551.0000],
        [ 9924758.0000,  2492507.5000],
        [ 9125389.0000,  3896422.0000],
        [13567922.0000,        0.0000],
        [13803450.0000,        0.0000],
        [10834684.0000,  1199207.5000],
        [10798862.0000,  1194596.0000],
        [11668068.0000,  1288611.2500],
        [13185092.0000,        0.0000],
        [11675940.0000,  1288401.0000],
        [ 7212208.5000,  4845677.0000],
        [11272272.0000,  1254436.7500],
        [13205928.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 50.0
Top1 accuracy for validation set is 50.0 size is torch.Size([64, 1])
Epoch 11/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:05, 60.20s/it]  7%|▋         | 2/29 [01:01<11:24, 25.33s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 7.816591262817383
Epoch 12/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:22, 56.53s/it]  7%|▋         | 2/29 [01:01<11:44, 26.08s/it] 10%|█         | 3/29 [01:02<06:19, 14.59s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.20s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.21s/it] 21%|██        | 6/29 [01:04<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 7.835500240325928
Epoch 13/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.80s/it]  7%|▋         | 2/29 [01:00<11:19, 25.17s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 7.8288164138793945
Epoch 14/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:24, 58.75s/it]  7%|▋         | 2/29 [00:59<11:07, 24.73s/it] 10%|█         | 3/29 [01:00<06:00, 13.86s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.75s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.22s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 7.786145210266113
Epoch 15/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<28:58, 62.09s/it]  7%|▋         | 2/29 [01:03<11:44, 26.11s/it] 10%|█         | 3/29 [01:03<06:19, 14.61s/it] 14%|█▍        | 4/29 [01:04<03:50,  9.20s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.22s/it] 21%|██        | 6/29 [01:06<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.04s/it]
Epoch loss is 7.69618558883667
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0301, 0.0150, 0.0092,  ..., 0.0072, 0.0136, 0.0160],
        [0.0418, 0.0098, 0.0038,  ..., 0.0057, 0.0112, 0.0161],
        [0.0342, 0.0124, 0.0115,  ..., 0.0068, 0.0148, 0.0108],
        ...,
        [0.0408, 0.0197, 0.0118,  ..., 0.0088, 0.0180, 0.0165],
        [0.0387, 0.0118, 0.0116,  ..., 0.0077, 0.0116, 0.0204],
        [0.0432, 0.0114, 0.0092,  ..., 0.0067, 0.0170, 0.0190]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9894, 0.9892, 0.9892, 0.9890, 0.9889, 0.9889, 0.9889, 0.9889, 0.9889,
         0.9888],
        [0.9900, 0.9900, 0.9899, 0.9899, 0.9897, 0.9895, 0.9895, 0.9894, 0.9894,
         0.9894],
        [0.9862, 0.9860, 0.9859, 0.9858, 0.9856, 0.9855, 0.9853, 0.9853, 0.9852,
         0.9851],
        [0.9848, 0.9847, 0.9846, 0.9843, 0.9842, 0.9841, 0.9841, 0.9841, 0.9840,
         0.9840],
        [0.9789, 0.9780, 0.9767, 0.9767, 0.9761, 0.9756, 0.9754, 0.9754, 0.9753,
         0.9750],
        [0.9825, 0.9814, 0.9813, 0.9810, 0.9809, 0.9808, 0.9808, 0.9807, 0.9807,
         0.9807],
        [0.9843, 0.9838, 0.9833, 0.9833, 0.9827, 0.9827, 0.9822, 0.9817, 0.9816,
         0.9815],
        [0.9844, 0.9838, 0.9831, 0.9829, 0.9829, 0.9828, 0.9828, 0.9827, 0.9827,
         0.9823],
        [0.9900, 0.9898, 0.9898, 0.9895, 0.9894, 0.9894, 0.9894, 0.9894, 0.9894,
         0.9893],
        [0.9821, 0.9815, 0.9814, 0.9813, 0.9811, 0.9810, 0.9810, 0.9810, 0.9808,
         0.9808],
        [0.9910, 0.9906, 0.9904, 0.9904, 0.9903, 0.9903, 0.9902, 0.9901, 0.9901,
         0.9901],
        [0.9850, 0.9848, 0.9845, 0.9844, 0.9843, 0.9841, 0.9840, 0.9840, 0.9838,
         0.9838],
        [0.9831, 0.9826, 0.9822, 0.9822, 0.9821, 0.9821, 0.9820, 0.9820, 0.9818,
         0.9818],
        [0.9913, 0.9911, 0.9911, 0.9911, 0.9910, 0.9909, 0.9909, 0.9908, 0.9908,
         0.9907],
        [0.9906, 0.9906, 0.9902, 0.9901, 0.9900, 0.9900, 0.9900, 0.9900, 0.9900,
         0.9900],
        [0.9907, 0.9901, 0.9901, 0.9901, 0.9900, 0.9899, 0.9898, 0.9898, 0.9897,
         0.9897],
        [0.9891, 0.9891, 0.9889, 0.9889, 0.9889, 0.9888, 0.9886, 0.9886, 0.9886,
         0.9886],
        [0.9875, 0.9875, 0.9874, 0.9872, 0.9871, 0.9871, 0.9871, 0.9871, 0.9871,
         0.9870],
        [0.9888, 0.9883, 0.9881, 0.9881, 0.9881, 0.9880, 0.9880, 0.9879, 0.9879,
         0.9878],
        [0.9905, 0.9899, 0.9899, 0.9899, 0.9898, 0.9898, 0.9897, 0.9897, 0.9896,
         0.9896],
        [0.9901, 0.9899, 0.9898, 0.9898, 0.9898, 0.9897, 0.9897, 0.9896, 0.9895,
         0.9894],
        [0.9880, 0.9873, 0.9872, 0.9872, 0.9870, 0.9869, 0.9867, 0.9867, 0.9865,
         0.9865],
        [0.9893, 0.9886, 0.9883, 0.9883, 0.9883, 0.9882, 0.9881, 0.9881, 0.9880,
         0.9880],
        [0.9908, 0.9904, 0.9904, 0.9904, 0.9904, 0.9903, 0.9903, 0.9903, 0.9902,
         0.9902],
        [0.9863, 0.9860, 0.9860, 0.9859, 0.9859, 0.9856, 0.9854, 0.9854, 0.9854,
         0.9853],
        [0.9877, 0.9877, 0.9875, 0.9875, 0.9874, 0.9873, 0.9873, 0.9871, 0.9871,
         0.9871],
        [0.9866, 0.9864, 0.9862, 0.9857, 0.9857, 0.9856, 0.9856, 0.9855, 0.9854,
         0.9854],
        [0.9889, 0.9889, 0.9887, 0.9886, 0.9884, 0.9884, 0.9882, 0.9882, 0.9882,
         0.9881],
        [0.9903, 0.9901, 0.9900, 0.9899, 0.9899, 0.9898, 0.9898, 0.9898, 0.9897,
         0.9896],
        [0.9915, 0.9908, 0.9907, 0.9907, 0.9906, 0.9906, 0.9905, 0.9904, 0.9904,
         0.9904],
        [0.9910, 0.9905, 0.9900, 0.9900, 0.9899, 0.9899, 0.9897, 0.9897, 0.9896,
         0.9896],
        [0.9907, 0.9907, 0.9903, 0.9901, 0.9901, 0.9900, 0.9900, 0.9900, 0.9900,
         0.9900],
        [0.9850, 0.9847, 0.9846, 0.9845, 0.9843, 0.9841, 0.9839, 0.9838, 0.9838,
         0.9838],
        [0.9877, 0.9877, 0.9876, 0.9875, 0.9872, 0.9872, 0.9872, 0.9871, 0.9871,
         0.9871],
        [0.9899, 0.9898, 0.9898, 0.9898, 0.9897, 0.9896, 0.9896, 0.9896, 0.9895,
         0.9894],
        [0.9877, 0.9877, 0.9875, 0.9875, 0.9874, 0.9874, 0.9873, 0.9873, 0.9873,
         0.9873],
        [0.9884, 0.9884, 0.9882, 0.9880, 0.9880, 0.9879, 0.9878, 0.9878, 0.9877,
         0.9877],
        [0.9868, 0.9862, 0.9862, 0.9861, 0.9861, 0.9859, 0.9859, 0.9859, 0.9859,
         0.9858],
        [0.9820, 0.9814, 0.9808, 0.9808, 0.9808, 0.9807, 0.9806, 0.9805, 0.9802,
         0.9801],
        [0.9906, 0.9902, 0.9901, 0.9899, 0.9899, 0.9898, 0.9898, 0.9898, 0.9897,
         0.9897],
        [0.9878, 0.9869, 0.9867, 0.9866, 0.9866, 0.9865, 0.9865, 0.9864, 0.9864,
         0.9864],
        [0.9899, 0.9894, 0.9894, 0.9892, 0.9891, 0.9891, 0.9891, 0.9890, 0.9890,
         0.9890],
        [0.9903, 0.9903, 0.9901, 0.9901, 0.9900, 0.9899, 0.9898, 0.9898, 0.9898,
         0.9897],
        [0.9908, 0.9907, 0.9907, 0.9905, 0.9905, 0.9905, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9836, 0.9831, 0.9827, 0.9826, 0.9825, 0.9824, 0.9822, 0.9822, 0.9821,
         0.9821],
        [0.9771, 0.9766, 0.9765, 0.9765, 0.9761, 0.9761, 0.9760, 0.9759, 0.9759,
         0.9756],
        [0.9749, 0.9723, 0.9723, 0.9719, 0.9715, 0.9709, 0.9705, 0.9705, 0.9701,
         0.9700],
        [0.9875, 0.9872, 0.9870, 0.9867, 0.9866, 0.9866, 0.9864, 0.9863, 0.9861,
         0.9861],
        [0.9847, 0.9845, 0.9845, 0.9844, 0.9843, 0.9839, 0.9838, 0.9837, 0.9835,
         0.9834],
        [0.9877, 0.9875, 0.9874, 0.9874, 0.9872, 0.9872, 0.9871, 0.9871, 0.9871,
         0.9871],
        [0.9885, 0.9885, 0.9883, 0.9880, 0.9879, 0.9879, 0.9878, 0.9878, 0.9878,
         0.9878],
        [0.9863, 0.9862, 0.9860, 0.9860, 0.9858, 0.9857, 0.9856, 0.9856, 0.9854,
         0.9854],
        [0.9825, 0.9819, 0.9817, 0.9815, 0.9813, 0.9812, 0.9811, 0.9810, 0.9808,
         0.9808],
        [0.9854, 0.9849, 0.9849, 0.9848, 0.9847, 0.9847, 0.9845, 0.9844, 0.9844,
         0.9844],
        [0.9897, 0.9892, 0.9891, 0.9891, 0.9891, 0.9891, 0.9891, 0.9890, 0.9890,
         0.9890],
        [0.9906, 0.9905, 0.9904, 0.9904, 0.9902, 0.9902, 0.9902, 0.9901, 0.9901,
         0.9900],
        [0.9798, 0.9797, 0.9797, 0.9795, 0.9794, 0.9792, 0.9791, 0.9790, 0.9790,
         0.9788],
        [0.9793, 0.9793, 0.9787, 0.9785, 0.9785, 0.9784, 0.9783, 0.9782, 0.9777,
         0.9775],
        [0.9860, 0.9858, 0.9858, 0.9857, 0.9854, 0.9854, 0.9852, 0.9852, 0.9851,
         0.9850],
        [0.9856, 0.9856, 0.9855, 0.9854, 0.9853, 0.9849, 0.9848, 0.9847, 0.9847,
         0.9847],
        [0.9850, 0.9849, 0.9848, 0.9844, 0.9843, 0.9843, 0.9842, 0.9842, 0.9841,
         0.9840],
        [0.9790, 0.9789, 0.9785, 0.9783, 0.9781, 0.9781, 0.9781, 0.9778, 0.9769,
         0.9768],
        [0.9840, 0.9838, 0.9834, 0.9831, 0.9828, 0.9828, 0.9828, 0.9828, 0.9827,
         0.9827],
        [0.9875, 0.9871, 0.9870, 0.9870, 0.9870, 0.9869, 0.9868, 0.9867, 0.9867,
         0.9867]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 0, 0, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 1, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1375304.6250, 1372097.6250, 1371682.7500, 1368322.3750, 1365943.0000,
         1365793.2500, 1365569.1250, 1365287.8750, 1364952.0000, 1363468.7500],
        [1387030.1250, 1386523.6250, 1385792.6250, 1385047.3750, 1380815.1250,
         1378241.7500, 1377537.5000, 1376297.8750, 1376297.8750, 1375791.2500],
        [1314223.5000, 1310286.3750, 1308458.2500, 1305622.5000, 1303483.8750,
         1301683.8750, 1296975.2500, 1296468.2500, 1294879.1250, 1294358.1250],
        [1287112.7500, 1285603.8750, 1284326.8750, 1278920.8750, 1277595.7500,
         1275093.2500, 1274940.0000, 1274546.1250, 1273830.3750, 1272872.2500],
        [1184153.8750, 1168190.3750, 1147049.3750, 1146875.5000, 1137345.1250,
         1129136.8750, 1126671.3750, 1125838.0000, 1125075.8750, 1119203.8750],
        [1246936.7500, 1226694.3750, 1224670.8750, 1219762.6250, 1218494.1250,
         1216534.2500, 1215998.2500, 1215534.6250, 1214062.1250, 1213827.1250],
        [1278706.2500, 1268946.5000, 1260970.1250, 1260634.6250, 1249531.8750,
         1249094.6250, 1241602.8750, 1231832.5000, 1230864.8750, 1229404.3750],
        [1280361.0000, 1269950.1250, 1257120.6250, 1254347.0000, 1254332.6250,
         1251835.0000, 1251702.5000, 1249452.0000, 1249182.7500, 1242571.8750],
        [1387571.2500, 1383776.0000, 1382770.7500, 1378094.5000, 1376170.5000,
         1375921.1250, 1375669.2500, 1375652.2500, 1375361.0000, 1373765.6250],
        [1239215.7500, 1228644.8750, 1227436.2500, 1225299.5000, 1222373.5000,
         1220723.8750, 1220506.2500, 1219732.3750, 1216595.6250, 1215694.6250],
        [1406935.1250, 1398378.1250, 1395056.0000, 1394843.1250, 1393126.8750,
         1392594.2500, 1391150.0000, 1389772.2500, 1389479.3750, 1389148.1250],
        [1291190.7500, 1287745.1250, 1282685.5000, 1280656.5000, 1279306.3750,
         1274927.7500, 1273962.7500, 1273229.2500, 1269193.3750, 1268893.2500],
        [1256954.0000, 1248964.7500, 1240488.0000, 1240153.2500, 1240010.1250,
         1239305.5000, 1237814.8750, 1237646.1250, 1234253.7500, 1234019.6250],
        [1413371.5000, 1409997.7500, 1409879.3750, 1408911.6250, 1406546.1250,
         1405201.3750, 1404940.0000, 1403762.7500, 1403737.3750, 1401974.0000],
        [1399849.7500, 1398590.1250, 1390340.8750, 1389690.1250, 1387972.2500,
         1387397.8750, 1387344.8750, 1387318.5000, 1386601.6250, 1386342.5000],
        [1400675.1250, 1389785.5000, 1389772.2500, 1389537.6250, 1387768.5000,
         1384993.2500, 1384076.8750, 1382722.0000, 1381314.3750, 1380659.7500],
        [1369980.6250, 1369321.1250, 1366068.0000, 1365996.3750, 1365432.5000,
         1363892.7500, 1360018.2500, 1359594.2500, 1359323.2500, 1359060.1250],
        [1338989.3750, 1338569.3750, 1337281.8750, 1333773.0000, 1331509.3750,
         1331311.3750, 1330942.0000, 1330627.2500, 1330481.3750, 1329838.2500],
        [1363081.3750, 1354118.0000, 1350478.6250, 1349688.1250, 1349604.3750,
         1348509.6250, 1348501.8750, 1346886.3750, 1346779.7500, 1344972.5000],
        [1397816.7500, 1385784.6250, 1385393.5000, 1385114.7500, 1383989.7500,
         1383869.6250, 1381879.6250, 1381066.7500, 1379906.8750, 1379533.1250],
        [1388380.0000, 1384595.7500, 1383745.6250, 1383694.1250, 1383227.0000,
         1381875.6250, 1381150.8750, 1378742.6250, 1377955.2500, 1376192.7500],
        [1348368.1250, 1334238.6250, 1333058.2500, 1332244.8750, 1328308.2500,
         1327364.8750, 1322839.6250, 1322521.6250, 1320239.5000, 1318811.2500],
        [1374098.3750, 1359733.0000, 1354899.6250, 1354566.2500, 1353182.1250,
         1351696.3750, 1350316.3750, 1350273.8750, 1348501.8750, 1347661.0000],
        [1403633.0000, 1395803.8750, 1395235.6250, 1395235.6250, 1394856.5000,
         1393702.3750, 1393589.3750, 1393582.6250, 1391853.3750, 1390522.6250],
        [1315158.8750, 1309847.8750, 1309322.1250, 1309272.1250, 1307688.6250,
         1302701.0000, 1299877.7500, 1299375.7500, 1299155.1250, 1298072.7500],
        [1342884.6250, 1342192.0000, 1339120.8750, 1339089.0000, 1336255.6250,
         1335388.1250, 1334875.0000, 1331669.3750, 1331044.7500, 1330308.7500],
        [1322004.6250, 1317343.0000, 1313424.1250, 1304613.1250, 1304059.5000,
         1302820.2500, 1302666.1250, 1301783.2500, 1299126.7500, 1299047.3750],
        [1365720.2500, 1365073.0000, 1362444.6250, 1360075.3750, 1356652.8750,
         1355529.0000, 1352690.6250, 1352061.1250, 1351613.7500, 1350541.8750],
        [1392519.8750, 1388968.0000, 1386420.5000, 1385150.3750, 1384685.5000,
         1383583.3750, 1383034.5000, 1383026.6250, 1381201.0000, 1380355.6250],
        [1416803.3750, 1402327.1250, 1400904.8750, 1400819.3750, 1398811.6250,
         1398242.0000, 1396353.7500, 1395298.2500, 1395109.2500, 1394679.6250],
        [1407106.8750, 1396384.3750, 1388264.8750, 1387057.8750, 1385747.6250,
         1384896.7500, 1381940.2500, 1380770.3750, 1379742.3750, 1379576.5000],
        [1402059.6250, 1401490.1250, 1393392.6250, 1388958.7500, 1388474.0000,
         1387974.8750, 1387530.1250, 1387334.3750, 1387142.6250, 1386509.0000],
        [1291410.0000, 1285503.2500, 1284585.5000, 1281822.1250, 1277911.5000,
         1275836.3750, 1272409.8750, 1270567.8750, 1270538.8750, 1270088.2500],
        [1343048.6250, 1342081.8750, 1340388.3750, 1339339.3750, 1332590.5000,
         1332153.3750, 1331936.1250, 1331319.0000, 1330489.0000, 1330335.3750],
        [1385306.2500, 1384078.2500, 1383084.6250, 1382474.0000, 1382203.7500,
         1379843.6250, 1379137.1250, 1378768.8750, 1377223.5000, 1375826.6250],
        [1343304.8750, 1342865.5000, 1339488.7500, 1338813.2500, 1336676.2500,
         1336333.3750, 1335076.1250, 1334092.2500, 1333934.5000, 1333843.0000],
        [1356519.6250, 1355005.6250, 1351107.2500, 1348926.3750, 1347301.2500,
         1345864.2500, 1345134.1250, 1344123.7500, 1342878.2500, 1342245.8750],
        [1325420.7500, 1313999.2500, 1313296.3750, 1312574.0000, 1311621.6250,
         1308812.7500, 1308702.8750, 1307696.0000, 1307585.0000, 1306990.3750],
        [1237089.0000, 1226659.1250, 1217087.7500, 1216986.7500, 1216385.7500,
         1215403.6250, 1212497.7500, 1210381.1250, 1206286.8750, 1204211.0000],
        [1399029.0000, 1391723.2500, 1389511.1250, 1386082.0000, 1385530.8750,
         1384071.6250, 1383918.5000, 1383171.7500, 1382165.5000, 1381761.0000],
        [1344987.8750, 1328017.0000, 1323820.1250, 1321891.1250, 1321550.8750,
         1319665.3750, 1319348.3750, 1317888.3750, 1317813.0000, 1317718.7500],
        [1384338.2500, 1375963.1250, 1375328.1250, 1370896.8750, 1369156.5000,
         1369153.8750, 1368720.3750, 1368524.6250, 1368091.3750, 1367925.7500],
        [1392878.5000, 1392878.5000, 1388520.2500, 1388378.6250, 1387261.6250,
         1385250.8750, 1383537.1250, 1383461.8750, 1382485.8750, 1381979.7500],
        [1402280.2500, 1400709.8750, 1400225.0000, 1397866.1250, 1397856.7500,
         1396628.1250, 1395343.3750, 1394295.1250, 1393394.0000, 1392895.7500],
        [1266702.3750, 1256459.0000, 1249155.3750, 1247655.2500, 1245963.2500,
         1244299.6250, 1241640.7500, 1240425.3750, 1239609.2500, 1239024.2500],
        [1154235.8750, 1146396.5000, 1144638.7500, 1144134.6250, 1137269.1250,
         1136994.7500, 1136225.1250, 1133707.5000, 1133590.7500, 1129149.7500],
        [1117850.3750, 1077260.3750, 1076749.8750, 1071413.2500, 1064359.6250,
         1055561.2500, 1050516.8750, 1049991.0000, 1043823.8750, 1042297.8750],
        [1338857.8750, 1332494.0000, 1329429.8750, 1322506.5000, 1322254.2500,
         1320982.5000, 1317231.2500, 1315412.2500, 1312089.5000, 1312074.5000],
        [1286983.8750, 1282416.3750, 1281802.6250, 1280199.8750, 1279668.7500,
         1271488.0000, 1270348.6250, 1267028.6250, 1263688.3750, 1263325.6250],
        [1343315.0000, 1339057.1250, 1336982.2500, 1336004.6250, 1333802.1250,
         1332519.3750, 1331515.8750, 1331079.1250, 1330997.8750, 1330707.1250],
        [1357598.8750, 1357188.6250, 1353636.5000, 1347790.8750, 1346149.2500,
         1345938.6250, 1344807.0000, 1344364.6250, 1344113.3750, 1343882.7500],
        [1315689.5000, 1314380.1250, 1311087.6250, 1309901.5000, 1307393.1250,
         1303924.0000, 1302199.1250, 1302175.6250, 1299556.7500, 1298851.7500],
        [1246976.1250, 1235299.5000, 1232745.6250, 1229325.8750, 1224841.3750,
         1223996.0000, 1221678.8750, 1220323.5000, 1217278.1250, 1216936.8750],
        [1298456.6250, 1289354.8750, 1289057.3750, 1288206.8750, 1286934.7500,
         1285760.7500, 1283066.0000, 1281442.0000, 1280612.5000, 1280259.6250],
        [1381913.8750, 1371622.6250, 1370507.2500, 1370460.2500, 1370089.1250,
         1369144.7500, 1369058.6250, 1368391.6250, 1367666.2500, 1367554.0000],
        [1398643.3750, 1396674.7500, 1395448.6250, 1394855.1250, 1391508.2500,
         1391460.5000, 1390343.6250, 1390057.2500, 1388580.0000, 1386843.6250],
        [1199101.0000, 1197681.6250, 1196904.0000, 1193975.1250, 1191754.5000,
         1189015.2500, 1188051.7500, 1186160.0000, 1185878.3750, 1181739.6250],
        [1190376.7500, 1190221.2500, 1180336.2500, 1176884.3750, 1176735.1250,
         1175093.2500, 1174174.7500, 1172538.7500, 1162903.7500, 1160075.7500],
        [1310643.8750, 1307201.0000, 1305838.0000, 1304360.5000, 1299412.8750,
         1298168.1250, 1295847.6250, 1294932.1250, 1293579.3750, 1292377.1250],
        [1303471.5000, 1301895.0000, 1300543.6250, 1298159.5000, 1297414.3750,
         1289587.3750, 1287989.5000, 1287015.7500, 1285575.6250, 1285531.5000],
        [1291461.6250, 1290578.8750, 1287327.6250, 1280439.1250, 1279678.5000,
         1278783.1250, 1277865.1250, 1276766.3750, 1275981.1250, 1273877.7500],
        [1185543.6250, 1183539.6250, 1177789.3750, 1174390.8750, 1170909.5000,
         1170525.5000, 1169566.8750, 1165982.0000, 1150244.7500, 1149261.2500],
        [1273711.3750, 1269892.0000, 1263238.8750, 1257341.2500, 1251864.8750,
         1251541.3750, 1250805.2500, 1250805.2500, 1250713.3750, 1250330.5000],
        [1339472.1250, 1330349.3750, 1330020.8750, 1329669.5000, 1328412.2500,
         1327121.8750, 1325421.8750, 1324015.7500, 1323715.2500, 1323603.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1375304.6250,       0.0000],
         [1372097.6250,       0.0000],
         [1371682.7500,       0.0000],
         ...,
         [1365287.8750,       0.0000],
         [1364952.0000,       0.0000],
         [      0.0000, 1363468.7500]],

        [[1387030.1250,       0.0000],
         [1386523.6250,       0.0000],
         [1385792.6250,       0.0000],
         ...,
         [1376297.8750,       0.0000],
         [1376297.8750,       0.0000],
         [1375791.2500,       0.0000]],

        [[1314223.5000,       0.0000],
         [1310286.3750,       0.0000],
         [1308458.2500,       0.0000],
         ...,
         [      0.0000, 1296468.2500],
         [1294879.1250,       0.0000],
         [1294358.1250,       0.0000]],

        ...,

        [[1185543.6250,       0.0000],
         [1183539.6250,       0.0000],
         [1177789.3750,       0.0000],
         ...,
         [      0.0000, 1165982.0000],
         [1150244.7500,       0.0000],
         [      0.0000, 1149261.2500]],

        [[1273711.3750,       0.0000],
         [1269892.0000,       0.0000],
         [1263238.8750,       0.0000],
         ...,
         [1250805.2500,       0.0000],
         [1250713.3750,       0.0000],
         [1250330.5000,       0.0000]],

        [[1339472.1250,       0.0000],
         [1330349.3750,       0.0000],
         [1330020.8750,       0.0000],
         ...,
         [1324015.7500,       0.0000],
         [1323715.2500,       0.0000],
         [1323603.0000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12314952.0000,  1363468.7500],
        [13809375.0000,        0.0000],
        [ 9131312.0000,  3895127.2500],
        [10227643.0000,  2557199.0000],
        [ 4535134.5000,  6874406.0000],
        [ 9747084.0000,  2465431.0000],
        [11270723.0000,  1230864.8750],
        [11309153.0000,  1251702.5000],
        [13784752.0000,        0.0000],
        [ 6123990.5000,  6112232.5000],
        [11153046.0000,  2787437.5000],
        [11501134.0000,  1280656.5000],
        [ 9941336.0000,  2468273.5000],
        [14068322.0000,        0.0000],
        [12514846.0000,  1386601.6250],
        [13871306.0000,        0.0000],
        [10913236.0000,  2725450.7500],
        [12002381.0000,  1330942.0000],
        [10799993.0000,  2702627.5000],
        [12458570.0000,  1385784.6250],
        [11059666.0000,  2759893.5000],
        [11960630.0000,  1327364.8750],
        [12190029.0000,  1354899.6250],
        [13948015.0000,        0.0000],
        [10431878.0000,  2618594.2500],
        [12032520.0000,  1330308.7500],
        [11767762.0000,  1299126.7500],
        [13572402.0000,        0.0000],
        [13848945.0000,        0.0000],
        [13999348.0000,        0.0000],
        [12464380.0000,  1407106.8750],
        [13910866.0000,        0.0000],
        [11510134.0000,  1270538.8750],
        [13353682.0000,        0.0000],
        [11044025.0000,  2763922.0000],
        [13374428.0000,        0.0000],
        [13479106.0000,        0.0000],
        [11803403.0000,  1313296.3750],
        [ 8483837.0000,  3679151.7500],
        [12467936.0000,  1399029.0000],
        [ 9273256.0000,  3959445.0000],
        [13718100.0000,        0.0000],
        [13866632.0000,        0.0000],
        [13971495.0000,        0.0000],
        [ 8710778.0000,  3760157.5000],
        [10249946.0000,  1146396.5000],
        [10649824.0000,        0.0000],
        [13223333.0000,        0.0000],
        [12746950.0000,        0.0000],
        [12015274.0000,  1330707.1250],
        [13485470.0000,        0.0000],
        [13065159.0000,        0.0000],
        [ 9823140.0000,  2446262.7500],
        [12863151.0000,        0.0000],
        [13706409.0000,        0.0000],
        [12529560.0000,  1394855.1250],
        [ 8339427.0000,  3570834.0000],
        [ 8237533.5000,  3521806.7500],
        [11704192.0000,  1298168.1250],
        [11635289.0000,  1301895.0000],
        [ 8968550.0000,  3844209.0000],
        [ 5866684.0000,  5831069.0000],
        [12570244.0000,        0.0000],
        [13281802.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 48.4375
Top1 accuracy for validation set is 48.4375 size is torch.Size([64, 1])
Epoch 16/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:04, 60.18s/it]  7%|▋         | 2/29 [01:01<11:23, 25.32s/it] 10%|█         | 3/29 [01:02<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 7.646467208862305
Epoch 17/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:39, 57.14s/it]  7%|▋         | 2/29 [00:59<11:19, 25.17s/it] 10%|█         | 3/29 [01:00<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 7.529799938201904
Epoch 18/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:13, 60.47s/it]  7%|▋         | 2/29 [01:01<11:26, 25.44s/it] 10%|█         | 3/29 [01:02<06:10, 14.25s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 7.41454553604126
Epoch 19/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:15, 56.28s/it]  7%|▋         | 2/29 [01:00<11:35, 25.75s/it] 10%|█         | 3/29 [01:01<06:14, 14.41s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.14s/it] 21%|██        | 6/29 [01:04<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 7.290076732635498
Epoch 20/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:31, 56.82s/it]  7%|▋         | 2/29 [01:00<11:34, 25.71s/it] 10%|█         | 3/29 [01:01<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.13s/it] 21%|██        | 6/29 [01:04<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 7.148160934448242
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0347, 0.0076, 0.0064,  ..., 0.0052, 0.0164, 0.0174],
        [0.0348, 0.0121, 0.0049,  ..., 0.0052, 0.0103, 0.0164],
        [0.0395, 0.0141, 0.0095,  ..., 0.0085, 0.0116, 0.0199],
        ...,
        [0.0310, 0.0191, 0.0096,  ..., 0.0080, 0.0109, 0.0185],
        [0.0387, 0.0104, 0.0065,  ..., 0.0031, 0.0174, 0.0171],
        [0.0397, 0.0128, 0.0084,  ..., 0.0061, 0.0117, 0.0187]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9903, 0.9900, 0.9900, 0.9899, 0.9896, 0.9895, 0.9895, 0.9895, 0.9895,
         0.9895],
        [0.9906, 0.9906, 0.9902, 0.9901, 0.9900, 0.9900, 0.9900, 0.9899, 0.9899,
         0.9898],
        [0.9865, 0.9864, 0.9863, 0.9862, 0.9860, 0.9860, 0.9860, 0.9859, 0.9858,
         0.9858],
        [0.9861, 0.9861, 0.9860, 0.9858, 0.9854, 0.9854, 0.9853, 0.9853, 0.9853,
         0.9852],
        [0.9797, 0.9794, 0.9787, 0.9779, 0.9778, 0.9774, 0.9773, 0.9773, 0.9772,
         0.9772],
        [0.9824, 0.9823, 0.9823, 0.9821, 0.9820, 0.9816, 0.9816, 0.9815, 0.9813,
         0.9812],
        [0.9843, 0.9834, 0.9829, 0.9829, 0.9828, 0.9825, 0.9825, 0.9823, 0.9822,
         0.9821],
        [0.9818, 0.9817, 0.9807, 0.9806, 0.9805, 0.9802, 0.9800, 0.9796, 0.9794,
         0.9792],
        [0.9903, 0.9900, 0.9900, 0.9899, 0.9899, 0.9899, 0.9899, 0.9898, 0.9898,
         0.9897],
        [0.9847, 0.9845, 0.9840, 0.9839, 0.9836, 0.9836, 0.9835, 0.9835, 0.9834,
         0.9834],
        [0.9913, 0.9907, 0.9905, 0.9904, 0.9904, 0.9904, 0.9904, 0.9903, 0.9903,
         0.9903],
        [0.9866, 0.9861, 0.9858, 0.9857, 0.9857, 0.9856, 0.9856, 0.9854, 0.9854,
         0.9853],
        [0.9849, 0.9846, 0.9846, 0.9842, 0.9841, 0.9840, 0.9839, 0.9839, 0.9838,
         0.9836],
        [0.9911, 0.9910, 0.9910, 0.9909, 0.9908, 0.9907, 0.9907, 0.9907, 0.9907,
         0.9906],
        [0.9910, 0.9909, 0.9908, 0.9907, 0.9906, 0.9905, 0.9905, 0.9905, 0.9904,
         0.9904],
        [0.9912, 0.9912, 0.9909, 0.9908, 0.9905, 0.9904, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9895, 0.9892, 0.9892, 0.9891, 0.9890, 0.9889, 0.9886, 0.9886, 0.9886,
         0.9886],
        [0.9882, 0.9880, 0.9880, 0.9880, 0.9879, 0.9879, 0.9878, 0.9878, 0.9877,
         0.9877],
        [0.9890, 0.9888, 0.9886, 0.9885, 0.9884, 0.9882, 0.9882, 0.9882, 0.9881,
         0.9880],
        [0.9910, 0.9907, 0.9906, 0.9906, 0.9905, 0.9905, 0.9905, 0.9904, 0.9904,
         0.9903],
        [0.9904, 0.9901, 0.9899, 0.9898, 0.9897, 0.9896, 0.9896, 0.9895, 0.9895,
         0.9894],
        [0.9878, 0.9877, 0.9874, 0.9871, 0.9871, 0.9870, 0.9869, 0.9867, 0.9866,
         0.9866],
        [0.9888, 0.9887, 0.9886, 0.9885, 0.9884, 0.9883, 0.9882, 0.9881, 0.9880,
         0.9879],
        [0.9913, 0.9909, 0.9909, 0.9907, 0.9907, 0.9907, 0.9907, 0.9905, 0.9905,
         0.9905],
        [0.9880, 0.9876, 0.9875, 0.9873, 0.9872, 0.9872, 0.9871, 0.9871, 0.9870,
         0.9869],
        [0.9902, 0.9899, 0.9899, 0.9895, 0.9893, 0.9893, 0.9893, 0.9893, 0.9893,
         0.9893],
        [0.9874, 0.9874, 0.9871, 0.9870, 0.9867, 0.9867, 0.9866, 0.9865, 0.9865,
         0.9864],
        [0.9904, 0.9903, 0.9902, 0.9902, 0.9900, 0.9900, 0.9898, 0.9898, 0.9898,
         0.9898],
        [0.9914, 0.9913, 0.9912, 0.9912, 0.9912, 0.9911, 0.9911, 0.9911, 0.9910,
         0.9910],
        [0.9921, 0.9919, 0.9914, 0.9913, 0.9912, 0.9912, 0.9912, 0.9911, 0.9911,
         0.9910],
        [0.9907, 0.9907, 0.9906, 0.9905, 0.9905, 0.9905, 0.9905, 0.9905, 0.9904,
         0.9904],
        [0.9923, 0.9914, 0.9914, 0.9914, 0.9914, 0.9914, 0.9911, 0.9910, 0.9910,
         0.9910],
        [0.9847, 0.9844, 0.9841, 0.9838, 0.9835, 0.9834, 0.9832, 0.9832, 0.9832,
         0.9832],
        [0.9886, 0.9884, 0.9884, 0.9884, 0.9884, 0.9882, 0.9881, 0.9881, 0.9881,
         0.9880],
        [0.9905, 0.9904, 0.9902, 0.9902, 0.9902, 0.9901, 0.9901, 0.9900, 0.9899,
         0.9898],
        [0.9889, 0.9889, 0.9888, 0.9886, 0.9886, 0.9885, 0.9884, 0.9884, 0.9883,
         0.9883],
        [0.9879, 0.9878, 0.9875, 0.9874, 0.9873, 0.9870, 0.9869, 0.9869, 0.9868,
         0.9868],
        [0.9880, 0.9879, 0.9878, 0.9877, 0.9877, 0.9876, 0.9873, 0.9872, 0.9869,
         0.9869],
        [0.9856, 0.9852, 0.9848, 0.9846, 0.9846, 0.9845, 0.9844, 0.9844, 0.9843,
         0.9843],
        [0.9903, 0.9902, 0.9900, 0.9900, 0.9899, 0.9899, 0.9899, 0.9899, 0.9898,
         0.9898],
        [0.9878, 0.9869, 0.9869, 0.9868, 0.9867, 0.9867, 0.9866, 0.9866, 0.9864,
         0.9863],
        [0.9911, 0.9911, 0.9907, 0.9906, 0.9906, 0.9905, 0.9905, 0.9905, 0.9904,
         0.9904],
        [0.9914, 0.9912, 0.9910, 0.9910, 0.9910, 0.9909, 0.9909, 0.9909, 0.9908,
         0.9908],
        [0.9917, 0.9914, 0.9913, 0.9912, 0.9912, 0.9910, 0.9910, 0.9910, 0.9909,
         0.9909],
        [0.9861, 0.9848, 0.9844, 0.9844, 0.9843, 0.9841, 0.9840, 0.9840, 0.9840,
         0.9840],
        [0.9783, 0.9781, 0.9780, 0.9777, 0.9774, 0.9771, 0.9771, 0.9770, 0.9769,
         0.9769],
        [0.9752, 0.9737, 0.9736, 0.9709, 0.9699, 0.9696, 0.9691, 0.9677, 0.9676,
         0.9674],
        [0.9864, 0.9864, 0.9861, 0.9858, 0.9857, 0.9856, 0.9856, 0.9856, 0.9855,
         0.9852],
        [0.9860, 0.9860, 0.9858, 0.9857, 0.9855, 0.9855, 0.9854, 0.9851, 0.9849,
         0.9849],
        [0.9882, 0.9878, 0.9878, 0.9877, 0.9876, 0.9876, 0.9875, 0.9875, 0.9874,
         0.9873],
        [0.9885, 0.9882, 0.9878, 0.9877, 0.9877, 0.9877, 0.9877, 0.9876, 0.9874,
         0.9872],
        [0.9882, 0.9879, 0.9879, 0.9877, 0.9875, 0.9874, 0.9873, 0.9872, 0.9871,
         0.9871],
        [0.9838, 0.9833, 0.9832, 0.9831, 0.9831, 0.9830, 0.9828, 0.9825, 0.9825,
         0.9825],
        [0.9867, 0.9853, 0.9852, 0.9850, 0.9846, 0.9845, 0.9844, 0.9843, 0.9843,
         0.9842],
        [0.9906, 0.9905, 0.9903, 0.9903, 0.9902, 0.9902, 0.9902, 0.9902, 0.9902,
         0.9901],
        [0.9910, 0.9908, 0.9906, 0.9905, 0.9905, 0.9905, 0.9904, 0.9903, 0.9903,
         0.9903],
        [0.9820, 0.9806, 0.9805, 0.9805, 0.9803, 0.9802, 0.9798, 0.9795, 0.9793,
         0.9790],
        [0.9811, 0.9811, 0.9810, 0.9802, 0.9800, 0.9800, 0.9800, 0.9799, 0.9796,
         0.9796],
        [0.9854, 0.9853, 0.9853, 0.9851, 0.9851, 0.9850, 0.9846, 0.9845, 0.9844,
         0.9844],
        [0.9872, 0.9871, 0.9868, 0.9868, 0.9868, 0.9866, 0.9866, 0.9864, 0.9862,
         0.9862],
        [0.9842, 0.9840, 0.9839, 0.9837, 0.9836, 0.9833, 0.9831, 0.9831, 0.9831,
         0.9830],
        [0.9779, 0.9777, 0.9776, 0.9757, 0.9739, 0.9736, 0.9733, 0.9728, 0.9727,
         0.9726],
        [0.9858, 0.9857, 0.9857, 0.9857, 0.9856, 0.9856, 0.9855, 0.9855, 0.9854,
         0.9854],
        [0.9888, 0.9885, 0.9883, 0.9881, 0.9881, 0.9880, 0.9879, 0.9879, 0.9879,
         0.9878]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 0, 0, 1, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 1, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 1, 0, 1, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1393711.5000, 1386919.0000, 1386546.0000, 1384886.2500, 1379993.6250,
         1378137.8750, 1377751.6250, 1377352.1250, 1377075.0000, 1376689.0000],
        [1398496.7500, 1398370.0000, 1391448.6250, 1388452.8750, 1387415.1250,
         1387139.8750, 1387097.5000, 1385464.7500, 1385365.7500, 1384305.2500],
        [1319345.8750, 1318268.0000, 1315350.7500, 1314562.0000, 1310680.1250,
         1310260.2500, 1309644.2500, 1309224.7500, 1305651.1250, 1305575.2500],
        [1312287.3750, 1311743.0000, 1310672.5000, 1306980.3750, 1299380.7500,
         1298954.5000, 1297102.5000, 1297088.8750, 1296523.7500, 1295737.6250],
        [1196950.7500, 1191789.8750, 1180838.3750, 1167085.6250, 1165648.5000,
         1158844.0000, 1157839.8750, 1157827.7500, 1155763.6250, 1154624.5000],
        [1244723.3750, 1243659.0000, 1242432.1250, 1239878.8750, 1237615.3750,
         1231028.1250, 1230151.5000, 1227782.7500, 1224774.8750, 1223933.0000],
        [1279599.2500, 1262070.8750, 1254165.1250, 1253918.8750, 1252373.6250,
         1246571.8750, 1245865.8750, 1242006.7500, 1240239.6250, 1239891.8750],
        [1233746.6250, 1231394.3750, 1214563.5000, 1213161.6250, 1210690.5000,
         1206295.0000, 1202620.3750, 1195042.6250, 1192675.5000, 1189240.8750],
        [1393339.5000, 1388230.3750, 1388123.1250, 1385520.3750, 1385151.7500,
         1385002.5000, 1384513.7500, 1383050.3750, 1382665.2500, 1381797.8750],
        [1285352.6250, 1282229.2500, 1273681.0000, 1270872.1250, 1266553.7500,
         1265552.8750, 1264245.2500, 1263719.6250, 1263223.2500, 1262677.7500],
        [1413057.5000, 1400442.6250, 1396761.3750, 1396000.8750, 1395621.5000,
         1394972.2500, 1394301.8750, 1393703.6250, 1393194.6250, 1392789.5000],
        [1321356.7500, 1311286.3750, 1305627.3750, 1304126.6250, 1304045.8750,
         1302715.8750, 1302287.3750, 1299305.1250, 1298996.6250, 1296786.0000],
        [1289410.2500, 1284939.5000, 1284888.1250, 1277671.3750, 1274836.6250,
         1273208.6250, 1271714.7500, 1270920.6250, 1269299.8750, 1266707.2500],
        [1410169.8750, 1407545.7500, 1406535.3750, 1404668.0000, 1403898.0000,
         1401594.3750, 1401099.8750, 1400676.3750, 1400432.0000, 1400159.6250],
        [1407655.8750, 1405936.0000, 1402842.1250, 1402057.0000, 1398384.7500,
         1397097.0000, 1396395.1250, 1396379.0000, 1395674.8750, 1394832.5000],
        [1411749.6250, 1411290.5000, 1405385.0000, 1402678.7500, 1398119.3750,
         1396030.1250, 1395294.1250, 1394529.2500, 1393161.3750, 1392970.1250],
        [1377926.3750, 1371107.3750, 1370806.6250, 1370021.2500, 1367038.8750,
         1365218.8750, 1360720.1250, 1360076.7500, 1359605.8750, 1359113.2500],
        [1351985.1250, 1348655.0000, 1348477.5000, 1347496.6250, 1346639.7500,
         1346345.6250, 1344890.5000, 1343985.2500, 1342752.7500, 1342256.0000],
        [1366752.1250, 1363749.6250, 1360129.8750, 1358383.8750, 1355997.1250,
         1352802.8750, 1352724.1250, 1352484.2500, 1350742.7500, 1348882.6250],
        [1407223.6250, 1400624.2500, 1399433.3750, 1398886.2500, 1397782.1250,
         1397532.7500, 1396359.1250, 1395496.3750, 1395344.6250, 1394111.6250],
        [1394799.2500, 1388507.1250, 1384960.1250, 1382418.6250, 1381987.6250,
         1379388.3750, 1378460.0000, 1376721.7500, 1376694.2500, 1375698.1250],
        [1344441.6250, 1343157.5000, 1337427.3750, 1331896.7500, 1330697.0000,
         1329059.7500, 1326863.6250, 1322821.8750, 1322042.3750, 1321785.2500],
        [1363675.6250, 1362244.5000, 1359373.7500, 1357912.2500, 1355115.5000,
         1354234.2500, 1352999.0000, 1350221.1250, 1348851.7500, 1346510.0000],
        [1414169.6250, 1405181.2500, 1404330.5000, 1401786.8750, 1401680.0000,
         1401662.6250, 1400769.8750, 1397412.8750, 1396704.0000, 1396453.7500],
        [1347558.2500, 1339589.7500, 1339414.7500, 1335523.0000, 1333377.3750,
         1332143.2500, 1331331.6250, 1331203.5000, 1328394.5000, 1327486.5000],
        [1391196.5000, 1385885.1250, 1385139.8750, 1377044.8750, 1373819.3750,
         1373664.7500, 1373205.0000, 1373100.2500, 1373081.8750, 1372931.3750],
        [1337239.8750, 1337155.6250, 1330074.1250, 1329517.3750, 1324038.5000,
         1323373.2500, 1321278.6250, 1320063.2500, 1318818.7500, 1318564.7500],
        [1396002.2500, 1392434.8750, 1392160.0000, 1390707.0000, 1388045.0000,
         1386875.3750, 1384247.1250, 1384034.6250, 1383807.6250, 1383407.8750],
        [1416087.5000, 1413161.2500, 1411950.2500, 1410908.3750, 1410473.7500,
         1409771.8750, 1409400.7500, 1408754.5000, 1407893.5000, 1407674.6250],
        [1429442.8750, 1424532.7500, 1414697.1250, 1412488.8750, 1412060.6250,
         1411715.8750, 1410596.2500, 1409894.1250, 1409822.8750, 1407438.3750],
        [1401794.8750, 1401670.6250, 1399365.2500, 1398219.3750, 1397799.5000,
         1396553.5000, 1396512.2500, 1396367.0000, 1396166.1250, 1395732.0000],
        [1433563.0000, 1415848.3750, 1415401.6250, 1415386.7500, 1414895.5000,
         1414821.2500, 1408344.7500, 1408189.0000, 1407337.7500, 1406350.2500],
        [1286583.8750, 1279739.6250, 1274940.0000, 1269588.0000, 1264643.2500,
         1261703.8750, 1259593.8750, 1259067.8750, 1258817.0000, 1258347.6250],
        [1359692.8750, 1356332.0000, 1356196.2500, 1356180.7500, 1355756.5000,
         1351738.8750, 1350548.2500, 1349272.5000, 1349214.5000, 1349156.6250],
        [1397097.0000, 1395429.8750, 1392055.1250, 1391659.6250, 1391517.6250,
         1389018.3750, 1388787.8750, 1387344.8750, 1384346.2500, 1382922.3750],
        [1365440.2500, 1365294.3750, 1364171.2500, 1360589.1250, 1360425.6250,
         1357582.1250, 1356373.5000, 1355221.3750, 1354491.3750, 1353320.2500],
        [1347019.8750, 1345125.1250, 1338000.1250, 1337197.7500, 1334281.7500,
         1328901.3750, 1327589.0000, 1327115.5000, 1324570.2500, 1324547.5000],
        [1347929.6250, 1345940.0000, 1345254.6250, 1342224.1250, 1341800.3750,
         1340190.2500, 1334803.6250, 1333369.7500, 1327233.2500, 1327000.3750],
        [1302127.1250, 1295789.5000, 1287494.5000, 1285076.7500, 1284416.3750,
         1282568.0000, 1280816.5000, 1280334.1250, 1279544.3750, 1278324.6250],
        [1392974.1250, 1390340.8750, 1388252.8750, 1386739.1250, 1385846.7500,
         1385487.3750, 1385192.7500, 1384500.6250, 1384237.8750, 1383959.3750],
        [1345144.3750, 1327630.7500, 1327478.8750, 1324497.0000, 1324259.5000,
         1323693.8750, 1321665.5000, 1321129.8750, 1317855.7500, 1315833.7500],
        [1409821.6250, 1409617.1250, 1400851.3750, 1398874.2500, 1398710.1250,
         1398144.7500, 1397859.3750, 1397524.7500, 1395759.8750, 1395547.0000],
        [1415752.6250, 1411205.7500, 1406840.0000, 1406475.0000, 1406299.2500,
         1405578.0000, 1404701.6250, 1404652.0000, 1404131.0000, 1404001.1250],
        [1420846.3750, 1414780.7500, 1413916.2500, 1412039.0000, 1411617.6250,
         1408070.7500, 1407590.1250, 1407234.5000, 1405193.2500, 1404988.3750],
        [1311964.5000, 1287853.1250, 1281404.2500, 1281183.0000, 1277993.1250,
         1275690.3750, 1273653.0000, 1273077.5000, 1272916.0000, 1272473.0000],
        [1174370.7500, 1170352.5000, 1168247.1250, 1163014.6250, 1159151.3750,
         1153246.6250, 1153002.5000, 1151742.0000, 1150627.6250, 1150068.1250],
        [1122562.6250, 1099289.2500, 1097948.1250, 1055930.7500, 1040737.4375,
         1036837.2500, 1029811.0000, 1009260.1250, 1007188.0625, 1004626.6875],
        [1318337.1250, 1317779.0000, 1311416.6250, 1307385.5000, 1303875.5000,
         1303516.1250, 1303329.7500, 1302812.7500, 1301535.0000, 1295315.0000],
        [1310886.3750, 1309976.6250, 1306282.6250, 1304481.2500, 1301289.2500,
         1300704.8750, 1298456.6250, 1292925.7500, 1290506.2500, 1290249.1250],
        [1352494.5000, 1345049.5000, 1344309.5000, 1342041.0000, 1341100.6250,
         1340947.1250, 1338214.5000, 1337734.7500, 1337443.8750, 1335418.6250],
        [1358451.1250, 1351902.6250, 1344631.3750, 1343275.3750, 1343021.7500,
         1341989.7500, 1341682.6250, 1340681.1250, 1336291.3750, 1332366.8750],
        [1352862.2500, 1346688.5000, 1345793.6250, 1342582.5000, 1338025.7500,
         1336835.6250, 1335338.3750, 1332572.7500, 1331471.3750, 1331256.7500],
        [1268950.1250, 1260302.8750, 1258842.1250, 1256442.1250, 1256435.0000,
         1255731.8750, 1252335.3750, 1246995.0000, 1245916.8750, 1245655.5000],
        [1324298.7500, 1297582.6250, 1295159.3750, 1291581.1250, 1284666.3750,
         1282229.2500, 1280983.7500, 1279497.8750, 1277893.2500, 1277532.3750],
        [1398698.2500, 1396697.3750, 1394114.3750, 1393792.6250, 1391553.3750,
         1391315.7500, 1390940.3750, 1390730.8750, 1390473.6250, 1389260.7500],
        [1407685.5000, 1404195.2500, 1399263.8750, 1397986.0000, 1397519.5000,
         1396753.2500, 1394468.1250, 1393867.1250, 1393028.5000, 1392525.1250],
        [1237718.1250, 1213151.2500, 1211519.8750, 1210694.0000, 1208135.8750,
         1205758.8750, 1198334.0000, 1194711.0000, 1190175.8750, 1186020.8750],
        [1222223.1250, 1221436.5000, 1220102.3750, 1205402.6250, 1202467.7500,
         1202388.7500, 1201955.2500, 1200319.5000, 1195967.2500, 1195913.6250],
        [1299534.3750, 1297054.2500, 1296642.5000, 1294143.2500, 1293023.1250,
         1291055.3750, 1283838.2500, 1283103.8750, 1281509.2500, 1280277.8750],
        [1333245.1250, 1331797.7500, 1325088.2500, 1324961.8750, 1324797.7500,
         1321750.0000, 1321607.5000, 1317609.3750, 1314717.3750, 1314702.3750],
        [1276070.1250, 1273359.1250, 1270866.0000, 1268209.7500, 1266803.8750,
         1260967.7500, 1257818.5000, 1257771.7500, 1256472.1250, 1256090.0000],
        [1167613.3750, 1163059.0000, 1161615.7500, 1131059.5000, 1102384.1250,
         1097572.2500, 1092266.7500, 1085661.7500, 1083557.8750, 1081772.6250],
        [1306387.2500, 1304718.8750, 1304426.5000, 1303726.2500, 1303461.3750,
         1302743.1250, 1300123.1250, 1300048.8750, 1299546.7500, 1298493.7500],
        [1363267.2500, 1358592.3750, 1353278.8750, 1350963.0000, 1349190.1250,
         1348257.5000, 1346995.5000, 1346628.1250, 1345803.8750, 1344819.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1393711.5000,       0.0000],
         [1386919.0000,       0.0000],
         [1386546.0000,       0.0000],
         ...,
         [1377352.1250,       0.0000],
         [1377075.0000,       0.0000],
         [1376689.0000,       0.0000]],

        [[1398496.7500,       0.0000],
         [1398370.0000,       0.0000],
         [1391448.6250,       0.0000],
         ...,
         [1385464.7500,       0.0000],
         [1385365.7500,       0.0000],
         [1384305.2500,       0.0000]],

        [[1319345.8750,       0.0000],
         [      0.0000, 1318268.0000],
         [      0.0000, 1315350.7500],
         ...,
         [1309224.7500,       0.0000],
         [1305651.1250,       0.0000],
         [1305575.2500,       0.0000]],

        ...,

        [[1167613.3750,       0.0000],
         [      0.0000, 1163059.0000],
         [1161615.7500,       0.0000],
         ...,
         [      0.0000, 1085661.7500],
         [1083557.8750,       0.0000],
         [1081772.6250,       0.0000]],

        [[1306387.2500,       0.0000],
         [1304718.8750,       0.0000],
         [1304426.5000,       0.0000],
         ...,
         [1300048.8750,       0.0000],
         [1299546.7500,       0.0000],
         [1298493.7500,       0.0000]],

        [[1363267.2500,       0.0000],
         [1358592.3750,       0.0000],
         [1353278.8750,       0.0000],
         ...,
         [1346628.1250,       0.0000],
         [1345803.8750,       0.0000],
         [1344819.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12441310.0000,  1377751.6250],
        [13893556.0000,        0.0000],
        [10484944.0000,  2633618.7500],
        [10416844.0000,  2609627.0000],
        [ 3471431.2500,  8215782.0000],
        [11108364.0000,  1237615.3750],
        [12516704.0000,        0.0000],
        [ 8434185.0000,  3655246.5000],
        [13857395.0000,        0.0000],
        [10142197.0000,  2555910.2500],
        [12578056.0000,  1392789.5000],
        [10439773.0000,  2606761.7500],
        [12763597.0000,        0.0000],
        [14036780.0000,        0.0000],
        [12600157.0000,  1397097.0000],
        [12598529.0000,  1402678.7500],
        [10941802.0000,  2719833.5000],
        [ 9424761.0000,  4038723.2500],
        [13562649.0000,        0.0000],
        [11184636.0000,  2798157.0000],
        [12442940.0000,  1376694.2500],
        [13310192.0000,        0.0000],
        [13551138.0000,        0.0000],
        [12619382.0000,  1400769.8750],
        [13346022.0000,        0.0000],
        [12393184.0000,  1385885.1250],
        [11941306.0000,  1318818.7500],
        [13881722.0000,        0.0000],
        [14106076.0000,        0.0000],
        [14142691.0000,        0.0000],
        [13980180.0000,        0.0000],
        [14140138.0000,        0.0000],
        [ 7615031.0000,  5057994.0000],
        [13534089.0000,        0.0000],
        [13900178.0000,        0.0000],
        [12235328.0000,  1357582.1250],
        [10682662.0000,  2651685.7500],
        [12043522.0000,  1342224.1250],
        [ 8997962.0000,  3858530.5000],
        [12479279.0000,  1388252.8750],
        [10606836.0000,  2642352.7500],
        [14002710.0000,        0.0000],
        [14069637.0000,        0.0000],
        [12698686.0000,  1407590.1250],
        [10223328.0000,  2584880.5000],
        [ 5777538.0000,  5816285.0000],
        [ 7297694.0000,  3206497.5000],
        [ 7839109.0000,  5226193.5000],
        [11694872.0000,  1310886.3750],
        [13414754.0000,        0.0000],
        [13434294.0000,        0.0000],
        [10724145.0000,  2669282.5000],
        [ 7524224.0000,  5023383.0000],
        [10328865.0000,  2562559.5000],
        [13927578.0000,        0.0000],
        [13977292.0000,        0.0000],
        [ 7240629.0000,  4815590.5000],
        [ 7226082.0000,  4842095.0000],
        [11603539.0000,  1296642.5000],
        [10590598.0000,  2639679.2500],
        [ 7586613.5000,  5057815.0000],
        [ 6689210.5000,  4477352.5000],
        [11719949.0000,  1303726.2500],
        [13507797.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 50.0
Top1 accuracy for validation set is 50.0 size is torch.Size([64, 1])
Epoch 21/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:38, 57.11s/it]  7%|▋         | 2/29 [00:58<10:57, 24.34s/it] 10%|█         | 3/29 [01:00<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:01<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.06s/it] 21%|██        | 6/29 [01:03<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 7.000752925872803
Epoch 22/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.79s/it]  7%|▋         | 2/29 [01:01<11:32, 25.64s/it] 10%|█         | 3/29 [01:02<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 6.877187252044678
Epoch 23/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:23, 58.70s/it]  7%|▋         | 2/29 [01:00<11:20, 25.21s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 6.78356409072876
Epoch 24/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.82s/it]  7%|▋         | 2/29 [00:57<10:46, 23.94s/it] 10%|█         | 3/29 [00:58<05:52, 13.57s/it] 14%|█▍        | 4/29 [01:00<03:45,  9.00s/it] 17%|█▋        | 5/29 [01:01<02:26,  6.09s/it] 21%|██        | 6/29 [01:02<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.49s/it] 31%|███       | 9/29 [01:05<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 6.662674427032471
Epoch 25/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:19, 58.54s/it]  7%|▋         | 2/29 [01:00<11:20, 25.19s/it] 10%|█         | 3/29 [01:01<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 6.567741870880127
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0339, 0.0092, 0.0092,  ..., 0.0048, 0.0126, 0.0177],
        [0.0325, 0.0134, 0.0024,  ..., 0.0029, 0.0100, 0.0223],
        [0.0361, 0.0143, 0.0109,  ..., 0.0068, 0.0097, 0.0176],
        ...,
        [0.0317, 0.0185, 0.0055,  ..., 0.0045, 0.0051, 0.0221],
        [0.0350, 0.0114, 0.0064,  ..., 0.0031, 0.0155, 0.0169],
        [0.0310, 0.0119, 0.0034,  ..., 0.0046, 0.0122, 0.0208]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9906, 0.9905, 0.9904, 0.9903, 0.9903, 0.9901, 0.9900, 0.9899, 0.9899,
         0.9898],
        [0.9912, 0.9910, 0.9909, 0.9909, 0.9908, 0.9908, 0.9907, 0.9907, 0.9907,
         0.9906],
        [0.9864, 0.9861, 0.9859, 0.9858, 0.9857, 0.9857, 0.9856, 0.9855, 0.9855,
         0.9855],
        [0.9887, 0.9873, 0.9869, 0.9869, 0.9868, 0.9864, 0.9863, 0.9863, 0.9859,
         0.9858],
        [0.9819, 0.9811, 0.9806, 0.9803, 0.9796, 0.9793, 0.9790, 0.9788, 0.9787,
         0.9787],
        [0.9839, 0.9834, 0.9830, 0.9829, 0.9821, 0.9820, 0.9811, 0.9810, 0.9810,
         0.9807],
        [0.9839, 0.9836, 0.9836, 0.9827, 0.9826, 0.9823, 0.9822, 0.9821, 0.9818,
         0.9818],
        [0.9839, 0.9819, 0.9808, 0.9805, 0.9803, 0.9803, 0.9800, 0.9797, 0.9792,
         0.9792],
        [0.9913, 0.9908, 0.9907, 0.9906, 0.9905, 0.9905, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9865, 0.9863, 0.9862, 0.9853, 0.9853, 0.9853, 0.9853, 0.9853, 0.9853,
         0.9852],
        [0.9912, 0.9911, 0.9911, 0.9908, 0.9907, 0.9906, 0.9906, 0.9906, 0.9906,
         0.9906],
        [0.9880, 0.9858, 0.9857, 0.9855, 0.9855, 0.9855, 0.9854, 0.9853, 0.9852,
         0.9852],
        [0.9861, 0.9858, 0.9854, 0.9854, 0.9853, 0.9853, 0.9852, 0.9852, 0.9852,
         0.9852],
        [0.9918, 0.9918, 0.9917, 0.9917, 0.9915, 0.9914, 0.9914, 0.9914, 0.9913,
         0.9912],
        [0.9921, 0.9919, 0.9917, 0.9917, 0.9916, 0.9916, 0.9916, 0.9915, 0.9915,
         0.9915],
        [0.9923, 0.9919, 0.9918, 0.9918, 0.9917, 0.9917, 0.9917, 0.9916, 0.9916,
         0.9916],
        [0.9897, 0.9896, 0.9893, 0.9892, 0.9892, 0.9891, 0.9890, 0.9889, 0.9889,
         0.9889],
        [0.9890, 0.9886, 0.9885, 0.9884, 0.9881, 0.9880, 0.9879, 0.9879, 0.9879,
         0.9879],
        [0.9895, 0.9895, 0.9895, 0.9895, 0.9894, 0.9894, 0.9893, 0.9893, 0.9891,
         0.9891],
        [0.9914, 0.9913, 0.9913, 0.9910, 0.9910, 0.9909, 0.9909, 0.9908, 0.9908,
         0.9908],
        [0.9908, 0.9906, 0.9904, 0.9904, 0.9903, 0.9902, 0.9900, 0.9900, 0.9899,
         0.9898],
        [0.9884, 0.9881, 0.9879, 0.9878, 0.9876, 0.9876, 0.9875, 0.9875, 0.9875,
         0.9875],
        [0.9899, 0.9899, 0.9898, 0.9897, 0.9896, 0.9895, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9926, 0.9923, 0.9922, 0.9922, 0.9921, 0.9920, 0.9919, 0.9918, 0.9918,
         0.9918],
        [0.9890, 0.9886, 0.9879, 0.9878, 0.9878, 0.9875, 0.9875, 0.9875, 0.9875,
         0.9874],
        [0.9923, 0.9920, 0.9917, 0.9916, 0.9916, 0.9916, 0.9915, 0.9915, 0.9915,
         0.9915],
        [0.9894, 0.9889, 0.9887, 0.9887, 0.9885, 0.9884, 0.9883, 0.9883, 0.9883,
         0.9882],
        [0.9923, 0.9922, 0.9921, 0.9918, 0.9916, 0.9916, 0.9915, 0.9914, 0.9914,
         0.9914],
        [0.9924, 0.9921, 0.9920, 0.9919, 0.9918, 0.9918, 0.9918, 0.9918, 0.9917,
         0.9917],
        [0.9925, 0.9921, 0.9921, 0.9921, 0.9920, 0.9920, 0.9920, 0.9919, 0.9919,
         0.9919],
        [0.9924, 0.9922, 0.9919, 0.9919, 0.9918, 0.9918, 0.9917, 0.9917, 0.9916,
         0.9916],
        [0.9928, 0.9926, 0.9925, 0.9924, 0.9923, 0.9923, 0.9923, 0.9923, 0.9922,
         0.9921],
        [0.9851, 0.9845, 0.9845, 0.9844, 0.9844, 0.9844, 0.9843, 0.9842, 0.9841,
         0.9840],
        [0.9898, 0.9897, 0.9896, 0.9896, 0.9896, 0.9895, 0.9895, 0.9895, 0.9894,
         0.9893],
        [0.9915, 0.9914, 0.9909, 0.9908, 0.9907, 0.9907, 0.9907, 0.9907, 0.9907,
         0.9906],
        [0.9903, 0.9900, 0.9899, 0.9898, 0.9898, 0.9898, 0.9897, 0.9896, 0.9896,
         0.9895],
        [0.9887, 0.9875, 0.9873, 0.9873, 0.9872, 0.9872, 0.9868, 0.9867, 0.9867,
         0.9867],
        [0.9898, 0.9891, 0.9890, 0.9890, 0.9888, 0.9886, 0.9885, 0.9885, 0.9884,
         0.9884],
        [0.9866, 0.9865, 0.9863, 0.9863, 0.9862, 0.9861, 0.9859, 0.9858, 0.9858,
         0.9857],
        [0.9905, 0.9904, 0.9904, 0.9903, 0.9902, 0.9902, 0.9902, 0.9901, 0.9901,
         0.9900],
        [0.9868, 0.9867, 0.9866, 0.9864, 0.9863, 0.9862, 0.9859, 0.9858, 0.9858,
         0.9858],
        [0.9921, 0.9918, 0.9917, 0.9917, 0.9917, 0.9917, 0.9917, 0.9916, 0.9916,
         0.9916],
        [0.9916, 0.9912, 0.9912, 0.9911, 0.9911, 0.9911, 0.9909, 0.9909, 0.9909,
         0.9908],
        [0.9914, 0.9914, 0.9914, 0.9913, 0.9912, 0.9912, 0.9912, 0.9912, 0.9911,
         0.9911],
        [0.9868, 0.9866, 0.9866, 0.9864, 0.9864, 0.9864, 0.9864, 0.9863, 0.9862,
         0.9862],
        [0.9828, 0.9828, 0.9827, 0.9822, 0.9817, 0.9817, 0.9816, 0.9815, 0.9813,
         0.9811],
        [0.9784, 0.9741, 0.9715, 0.9698, 0.9696, 0.9693, 0.9686, 0.9679, 0.9678,
         0.9674],
        [0.9858, 0.9850, 0.9846, 0.9844, 0.9841, 0.9839, 0.9838, 0.9837, 0.9836,
         0.9835],
        [0.9868, 0.9867, 0.9864, 0.9862, 0.9861, 0.9861, 0.9860, 0.9860, 0.9858,
         0.9857],
        [0.9887, 0.9885, 0.9883, 0.9881, 0.9881, 0.9880, 0.9879, 0.9879, 0.9879,
         0.9878],
        [0.9883, 0.9874, 0.9874, 0.9873, 0.9871, 0.9871, 0.9870, 0.9869, 0.9867,
         0.9866],
        [0.9878, 0.9874, 0.9872, 0.9872, 0.9871, 0.9871, 0.9871, 0.9870, 0.9870,
         0.9870],
        [0.9842, 0.9842, 0.9839, 0.9838, 0.9838, 0.9838, 0.9837, 0.9837, 0.9837,
         0.9836],
        [0.9851, 0.9850, 0.9847, 0.9843, 0.9843, 0.9842, 0.9840, 0.9839, 0.9838,
         0.9838],
        [0.9912, 0.9907, 0.9907, 0.9905, 0.9905, 0.9905, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9910, 0.9909, 0.9908, 0.9907, 0.9907, 0.9907, 0.9907, 0.9906, 0.9905,
         0.9905],
        [0.9813, 0.9812, 0.9809, 0.9809, 0.9805, 0.9804, 0.9804, 0.9803, 0.9802,
         0.9799],
        [0.9818, 0.9818, 0.9815, 0.9814, 0.9814, 0.9812, 0.9810, 0.9801, 0.9800,
         0.9799],
        [0.9864, 0.9863, 0.9860, 0.9854, 0.9854, 0.9853, 0.9853, 0.9848, 0.9848,
         0.9847],
        [0.9880, 0.9876, 0.9876, 0.9875, 0.9874, 0.9872, 0.9872, 0.9872, 0.9871,
         0.9870],
        [0.9841, 0.9840, 0.9836, 0.9830, 0.9829, 0.9827, 0.9826, 0.9826, 0.9826,
         0.9824],
        [0.9822, 0.9810, 0.9796, 0.9786, 0.9782, 0.9779, 0.9775, 0.9774, 0.9773,
         0.9769],
        [0.9880, 0.9877, 0.9875, 0.9871, 0.9869, 0.9869, 0.9868, 0.9867, 0.9867,
         0.9867],
        [0.9903, 0.9896, 0.9895, 0.9895, 0.9895, 0.9895, 0.9894, 0.9894, 0.9894,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [0, 1, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1399720.2500, 1398028.7500, 1394767.2500, 1394036.0000, 1393475.0000,
         1390029.3750, 1388079.5000, 1386029.2500, 1385549.3750, 1383092.5000],
        [1412123.8750, 1407007.6250, 1405535.1250, 1404319.7500, 1403686.5000,
         1403084.2500, 1401536.8750, 1401389.8750, 1400887.5000, 1399537.3750],
        [1318059.3750, 1312338.6250, 1308183.7500, 1306288.8750, 1305163.1250,
         1304370.5000, 1303476.3750, 1300805.2500, 1300537.3750, 1300373.7500],
        [1361556.1250, 1334323.7500, 1327302.8750, 1326358.8750, 1325576.1250,
         1317968.8750, 1316732.6250, 1315569.1250, 1308716.6250, 1307374.3750],
        [1235299.5000, 1220841.5000, 1213179.0000, 1208618.7500, 1195316.1250,
         1190913.8750, 1185778.8750, 1181706.8750, 1181157.1250, 1180585.0000],
        [1270992.1250, 1262925.7500, 1254581.5000, 1254088.7500, 1238806.8750,
         1238310.7500, 1221860.6250, 1219967.3750, 1219782.3750, 1215511.3750],
        [1271153.3750, 1266311.0000, 1265602.3750, 1249138.7500, 1248217.0000,
         1241989.0000, 1241150.6250, 1238925.0000, 1234424.5000, 1234074.8750],
        [1272373.3750, 1235656.5000, 1215760.6250, 1211186.0000, 1207584.0000,
         1207340.0000, 1203104.5000, 1197893.0000, 1188901.8750, 1188847.3750],
        [1413036.0000, 1403378.6250, 1401364.5000, 1400008.6250, 1396678.7500,
         1396289.8750, 1396027.5000, 1395754.6250, 1393788.6250, 1393695.6250],
        [1320226.8750, 1314967.0000, 1313322.6250, 1297894.5000, 1297889.6250,
         1297522.0000, 1297034.6250, 1296991.2500, 1296520.0000, 1296060.2500],
        [1410294.8750, 1409874.0000, 1409371.2500, 1403052.1250, 1400737.8750,
         1400163.5000, 1399315.8750, 1399250.5000, 1398747.5000, 1398279.3750],
        [1348311.5000, 1306462.0000, 1303947.6250, 1301227.1250, 1300280.6250,
         1300099.6250, 1298265.8750, 1297946.5000, 1296092.3750, 1295395.3750],
        [1311360.2500, 1306996.5000, 1298919.7500, 1298486.3750, 1297861.0000,
         1296460.6250, 1296199.8750, 1295969.8750, 1295583.1250, 1295079.1250],
        [1424028.8750, 1423195.1250, 1421967.3750, 1421064.5000, 1418095.6250,
         1415972.6250, 1415313.8750, 1414548.7500, 1413348.6250, 1412016.2500],
        [1428638.7500, 1424888.7500, 1422036.6250, 1420811.1250, 1418723.2500,
         1418657.1250, 1418358.1250, 1418048.3750, 1417361.5000, 1417135.7500],
        [1434163.2500, 1424854.7500, 1423043.2500, 1422741.8750, 1421103.8750,
         1420731.1250, 1420542.8750, 1419952.3750, 1419543.3750, 1419538.0000],
        [1381219.5000, 1379884.3750, 1374399.8750, 1372238.8750, 1372208.7500,
         1369373.2500, 1368355.0000, 1365733.2500, 1365450.6250, 1365287.8750],
        [1368193.2500, 1360587.7500, 1357601.5000, 1355869.0000, 1349251.8750,
         1348447.8750, 1346958.2500, 1346725.7500, 1346151.7500, 1345920.6250],
        [1378139.2500, 1378126.0000, 1378109.0000, 1377657.0000, 1375678.5000,
         1374874.5000, 1373786.5000, 1373155.2500, 1369351.1250, 1369236.1250],
        [1414563.6250, 1413457.8750, 1412922.7500, 1407320.2500, 1406846.6250,
         1405275.1250, 1405083.3750, 1404172.5000, 1404141.6250, 1404131.0000],
        [1402359.1250, 1399572.1250, 1394897.7500, 1394836.5000, 1392667.2500,
         1390900.6250, 1386330.5000, 1386293.5000, 1384982.7500, 1382605.8750],
        [1355724.2500, 1349326.5000, 1346869.6250, 1344496.7500, 1341114.6250,
         1340374.2500, 1339409.6250, 1338988.1250, 1338845.1250, 1338658.7500],
        [1385260.0000, 1384587.8750, 1383372.2500, 1381205.0000, 1379322.6250,
         1377959.2500, 1377819.8750, 1375531.5000, 1375180.0000, 1373474.8750],
        [1439333.0000, 1432710.1250, 1432577.6250, 1431012.7500, 1430546.1250,
         1427821.5000, 1424660.5000, 1424164.6250, 1423999.0000, 1423978.6250],
        [1367441.8750, 1359279.2500, 1346009.2500, 1343704.6250, 1343677.6250,
         1338656.1250, 1338420.0000, 1338173.6250, 1338084.2500, 1336690.2500],
        [1432661.0000, 1426563.8750, 1421230.0000, 1419982.1250, 1419356.7500,
         1418607.0000, 1417915.8750, 1417642.6250, 1417123.6250, 1416612.8750],
        [1375270.3750, 1366352.1250, 1360900.6250, 1360873.2500, 1357742.6250,
         1355450.2500, 1354435.8750, 1353694.6250, 1353042.7500, 1352937.0000],
        [1433273.1250, 1432570.7500, 1429500.0000, 1422666.0000, 1420067.5000,
         1419240.2500, 1416337.2500, 1416134.7500, 1415875.3750, 1414842.8750],
        [1436402.6250, 1428523.0000, 1428302.2500, 1424786.8750, 1423914.7500,
         1423036.3750, 1422765.1250, 1422659.1250, 1422389.2500, 1421909.1250],
        [1438613.8750, 1430536.6250, 1429222.0000, 1429046.1250, 1428209.7500,
         1428044.8750, 1427236.0000, 1425843.0000, 1425473.1250, 1425263.8750],
        [1435223.7500, 1430975.8750, 1426187.1250, 1425553.3750, 1422961.7500,
         1422546.5000, 1421006.2500, 1420693.2500, 1420108.1250, 1419233.5000],
        [1442987.5000, 1440450.7500, 1437058.8750, 1434735.1250, 1434390.3750,
         1433996.5000, 1432742.8750, 1432650.0000, 1431778.6250, 1429061.1250],
        [1293417.7500, 1282392.0000, 1282050.7500, 1281247.7500, 1280820.1250,
         1279779.8750, 1279429.6250, 1277692.0000, 1274989.8750, 1273173.3750],
        [1383026.6250, 1381850.6250, 1380168.6250, 1378627.0000, 1378627.0000,
         1377496.7500, 1376824.2500, 1376738.8750, 1375387.2500, 1373709.2500],
        [1416727.7500, 1415343.6250, 1405488.2500, 1402555.8750, 1401955.2500,
         1401915.2500, 1401774.7500, 1401561.0000, 1401365.8750, 1399727.0000],
        [1392486.6250, 1386391.3750, 1384607.6250, 1384033.2500, 1383844.6250,
         1382513.5000, 1381563.3750, 1380334.6250, 1379681.7500, 1377056.7500],
        [1362086.0000, 1338181.3750, 1335137.2500, 1333895.1250, 1333035.3750,
         1332788.8750, 1325200.7500, 1324037.3750, 1323234.5000, 1322914.0000],
        [1382582.2500, 1369938.8750, 1367333.6250, 1367066.3750, 1364647.3750,
         1359744.6250, 1357426.7500, 1357327.1250, 1356308.7500, 1355671.2500],
        [1321359.2500, 1319869.3750, 1316158.8750, 1315658.1250, 1314411.5000,
         1311889.3750, 1308923.7500, 1306977.8750, 1306941.7500, 1304535.8750],
        [1397720.7500, 1395925.1250, 1394937.6250, 1393981.3750, 1391930.2500,
         1390384.6250, 1390379.3750, 1389759.0000, 1388328.3750, 1387395.2500],
        [1325531.8750, 1323518.3750, 1320852.7500, 1316922.2500, 1316406.1250,
         1313186.1250, 1309124.7500, 1307209.7500, 1307184.7500, 1307131.2500],
        [1430251.5000, 1422820.6250, 1422198.0000, 1422119.3750, 1421887.3750,
         1421764.0000, 1421440.0000, 1420370.8750, 1420110.7500, 1419565.1250],
        [1418987.2500, 1411297.2500, 1411005.2500, 1410251.8750, 1409399.5000,
         1408289.6250, 1406231.0000, 1405880.8750, 1404465.7500, 1403864.5000],
        [1415690.5000, 1414355.8750, 1414342.3750, 1413185.5000, 1411640.5000,
         1411453.5000, 1411224.6250, 1410919.1250, 1409149.5000, 1408452.2500],
        [1324945.5000, 1322143.3750, 1320774.6250, 1318430.2500, 1318005.2500,
         1317505.1250, 1316972.3750, 1316684.8750, 1314676.0000, 1313722.2500],
        [1252298.2500, 1251237.1250, 1250449.7500, 1241123.3750, 1232430.6250,
         1231715.1250, 1230404.8750, 1228499.6250, 1224840.3750, 1222261.5000],
        [1175314.1250, 1105963.3750, 1065277.6250, 1040023.0625, 1036894.5625,
         1032136.2500, 1021861.2500, 1011324.8125, 1010138.2500, 1004408.1875],
        [1307250.8750, 1291130.5000, 1285123.3750, 1279921.3750, 1274569.2500,
         1272116.2500, 1270457.7500, 1267165.1250, 1266284.5000, 1263942.6250],
        [1324351.7500, 1322760.0000, 1318378.6250, 1314039.2500, 1312117.1250,
         1312065.8750, 1310520.0000, 1309513.1250, 1306839.5000, 1305103.3750],
        [1361277.0000, 1357425.5000, 1353334.5000, 1350351.2500, 1349921.1250,
         1348770.7500, 1345988.7500, 1345800.0000, 1345354.7500, 1345132.8750],
        [1353498.3750, 1337247.5000, 1336107.8750, 1335479.7500, 1331754.6250,
         1330522.0000, 1328152.5000, 1327348.5000, 1322695.7500, 1322453.5000],
        [1343831.3750, 1336253.1250, 1333346.8750, 1332214.3750, 1331797.7500,
         1331710.1250, 1330834.1250, 1329594.7500, 1329537.7500, 1328696.0000],
        [1277338.7500, 1276608.0000, 1272338.2500, 1269814.5000, 1269116.0000,
         1268896.8750, 1268635.5000, 1268464.8750, 1267342.8750, 1265782.2500],
        [1293533.7500, 1292139.2500, 1287035.5000, 1279610.2500, 1278401.3750,
         1277028.1250, 1273566.8750, 1271735.3750, 1270296.6250, 1269050.6250],
        [1410752.3750, 1400789.8750, 1400647.0000, 1397278.2500, 1397007.7500,
         1396634.7500, 1395294.1250, 1395222.3750, 1394107.7500, 1394075.8750],
        [1406315.5000, 1404629.1250, 1403529.8750, 1401709.3750, 1401328.3750,
         1401101.2500, 1400751.2500, 1399776.3750, 1397611.3750, 1396493.6250],
        [1225989.0000, 1223243.3750, 1218855.6250, 1217661.3750, 1211613.5000,
         1209921.8750, 1209797.2500, 1208124.2500, 1206230.6250, 1201731.8750],
        [1234570.5000, 1234300.8750, 1228217.2500, 1227721.8750, 1226947.0000,
         1223350.7500, 1219124.1250, 1204620.0000, 1202536.6250, 1201013.5000],
        [1317697.3750, 1315616.7500, 1309705.5000, 1299649.6250, 1299436.5000,
         1297817.7500, 1297472.5000, 1288605.0000, 1287617.2500, 1286523.7500],
        [1347442.6250, 1340958.6250, 1339738.0000, 1339496.3750, 1336199.6250,
         1332928.6250, 1332832.0000, 1332744.3750, 1331627.6250, 1329897.7500],
        [1275042.1250, 1272435.3750, 1266005.5000, 1254597.1250, 1252932.6250,
         1249741.6250, 1248917.1250, 1248250.3750, 1247743.2500, 1245358.6250],
        [1241319.8750, 1220729.7500, 1195260.2500, 1179514.7500, 1171444.5000,
         1167537.6250, 1160567.1250, 1158152.3750, 1156351.2500, 1150874.6250],
        [1348931.5000, 1341925.7500, 1339255.0000, 1331338.0000, 1327154.7500,
         1326329.8750, 1325561.0000, 1324325.2500, 1323454.0000, 1323454.0000],
        [1393839.1250, 1379339.7500, 1378364.0000, 1378319.3750, 1377198.5000,
         1376870.2500, 1374888.8750, 1374789.2500, 1374711.8750, 1374223.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1399720.2500,       0.0000],
         [1398028.7500,       0.0000],
         [1394767.2500,       0.0000],
         ...,
         [1386029.2500,       0.0000],
         [1385549.3750,       0.0000],
         [1383092.5000,       0.0000]],

        [[1412123.8750,       0.0000],
         [1407007.6250,       0.0000],
         [1405535.1250,       0.0000],
         ...,
         [1401389.8750,       0.0000],
         [1400887.5000,       0.0000],
         [1399537.3750,       0.0000]],

        [[      0.0000, 1318059.3750],
         [1312338.6250,       0.0000],
         [1308183.7500,       0.0000],
         ...,
         [1300805.2500,       0.0000],
         [1300537.3750,       0.0000],
         [1300373.7500,       0.0000]],

        ...,

        [[1241319.8750,       0.0000],
         [1220729.7500,       0.0000],
         [1195260.2500,       0.0000],
         ...,
         [1158152.3750,       0.0000],
         [1156351.2500,       0.0000],
         [1150874.6250,       0.0000]],

        [[1348931.5000,       0.0000],
         [1341925.7500,       0.0000],
         [1339255.0000,       0.0000],
         ...,
         [1324325.2500,       0.0000],
         [1323454.0000,       0.0000],
         [1323454.0000,       0.0000]],

        [[1393839.1250,       0.0000],
         [1379339.7500,       0.0000],
         [1378364.0000,       0.0000],
         ...,
         [1374789.2500,       0.0000],
         [1374711.8750,       0.0000],
         [1374223.0000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13912807.0000,        0.0000],
        [14039110.0000,        0.0000],
        [11741537.0000,  1318059.3750],
        [10606802.0000,  2634677.2500],
        [ 2386230.0000,  9607166.0000],
        [12396828.0000,        0.0000],
        [12490987.0000,        0.0000],
        [ 8534268.0000,  3594379.0000],
        [13990023.0000,        0.0000],
        [10416427.0000,  2612001.5000],
        [12630340.0000,  1398747.5000],
        [10449482.0000,  2598546.5000],
        [ 9101770.0000,  3891147.0000],
        [14179551.0000,        0.0000],
        [14204660.0000,        0.0000],
        [14226214.0000,        0.0000],
        [12344778.0000,  1369373.2500],
        [ 9450201.0000,  4075506.7500],
        [12374958.0000,  1373155.2500],
        [12664457.0000,  1413457.8750],
        [11129580.0000,  2785865.5000],
        [13433808.0000,        0.0000],
        [13793712.0000,        0.0000],
        [14290804.0000,        0.0000],
        [10773632.0000,  2676504.2500],
        [14207697.0000,        0.0000],
        [13590700.0000,        0.0000],
        [14220508.0000,        0.0000],
        [14254690.0000,        0.0000],
        [14287489.0000,        0.0000],
        [14244490.0000,        0.0000],
        [14349852.0000,        0.0000],
        [ 6410708.5000,  6394285.0000],
        [ 9649594.0000,  4132862.7500],
        [14048415.0000,        0.0000],
        [ 8292390.5000,  5540123.5000],
        [11992330.0000,  1338181.3750],
        [12268108.0000,  1369938.8750],
        [ 9206288.0000,  3920437.5000],
        [13920742.0000,        0.0000],
        [ 9183762.0000,  3963306.7500],
        [14222528.0000,        0.0000],
        [14089673.0000,        0.0000],
        [14120414.0000,        0.0000],
        [ 9236480.0000,  3947379.5000],
        [ 2456555.5000,  9908705.0000],
        [ 7356075.5000,  3147266.0000],
        [11498040.0000,  1279921.3750],
        [11828850.0000,  1306839.5000],
        [13503356.0000,        0.0000],
        [11989152.0000,  1336107.8750],
        [10659853.0000,  2667963.2500],
        [ 2537532.5000, 10166806.0000],
        [ 7682444.0000,  5109953.5000],
        [12586516.0000,  1395294.1250],
        [14013247.0000,        0.0000],
        [ 9692264.0000,  2440904.7500],
        [ 6062839.0000,  6139563.5000],
        [ 7769705.5000,  5230436.0000],
        [12024128.0000,  1339738.0000],
        [ 8812818.0000,  3748206.0000],
        [11801753.0000,        0.0000],
        [11984574.0000,  1327154.7500],
        [13782544.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 53.125
Top1 accuracy for validation set is 53.125 size is torch.Size([64, 1])
Epoch 26/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:22, 58.68s/it]  7%|▋         | 2/29 [01:00<11:17, 25.08s/it] 10%|█         | 3/29 [01:01<06:05, 14.05s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:03<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 6.494928359985352
Epoch 27/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:47, 61.69s/it]  7%|▋         | 2/29 [01:02<11:40, 25.94s/it] 10%|█         | 3/29 [01:03<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 6.434146881103516
Epoch 28/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.79s/it]  7%|▋         | 2/29 [01:01<11:30, 25.58s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 6.372785568237305
Epoch 29/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:35, 56.99s/it]  7%|▋         | 2/29 [01:00<11:29, 25.54s/it] 10%|█         | 3/29 [01:01<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.10s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 6.33787727355957
Epoch 30/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:07, 58.12s/it]  7%|▋         | 2/29 [00:59<11:00, 24.48s/it] 10%|█         | 3/29 [01:01<06:12, 14.33s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.04s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.11s/it] 21%|██        | 6/29 [01:04<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.49s/it] 31%|███       | 9/29 [01:06<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 6.216337203979492
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0316, 0.0109, 0.0022,  ..., 0.0067, 0.0101, 0.0227],
        [0.0304, 0.0077, 0.0026,  ..., 0.0043, 0.0072, 0.0230],
        [0.0379, 0.0143, 0.0091,  ..., 0.0104, 0.0143, 0.0162],
        ...,
        [0.0284, 0.0123, 0.0026,  ..., 0.0032, 0.0074, 0.0237],
        [0.0278, 0.0115, 0.0020,  ..., 0.0030, 0.0126, 0.0196],
        [0.0281, 0.0112, 0.0025,  ..., 0.0042, 0.0085, 0.0254]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9911, 0.9910, 0.9910, 0.9910, 0.9909, 0.9908, 0.9907, 0.9907, 0.9907,
         0.9906],
        [0.9920, 0.9917, 0.9916, 0.9912, 0.9911, 0.9911, 0.9911, 0.9910, 0.9910,
         0.9909],
        [0.9858, 0.9854, 0.9853, 0.9853, 0.9850, 0.9850, 0.9849, 0.9849, 0.9847,
         0.9844],
        [0.9880, 0.9873, 0.9870, 0.9868, 0.9867, 0.9866, 0.9866, 0.9864, 0.9861,
         0.9861],
        [0.9818, 0.9812, 0.9807, 0.9807, 0.9806, 0.9796, 0.9794, 0.9789, 0.9787,
         0.9787],
        [0.9841, 0.9830, 0.9821, 0.9818, 0.9812, 0.9809, 0.9808, 0.9806, 0.9806,
         0.9805],
        [0.9862, 0.9845, 0.9844, 0.9836, 0.9835, 0.9833, 0.9832, 0.9827, 0.9824,
         0.9822],
        [0.9827, 0.9821, 0.9813, 0.9812, 0.9812, 0.9808, 0.9801, 0.9799, 0.9798,
         0.9797],
        [0.9908, 0.9906, 0.9905, 0.9905, 0.9904, 0.9904, 0.9903, 0.9903, 0.9902,
         0.9901],
        [0.9858, 0.9853, 0.9852, 0.9852, 0.9851, 0.9851, 0.9851, 0.9848, 0.9848,
         0.9847],
        [0.9919, 0.9918, 0.9915, 0.9915, 0.9914, 0.9914, 0.9913, 0.9913, 0.9913,
         0.9913],
        [0.9868, 0.9867, 0.9864, 0.9859, 0.9859, 0.9859, 0.9857, 0.9857, 0.9855,
         0.9854],
        [0.9863, 0.9858, 0.9853, 0.9852, 0.9849, 0.9849, 0.9849, 0.9848, 0.9848,
         0.9847],
        [0.9927, 0.9923, 0.9922, 0.9921, 0.9920, 0.9920, 0.9919, 0.9919, 0.9919,
         0.9919],
        [0.9928, 0.9924, 0.9923, 0.9923, 0.9921, 0.9921, 0.9920, 0.9920, 0.9920,
         0.9920],
        [0.9923, 0.9923, 0.9923, 0.9923, 0.9922, 0.9922, 0.9922, 0.9921, 0.9921,
         0.9921],
        [0.9900, 0.9897, 0.9897, 0.9896, 0.9896, 0.9895, 0.9894, 0.9894, 0.9894,
         0.9894],
        [0.9888, 0.9887, 0.9886, 0.9886, 0.9884, 0.9883, 0.9883, 0.9883, 0.9882,
         0.9882],
        [0.9898, 0.9896, 0.9894, 0.9893, 0.9891, 0.9891, 0.9890, 0.9890, 0.9890,
         0.9889],
        [0.9916, 0.9914, 0.9913, 0.9912, 0.9910, 0.9908, 0.9908, 0.9908, 0.9907,
         0.9907],
        [0.9919, 0.9916, 0.9915, 0.9915, 0.9914, 0.9913, 0.9912, 0.9911, 0.9911,
         0.9910],
        [0.9888, 0.9887, 0.9886, 0.9885, 0.9884, 0.9884, 0.9883, 0.9883, 0.9881,
         0.9880],
        [0.9913, 0.9913, 0.9911, 0.9911, 0.9910, 0.9908, 0.9908, 0.9908, 0.9907,
         0.9906],
        [0.9932, 0.9930, 0.9930, 0.9930, 0.9929, 0.9929, 0.9929, 0.9929, 0.9929,
         0.9929],
        [0.9875, 0.9871, 0.9871, 0.9870, 0.9869, 0.9869, 0.9867, 0.9867, 0.9866,
         0.9866],
        [0.9926, 0.9924, 0.9924, 0.9923, 0.9923, 0.9923, 0.9922, 0.9920, 0.9920,
         0.9920],
        [0.9912, 0.9912, 0.9909, 0.9907, 0.9906, 0.9905, 0.9903, 0.9903, 0.9901,
         0.9901],
        [0.9929, 0.9928, 0.9927, 0.9927, 0.9927, 0.9926, 0.9926, 0.9926, 0.9925,
         0.9925],
        [0.9932, 0.9930, 0.9929, 0.9928, 0.9928, 0.9926, 0.9926, 0.9925, 0.9925,
         0.9924],
        [0.9932, 0.9931, 0.9929, 0.9928, 0.9927, 0.9927, 0.9926, 0.9926, 0.9926,
         0.9925],
        [0.9928, 0.9927, 0.9927, 0.9926, 0.9926, 0.9925, 0.9925, 0.9925, 0.9924,
         0.9924],
        [0.9931, 0.9931, 0.9928, 0.9928, 0.9928, 0.9927, 0.9927, 0.9927, 0.9926,
         0.9926],
        [0.9861, 0.9853, 0.9839, 0.9839, 0.9837, 0.9832, 0.9830, 0.9827, 0.9826,
         0.9825],
        [0.9902, 0.9900, 0.9899, 0.9899, 0.9898, 0.9898, 0.9897, 0.9895, 0.9895,
         0.9894],
        [0.9917, 0.9917, 0.9916, 0.9915, 0.9915, 0.9915, 0.9914, 0.9914, 0.9914,
         0.9914],
        [0.9913, 0.9907, 0.9905, 0.9905, 0.9903, 0.9903, 0.9902, 0.9902, 0.9902,
         0.9901],
        [0.9867, 0.9865, 0.9865, 0.9863, 0.9863, 0.9862, 0.9862, 0.9861, 0.9861,
         0.9857],
        [0.9896, 0.9891, 0.9889, 0.9889, 0.9889, 0.9889, 0.9888, 0.9888, 0.9888,
         0.9887],
        [0.9870, 0.9868, 0.9866, 0.9865, 0.9864, 0.9860, 0.9859, 0.9856, 0.9856,
         0.9856],
        [0.9911, 0.9911, 0.9909, 0.9905, 0.9905, 0.9905, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9867, 0.9864, 0.9862, 0.9861, 0.9858, 0.9856, 0.9855, 0.9855, 0.9853,
         0.9852],
        [0.9931, 0.9929, 0.9928, 0.9927, 0.9926, 0.9926, 0.9926, 0.9925, 0.9925,
         0.9924],
        [0.9926, 0.9926, 0.9926, 0.9925, 0.9924, 0.9924, 0.9924, 0.9923, 0.9923,
         0.9922],
        [0.9920, 0.9919, 0.9919, 0.9919, 0.9919, 0.9919, 0.9918, 0.9918, 0.9918,
         0.9918],
        [0.9888, 0.9887, 0.9884, 0.9883, 0.9879, 0.9878, 0.9878, 0.9876, 0.9876,
         0.9875],
        [0.9827, 0.9821, 0.9817, 0.9814, 0.9813, 0.9811, 0.9808, 0.9808, 0.9808,
         0.9808],
        [0.9709, 0.9700, 0.9692, 0.9668, 0.9668, 0.9640, 0.9629, 0.9617, 0.9613,
         0.9610],
        [0.9864, 0.9853, 0.9840, 0.9835, 0.9835, 0.9832, 0.9826, 0.9825, 0.9824,
         0.9822],
        [0.9867, 0.9866, 0.9864, 0.9862, 0.9862, 0.9861, 0.9859, 0.9855, 0.9854,
         0.9854],
        [0.9887, 0.9884, 0.9882, 0.9877, 0.9877, 0.9875, 0.9875, 0.9874, 0.9873,
         0.9872],
        [0.9872, 0.9869, 0.9869, 0.9868, 0.9865, 0.9861, 0.9861, 0.9860, 0.9860,
         0.9859],
        [0.9886, 0.9874, 0.9873, 0.9871, 0.9871, 0.9871, 0.9870, 0.9870, 0.9869,
         0.9869],
        [0.9854, 0.9846, 0.9843, 0.9842, 0.9841, 0.9841, 0.9839, 0.9832, 0.9830,
         0.9830],
        [0.9858, 0.9856, 0.9848, 0.9848, 0.9847, 0.9846, 0.9842, 0.9841, 0.9839,
         0.9838],
        [0.9919, 0.9917, 0.9913, 0.9913, 0.9913, 0.9912, 0.9912, 0.9912, 0.9912,
         0.9911],
        [0.9920, 0.9914, 0.9913, 0.9912, 0.9912, 0.9912, 0.9911, 0.9911, 0.9911,
         0.9910],
        [0.9834, 0.9832, 0.9832, 0.9830, 0.9821, 0.9819, 0.9818, 0.9815, 0.9814,
         0.9813],
        [0.9837, 0.9821, 0.9821, 0.9819, 0.9811, 0.9810, 0.9804, 0.9804, 0.9803,
         0.9803],
        [0.9864, 0.9861, 0.9855, 0.9854, 0.9852, 0.9850, 0.9843, 0.9842, 0.9842,
         0.9841],
        [0.9895, 0.9883, 0.9875, 0.9874, 0.9871, 0.9870, 0.9868, 0.9868, 0.9866,
         0.9866],
        [0.9862, 0.9856, 0.9849, 0.9839, 0.9832, 0.9831, 0.9831, 0.9830, 0.9828,
         0.9827],
        [0.9871, 0.9858, 0.9856, 0.9844, 0.9842, 0.9841, 0.9837, 0.9836, 0.9835,
         0.9834],
        [0.9875, 0.9872, 0.9870, 0.9870, 0.9868, 0.9868, 0.9868, 0.9866, 0.9866,
         0.9866],
        [0.9899, 0.9896, 0.9896, 0.9894, 0.9893, 0.9893, 0.9893, 0.9893, 0.9892,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 0, 1, 1, 0],
        [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1],
        [1, 1, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1408428.0000, 1408001.0000, 1407179.5000, 1406361.0000, 1404518.1250,
         1402875.5000, 1401926.0000, 1401011.7500, 1400749.8750, 1399234.5000],
        [1427419.8750, 1421379.0000, 1418386.3750, 1410989.1250, 1410013.8750,
         1408965.3750, 1408253.3750, 1407881.5000, 1406622.6250, 1405657.1250],
        [1305891.5000, 1299598.7500, 1297861.0000, 1296856.5000, 1292308.0000,
         1291488.7500, 1290251.6250, 1290138.3750, 1285212.7500, 1280837.2500],
        [1347512.0000, 1334449.8750, 1328545.2500, 1324882.3750, 1322767.6250,
         1322155.8750, 1321718.5000, 1318612.5000, 1311585.3750, 1311329.0000],
        [1233377.1250, 1223746.2500, 1215088.3750, 1215059.3750, 1212419.1250,
         1196237.5000, 1191579.6250, 1183059.0000, 1180933.0000, 1180823.7500],
        [1275806.0000, 1255845.6250, 1238804.5000, 1234657.6250, 1223424.2500,
         1218279.2500, 1216479.6250, 1213493.7500, 1212383.2500, 1211186.0000],
        [1314013.0000, 1283146.7500, 1281501.8750, 1266157.7500, 1263396.7500,
         1260840.2500, 1259726.1250, 1249522.3750, 1244101.5000, 1241258.3750],
        [1250352.0000, 1239887.1250, 1225687.3750, 1224080.1250, 1223977.3750,
         1216216.3750, 1204340.7500, 1200910.3750, 1199928.1250, 1198051.7500],
        [1402804.5000, 1398650.1250, 1397281.0000, 1396564.2500, 1395479.1250,
         1394804.6250, 1393117.5000, 1392928.8750, 1390346.2500, 1389619.8750],
        [1306377.2500, 1296599.2500, 1295234.7500, 1294672.8750, 1293494.2500,
         1293410.3750, 1292954.0000, 1288343.3750, 1287907.1250, 1286707.7500],
        [1426173.3750, 1423356.7500, 1417188.5000, 1416771.0000, 1415394.7500,
         1414393.5000, 1414059.1250, 1413723.3750, 1413146.3750, 1412749.0000],
        [1324580.3750, 1323609.2500, 1318117.1250, 1308853.8750, 1308836.3750,
         1308437.0000, 1304976.3750, 1303975.0000, 1300014.1250, 1299812.0000],
        [1315037.1250, 1307249.6250, 1297472.5000, 1295017.3750, 1290649.1250,
         1289840.6250, 1289709.0000, 1288257.3750, 1288031.2500, 1286446.5000],
        [1441915.8750, 1434186.5000, 1430896.7500, 1429757.7500, 1427681.2500,
         1427019.6250, 1426374.7500, 1426287.7500, 1425272.0000, 1424971.6250],
        [1443043.8750, 1436168.3750, 1433709.2500, 1432703.2500, 1430216.0000,
         1429901.0000, 1427945.3750, 1427184.3750, 1427161.2500, 1426660.3750],
        [1434560.0000, 1433520.5000, 1432908.2500, 1432896.0000, 1431591.6250,
         1431553.2500, 1431087.8750, 1430340.1250, 1429858.7500, 1428915.3750],
        [1387371.3750, 1382057.5000, 1381921.7500, 1380025.2500, 1379801.5000,
         1378011.7500, 1375528.8750, 1375283.6250, 1375211.5000, 1374974.1250],
        [1363023.0000, 1361582.1250, 1360606.0000, 1359333.7500, 1355331.2500,
         1354242.0000, 1353583.5000, 1353504.7500, 1352906.0000, 1351900.1250],
        [1383464.6250, 1379125.3750, 1375176.0000, 1373109.3750, 1369336.7500,
         1369228.3750, 1368477.7500, 1368281.8750, 1367123.7500, 1364942.8750],
        [1419937.5000, 1415779.6250, 1412588.6250, 1410417.3750, 1407952.5000,
         1403346.5000, 1403329.1250, 1402788.5000, 1401585.0000, 1401196.1250],
        [1425191.7500, 1420267.8750, 1417929.2500, 1417690.0000, 1415818.7500,
         1413207.1250, 1411996.0000, 1409828.2500, 1409015.1250, 1407692.1250],
        [1363411.6250, 1361526.2500, 1359287.0000, 1356932.2500, 1356579.1250,
         1355088.2500, 1354566.2500, 1353153.7500, 1350897.2500, 1348130.2500],
        [1412871.5000, 1412379.7500, 1410036.6250, 1408283.0000, 1407869.3750,
         1403421.5000, 1403188.6250, 1403092.2500, 1401522.2500, 1399529.3750],
        [1452161.0000, 1448866.0000, 1448386.6250, 1447622.8750, 1446819.6250,
         1446819.6250, 1446214.0000, 1445825.1250, 1445610.0000, 1445258.5000],
        [1339270.3750, 1331512.0000, 1331294.8750, 1329991.7500, 1327134.5000,
         1326813.1250, 1323327.7500, 1322762.6250, 1322447.2500, 1322425.7500],
        [1440766.6250, 1436298.5000, 1436295.7500, 1434012.7500, 1432923.3750,
         1432625.5000, 1431419.5000, 1427379.0000, 1427040.1250, 1426811.5000],
        [1411826.3750, 1411584.0000, 1404980.2500, 1400473.3750, 1399931.2500,
         1398144.7500, 1393629.2500, 1393079.1250, 1390142.0000, 1390118.1250],
        [1445946.5000, 1443714.2500, 1442461.8750, 1441973.6250, 1440928.8750,
         1440048.2500, 1439959.0000, 1439247.8750, 1438502.6250, 1437962.3750],
        [1452276.0000, 1447515.2500, 1445665.2500, 1443925.0000, 1443547.7500,
         1440233.6250, 1439179.1250, 1438683.8750, 1438078.8750, 1435652.1250],
        [1451968.6250, 1449512.7500, 1445237.8750, 1443386.6250, 1442466.0000,
         1441980.5000, 1439864.3750, 1439626.7500, 1439005.0000, 1438041.7500],
        [1444637.1250, 1441407.2500, 1441254.6250, 1439739.2500, 1439500.3750,
         1438742.7500, 1437825.2500, 1437663.3750, 1436124.5000, 1435167.5000],
        [1450533.2500, 1449688.3750, 1444929.2500, 1443920.7500, 1443026.0000,
         1442814.1250, 1442658.6250, 1442112.6250, 1440552.3750, 1439125.6250],
        [1311286.3750, 1296753.8750, 1271582.5000, 1271401.8750, 1267729.6250,
         1259696.0000, 1254726.2500, 1249379.3750, 1248757.6250, 1246669.2500],
        [1391982.1250, 1387472.0000, 1386273.7500, 1385575.8750, 1383835.3750,
         1382845.8750, 1380913.8750, 1377177.5000, 1376553.7500, 1376122.0000],
        [1421723.3750, 1421285.5000, 1418350.0000, 1417400.6250, 1417396.6250,
         1416843.8750, 1415853.7500, 1415650.0000, 1415189.6250, 1414740.3750],
        [1412649.2500, 1400979.6250, 1397795.3750, 1396335.1250, 1393839.1250,
         1392497.2500, 1391787.0000, 1391224.2500, 1391070.3750, 1390016.1250],
        [1323863.1250, 1319031.2500, 1318840.1250, 1315853.8750, 1315335.7500,
         1314036.7500, 1313054.7500, 1311951.8750, 1311614.1250, 1305281.3750],
        [1378825.3750, 1370362.2500, 1366500.6250, 1366198.2500, 1365591.3750,
         1364988.5000, 1363250.3750, 1363009.8750, 1363004.7500, 1361791.1250],
        [1328214.5000, 1325008.6250, 1322019.7500, 1320491.3750, 1317091.7500,
         1309781.6250, 1308876.3750, 1303226.5000, 1302276.1250, 1302127.1250],
        [1408856.5000, 1408693.8750, 1404467.1250, 1396981.1250, 1396862.6250,
         1396392.3750, 1396026.2500, 1394307.1250, 1393836.5000, 1393291.6250],
        [1322506.5000, 1317074.1250, 1313843.8750, 1311597.8750, 1305576.3750,
         1301933.3750, 1300531.1250, 1300279.3750, 1297252.2500, 1294585.1250],
        [1449458.8750, 1445896.8750, 1443254.5000, 1441157.0000, 1440794.1250,
         1439650.0000, 1439007.7500, 1437459.1250, 1437063.0000, 1434837.7500],
        [1439201.1250, 1439059.7500, 1439028.2500, 1436860.2500, 1435812.2500,
         1435524.8750, 1435044.3750, 1433802.2500, 1433332.0000, 1432094.0000],
        [1427185.7500, 1426207.5000, 1426140.7500, 1425707.1250, 1424975.6250,
         1424777.2500, 1423670.3750, 1423354.1250, 1423150.3750, 1423128.7500],
        [1364352.0000, 1361651.0000, 1355137.3750, 1353684.3750, 1346815.6250,
         1344898.1250, 1343934.0000, 1340949.6250, 1340044.6250, 1338305.1250],
        [1249134.0000, 1239946.2500, 1232175.6250, 1227335.5000, 1224556.5000,
         1222197.3750, 1216911.3750, 1216686.2500, 1216449.5000, 1216345.1250],
        [1055409.2500, 1042751.2500, 1031019.6875,  996546.2500,  995249.7500,
          956225.5625,  942217.0625,  925695.1875,  920131.7500,  916749.9375],
        [1318318.2500, 1296788.3750, 1274028.5000, 1264902.5000, 1263581.1250,
         1257966.1250, 1247896.8750, 1246059.5000, 1244833.7500, 1240902.1250],
        [1322623.8750, 1321547.0000, 1317258.8750, 1314352.6250, 1313926.5000,
         1311422.7500, 1308036.5000, 1300141.7500, 1299530.6250, 1298809.5000],
        [1361235.3750, 1355783.7500, 1351669.2500, 1343330.3750, 1341518.8750,
         1339560.2500, 1339232.0000, 1336813.8750, 1334754.0000, 1333713.1250],
        [1333386.2500, 1327694.1250, 1327305.3750, 1324649.8750, 1319062.7500,
         1312930.7500, 1312415.0000, 1310953.8750, 1310930.1250, 1307657.5000],
        [1359504.7500, 1335767.6250, 1334476.5000, 1330544.8750, 1330492.7500,
         1330376.1250, 1329991.7500, 1328758.1250, 1327629.5000, 1327156.1250],
        [1298243.6250, 1283434.3750, 1279314.8750, 1276460.7500, 1275866.7500,
         1275427.6250, 1271440.6250, 1258141.2500, 1255723.3750, 1255443.2500],
        [1307004.1250, 1302585.5000, 1288380.2500, 1287252.7500, 1285569.6250,
         1285021.6250, 1276284.2500, 1274829.3750, 1270727.8750, 1269378.5000],
        [1424631.8750, 1420522.6250, 1413972.7500, 1412801.5000, 1412311.1250,
         1412055.2500, 1411191.0000, 1410549.1250, 1410398.5000, 1410223.6250],
        [1427218.3750, 1415107.3750, 1413103.3750, 1412200.6250, 1411095.5000,
         1410997.1250, 1408990.8750, 1408915.7500, 1408861.8750, 1407431.6250],
        [1261874.7500, 1258841.0000, 1258545.6250, 1255884.0000, 1239908.3750,
         1236014.7500, 1233756.0000, 1229349.2500, 1226040.5000, 1224910.3750],
        [1268230.2500, 1239460.3750, 1238560.0000, 1235431.5000, 1222379.3750,
         1219630.0000, 1210216.1250, 1210074.1250, 1208370.8750, 1208289.1250],
        [1317939.8750, 1311818.0000, 1300017.7500, 1298485.0000, 1294661.7500,
         1290789.5000, 1278186.8750, 1276649.5000, 1276096.8750, 1275314.6250],
        [1377718.6250, 1354624.5000, 1338552.7500, 1336909.6250, 1330581.5000,
         1329241.0000, 1326119.8750, 1325749.3750, 1322425.7500, 1320873.0000],
        [1314918.1250, 1302478.6250, 1290385.7500, 1271035.7500, 1259391.0000,
         1256227.6250, 1256176.2500, 1254497.7500, 1251410.1250, 1250076.5000],
        [1331656.7500, 1306045.8750, 1303349.6250, 1280025.2500, 1277463.0000,
         1274424.5000, 1268702.1250, 1266046.6250, 1265028.0000, 1262279.1250],
        [1338426.3750, 1332818.0000, 1329460.3750, 1329020.5000, 1325384.0000,
         1324900.0000, 1324767.3750, 1322406.8750, 1321195.3750, 1321093.5000],
        [1385265.3750, 1379893.6250, 1379322.6250, 1376085.2500, 1374420.8750,
         1373442.1250, 1372826.5000, 1372558.2500, 1372487.5000, 1371770.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1408428.0000,       0.0000],
         [1408001.0000,       0.0000],
         [      0.0000, 1407179.5000],
         ...,
         [1401011.7500,       0.0000],
         [1400749.8750,       0.0000],
         [1399234.5000,       0.0000]],

        [[1427419.8750,       0.0000],
         [1421379.0000,       0.0000],
         [1418386.3750,       0.0000],
         ...,
         [1407881.5000,       0.0000],
         [1406622.6250,       0.0000],
         [1405657.1250,       0.0000]],

        [[1305891.5000,       0.0000],
         [1299598.7500,       0.0000],
         [1297861.0000,       0.0000],
         ...,
         [1290138.3750,       0.0000],
         [      0.0000, 1285212.7500],
         [1280837.2500,       0.0000]],

        ...,

        [[1331656.7500,       0.0000],
         [1306045.8750,       0.0000],
         [1303349.6250,       0.0000],
         ...,
         [1266046.6250,       0.0000],
         [1265028.0000,       0.0000],
         [1262279.1250,       0.0000]],

        [[1338426.3750,       0.0000],
         [1332818.0000,       0.0000],
         [1329460.3750,       0.0000],
         ...,
         [1322406.8750,       0.0000],
         [      0.0000, 1321195.3750],
         [1321093.5000,       0.0000]],

        [[1385265.3750,       0.0000],
         [1379893.6250,       0.0000],
         [1379322.6250,       0.0000],
         ...,
         [1372558.2500,       0.0000],
         [1372487.5000,       0.0000],
         [1371770.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12633106.0000,  1407179.5000],
        [14125568.0000,        0.0000],
        [10354980.0000,  2575464.5000],
        [11921840.0000,  1321718.5000],
        [ 3587463.0000,  8444860.0000],
        [11065702.0000,  1234657.6250],
        [12663665.0000,        0.0000],
        [ 7314315.5000,  4869115.5000],
        [12555031.0000,  1396564.2500],
        [ 9057450.0000,  3878251.0000],
        [12750185.0000,  1416771.0000],
        [ 9172642.0000,  3928569.5000],
        [ 9080774.0000,  3866936.0000],
        [14294364.0000,        0.0000],
        [14314694.0000,        0.0000],
        [14317231.0000,        0.0000],
        [12408266.0000,  1381921.7500],
        [ 8139018.5000,  5426994.0000],
        [12343091.0000,  1375176.0000],
        [11263543.0000,  2815377.0000],
        [11311448.0000,  2837187.7500],
        [12204484.0000,  1355088.2500],
        [14062194.0000,        0.0000],
        [14473582.0000,        0.0000],
        [10622140.0000,  2654839.7500],
        [14325573.0000,        0.0000],
        [13993908.0000,        0.0000],
        [14410746.0000,        0.0000],
        [14424757.0000,        0.0000],
        [14431090.0000,        0.0000],
        [14392062.0000,        0.0000],
        [14439362.0000,        0.0000],
        [ 6323459.5000,  6354523.5000],
        [ 9683776.0000,  4144975.5000],
        [12756084.0000,  1418350.0000],
        [11168612.0000,  2789582.5000],
        [10523857.0000,  2625006.5000],
        [12300518.0000,  1363004.7500],
        [ 9201097.0000,  3938016.7500],
        [13989716.0000,        0.0000],
        [ 6534277.5000,  6530902.0000],
        [12959120.0000,  1449458.8750],
        [12920730.0000,  1439028.2500],
        [12824628.0000,  1423670.3750],
        [ 9437372.0000,  4052400.5000],
        [ 1216911.3750, 11044826.0000],
        [ 8726586.0000,  1055409.2500],
        [10156409.0000,  2498868.2500],
        [11796228.0000,  1311422.7500],
        [10767083.0000,  2670527.0000],
        [11876056.0000,  1310930.1250],
        [10678311.0000,  2656387.5000],
        [ 2527164.0000, 10202333.0000],
        [ 8993335.0000,  3853699.0000],
        [14138658.0000,        0.0000],
        [14123922.0000,        0.0000],
        [ 9907365.0000,  2517758.7500],
        [ 6095946.0000,  6164695.5000],
        [ 6450015.5000,  6469944.0000],
        [ 7987154.0000,  5375642.0000],
        [ 6326720.0000,  6379877.0000],
        [12835021.0000,        0.0000],
        [10623510.0000,  2645962.7500],
        [13758072.0000,        0.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 57.8125
Top1 accuracy for validation set is 57.8125 size is torch.Size([64, 1])
Epoch 31/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:56, 59.88s/it]  7%|▋         | 2/29 [01:00<11:20, 25.20s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 6.065765380859375
Epoch 32/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.87s/it]  7%|▋         | 2/29 [00:59<11:13, 24.93s/it] 10%|█         | 3/29 [01:00<06:03, 13.97s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.82s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 5.939088344573975
Epoch 33/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.23s/it]  7%|▋         | 2/29 [01:01<11:24, 25.34s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 5.851106643676758
Epoch 34/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:53, 57.63s/it]  7%|▋         | 2/29 [01:00<11:27, 25.48s/it] 10%|█         | 3/29 [01:01<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.12s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 5.759471416473389
Epoch 35/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:53, 61.91s/it]  7%|▋         | 2/29 [01:02<11:42, 26.03s/it] 10%|█         | 3/29 [01:03<06:18, 14.57s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.20s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 5.664917469024658
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0299, 0.0054, 0.0010,  ..., 0.0067, 0.0080, 0.0214],
        [0.0253, 0.0057, 0.0021,  ..., 0.0039, 0.0094, 0.0264],
        [0.0342, 0.0108, 0.0088,  ..., 0.0104, 0.0133, 0.0177],
        ...,
        [0.0278, 0.0126, 0.0017,  ..., 0.0024, 0.0073, 0.0228],
        [0.0232, 0.0107, 0.0008,  ..., 0.0027, 0.0082, 0.0199],
        [0.0263, 0.0095, 0.0020,  ..., 0.0047, 0.0108, 0.0244]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9926, 0.9926, 0.9922, 0.9922, 0.9921, 0.9921, 0.9919, 0.9919, 0.9919,
         0.9918],
        [0.9927, 0.9924, 0.9924, 0.9924, 0.9923, 0.9922, 0.9922, 0.9922, 0.9922,
         0.9922],
        [0.9874, 0.9873, 0.9861, 0.9860, 0.9859, 0.9855, 0.9855, 0.9854, 0.9853,
         0.9852],
        [0.9892, 0.9889, 0.9886, 0.9883, 0.9880, 0.9880, 0.9878, 0.9878, 0.9876,
         0.9876],
        [0.9851, 0.9834, 0.9826, 0.9820, 0.9815, 0.9805, 0.9802, 0.9801, 0.9799,
         0.9799],
        [0.9847, 0.9842, 0.9832, 0.9815, 0.9812, 0.9812, 0.9808, 0.9806, 0.9799,
         0.9797],
        [0.9875, 0.9851, 0.9843, 0.9843, 0.9835, 0.9834, 0.9825, 0.9823, 0.9815,
         0.9814],
        [0.9830, 0.9821, 0.9812, 0.9811, 0.9805, 0.9805, 0.9801, 0.9799, 0.9795,
         0.9794],
        [0.9917, 0.9916, 0.9916, 0.9915, 0.9914, 0.9914, 0.9913, 0.9912, 0.9912,
         0.9912],
        [0.9869, 0.9867, 0.9865, 0.9859, 0.9855, 0.9855, 0.9855, 0.9855, 0.9854,
         0.9852],
        [0.9928, 0.9926, 0.9925, 0.9924, 0.9924, 0.9923, 0.9923, 0.9923, 0.9923,
         0.9923],
        [0.9885, 0.9876, 0.9874, 0.9873, 0.9872, 0.9869, 0.9869, 0.9868, 0.9867,
         0.9866],
        [0.9875, 0.9870, 0.9869, 0.9865, 0.9864, 0.9861, 0.9861, 0.9860, 0.9858,
         0.9858],
        [0.9934, 0.9928, 0.9928, 0.9928, 0.9928, 0.9928, 0.9927, 0.9927, 0.9927,
         0.9927],
        [0.9935, 0.9935, 0.9934, 0.9932, 0.9932, 0.9932, 0.9931, 0.9931, 0.9931,
         0.9931],
        [0.9938, 0.9934, 0.9934, 0.9933, 0.9933, 0.9933, 0.9932, 0.9932, 0.9931,
         0.9931],
        [0.9909, 0.9909, 0.9908, 0.9907, 0.9906, 0.9905, 0.9904, 0.9904, 0.9904,
         0.9904],
        [0.9920, 0.9918, 0.9907, 0.9907, 0.9906, 0.9905, 0.9904, 0.9904, 0.9904,
         0.9903],
        [0.9917, 0.9913, 0.9912, 0.9911, 0.9909, 0.9907, 0.9907, 0.9906, 0.9906,
         0.9905],
        [0.9928, 0.9927, 0.9925, 0.9924, 0.9924, 0.9923, 0.9922, 0.9921, 0.9921,
         0.9921],
        [0.9929, 0.9927, 0.9927, 0.9927, 0.9925, 0.9924, 0.9924, 0.9924, 0.9924,
         0.9924],
        [0.9902, 0.9892, 0.9891, 0.9889, 0.9889, 0.9888, 0.9888, 0.9887, 0.9887,
         0.9887],
        [0.9922, 0.9922, 0.9921, 0.9920, 0.9919, 0.9917, 0.9916, 0.9915, 0.9915,
         0.9913],
        [0.9936, 0.9933, 0.9932, 0.9931, 0.9931, 0.9931, 0.9930, 0.9930, 0.9930,
         0.9930],
        [0.9899, 0.9894, 0.9893, 0.9891, 0.9891, 0.9890, 0.9888, 0.9888, 0.9887,
         0.9886],
        [0.9932, 0.9931, 0.9931, 0.9931, 0.9930, 0.9929, 0.9929, 0.9929, 0.9928,
         0.9928],
        [0.9935, 0.9927, 0.9926, 0.9925, 0.9925, 0.9925, 0.9924, 0.9923, 0.9922,
         0.9921],
        [0.9936, 0.9934, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9932, 0.9931,
         0.9931],
        [0.9938, 0.9936, 0.9936, 0.9935, 0.9934, 0.9934, 0.9933, 0.9933, 0.9933,
         0.9932],
        [0.9945, 0.9942, 0.9942, 0.9942, 0.9942, 0.9941, 0.9940, 0.9940, 0.9940,
         0.9939],
        [0.9941, 0.9941, 0.9938, 0.9938, 0.9937, 0.9936, 0.9936, 0.9936, 0.9936,
         0.9935],
        [0.9941, 0.9940, 0.9939, 0.9938, 0.9938, 0.9938, 0.9938, 0.9938, 0.9937,
         0.9936],
        [0.9864, 0.9858, 0.9857, 0.9849, 0.9843, 0.9838, 0.9836, 0.9835, 0.9833,
         0.9832],
        [0.9919, 0.9919, 0.9918, 0.9918, 0.9918, 0.9918, 0.9916, 0.9915, 0.9914,
         0.9914],
        [0.9932, 0.9928, 0.9927, 0.9927, 0.9926, 0.9926, 0.9925, 0.9925, 0.9925,
         0.9924],
        [0.9924, 0.9921, 0.9919, 0.9918, 0.9917, 0.9916, 0.9915, 0.9915, 0.9914,
         0.9914],
        [0.9876, 0.9869, 0.9868, 0.9866, 0.9865, 0.9865, 0.9864, 0.9863, 0.9861,
         0.9861],
        [0.9909, 0.9905, 0.9904, 0.9904, 0.9903, 0.9900, 0.9900, 0.9899, 0.9899,
         0.9898],
        [0.9876, 0.9873, 0.9872, 0.9871, 0.9868, 0.9868, 0.9867, 0.9867, 0.9867,
         0.9865],
        [0.9927, 0.9927, 0.9924, 0.9924, 0.9922, 0.9919, 0.9919, 0.9919, 0.9918,
         0.9917],
        [0.9863, 0.9856, 0.9852, 0.9850, 0.9849, 0.9846, 0.9845, 0.9844, 0.9841,
         0.9841],
        [0.9938, 0.9936, 0.9935, 0.9935, 0.9935, 0.9934, 0.9934, 0.9934, 0.9933,
         0.9933],
        [0.9935, 0.9934, 0.9933, 0.9933, 0.9932, 0.9931, 0.9931, 0.9931, 0.9930,
         0.9930],
        [0.9932, 0.9932, 0.9931, 0.9931, 0.9930, 0.9930, 0.9929, 0.9929, 0.9928,
         0.9928],
        [0.9904, 0.9903, 0.9896, 0.9894, 0.9893, 0.9893, 0.9892, 0.9892, 0.9891,
         0.9891],
        [0.9819, 0.9818, 0.9812, 0.9811, 0.9811, 0.9810, 0.9809, 0.9809, 0.9808,
         0.9808],
        [0.9731, 0.9689, 0.9664, 0.9660, 0.9657, 0.9632, 0.9623, 0.9612, 0.9566,
         0.9559],
        [0.9870, 0.9858, 0.9826, 0.9817, 0.9807, 0.9805, 0.9803, 0.9798, 0.9797,
         0.9788],
        [0.9879, 0.9877, 0.9875, 0.9868, 0.9865, 0.9864, 0.9861, 0.9859, 0.9859,
         0.9859],
        [0.9900, 0.9893, 0.9891, 0.9886, 0.9886, 0.9886, 0.9886, 0.9884, 0.9884,
         0.9884],
        [0.9880, 0.9880, 0.9878, 0.9877, 0.9876, 0.9872, 0.9872, 0.9871, 0.9871,
         0.9871],
        [0.9885, 0.9885, 0.9884, 0.9884, 0.9883, 0.9881, 0.9880, 0.9880, 0.9878,
         0.9878],
        [0.9874, 0.9865, 0.9863, 0.9863, 0.9862, 0.9860, 0.9860, 0.9851, 0.9850,
         0.9850],
        [0.9869, 0.9859, 0.9856, 0.9847, 0.9846, 0.9846, 0.9845, 0.9842, 0.9838,
         0.9836],
        [0.9913, 0.9913, 0.9912, 0.9912, 0.9910, 0.9910, 0.9909, 0.9909, 0.9909,
         0.9909],
        [0.9919, 0.9918, 0.9918, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916,
         0.9915],
        [0.9847, 0.9839, 0.9831, 0.9831, 0.9830, 0.9828, 0.9827, 0.9826, 0.9822,
         0.9818],
        [0.9837, 0.9832, 0.9819, 0.9814, 0.9812, 0.9803, 0.9802, 0.9801, 0.9799,
         0.9798],
        [0.9876, 0.9865, 0.9863, 0.9857, 0.9855, 0.9849, 0.9845, 0.9845, 0.9842,
         0.9838],
        [0.9889, 0.9881, 0.9880, 0.9879, 0.9878, 0.9877, 0.9876, 0.9876, 0.9876,
         0.9876],
        [0.9857, 0.9847, 0.9846, 0.9842, 0.9841, 0.9838, 0.9835, 0.9834, 0.9833,
         0.9827],
        [0.9901, 0.9891, 0.9890, 0.9889, 0.9887, 0.9886, 0.9886, 0.9885, 0.9885,
         0.9885],
        [0.9910, 0.9903, 0.9895, 0.9894, 0.9893, 0.9893, 0.9892, 0.9891, 0.9891,
         0.9891],
        [0.9913, 0.9907, 0.9904, 0.9904, 0.9903, 0.9903, 0.9901, 0.9900, 0.9900,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 1, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 1, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 0, 0, 1],
        [1, 1, 1, 0, 0, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 1, 1, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1439819.0000, 1438881.3750, 1432266.1250, 1432195.1250, 1430356.3750,
         1429843.7500, 1425773.6250, 1425492.2500, 1425145.6250, 1424039.6250],
        [1441141.8750, 1435967.1250, 1435563.1250, 1435229.1250, 1433926.6250,
         1432583.1250, 1432218.2500, 1432218.2500, 1431967.1250, 1431913.7500],
        [1337002.6250, 1334201.6250, 1312115.7500, 1310246.5000, 1307964.2500,
         1300401.0000, 1300262.1250, 1299864.1250, 1298048.0000, 1294949.5000],
        [1372355.3750, 1365066.5000, 1359854.8750, 1353630.1250, 1348948.1250,
         1347915.5000, 1344805.7500, 1344776.2500, 1340080.3750, 1339707.2500],
        [1293290.7500, 1262706.6250, 1248364.6250, 1237984.8750, 1229112.5000,
         1211812.2500, 1206712.6250, 1204332.7500, 1201294.1250, 1201188.7500],
        [1286802.2500, 1277219.3750, 1259490.6250, 1229106.5000, 1223137.2500,
         1223122.1250, 1217013.5000, 1213747.2500, 1201366.2500, 1196909.6250],
        [1339214.2500, 1293579.3750, 1279268.6250, 1279063.7500, 1263372.6250,
         1261978.2500, 1245937.0000, 1243562.8750, 1228026.3750, 1226875.6250],
        [1254801.6250, 1238602.5000, 1223196.7500, 1221215.2500, 1210791.0000,
         1210481.6250, 1203724.1250, 1201082.2500, 1193448.1250, 1192091.1250],
        [1420630.8750, 1419393.1250, 1418427.0000, 1418245.7500, 1415034.5000,
         1414902.2500, 1413296.1250, 1412233.0000, 1410886.8750, 1410333.8750],
        [1327013.0000, 1322541.8750, 1319421.2500, 1308333.5000, 1301783.2500,
         1300624.2500, 1300619.2500, 1300079.7500, 1298665.8750, 1295427.5000],
        [1443688.1250, 1440092.2500, 1437697.7500, 1435704.1250, 1435567.1250,
         1434614.7500, 1434246.7500, 1433289.6250, 1432999.8750, 1432969.7500],
        [1358123.5000, 1340985.5000, 1335749.8750, 1335619.8750, 1332750.6250,
         1327723.1250, 1327019.3750, 1324750.8750, 1322819.3750, 1322369.1250],
        [1339509.2500, 1328176.6250, 1327308.0000, 1318724.3750, 1317980.1250,
         1312709.1250, 1312587.7500, 1309770.3750, 1306427.1250, 1306276.2500],
        [1455857.8750, 1444581.8750, 1444466.2500, 1444115.0000, 1443459.6250,
         1442957.2500, 1442261.0000, 1442189.5000, 1442126.2500, 1440889.1250],
        [1458310.3750, 1457377.5000, 1456303.5000, 1452134.6250, 1452053.0000,
         1451799.5000, 1450743.5000, 1450501.3750, 1450068.6250, 1450046.3750],
        [1465430.2500, 1456734.1250, 1456392.3750, 1454879.2500, 1454335.3750,
         1453456.3750, 1451871.6250, 1451652.8750, 1450998.1250, 1450988.5000],
        [1404977.5000, 1404546.1250, 1403591.5000, 1401149.3750, 1400182.2500,
         1396656.1250, 1395544.3750, 1395195.7500, 1394888.3750, 1394680.8750],
        [1426600.5000, 1422439.5000, 1402040.8750, 1401611.7500, 1399633.5000,
         1397259.6250, 1395909.0000, 1395543.0000, 1394763.3750, 1393828.5000],
        [1421309.7500, 1412747.6250, 1410503.3750, 1410066.2500, 1406150.3750,
         1402178.6250, 1401782.8750, 1399003.7500, 1398666.2500, 1397340.8750],
        [1442892.6250, 1440997.5000, 1438517.7500, 1436253.2500, 1435676.7500,
         1434586.0000, 1432171.8750, 1430486.1250, 1430201.0000, 1429217.8750],
        [1445282.0000, 1441854.0000, 1441698.6250, 1441221.6250, 1438491.7500,
         1436693.1250, 1435323.6250, 1435275.6250, 1435073.1250, 1435058.0000],
        [1390916.5000, 1372169.6250, 1369091.2500, 1366307.8750, 1366198.2500,
         1363692.5000, 1363056.7500, 1362387.3750, 1362209.5000, 1362011.8750],
        [1431126.0000, 1430768.5000, 1430527.0000, 1428027.1250, 1424862.8750,
         1422033.8750, 1419557.0000, 1417422.3750, 1417079.1250, 1414053.7500],
        [1459668.3750, 1454603.2500, 1452433.7500, 1450580.2500, 1450520.8750,
         1450117.0000, 1448953.0000, 1448012.2500, 1447988.8750, 1447618.7500],
        [1385568.0000, 1375568.1250, 1374132.5000, 1369588.8750, 1369173.5000,
         1367350.6250, 1364503.0000, 1363084.0000, 1361406.8750, 1359289.6250],
        [1452089.0000, 1450241.5000, 1450034.0000, 1449792.0000, 1447645.0000,
         1446030.6250, 1445501.1250, 1445167.5000, 1443838.2500, 1443827.1250],
        [1458443.8750, 1441288.8750, 1439924.7500, 1438379.2500, 1436878.0000,
         1436778.0000, 1435791.7500, 1433174.7500, 1432143.1250, 1430049.6250],
        [1461341.1250, 1455417.7500, 1455005.5000, 1454601.7500, 1454526.8750,
         1454393.7500, 1453645.0000, 1452864.7500, 1451043.8750, 1450083.7500],
        [1464681.3750, 1461155.7500, 1459903.7500, 1458075.3750, 1455743.8750,
         1455441.2500, 1454944.5000, 1454822.3750, 1453597.7500, 1453118.2500],
        [1479966.5000, 1473746.8750, 1472624.2500, 1472205.8750, 1472196.0000,
         1470780.0000, 1469411.7500, 1469036.2500, 1468274.2500, 1467732.5000],
        [1471123.7500, 1469965.3750, 1465315.7500, 1464273.6250, 1462192.8750,
         1461452.7500, 1460856.2500, 1460839.5000, 1460083.2500, 1459156.2500],
        [1470042.5000, 1468160.8750, 1466543.1250, 1464833.6250, 1464735.8750,
         1464696.7500, 1464332.2500, 1464235.8750, 1462845.7500, 1461247.7500],
        [1317939.8750, 1307319.5000, 1303951.3750, 1288940.6250, 1278268.5000,
         1269642.5000, 1266137.1250, 1264680.6250, 1260855.8750, 1259221.6250],
        [1425102.1250, 1424928.1250, 1423515.5000, 1422963.1250, 1422657.8750,
         1422625.2500, 1419578.6250, 1417457.5000, 1415779.6250, 1415079.0000],
        [1452384.0000, 1443411.3750, 1441885.6250, 1440920.6250, 1440757.1250,
         1438891.0000, 1437688.1250, 1437333.1250, 1436972.5000, 1435757.6250],
        [1435433.0000, 1430093.2500, 1425738.2500, 1423244.1250, 1421825.0000,
         1420355.8750, 1417817.1250, 1416873.6250, 1416275.1250, 1415652.7500],
        [1339704.7500, 1327396.5000, 1325721.5000, 1322420.7500, 1320531.6250,
         1320365.3750, 1317589.2500, 1315329.3750, 1311848.0000, 1311821.7500],
        [1405430.5000, 1397013.1250, 1395795.8750, 1395258.2500, 1392982.0000,
         1387051.2500, 1386781.5000, 1385365.7500, 1384917.8750, 1384038.5000],
        [1340906.2500, 1334220.7500, 1332877.8750, 1330967.3750, 1325788.5000,
         1325381.5000, 1323750.7500, 1323541.1250, 1323085.5000, 1319832.8750],
        [1442043.8750, 1440960.5000, 1435337.2500, 1435303.0000, 1431826.3750,
         1426425.1250, 1426406.0000, 1424826.2500, 1423468.0000, 1421899.6250],
        [1315066.1250, 1302635.1250, 1294960.6250, 1291114.5000, 1289562.7500,
         1283986.5000, 1281696.2500, 1280413.3750, 1275796.2500, 1274693.2500],
        [1464325.2500, 1460250.3750, 1458841.7500, 1458637.2500, 1457374.7500,
         1457125.8750, 1456368.7500, 1456002.1250, 1455122.1250, 1454750.2500],
        [1457745.8750, 1456435.5000, 1454134.3750, 1453265.1250, 1452255.2500,
         1450740.7500, 1449646.8750, 1449084.2500, 1448707.1250, 1448552.3750],
        [1452161.0000, 1451239.0000, 1450067.1250, 1449160.2500, 1448441.8750,
         1447941.7500, 1446629.1250, 1445390.8750, 1444737.6250, 1444581.8750],
        [1394863.0000, 1393611.8750, 1379447.6250, 1376175.7500, 1373494.5000,
         1373003.3750, 1371277.3750, 1370644.5000, 1369708.8750, 1369571.8750],
        [1235816.7500, 1233583.1250, 1223721.7500, 1222448.1250, 1221705.7500,
         1220299.0000, 1218994.0000, 1218434.8750, 1216740.7500, 1215903.2500],
        [1089005.0000, 1025797.0625,  990083.8125,  984539.8125,  979733.0000,
          945449.3750,  934551.3125,  919241.5000,  861337.4375,  852131.0625],
        [1329651.7500, 1306243.8750, 1247463.7500, 1231800.8750, 1214958.6250,
         1211083.1250, 1207198.3750, 1199975.0000, 1197508.0000, 1181939.1250],
        [1346081.1250, 1341709.5000, 1338231.1250, 1324838.1250, 1320359.1250,
         1317525.2500, 1311983.2500, 1309232.1250, 1307702.2500, 1307537.7500],
        [1386522.3750, 1373621.5000, 1368762.2500, 1360781.1250, 1360079.2500,
         1359819.8750, 1359410.1250, 1356802.8750, 1356646.3750, 1356063.1250],
        [1348144.3750, 1348071.1250, 1344971.2500, 1342925.6250, 1339905.3750,
         1333471.5000, 1332328.7500, 1331429.5000, 1330355.7500, 1330339.2500],
        [1357359.5000, 1356990.6250, 1356370.7500, 1355456.7500, 1354050.8750,
         1350867.7500, 1348620.1250, 1348573.8750, 1344731.3750, 1344539.0000],
        [1337290.8750, 1319454.0000, 1315643.1250, 1314973.2500, 1313352.7500,
         1310503.8750, 1310021.5000, 1293660.8750, 1291327.3750, 1290944.5000],
        [1327866.2500, 1307812.1250, 1302750.6250, 1285672.5000, 1283837.1250,
         1283583.7500, 1282582.7500, 1276837.0000, 1270431.0000, 1266266.3750],
        [1412867.5000, 1412867.5000, 1411577.3750, 1411193.6250, 1407249.2500,
         1406679.0000, 1405993.6250, 1405792.5000, 1404830.2500, 1404598.3750],
        [1425301.8750, 1424118.3750, 1423880.8750, 1420001.0000, 1419562.3750,
         1419096.8750, 1419030.5000, 1418958.7500, 1418505.5000, 1417488.6250],
        [1286985.1250, 1272241.1250, 1257089.3750, 1257076.2500, 1254661.6250,
         1251702.5000, 1250539.2500, 1248186.1250, 1240331.8750, 1234412.7500],
        [1268723.7500, 1259152.0000, 1235331.3750, 1227651.6250, 1222862.0000,
         1206927.8750, 1205673.8750, 1205098.0000, 1200146.7500, 1199287.3750],
        [1340772.0000, 1318716.8750, 1316328.3750, 1305399.6250, 1301309.1250,
         1289460.6250, 1282634.2500, 1282134.0000, 1277795.6250, 1269027.5000],
        [1364827.0000, 1349752.5000, 1348507.1250, 1345507.5000, 1343991.6250,
         1342713.0000, 1341227.2500, 1341159.5000, 1341073.7500, 1340747.7500],
        [1304768.6250, 1286781.3750, 1284638.1250, 1276414.5000, 1275820.6250,
         1270079.7500, 1263476.2500, 1262438.1250, 1261203.3750, 1250416.3750],
        [1389058.0000, 1370423.7500, 1366649.1250, 1366060.2500, 1361110.7500,
         1360560.6250, 1358852.8750, 1358286.6250, 1358188.2500, 1357689.6250],
        [1406657.5000, 1393554.7500, 1377984.1250, 1376203.3750, 1373632.1250,
         1372850.1250, 1370662.8750, 1370095.7500, 1369514.3750, 1369330.1250],
        [1413240.7500, 1401500.7500, 1396030.1250, 1394563.8750, 1394038.6250,
         1392603.5000, 1389297.8750, 1388037.1250, 1387192.7500, 1385225.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1439819.0000,       0.0000],
         [1438881.3750,       0.0000],
         [1432266.1250,       0.0000],
         ...,
         [1425492.2500,       0.0000],
         [1425145.6250,       0.0000],
         [1424039.6250,       0.0000]],

        [[1441141.8750,       0.0000],
         [1435967.1250,       0.0000],
         [1435563.1250,       0.0000],
         ...,
         [1432218.2500,       0.0000],
         [1431967.1250,       0.0000],
         [1431913.7500,       0.0000]],

        [[      0.0000, 1337002.6250],
         [      0.0000, 1334201.6250],
         [1312115.7500,       0.0000],
         ...,
         [      0.0000, 1299864.1250],
         [      0.0000, 1298048.0000],
         [1294949.5000,       0.0000]],

        ...,

        [[1389058.0000,       0.0000],
         [1370423.7500,       0.0000],
         [1366649.1250,       0.0000],
         ...,
         [1358286.6250,       0.0000],
         [1358188.2500,       0.0000],
         [1357689.6250,       0.0000]],

        [[1406657.5000,       0.0000],
         [1393554.7500,       0.0000],
         [1377984.1250,       0.0000],
         ...,
         [1370095.7500,       0.0000],
         [1369514.3750,       0.0000],
         [1369330.1250,       0.0000]],

        [[1413240.7500,       0.0000],
         [1401500.7500,       0.0000],
         [1396030.1250,       0.0000],
         ...,
         [1388037.1250,       0.0000],
         [1387192.7500,       0.0000],
         [1385225.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12871618.0000,  1432195.1250],
        [14342730.0000,        0.0000],
        [ 5217574.0000,  7877481.5000],
        [13517140.0000,        0.0000],
        [ 3619713.5000,  8677086.0000],
        [ 9871514.0000,  2456400.2500],
        [12660878.0000,        0.0000],
        [ 6060054.0000,  6089380.0000],
        [11322905.0000,  2830478.7500],
        [11774430.0000,  1300079.7500],
        [12925304.0000,  1435567.1250],
        [12005092.0000,  1322819.3750],
        [10555213.0000,  2624256.5000],
        [14442904.0000,        0.0000],
        [14529339.0000,        0.0000],
        [13092404.0000,  1454335.3750],
        [12590263.0000,  1401149.3750],
        [ 9838544.0000,  4191085.5000],
        [12649246.0000,  1410503.3750],
        [11480738.0000,  2870262.7500],
        [11508794.0000,  2877177.5000],
        [13678041.0000,        0.0000],
        [14235458.0000,        0.0000],
        [14510496.0000,        0.0000],
        [10939965.0000,  2749700.5000],
        [14474166.0000,        0.0000],
        [14382852.0000,        0.0000],
        [14542924.0000,        0.0000],
        [14571484.0000,        0.0000],
        [14715974.0000,        0.0000],
        [14635259.0000,        0.0000],
        [14651674.0000,        0.0000],
        [ 6377261.5000,  6439696.0000],
        [ 9949020.0000,  4260667.5000],
        [12965081.0000,  1440920.6250],
        [14223308.0000,        0.0000],
        [ 6619974.0000,  6592755.0000],
        [12521653.0000,  1392982.0000],
        [ 9292819.0000,  3987533.0000],
        [14308495.0000,        0.0000],
        [ 7748868.5000,  5141057.0000],
        [13119956.0000,  1458841.7500],
        [14520566.0000,        0.0000],
        [14480350.0000,        0.0000],
        [12395622.0000,  1376175.7500],
        [ 1221705.7500, 11005942.0000],
        [ 6691381.5000,  2890488.0000],
        [ 6210355.5000,  6117467.0000],
        [ 9245048.0000,  3980151.5000],
        [13638509.0000,        0.0000],
        [12051603.0000,  1330339.2500],
        [10803210.0000,  2714350.0000],
        [ 5189285.5000,  7907887.0000],
        [ 9042548.0000,  3845092.2500],
        [14083649.0000,        0.0000],
        [14205946.0000,        0.0000],
        [10009152.0000,  2544074.5000],
        [ 4835034.5000,  7395820.0000],
        [ 3888842.5000,  9094735.0000],
        [ 8071699.0000,  5387808.0000],
        [ 6377177.0000,  6358860.0000],
        [13646880.0000,        0.0000],
        [12407635.0000,  1372850.1250],
        [12549127.0000,  1392603.5000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 53.125
Top1 accuracy for validation set is 53.125 size is torch.Size([64, 1])
Epoch 36/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:05, 58.04s/it]  7%|▋         | 2/29 [00:58<10:59, 24.44s/it] 10%|█         | 3/29 [01:00<06:01, 13.90s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.78s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.95s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 5.625999927520752
Epoch 37/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:42, 57.24s/it]  7%|▋         | 2/29 [00:58<10:51, 24.12s/it] 10%|█         | 3/29 [00:59<05:51, 13.52s/it] 14%|█▍        | 4/29 [01:00<03:33,  8.55s/it] 17%|█▋        | 5/29 [01:00<02:19,  5.80s/it] 21%|██        | 6/29 [01:01<01:35,  4.14s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.09s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.40s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.08s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.06it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.87s/it]
Epoch loss is 5.569889068603516
Epoch 38/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:19, 58.57s/it]  7%|▋         | 2/29 [00:59<11:10, 24.82s/it] 10%|█         | 3/29 [01:00<06:01, 13.91s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.78s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.95s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 5.573665618896484
Epoch 39/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:03, 57.99s/it]  7%|▋         | 2/29 [00:58<10:59, 24.42s/it] 10%|█         | 3/29 [01:00<06:05, 14.04s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.86s/it] 17%|█▋        | 5/29 [01:02<02:23,  6.00s/it] 21%|██        | 6/29 [01:03<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 5.530132293701172
Epoch 40/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:13, 60.47s/it]  7%|▋         | 2/29 [01:01<11:26, 25.44s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 5.5456862449646
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0281, 0.0060, 0.0006,  ..., 0.0043, 0.0053, 0.0190],
        [0.0246, 0.0061, 0.0004,  ..., 0.0033, 0.0065, 0.0253],
        [0.0358, 0.0110, 0.0081,  ..., 0.0102, 0.0131, 0.0173],
        ...,
        [0.0237, 0.0105, 0.0007,  ..., 0.0035, 0.0047, 0.0262],
        [0.0197, 0.0090, 0.0007,  ..., 0.0025, 0.0077, 0.0204],
        [0.0255, 0.0091, 0.0010,  ..., 0.0030, 0.0061, 0.0264]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9928, 0.9923, 0.9923, 0.9921, 0.9921, 0.9921, 0.9921, 0.9921, 0.9920,
         0.9920],
        [0.9936, 0.9930, 0.9928, 0.9926, 0.9926, 0.9926, 0.9925, 0.9925, 0.9925,
         0.9925],
        [0.9851, 0.9851, 0.9850, 0.9841, 0.9840, 0.9837, 0.9837, 0.9836, 0.9836,
         0.9835],
        [0.9888, 0.9882, 0.9882, 0.9878, 0.9874, 0.9873, 0.9872, 0.9872, 0.9872,
         0.9870],
        [0.9844, 0.9835, 0.9831, 0.9813, 0.9794, 0.9789, 0.9786, 0.9786, 0.9786,
         0.9784],
        [0.9844, 0.9831, 0.9819, 0.9815, 0.9812, 0.9810, 0.9803, 0.9784, 0.9779,
         0.9776],
        [0.9846, 0.9844, 0.9841, 0.9836, 0.9835, 0.9835, 0.9834, 0.9833, 0.9817,
         0.9817],
        [0.9821, 0.9806, 0.9803, 0.9791, 0.9787, 0.9782, 0.9775, 0.9774, 0.9774,
         0.9772],
        [0.9919, 0.9919, 0.9918, 0.9918, 0.9917, 0.9917, 0.9917, 0.9916, 0.9916,
         0.9915],
        [0.9884, 0.9863, 0.9863, 0.9862, 0.9861, 0.9859, 0.9858, 0.9856, 0.9856,
         0.9856],
        [0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932, 0.9931, 0.9930,
         0.9930],
        [0.9885, 0.9881, 0.9880, 0.9876, 0.9872, 0.9870, 0.9867, 0.9866, 0.9865,
         0.9864],
        [0.9868, 0.9868, 0.9867, 0.9861, 0.9860, 0.9859, 0.9858, 0.9858, 0.9857,
         0.9856],
        [0.9940, 0.9940, 0.9938, 0.9938, 0.9937, 0.9936, 0.9936, 0.9935, 0.9935,
         0.9935],
        [0.9938, 0.9937, 0.9936, 0.9935, 0.9935, 0.9935, 0.9934, 0.9934, 0.9934,
         0.9934],
        [0.9945, 0.9940, 0.9938, 0.9937, 0.9937, 0.9937, 0.9937, 0.9936, 0.9936,
         0.9936],
        [0.9916, 0.9911, 0.9910, 0.9910, 0.9910, 0.9909, 0.9906, 0.9906, 0.9906,
         0.9906],
        [0.9921, 0.9916, 0.9915, 0.9913, 0.9909, 0.9907, 0.9907, 0.9905, 0.9904,
         0.9904],
        [0.9914, 0.9914, 0.9913, 0.9911, 0.9910, 0.9909, 0.9908, 0.9908, 0.9908,
         0.9907],
        [0.9930, 0.9930, 0.9928, 0.9928, 0.9927, 0.9927, 0.9927, 0.9926, 0.9925,
         0.9925],
        [0.9931, 0.9930, 0.9930, 0.9930, 0.9930, 0.9929, 0.9929, 0.9929, 0.9928,
         0.9927],
        [0.9907, 0.9903, 0.9900, 0.9898, 0.9897, 0.9896, 0.9894, 0.9892, 0.9891,
         0.9889],
        [0.9939, 0.9932, 0.9932, 0.9930, 0.9930, 0.9929, 0.9928, 0.9928, 0.9927,
         0.9927],
        [0.9945, 0.9944, 0.9944, 0.9943, 0.9943, 0.9943, 0.9942, 0.9942, 0.9941,
         0.9941],
        [0.9903, 0.9899, 0.9899, 0.9899, 0.9897, 0.9896, 0.9895, 0.9895, 0.9895,
         0.9894],
        [0.9940, 0.9940, 0.9936, 0.9935, 0.9935, 0.9935, 0.9935, 0.9934, 0.9934,
         0.9934],
        [0.9935, 0.9935, 0.9935, 0.9935, 0.9932, 0.9931, 0.9931, 0.9927, 0.9926,
         0.9926],
        [0.9948, 0.9945, 0.9945, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9944, 0.9944, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9946, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943, 0.9943, 0.9943, 0.9942,
         0.9942],
        [0.9948, 0.9947, 0.9946, 0.9945, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944,
         0.9943],
        [0.9946, 0.9945, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942, 0.9942, 0.9942,
         0.9942],
        [0.9862, 0.9845, 0.9840, 0.9832, 0.9830, 0.9826, 0.9824, 0.9815, 0.9812,
         0.9809],
        [0.9920, 0.9919, 0.9918, 0.9918, 0.9918, 0.9918, 0.9917, 0.9917, 0.9917,
         0.9917],
        [0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9933, 0.9932, 0.9930, 0.9930,
         0.9929],
        [0.9923, 0.9922, 0.9921, 0.9919, 0.9918, 0.9918, 0.9917, 0.9917, 0.9917,
         0.9916],
        [0.9870, 0.9866, 0.9863, 0.9853, 0.9850, 0.9850, 0.9849, 0.9848, 0.9847,
         0.9847],
        [0.9911, 0.9907, 0.9906, 0.9906, 0.9905, 0.9904, 0.9903, 0.9901, 0.9901,
         0.9901],
        [0.9885, 0.9882, 0.9880, 0.9880, 0.9879, 0.9876, 0.9873, 0.9872, 0.9871,
         0.9870],
        [0.9931, 0.9931, 0.9929, 0.9929, 0.9928, 0.9927, 0.9927, 0.9927, 0.9926,
         0.9926],
        [0.9856, 0.9855, 0.9848, 0.9846, 0.9844, 0.9841, 0.9838, 0.9834, 0.9830,
         0.9830],
        [0.9940, 0.9939, 0.9939, 0.9939, 0.9939, 0.9939, 0.9938, 0.9937, 0.9937,
         0.9937],
        [0.9938, 0.9936, 0.9935, 0.9935, 0.9934, 0.9934, 0.9934, 0.9934, 0.9934,
         0.9933],
        [0.9936, 0.9934, 0.9934, 0.9934, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932,
         0.9932],
        [0.9908, 0.9904, 0.9902, 0.9899, 0.9898, 0.9898, 0.9897, 0.9896, 0.9896,
         0.9896],
        [0.9814, 0.9814, 0.9810, 0.9806, 0.9805, 0.9802, 0.9802, 0.9801, 0.9797,
         0.9795],
        [0.9747, 0.9698, 0.9689, 0.9682, 0.9671, 0.9668, 0.9636, 0.9533, 0.9531,
         0.9530],
        [0.9877, 0.9859, 0.9794, 0.9763, 0.9759, 0.9756, 0.9750, 0.9746, 0.9743,
         0.9741],
        [0.9876, 0.9870, 0.9867, 0.9866, 0.9865, 0.9863, 0.9859, 0.9857, 0.9855,
         0.9855],
        [0.9889, 0.9887, 0.9885, 0.9884, 0.9882, 0.9881, 0.9881, 0.9879, 0.9879,
         0.9879],
        [0.9882, 0.9880, 0.9879, 0.9877, 0.9874, 0.9872, 0.9872, 0.9871, 0.9870,
         0.9870],
        [0.9895, 0.9887, 0.9882, 0.9882, 0.9881, 0.9881, 0.9881, 0.9881, 0.9879,
         0.9878],
        [0.9884, 0.9879, 0.9873, 0.9872, 0.9871, 0.9870, 0.9870, 0.9869, 0.9867,
         0.9860],
        [0.9876, 0.9870, 0.9870, 0.9853, 0.9852, 0.9849, 0.9843, 0.9842, 0.9837,
         0.9835],
        [0.9921, 0.9920, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916, 0.9915, 0.9915,
         0.9914],
        [0.9920, 0.9920, 0.9918, 0.9918, 0.9917, 0.9917, 0.9917, 0.9917, 0.9916,
         0.9916],
        [0.9837, 0.9835, 0.9833, 0.9832, 0.9829, 0.9828, 0.9824, 0.9819, 0.9814,
         0.9811],
        [0.9855, 0.9830, 0.9819, 0.9813, 0.9813, 0.9811, 0.9798, 0.9796, 0.9794,
         0.9793],
        [0.9868, 0.9867, 0.9860, 0.9860, 0.9858, 0.9854, 0.9849, 0.9849, 0.9847,
         0.9847],
        [0.9890, 0.9883, 0.9882, 0.9875, 0.9874, 0.9874, 0.9873, 0.9873, 0.9873,
         0.9872],
        [0.9860, 0.9851, 0.9847, 0.9843, 0.9842, 0.9839, 0.9838, 0.9829, 0.9829,
         0.9828],
        [0.9919, 0.9911, 0.9910, 0.9909, 0.9909, 0.9907, 0.9906, 0.9904, 0.9901,
         0.9900],
        [0.9903, 0.9898, 0.9897, 0.9895, 0.9894, 0.9894, 0.9894, 0.9894, 0.9892,
         0.9891],
        [0.9906, 0.9903, 0.9903, 0.9903, 0.9902, 0.9901, 0.9900, 0.9900, 0.9899,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 0, 0, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 1, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 1, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 1],
        [1, 0, 0, 1, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1444466.2500, 1433817.3750, 1433707.8750, 1429981.5000, 1429610.5000,
         1429451.0000, 1429408.7500, 1428601.8750, 1428472.5000, 1427689.5000],
        [1461352.3750, 1447166.0000, 1444329.8750, 1440655.5000, 1440538.7500,
         1439748.8750, 1438720.8750, 1438526.1250, 1437740.1250, 1436821.8750],
        [1293739.7500, 1293315.3750, 1291344.7500, 1275152.8750, 1274097.7500,
         1267220.7500, 1267057.6250, 1265939.2500, 1265615.6250, 1265028.0000],
        [1364655.2500, 1353028.6250, 1352738.3750, 1344168.6250, 1336185.5000,
         1335743.3750, 1333696.6250, 1333311.2500, 1332947.6250, 1329459.0000],
        [1280455.0000, 1264948.3750, 1256902.3750, 1225353.1250, 1191575.0000,
         1183694.3750, 1179619.3750, 1178635.3750, 1178374.7500, 1175464.3750],
        [1280458.7500, 1256975.5000, 1236014.7500, 1228412.8750, 1222687.1250,
         1220164.0000, 1207717.6250, 1176044.1250, 1167764.8750, 1161810.7500],
        [1284557.2500, 1281019.2500, 1274276.3750, 1266942.8750, 1264557.5000,
         1263657.0000, 1262746.3750, 1260938.8750, 1233038.5000, 1231735.0000],
        [1238656.8750, 1213241.5000, 1207229.5000, 1187883.0000, 1180991.6250,
         1171816.6250, 1159679.7500, 1159442.1250, 1158454.0000, 1155296.3750],
        [1426445.5000, 1426327.2500, 1423588.8750, 1422660.5000, 1420926.2500,
         1420896.5000, 1420621.3750, 1420158.1250, 1419723.5000, 1416915.5000],
        [1356226.0000, 1315653.1250, 1315141.2500, 1314186.0000, 1311918.1250,
         1308301.0000, 1305692.1250, 1302637.5000, 1302629.0000, 1302545.6250],
        [1459132.5000, 1459044.8750, 1455421.8750, 1455070.8750, 1454324.3750,
         1452618.0000, 1451929.7500, 1449668.8750, 1449062.2500, 1448197.3750],
        [1358359.1250, 1349771.8750, 1347694.5000, 1340580.2500, 1333834.0000,
         1329452.6250, 1322538.0000, 1321668.0000, 1320517.7500, 1318586.1250],
        [1326169.1250, 1324630.8750, 1323811.3750, 1311253.8750, 1309589.3750,
         1308468.2500, 1307149.8750, 1306165.5000, 1303911.6250, 1302831.3750],
        [1469432.7500, 1468782.6250, 1465589.6250, 1464216.3750, 1462517.8750,
         1460551.1250, 1459821.6250, 1459299.5000, 1458801.3750, 1458531.6250],
        [1464087.8750, 1462762.0000, 1460978.8750, 1458669.2500, 1458466.1250,
         1457761.1250, 1456530.0000, 1455948.0000, 1455873.1250, 1455810.5000],
        [1479567.1250, 1469846.2500, 1465322.6250, 1462577.8750, 1462258.5000,
         1461686.8750, 1461614.3750, 1461376.0000, 1460788.0000, 1460772.6250],
        [1419041.2500, 1408927.7500, 1407316.2500, 1406945.8750, 1406666.8750,
         1404759.1250, 1400199.6250, 1399593.5000, 1399376.0000, 1399335.8750],
        [1429333.7500, 1418466.2500, 1417864.3750, 1413997.1250, 1406234.8750,
         1402188.0000, 1401641.1250, 1397923.3750, 1395589.6250, 1395523.0000],
        [1415840.3750, 1414447.5000, 1412821.7500, 1409921.1250, 1406573.0000,
         1404297.0000, 1403231.3750, 1402752.3750, 1402284.2500, 1401773.5000],
        [1447367.5000, 1447359.2500, 1443214.5000, 1443089.3750, 1442649.0000,
         1442252.8750, 1440960.5000, 1439828.6250, 1438502.6250, 1438331.2500],
        [1450515.3750, 1449059.5000, 1448770.5000, 1448570.2500, 1448216.6250,
         1446852.7500, 1445963.0000, 1444932.0000, 1443725.2500, 1441371.5000],
        [1401888.3750, 1393407.2500, 1387974.8750, 1384004.2500, 1381199.6250,
         1379422.6250, 1375775.5000, 1370555.6250, 1369441.1250, 1365441.5000],
        [1466740.3750, 1452575.1250, 1451370.5000, 1448925.3750, 1448861.7500,
         1446301.0000, 1444642.6250, 1443556.0000, 1442778.3750, 1442658.6250],
        [1480140.1250, 1477343.6250, 1476894.2500, 1475680.6250, 1474933.6250,
         1474299.3750, 1473475.6250, 1472804.0000, 1471842.2500, 1470754.8750],
        [1392950.1250, 1385278.5000, 1384928.5000, 1384744.8750, 1380753.2500,
         1380154.1250, 1378197.1250, 1377691.1250, 1377239.2500, 1376141.6250],
        [1469568.7500, 1468355.5000, 1460864.6250, 1459395.6250, 1459206.2500,
         1457549.7500, 1457510.8750, 1457326.0000, 1457094.0000, 1456659.1250],
        [1459114.3750, 1458304.7500, 1458270.1250, 1458076.6250, 1452137.5000,
         1450097.5000, 1449186.5000, 1441810.0000, 1440729.6250, 1440483.7500],
        [1485073.3750, 1479129.7500, 1478796.8750, 1478681.2500, 1476419.7500,
         1474406.2500, 1474359.7500, 1473461.6250, 1472638.3750, 1471542.0000],
        [1477033.7500, 1476340.7500, 1475715.8750, 1475486.5000, 1475478.0000,
         1475065.8750, 1474581.8750, 1473613.2500, 1473578.2500, 1470102.7500],
        [1481385.7500, 1480104.7500, 1477594.3750, 1476609.7500, 1475777.7500,
         1475718.6250, 1474961.7500, 1474411.7500, 1474101.0000, 1474058.8750],
        [1486505.8750, 1483669.1250, 1481871.7500, 1478983.1250, 1478137.1250,
         1476568.8750, 1476471.8750, 1476449.2500, 1476442.1250, 1474480.6250],
        [1481991.8750, 1479468.3750, 1478832.2500, 1477827.0000, 1474646.6250,
         1474522.8750, 1473619.0000, 1473460.1250, 1473121.6250, 1472270.5000],
        [1314518.1250, 1281971.3750, 1272822.5000, 1258884.1250, 1256024.0000,
         1247829.0000, 1243810.8750, 1228551.1250, 1223885.2500, 1218595.2500],
        [1428243.6250, 1424440.3750, 1423853.6250, 1423339.1250, 1422948.2500,
         1422404.2500, 1421511.8750, 1421197.3750, 1421045.6250, 1420746.1250],
        [1457770.8750, 1457663.8750, 1455537.0000, 1453489.6250, 1453341.3750,
         1453291.5000, 1451363.5000, 1448784.5000, 1447856.2500, 1446127.1250],
        [1433105.1250, 1432021.6250, 1428581.5000, 1425516.7500, 1423743.6250,
         1423012.0000, 1421834.5000, 1420923.6250, 1420697.3750, 1420079.6250],
        [1328147.5000, 1321659.2500, 1315314.3750, 1297617.3750, 1291616.8750,
         1291482.6250, 1290172.7500, 1287933.0000, 1286715.1250, 1285378.2500],
        [1410229.0000, 1402077.0000, 1399155.7500, 1398962.3750, 1397078.5000,
         1395636.1250, 1392271.5000, 1389916.7500, 1389788.2500, 1389564.1250],
        [1358755.6250, 1351475.8750, 1348980.3750, 1348940.5000, 1346998.1250,
         1340826.8750, 1334901.6250, 1332847.3750, 1331794.0000, 1328289.2500],
        [1450677.1250, 1450270.5000, 1445352.2500, 1444937.5000, 1443444.5000,
         1442424.7500, 1441176.2500, 1440847.7500, 1440084.0000, 1439364.6250],
        [1303079.8750, 1301368.6250, 1287045.2500, 1283942.3750, 1279749.3750,
         1275578.5000, 1268812.1250, 1262981.1250, 1254512.1250, 1254442.7500],
        [1469762.0000, 1467409.1250, 1466852.2500, 1466787.8750, 1465969.7500,
         1465834.2500, 1464222.0000, 1463382.8750, 1462757.8750, 1462039.6250],
        [1464385.2500, 1460122.2500, 1459225.7500, 1458347.8750, 1457360.8750,
         1456781.3750, 1455510.6250, 1455448.2500, 1455316.3750, 1455013.8750],
        [1460807.5000, 1456582.6250, 1456517.3750, 1456467.3750, 1455903.5000,
         1454940.3750, 1454719.6250, 1452654.1250, 1452414.5000, 1452079.3750],
        [1402553.1250, 1394279.2500, 1390473.6250, 1384743.6250, 1383064.8750,
         1382611.1250, 1381519.8750, 1379735.7500, 1379068.7500, 1378642.7500],
        [1226775.0000, 1226442.7500, 1219859.1250, 1212570.5000, 1211619.2500,
         1205867.0000, 1205450.7500, 1204756.6250, 1197757.0000, 1194760.0000],
        [1114245.5000, 1039110.0000, 1025883.1250, 1015887.3750,  999521.5625,
          995358.0000,  951631.3750,  821765.3750,  818603.0000,  817928.7500],
        [1342380.2500, 1308505.7500, 1193003.1250, 1140042.5000, 1134990.5000,
         1129359.7500, 1120483.3750, 1113284.1250, 1107808.6250, 1104897.6250],
        [1340286.1250, 1329176.3750, 1323817.6250, 1320719.3750, 1319242.6250,
         1316239.2500, 1307702.2500, 1304936.6250, 1301284.2500, 1300348.8750],
        [1365264.5000, 1362696.7500, 1357529.0000, 1355050.8750, 1352000.6250,
         1350382.1250, 1349742.1250, 1347148.3750, 1346755.2500, 1346275.0000],
        [1352337.1250, 1347889.8750, 1345639.6250, 1343087.1250, 1336761.6250,
         1333066.0000, 1332580.3750, 1331211.1250, 1329554.1250, 1329385.5000],
        [1376595.7500, 1361604.1250, 1352303.6250, 1351897.3750, 1350467.0000,
         1350415.6250, 1350197.8750, 1349351.0000, 1346972.3750, 1343497.0000],
        [1354979.7500, 1346227.5000, 1334400.2500, 1332549.8750, 1331298.6250,
         1328891.1250, 1328831.6250, 1327949.8750, 1323364.5000, 1311000.1250],
        [1340259.3750, 1329570.6250, 1328207.0000, 1296708.1250, 1295543.6250,
         1289502.3750, 1279284.5000, 1276381.6250, 1268340.3750, 1263793.2500],
        [1429718.2500, 1427530.1250, 1420124.3750, 1420124.3750, 1419934.7500,
         1419282.2500, 1419215.8750, 1416646.6250, 1416391.3750, 1416259.0000],
        [1427195.2500, 1426827.8750, 1424133.3750, 1423787.0000, 1422283.3750,
         1421666.3750, 1421025.2500, 1420476.5000, 1420230.0000, 1420135.1250],
        [1268762.6250, 1264838.6250, 1260110.5000, 1259597.5000, 1253759.8750,
         1251922.2500, 1245071.2500, 1234924.8750, 1226742.2500, 1222098.3750],
        [1301429.3750, 1255492.3750, 1235640.0000, 1225145.2500, 1224539.0000,
         1220941.6250, 1198332.7500, 1196006.1250, 1192284.3750, 1190991.0000],
        [1325392.8750, 1323278.6250, 1311071.3750, 1309300.8750, 1307025.2500,
         1299354.6250, 1290266.3750, 1289919.3750, 1285735.1250, 1285576.8750],
        [1366855.1250, 1353868.8750, 1351363.7500, 1339278.0000, 1337528.0000,
         1336137.1250, 1334783.3750, 1334686.6250, 1334210.6250, 1332260.1250],
        [1309383.3750, 1293546.0000, 1285247.1250, 1278065.0000, 1276455.8750,
         1271826.2500, 1269833.8750, 1253892.5000, 1253828.0000, 1250833.8750],
        [1425466.3750, 1408735.6250, 1406956.6250, 1406194.7500, 1405767.0000,
         1401746.7500, 1399805.7500, 1395053.3750, 1389236.8750, 1386826.3750],
        [1392251.6250, 1382351.5000, 1381494.8750, 1377678.0000, 1376384.3750,
         1376116.7500, 1375841.1250, 1375309.8750, 1371486.6250, 1369412.3750],
        [1399290.5000, 1393673.1250, 1393036.5000, 1392376.3750, 1390400.6250,
         1388693.7500, 1388231.6250, 1388227.7500, 1384795.1250, 1384795.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1444466.2500,       0.0000],
         [1433817.3750,       0.0000],
         [1433707.8750,       0.0000],
         ...,
         [1428601.8750,       0.0000],
         [1428472.5000,       0.0000],
         [1427689.5000,       0.0000]],

        [[1461352.3750,       0.0000],
         [1447166.0000,       0.0000],
         [1444329.8750,       0.0000],
         ...,
         [1438526.1250,       0.0000],
         [1437740.1250,       0.0000],
         [1436821.8750,       0.0000]],

        [[      0.0000, 1293739.7500],
         [1293315.3750,       0.0000],
         [      0.0000, 1291344.7500],
         ...,
         [      0.0000, 1265939.2500],
         [1265615.6250,       0.0000],
         [      0.0000, 1265028.0000]],

        ...,

        [[1425466.3750,       0.0000],
         [1408735.6250,       0.0000],
         [1406956.6250,       0.0000],
         ...,
         [1395053.3750,       0.0000],
         [1389236.8750,       0.0000],
         [1386826.3750,       0.0000]],

        [[1392251.6250,       0.0000],
         [1382351.5000,       0.0000],
         [1381494.8750,       0.0000],
         ...,
         [1375309.8750,       0.0000],
         [1371486.6250,       0.0000],
         [1369412.3750,       0.0000]],

        [[1399290.5000,       0.0000],
         [1393673.1250,       0.0000],
         [1393036.5000,       0.0000],
         ...,
         [      0.0000, 1388227.7500],
         [1384795.1250,       0.0000],
         [1384795.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14315208.0000,        0.0000],
        [14425600.0000,        0.0000],
        [ 6367307.0000,  6391204.5000],
        [12082987.0000,  1332947.6250],
        [ 2355083.7500,  9759938.0000],
        [ 9733310.0000,  2424740.5000],
        [11360723.0000,  1262746.3750],
        [ 5907026.0000,  5925665.0000],
        [14218262.0000,        0.0000],
        [11832292.0000,  1302637.5000],
        [14534472.0000,        0.0000],
        [12020464.0000,  1322538.0000],
        [ 9202197.0000,  3921783.5000],
        [14627545.0000,        0.0000],
        [14586886.0000,        0.0000],
        [14645810.0000,        0.0000],
        [11240736.0000,  2811426.0000],
        [ 8449669.0000,  5629092.0000],
        [11264617.0000,  2809325.5000],
        [11545223.0000,  2878331.2500],
        [13021124.0000,  1446852.7500],
        [13809111.0000,        0.0000],
        [14488410.0000,        0.0000],
        [14748168.0000,        0.0000],
        [11057008.0000,  2761070.0000],
        [14603532.0000,        0.0000],
        [14508210.0000,        0.0000],
        [14764509.0000,        0.0000],
        [14746997.0000,        0.0000],
        [14764724.0000,        0.0000],
        [14789580.0000,        0.0000],
        [14759760.0000,        0.0000],
        [ 6228952.5000,  6317939.0000],
        [12808684.0000,  1421045.6250],
        [13067454.0000,  1457770.8750],
        [11397922.0000,  2851593.5000],
        [ 6489353.0000,  6506684.5000],
        [12562602.0000,  1402077.0000],
        [10740540.0000,  2683270.0000],
        [14438579.0000,        0.0000],
        [ 6438417.0000,  6333095.0000],
        [14655017.0000,        0.0000],
        [13117390.0000,  1460122.2500],
        [14553086.0000,        0.0000],
        [12476958.0000,  1379735.7500],
        [ 6043575.5000,  6062282.5000],
        [ 5717817.5000,  3882116.5000],
        [ 6947982.5000,  4746773.0000],
        [ 6543528.0000,  6620225.0000],
        [12182462.0000,  1350382.1250],
        [13381512.0000,        0.0000],
        [ 9478903.0000,  4054399.0000],
        [ 2651314.5000, 10668179.0000],
        [ 7832261.5000,  5135329.5000],
        [14205227.0000,        0.0000],
        [14227760.0000,        0.0000],
        [ 9967144.0000,  2520685.0000],
        [ 3613436.0000,  8627366.0000],
        [ 2608655.5000, 10418265.0000],
        [ 8034355.5000,  5386616.0000],
        [ 6374345.5000,  6368566.0000],
        [14025790.0000,        0.0000],
        [12402486.0000,  1375841.1250],
        [11127060.0000,  2776459.5000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 56.25
Top1 accuracy for validation set is 56.25 size is torch.Size([64, 1])
Epoch 41/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.86s/it]  7%|▋         | 2/29 [01:01<11:40, 25.95s/it] 10%|█         | 3/29 [01:02<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:05<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 5.511058330535889
Epoch 42/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:36, 61.31s/it]  7%|▋         | 2/29 [01:02<11:36, 25.79s/it] 10%|█         | 3/29 [01:03<06:15, 14.43s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 5.50612735748291
Epoch 43/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.98s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 5.491101264953613
Epoch 44/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:57, 57.78s/it]  7%|▋         | 2/29 [00:59<11:06, 24.68s/it] 10%|█         | 3/29 [01:00<06:00, 13.85s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.74s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.92s/it] 21%|██        | 6/29 [01:03<01:37,  4.22s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 5.461650371551514
Epoch 45/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:17, 60.62s/it]  7%|▋         | 2/29 [01:01<11:28, 25.50s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 5.45649528503418
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0253, 0.0052, 0.0004,  ..., 0.0033, 0.0051, 0.0173],
        [0.0214, 0.0055, 0.0004,  ..., 0.0026, 0.0044, 0.0222],
        [0.0391, 0.0062, 0.0058,  ..., 0.0100, 0.0152, 0.0171],
        ...,
        [0.0210, 0.0088, 0.0004,  ..., 0.0029, 0.0044, 0.0248],
        [0.0208, 0.0095, 0.0003,  ..., 0.0029, 0.0065, 0.0218],
        [0.0247, 0.0089, 0.0015,  ..., 0.0034, 0.0067, 0.0266]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9933, 0.9931, 0.9930, 0.9929, 0.9927, 0.9927, 0.9926, 0.9926, 0.9926,
         0.9926],
        [0.9941, 0.9938, 0.9938, 0.9937, 0.9937, 0.9934, 0.9934, 0.9934, 0.9934,
         0.9933],
        [0.9847, 0.9846, 0.9841, 0.9841, 0.9838, 0.9834, 0.9831, 0.9830, 0.9829,
         0.9826],
        [0.9896, 0.9894, 0.9892, 0.9886, 0.9884, 0.9879, 0.9878, 0.9878, 0.9877,
         0.9876],
        [0.9840, 0.9817, 0.9814, 0.9806, 0.9795, 0.9791, 0.9786, 0.9785, 0.9781,
         0.9778],
        [0.9836, 0.9836, 0.9807, 0.9802, 0.9798, 0.9796, 0.9790, 0.9787, 0.9774,
         0.9770],
        [0.9858, 0.9849, 0.9834, 0.9833, 0.9824, 0.9812, 0.9805, 0.9798, 0.9797,
         0.9786],
        [0.9809, 0.9805, 0.9800, 0.9790, 0.9787, 0.9787, 0.9786, 0.9784, 0.9775,
         0.9761],
        [0.9926, 0.9924, 0.9924, 0.9923, 0.9922, 0.9922, 0.9921, 0.9920, 0.9919,
         0.9919],
        [0.9889, 0.9865, 0.9863, 0.9861, 0.9860, 0.9856, 0.9856, 0.9856, 0.9856,
         0.9855],
        [0.9948, 0.9948, 0.9945, 0.9943, 0.9943, 0.9943, 0.9941, 0.9941, 0.9941,
         0.9941],
        [0.9891, 0.9882, 0.9881, 0.9880, 0.9876, 0.9875, 0.9872, 0.9871, 0.9869,
         0.9868],
        [0.9874, 0.9871, 0.9867, 0.9865, 0.9862, 0.9861, 0.9860, 0.9858, 0.9858,
         0.9858],
        [0.9944, 0.9944, 0.9944, 0.9942, 0.9942, 0.9942, 0.9940, 0.9940, 0.9940,
         0.9940],
        [0.9943, 0.9943, 0.9942, 0.9942, 0.9942, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9943, 0.9943, 0.9942, 0.9941, 0.9941, 0.9940, 0.9940, 0.9939, 0.9939,
         0.9938],
        [0.9921, 0.9919, 0.9919, 0.9918, 0.9917, 0.9917, 0.9916, 0.9915, 0.9915,
         0.9914],
        [0.9923, 0.9919, 0.9918, 0.9917, 0.9916, 0.9915, 0.9914, 0.9913, 0.9913,
         0.9912],
        [0.9918, 0.9917, 0.9915, 0.9913, 0.9911, 0.9910, 0.9909, 0.9909, 0.9908,
         0.9907],
        [0.9933, 0.9932, 0.9932, 0.9931, 0.9931, 0.9930, 0.9930, 0.9930, 0.9929,
         0.9929],
        [0.9942, 0.9940, 0.9940, 0.9938, 0.9936, 0.9936, 0.9936, 0.9935, 0.9935,
         0.9935],
        [0.9896, 0.9896, 0.9895, 0.9894, 0.9893, 0.9893, 0.9893, 0.9891, 0.9889,
         0.9889],
        [0.9939, 0.9937, 0.9936, 0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9932],
        [0.9953, 0.9952, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949,
         0.9948],
        [0.9911, 0.9906, 0.9905, 0.9904, 0.9902, 0.9902, 0.9902, 0.9900, 0.9899,
         0.9898],
        [0.9947, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944, 0.9943, 0.9941, 0.9941,
         0.9941],
        [0.9946, 0.9945, 0.9944, 0.9941, 0.9939, 0.9937, 0.9935, 0.9933, 0.9933,
         0.9933],
        [0.9949, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9943, 0.9943, 0.9943,
         0.9942],
        [0.9949, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9946],
        [0.9949, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9946, 0.9945, 0.9945,
         0.9945],
        [0.9952, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9947],
        [0.9953, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9947],
        [0.9861, 0.9860, 0.9842, 0.9813, 0.9811, 0.9806, 0.9804, 0.9804, 0.9801,
         0.9800],
        [0.9929, 0.9928, 0.9928, 0.9927, 0.9927, 0.9927, 0.9926, 0.9926, 0.9926,
         0.9925],
        [0.9941, 0.9938, 0.9938, 0.9938, 0.9938, 0.9938, 0.9937, 0.9937, 0.9937,
         0.9937],
        [0.9930, 0.9929, 0.9926, 0.9926, 0.9924, 0.9923, 0.9922, 0.9921, 0.9921,
         0.9920],
        [0.9862, 0.9862, 0.9861, 0.9858, 0.9856, 0.9851, 0.9850, 0.9850, 0.9845,
         0.9844],
        [0.9915, 0.9914, 0.9909, 0.9906, 0.9905, 0.9903, 0.9903, 0.9903, 0.9903,
         0.9903],
        [0.9892, 0.9886, 0.9885, 0.9884, 0.9883, 0.9880, 0.9880, 0.9879, 0.9879,
         0.9878],
        [0.9943, 0.9941, 0.9941, 0.9940, 0.9939, 0.9938, 0.9938, 0.9938, 0.9937,
         0.9936],
        [0.9868, 0.9864, 0.9856, 0.9849, 0.9849, 0.9849, 0.9847, 0.9837, 0.9837,
         0.9837],
        [0.9947, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9941, 0.9940, 0.9940, 0.9939, 0.9939, 0.9938, 0.9938, 0.9937, 0.9937,
         0.9937],
        [0.9940, 0.9940, 0.9940, 0.9938, 0.9938, 0.9938, 0.9937, 0.9937, 0.9937,
         0.9937],
        [0.9912, 0.9911, 0.9911, 0.9907, 0.9906, 0.9905, 0.9903, 0.9903, 0.9902,
         0.9902],
        [0.9822, 0.9818, 0.9815, 0.9814, 0.9813, 0.9812, 0.9808, 0.9806, 0.9806,
         0.9800],
        [0.9777, 0.9771, 0.9722, 0.9684, 0.9681, 0.9678, 0.9627, 0.9608, 0.9591,
         0.9547],
        [0.9860, 0.9832, 0.9769, 0.9744, 0.9739, 0.9737, 0.9736, 0.9722, 0.9715,
         0.9714],
        [0.9873, 0.9865, 0.9863, 0.9862, 0.9858, 0.9858, 0.9855, 0.9854, 0.9853,
         0.9851],
        [0.9889, 0.9887, 0.9886, 0.9886, 0.9886, 0.9883, 0.9883, 0.9882, 0.9881,
         0.9881],
        [0.9894, 0.9892, 0.9890, 0.9887, 0.9887, 0.9885, 0.9884, 0.9884, 0.9883,
         0.9882],
        [0.9892, 0.9891, 0.9883, 0.9882, 0.9882, 0.9880, 0.9877, 0.9876, 0.9876,
         0.9875],
        [0.9883, 0.9882, 0.9881, 0.9880, 0.9879, 0.9876, 0.9875, 0.9873, 0.9862,
         0.9861],
        [0.9874, 0.9872, 0.9869, 0.9857, 0.9851, 0.9845, 0.9844, 0.9843, 0.9837,
         0.9836],
        [0.9928, 0.9923, 0.9923, 0.9920, 0.9920, 0.9920, 0.9919, 0.9918, 0.9917,
         0.9917],
        [0.9926, 0.9925, 0.9925, 0.9925, 0.9924, 0.9924, 0.9924, 0.9922, 0.9921,
         0.9921],
        [0.9846, 0.9841, 0.9836, 0.9826, 0.9821, 0.9817, 0.9813, 0.9811, 0.9805,
         0.9802],
        [0.9859, 0.9835, 0.9829, 0.9811, 0.9810, 0.9810, 0.9808, 0.9800, 0.9795,
         0.9794],
        [0.9884, 0.9880, 0.9867, 0.9862, 0.9862, 0.9861, 0.9859, 0.9857, 0.9848,
         0.9848],
        [0.9906, 0.9899, 0.9899, 0.9892, 0.9884, 0.9875, 0.9875, 0.9874, 0.9874,
         0.9871],
        [0.9853, 0.9853, 0.9850, 0.9839, 0.9832, 0.9830, 0.9828, 0.9826, 0.9825,
         0.9822],
        [0.9922, 0.9921, 0.9920, 0.9920, 0.9919, 0.9918, 0.9916, 0.9914, 0.9914,
         0.9913],
        [0.9916, 0.9904, 0.9903, 0.9902, 0.9900, 0.9900, 0.9900, 0.9899, 0.9899,
         0.9897],
        [0.9905, 0.9905, 0.9904, 0.9903, 0.9903, 0.9903, 0.9902, 0.9900, 0.9899,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 1, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 1, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 0, 1, 0],
        [1, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 0, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 1, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1454725.2500, 1450390.7500, 1447181.1250, 1445362.0000, 1442510.0000,
         1442489.3750, 1440619.7500, 1440538.7500, 1440199.3750, 1439728.3750],
        [1470743.5000, 1464459.3750, 1464269.3750, 1462269.6250, 1461554.3750,
         1457049.5000, 1456799.3750, 1456477.1250, 1455978.6250, 1454944.5000],
        [1285423.6250, 1283802.8750, 1275630.7500, 1274963.1250, 1269338.6250,
         1262209.3750, 1256826.8750, 1255743.8750, 1253021.1250, 1247401.8750],
        [1379076.6250, 1376339.8750, 1372167.0000, 1359062.7500, 1356845.6250,
         1345783.3750, 1343777.5000, 1343772.5000, 1342711.8750, 1340654.3750],
        [1274088.0000, 1231615.2500, 1226861.6250, 1213416.1250, 1193602.8750,
         1187125.2500, 1178226.3750, 1177498.5000, 1170986.5000, 1164890.6250],
        [1265925.8750, 1265917.5000, 1214933.1250, 1206863.3750, 1198428.8750,
         1195293.3750, 1186191.6250, 1180133.6250, 1159328.1250, 1151889.2500],
        [1306305.0000, 1288906.2500, 1262715.0000, 1260929.2500, 1244952.3750,
         1223145.3750, 1211677.0000, 1199462.3750, 1197738.7500, 1178428.6250],
        [1217821.5000, 1211764.8750, 1202934.6250, 1184857.5000, 1180041.2500,
         1179649.7500, 1178069.1250, 1175141.6250, 1160121.1250, 1137989.6250],
        [1438841.6250, 1435459.1250, 1434659.7500, 1433493.2500, 1432404.1250,
         1431747.1250, 1428879.8750, 1427426.6250, 1426416.8750, 1426408.7500],
        [1366263.5000, 1319353.3750, 1315187.6250, 1311545.2500, 1310214.0000,
         1302738.2500, 1302179.3750, 1302035.2500, 1301981.8750, 1300249.6250],
        [1485465.7500, 1484815.5000, 1479335.7500, 1475337.2500, 1475267.0000,
         1475243.0000, 1471796.0000, 1471598.0000, 1470959.6250, 1470429.5000],
        [1369225.7500, 1351933.6250, 1350675.7500, 1348190.6250, 1340327.0000,
         1339221.8750, 1332211.8750, 1330686.8750, 1328071.5000, 1325515.5000],
        [1336149.8750, 1330130.0000, 1324277.1250, 1319410.0000, 1314866.7500,
         1311589.1250, 1309556.8750, 1306834.6250, 1306731.1250, 1305641.1250],
        [1477604.2500, 1477009.8750, 1476366.1250, 1473893.0000, 1473447.5000,
         1472694.5000, 1469424.3750, 1469416.0000, 1469386.5000, 1469026.3750],
        [1475914.2500, 1475770.7500, 1473218.5000, 1472415.0000, 1472036.0000,
         1471149.0000, 1470592.1250, 1468667.7500, 1467952.2500, 1465950.2500],
        [1475668.0000, 1475102.3750, 1472958.6250, 1471273.8750, 1470060.7500,
         1469435.5000, 1468922.7500, 1466492.8750, 1465774.1250, 1465570.0000],
        [1428983.5000, 1426463.2500, 1425379.3750, 1423432.7500, 1422078.6250,
         1421400.7500, 1419424.3750, 1418218.7500, 1416860.1250, 1414853.6250],
        [1433317.0000, 1426248.2500, 1422472.0000, 1421250.2500, 1420048.5000,
         1416802.1250, 1415527.1250, 1412820.2500, 1412700.3750, 1410814.1250],
        [1422469.3750, 1420378.8750, 1416927.7500, 1412711.2500, 1409559.3750,
         1407035.8750, 1405509.6250, 1405423.8750, 1403311.7500, 1401381.8750],
        [1454708.6250, 1452248.2500, 1451287.3750, 1449974.5000, 1449657.8750,
         1448971.0000, 1448182.1250, 1447516.6250, 1446728.5000, 1446421.0000],
        [1473505.1250, 1469410.2500, 1468260.2500, 1464112.8750, 1460701.6250,
         1460221.1250, 1459607.1250, 1458787.5000, 1458231.1250, 1458215.8750],
        [1379614.6250, 1378460.0000, 1377437.6250, 1375853.0000, 1373613.6250,
         1373288.8750, 1372910.3750, 1368592.5000, 1365600.3750, 1365539.2500],
        [1467483.3750, 1462618.2500, 1461412.2500, 1458309.0000, 1457846.0000,
         1455356.6250, 1454993.0000, 1454544.8750, 1452942.2500, 1451992.1250],
        [1495388.3750, 1493464.2500, 1489504.3750, 1489392.2500, 1488839.7500,
         1488310.2500, 1487829.1250, 1487646.1250, 1487441.8750, 1486490.2500],
        [1409201.8750, 1400199.6250, 1397007.7500, 1394636.8750, 1391605.2500,
         1391560.0000, 1390623.3750, 1387375.3750, 1385221.7500, 1383231.0000],
        [1482794.8750, 1479093.1250, 1478788.5000, 1477767.7500, 1476869.0000,
         1476552.1250, 1475385.1250, 1470307.5000, 1470262.6250, 1469969.5000],
        [1481250.1250, 1479934.1250, 1477519.7500, 1470860.0000, 1465804.8750,
         1461865.2500, 1458684.5000, 1455169.2500, 1455112.3750, 1454687.7500],
        [1487817.7500, 1482814.6250, 1482493.6250, 1480707.7500, 1479986.2500,
         1479134.0000, 1475776.3750, 1475169.8750, 1474462.3750, 1473662.5000],
        [1488737.5000, 1487637.5000, 1486138.7500, 1485445.8750, 1484901.8750,
         1484747.6250, 1484310.1250, 1483819.0000, 1482628.0000, 1481488.7500],
        [1488490.5000, 1486649.0000, 1485930.3750, 1484777.3750, 1484317.2500,
         1484249.3750, 1482230.6250, 1480199.5000, 1479039.6250, 1478699.6250],
        [1493797.6250, 1486918.5000, 1486627.7500, 1486437.7500, 1485190.8750,
         1484805.6250, 1483814.7500, 1483591.2500, 1483154.0000, 1483090.3750],
        [1496026.0000, 1490550.2500, 1488760.2500, 1488006.5000, 1485586.1250,
         1484727.8750, 1483857.2500, 1483588.3750, 1483107.5000, 1483045.2500],
        [1311959.5000, 1309811.6250, 1277363.1250, 1224438.5000, 1221247.8750,
         1213537.7500, 1209848.0000, 1209782.2500, 1205041.6250, 1203327.1250],
        [1446953.5000, 1444532.3750, 1442991.6250, 1441856.7500, 1441518.5000,
         1440978.3750, 1439843.7500, 1439419.3750, 1438969.2500, 1438567.2500],
        [1470269.5000, 1465382.7500, 1465124.2500, 1464712.1250, 1464545.8750,
         1464302.8750, 1463395.5000, 1462841.5000, 1462099.5000, 1461639.3750],
        [1447345.5000, 1446180.8750, 1440791.3750, 1439551.2500, 1434789.8750,
         1433762.6250, 1431079.6250, 1428953.5000, 1428581.5000, 1428117.0000],
        [1314554.5000, 1313278.7500, 1312431.2500, 1306640.2500, 1302769.2500,
         1293399.3750, 1291685.8750, 1291665.0000, 1282325.8750, 1280259.6250],
        [1416989.8750, 1415431.2500, 1404911.8750, 1400034.1250, 1396464.3750,
         1393989.5000, 1393759.3750, 1393659.7500, 1393230.5000, 1392429.5000],
        [1371697.2500, 1358997.8750, 1358414.8750, 1355450.2500, 1353690.7500,
         1347873.2500, 1347396.3750, 1346376.5000, 1345779.5000, 1344571.1250],
        [1474811.2500, 1470307.5000, 1470170.0000, 1468218.3750, 1467270.6250,
         1465022.2500, 1464928.6250, 1464896.5000, 1463205.6250, 1461387.1250],
        [1325863.1250, 1318369.8750, 1302432.6250, 1289726.2500, 1289659.8750,
         1289513.5000, 1285209.1250, 1268224.2500, 1268003.0000, 1267699.5000],
        [1483026.8750, 1479752.0000, 1479214.5000, 1477329.6250, 1476950.6250,
         1476716.7500, 1476352.1250, 1476166.2500, 1475653.8750, 1475290.8750],
        [1470472.8750, 1469734.0000, 1468648.2500, 1467125.1250, 1466294.2500,
         1465620.3750, 1463932.8750, 1463385.6250, 1462395.1250, 1462379.8750],
        [1469232.3750, 1469212.7500, 1469055.7500, 1465561.6250, 1465138.2500,
         1463674.6250, 1463523.8750, 1463127.5000, 1462359.0000, 1462103.7500],
        [1411474.8750, 1409832.3750, 1408254.7500, 1401745.3750, 1398738.2500,
         1396564.2500, 1392476.0000, 1392295.3750, 1391278.6250, 1390366.1250],
        [1240653.6250, 1234409.2500, 1229127.6250, 1226363.2500, 1224460.7500,
         1222748.8750, 1216065.6250, 1213547.0000, 1213456.6250, 1202841.7500],
        [1163339.7500, 1153906.7500, 1075476.2500, 1018793.1250, 1014729.3750,
         1010577.6250,  938746.0000,  914750.0625,  892586.3125,  838316.1875],
        [1310970.1250, 1259302.0000, 1149746.8750, 1110159.7500, 1101621.1250,
         1098825.8750, 1097073.1250, 1076186.2500, 1065014.5000, 1063562.0000],
        [1333973.8750, 1319975.1250, 1315934.1250, 1313266.3750, 1306165.5000,
         1305804.2500, 1301013.7500, 1299032.6250, 1296324.7500, 1293702.7500],
        [1365097.7500, 1362540.7500, 1358950.0000, 1358930.5000, 1358918.8750,
         1353535.7500, 1353183.3750, 1352266.1250, 1350664.1250, 1350288.1250],
        [1375608.8750, 1370970.1250, 1367968.7500, 1362102.8750, 1361571.7500,
         1358688.2500, 1356645.1250, 1355759.1250, 1353605.6250, 1351776.2500],
        [1372369.7500, 1368648.7500, 1353835.3750, 1352700.8750, 1352431.3750,
         1347427.2500, 1342729.6250, 1340787.2500, 1339837.6250, 1338344.7500],
        [1354761.3750, 1352993.7500, 1350249.5000, 1348500.6250, 1346701.3750,
         1339983.2500, 1338979.1250, 1335431.3750, 1313515.6250, 1312204.7500],
        [1336872.6250, 1332682.0000, 1327251.0000, 1305140.7500, 1294091.5000,
         1281817.3750, 1281019.2500, 1279535.7500, 1267481.7500, 1266486.2500],
        [1443701.8750, 1433956.7500, 1433956.7500, 1427654.1250, 1427445.7500,
         1426479.5000, 1424630.6250, 1422431.2500, 1421425.0000, 1420731.1250],
        [1439010.3750, 1437588.0000, 1437496.1250, 1436972.5000, 1436643.7500,
         1435772.6250, 1434865.1250, 1431072.8750, 1430432.8750, 1429813.7500],
        [1284051.5000, 1275190.5000, 1265376.6250, 1248796.7500, 1239714.5000,
         1231495.5000, 1224945.3750, 1221557.7500, 1211246.1250, 1205781.8750],
        [1308301.0000, 1264314.0000, 1253141.8750, 1221216.3750, 1220357.2500,
         1219440.5000, 1215838.3750, 1202604.3750, 1193317.2500, 1192652.7500],
        [1355658.2500, 1348405.5000, 1323822.6250, 1314178.3750, 1313986.6250,
         1312152.1250, 1308321.0000, 1304491.1250, 1287778.1250, 1287052.6250],
        [1398799.6250, 1385500.5000, 1385233.7500, 1370805.3750, 1355279.5000,
         1338514.5000, 1337808.6250, 1337632.7500, 1336324.5000, 1330980.0000],
        [1297882.2500, 1296840.3750, 1291280.6250, 1271262.3750, 1259580.7500,
         1255412.1250, 1251997.3750, 1248549.1250, 1245947.7500, 1240891.5000],
        [1430947.2500, 1428899.0000, 1427813.3750, 1427436.2500, 1424490.6250,
         1423506.0000, 1419088.6250, 1415771.3750, 1415656.6250, 1412614.2500],
        [1418868.1250, 1395702.7500, 1393723.5000, 1391132.7500, 1387722.1250,
         1387720.7500, 1386761.6250, 1385832.2500, 1384417.5000, 1380396.3750],
        [1397767.5000, 1396685.3750, 1394840.5000, 1393606.6250, 1393158.7500,
         1392468.1250, 1390770.6250, 1386793.3750, 1386206.2500, 1386109.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1454725.2500,       0.0000],
         [1450390.7500,       0.0000],
         [1447181.1250,       0.0000],
         ...,
         [1440538.7500,       0.0000],
         [1440199.3750,       0.0000],
         [      0.0000, 1439728.3750]],

        [[1470743.5000,       0.0000],
         [1464459.3750,       0.0000],
         [1464269.3750,       0.0000],
         ...,
         [1456477.1250,       0.0000],
         [1455978.6250,       0.0000],
         [      0.0000, 1454944.5000]],

        [[      0.0000, 1285423.6250],
         [1283802.8750,       0.0000],
         [      0.0000, 1275630.7500],
         ...,
         [1255743.8750,       0.0000],
         [      0.0000, 1253021.1250],
         [1247401.8750,       0.0000]],

        ...,

        [[1430947.2500,       0.0000],
         [1428899.0000,       0.0000],
         [1427813.3750,       0.0000],
         ...,
         [1415771.3750,       0.0000],
         [1415656.6250,       0.0000],
         [1412614.2500,       0.0000]],

        [[1418868.1250,       0.0000],
         [1395702.7500,       0.0000],
         [1393723.5000,       0.0000],
         ...,
         [1385832.2500,       0.0000],
         [1384417.5000,       0.0000],
         [1380396.3750,       0.0000]],

        [[1397767.5000,       0.0000],
         [1396685.3750,       0.0000],
         [1394840.5000,       0.0000],
         ...,
         [1386793.3750,       0.0000],
         [1386206.2500,       0.0000],
         [1386109.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13004017.0000,  1439728.3750],
        [13149601.0000,  1454944.5000],
        [ 6318738.5000,  6345624.0000],
        [12203345.0000,  1356845.6250],
        [ 3535610.2500,  8482701.0000],
        [ 7218174.0000,  4806730.5000],
        [11111544.0000,  1262715.0000],
        [ 5954348.0000,  5874042.5000],
        [14315738.0000,        0.0000],
        [11829568.0000,  1302179.3750],
        [14760247.0000,        0.0000],
        [10745047.0000,  2671014.0000],
        [13165186.0000,        0.0000],
        [14728269.0000,        0.0000],
        [14713665.0000,        0.0000],
        [14701259.0000,        0.0000],
        [12798877.0000,  1418218.7500],
        [ 9929060.0000,  4262939.0000],
        [14104709.0000,        0.0000],
        [14495695.0000,        0.0000],
        [13172822.0000,  1458231.1250],
        [12362318.0000,  1368592.5000],
        [14577498.0000,        0.0000],
        [14894306.0000,        0.0000],
        [11156808.0000,  2773854.5000],
        [14757791.0000,        0.0000],
        [14660887.0000,        0.0000],
        [14792026.0000,        0.0000],
        [13365108.0000,  1484747.6250],
        [14834584.0000,        0.0000],
        [14857429.0000,        0.0000],
        [14867255.0000,        0.0000],
        [ 6131779.0000,  6254578.5000],
        [12976662.0000,  1438969.2500],
        [13182674.0000,  1461639.3750],
        [14359154.0000,        0.0000],
        [ 9071635.0000,  3917375.0000],
        [11191710.0000,  2809190.5000],
        [10799553.0000,  2730695.0000],
        [14670217.0000,        0.0000],
        [ 7776315.0000,  5128386.0000],
        [14776454.0000,        0.0000],
        [13193695.0000,  1466294.2500],
        [14652989.0000,        0.0000],
        [12583194.0000,  1409832.3750],
        [ 7311464.0000,  4912210.0000],
        [ 5828930.0000,  4192291.2500],
        [ 5594949.0000,  5737512.0000],
        [ 7816277.5000,  5268915.5000],
        [12210840.0000,  1353535.7500],
        [12246728.0000,  1367968.7500],
        [ 8125467.5000,  5383645.0000],
        [ 2625720.5000, 10767600.0000],
        [ 7827124.0000,  5145254.0000],
        [12860988.0000,  1421425.0000],
        [12918594.0000,  1431072.8750],
        [ 8686828.0000,  3721329.0000],
        [ 3630372.0000,  8660812.0000],
        [ 1314178.3750, 11841667.0000],
        [ 6705560.0000,  6871319.5000],
        [ 7582370.0000,  5077274.5000],
        [14226224.0000,        0.0000],
        [13912278.0000,        0.0000],
        [12527636.0000,  1390770.6250]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 56.25
Top1 accuracy for validation set is 56.25 size is torch.Size([64, 1])
Epoch 46/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:22, 58.66s/it]  7%|▋         | 2/29 [01:00<11:21, 25.26s/it] 10%|█         | 3/29 [01:01<06:07, 14.15s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 5.4428815841674805
Epoch 47/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:40, 61.43s/it]  7%|▋         | 2/29 [01:02<11:37, 25.84s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 5.444502353668213
Epoch 48/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:44, 59.46s/it]  7%|▋         | 2/29 [01:00<11:15, 25.03s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 5.4210591316223145
Epoch 49/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.80s/it]  7%|▋         | 2/29 [00:59<11:20, 25.21s/it] 10%|█         | 3/29 [01:00<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 5.404120445251465
Epoch 50/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:29, 56.76s/it]  7%|▋         | 2/29 [01:00<11:25, 25.40s/it] 10%|█         | 3/29 [01:01<06:09, 14.22s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.07s/it] 21%|██        | 6/29 [01:03<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 5.369177341461182
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0223, 0.0061, 0.0005,  ..., 0.0027, 0.0034, 0.0193],
        [0.0214, 0.0036, 0.0005,  ..., 0.0013, 0.0043, 0.0228],
        [0.0374, 0.0073, 0.0028,  ..., 0.0105, 0.0145, 0.0164],
        ...,
        [0.0205, 0.0080, 0.0005,  ..., 0.0033, 0.0041, 0.0242],
        [0.0186, 0.0073, 0.0003,  ..., 0.0028, 0.0032, 0.0219],
        [0.0246, 0.0074, 0.0015,  ..., 0.0037, 0.0072, 0.0257]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9939, 0.9937, 0.9936, 0.9936, 0.9935, 0.9935, 0.9934, 0.9934, 0.9934,
         0.9934],
        [0.9945, 0.9943, 0.9941, 0.9940, 0.9939, 0.9939, 0.9939, 0.9938, 0.9938,
         0.9938],
        [0.9851, 0.9840, 0.9839, 0.9838, 0.9835, 0.9833, 0.9831, 0.9829, 0.9817,
         0.9813],
        [0.9908, 0.9903, 0.9902, 0.9901, 0.9893, 0.9892, 0.9891, 0.9891, 0.9890,
         0.9889],
        [0.9851, 0.9830, 0.9814, 0.9811, 0.9797, 0.9796, 0.9796, 0.9781, 0.9781,
         0.9779],
        [0.9851, 0.9838, 0.9811, 0.9808, 0.9802, 0.9799, 0.9792, 0.9783, 0.9777,
         0.9765],
        [0.9840, 0.9831, 0.9825, 0.9822, 0.9816, 0.9801, 0.9797, 0.9785, 0.9777,
         0.9772],
        [0.9820, 0.9815, 0.9803, 0.9802, 0.9797, 0.9794, 0.9783, 0.9778, 0.9775,
         0.9772],
        [0.9938, 0.9938, 0.9937, 0.9936, 0.9936, 0.9936, 0.9935, 0.9935, 0.9934,
         0.9932],
        [0.9899, 0.9874, 0.9871, 0.9869, 0.9868, 0.9864, 0.9862, 0.9861, 0.9860,
         0.9860],
        [0.9955, 0.9954, 0.9952, 0.9952, 0.9949, 0.9948, 0.9948, 0.9946, 0.9946,
         0.9946],
        [0.9895, 0.9893, 0.9892, 0.9887, 0.9885, 0.9883, 0.9881, 0.9879, 0.9879,
         0.9873],
        [0.9893, 0.9888, 0.9886, 0.9881, 0.9880, 0.9878, 0.9877, 0.9876, 0.9873,
         0.9870],
        [0.9950, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948,
         0.9948],
        [0.9950, 0.9950, 0.9950, 0.9948, 0.9947, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9945],
        [0.9951, 0.9949, 0.9949, 0.9947, 0.9946, 0.9946, 0.9946, 0.9946, 0.9945,
         0.9945],
        [0.9929, 0.9929, 0.9929, 0.9928, 0.9927, 0.9926, 0.9926, 0.9925, 0.9923,
         0.9923],
        [0.9935, 0.9930, 0.9929, 0.9929, 0.9928, 0.9925, 0.9923, 0.9922, 0.9921,
         0.9921],
        [0.9923, 0.9916, 0.9914, 0.9914, 0.9913, 0.9913, 0.9912, 0.9912, 0.9910,
         0.9910],
        [0.9943, 0.9943, 0.9943, 0.9941, 0.9941, 0.9940, 0.9940, 0.9938, 0.9938,
         0.9937],
        [0.9947, 0.9944, 0.9942, 0.9942, 0.9941, 0.9941, 0.9940, 0.9940, 0.9940,
         0.9938],
        [0.9905, 0.9902, 0.9901, 0.9900, 0.9900, 0.9899, 0.9898, 0.9897, 0.9897,
         0.9894],
        [0.9945, 0.9943, 0.9940, 0.9940, 0.9938, 0.9938, 0.9938, 0.9938, 0.9937,
         0.9937],
        [0.9956, 0.9954, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9950],
        [0.9929, 0.9915, 0.9915, 0.9914, 0.9912, 0.9912, 0.9909, 0.9907, 0.9907,
         0.9906],
        [0.9950, 0.9950, 0.9948, 0.9948, 0.9947, 0.9946, 0.9946, 0.9946, 0.9946,
         0.9946],
        [0.9951, 0.9950, 0.9949, 0.9945, 0.9944, 0.9943, 0.9941, 0.9941, 0.9940,
         0.9940],
        [0.9955, 0.9952, 0.9950, 0.9950, 0.9949, 0.9949, 0.9948, 0.9947, 0.9947,
         0.9947],
        [0.9954, 0.9954, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9949, 0.9949,
         0.9949],
        [0.9952, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9950,
         0.9950],
        [0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952, 0.9952,
         0.9952],
        [0.9877, 0.9864, 0.9863, 0.9825, 0.9824, 0.9814, 0.9813, 0.9811, 0.9809,
         0.9807],
        [0.9940, 0.9934, 0.9934, 0.9933, 0.9933, 0.9933, 0.9932, 0.9932, 0.9932,
         0.9932],
        [0.9946, 0.9946, 0.9945, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944, 0.9943,
         0.9943],
        [0.9934, 0.9932, 0.9932, 0.9931, 0.9930, 0.9930, 0.9930, 0.9930, 0.9930,
         0.9929],
        [0.9878, 0.9870, 0.9868, 0.9864, 0.9862, 0.9859, 0.9850, 0.9843, 0.9843,
         0.9827],
        [0.9918, 0.9916, 0.9915, 0.9914, 0.9914, 0.9914, 0.9914, 0.9913, 0.9912,
         0.9912],
        [0.9891, 0.9888, 0.9888, 0.9888, 0.9887, 0.9886, 0.9885, 0.9885, 0.9878,
         0.9877],
        [0.9946, 0.9944, 0.9942, 0.9942, 0.9942, 0.9941, 0.9940, 0.9940, 0.9940,
         0.9939],
        [0.9871, 0.9854, 0.9852, 0.9841, 0.9836, 0.9833, 0.9822, 0.9822, 0.9821,
         0.9818],
        [0.9950, 0.9948, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9947],
        [0.9951, 0.9948, 0.9947, 0.9947, 0.9947, 0.9945, 0.9945, 0.9945, 0.9945,
         0.9944],
        [0.9944, 0.9943, 0.9943, 0.9942, 0.9941, 0.9941, 0.9941, 0.9941, 0.9941,
         0.9941],
        [0.9911, 0.9910, 0.9909, 0.9909, 0.9908, 0.9907, 0.9906, 0.9905, 0.9905,
         0.9905],
        [0.9816, 0.9806, 0.9804, 0.9803, 0.9799, 0.9795, 0.9794, 0.9791, 0.9788,
         0.9788],
        [0.9820, 0.9772, 0.9747, 0.9695, 0.9686, 0.9666, 0.9652, 0.9652, 0.9593,
         0.9578],
        [0.9840, 0.9794, 0.9788, 0.9756, 0.9755, 0.9755, 0.9729, 0.9724, 0.9710,
         0.9708],
        [0.9873, 0.9873, 0.9866, 0.9865, 0.9862, 0.9860, 0.9857, 0.9857, 0.9856,
         0.9854],
        [0.9907, 0.9897, 0.9897, 0.9896, 0.9896, 0.9895, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9899, 0.9896, 0.9892, 0.9891, 0.9887, 0.9884, 0.9883, 0.9883, 0.9882,
         0.9881],
        [0.9892, 0.9891, 0.9890, 0.9890, 0.9888, 0.9886, 0.9883, 0.9883, 0.9882,
         0.9881],
        [0.9888, 0.9887, 0.9885, 0.9879, 0.9878, 0.9875, 0.9872, 0.9869, 0.9866,
         0.9859],
        [0.9880, 0.9880, 0.9869, 0.9853, 0.9852, 0.9851, 0.9850, 0.9838, 0.9837,
         0.9831],
        [0.9927, 0.9926, 0.9925, 0.9924, 0.9924, 0.9924, 0.9923, 0.9922, 0.9922,
         0.9921],
        [0.9934, 0.9933, 0.9932, 0.9930, 0.9930, 0.9929, 0.9928, 0.9928, 0.9928,
         0.9928],
        [0.9862, 0.9859, 0.9851, 0.9835, 0.9830, 0.9820, 0.9819, 0.9815, 0.9812,
         0.9812],
        [0.9861, 0.9839, 0.9839, 0.9825, 0.9809, 0.9804, 0.9803, 0.9802, 0.9794,
         0.9792],
        [0.9889, 0.9886, 0.9872, 0.9869, 0.9869, 0.9865, 0.9865, 0.9860, 0.9860,
         0.9860],
        [0.9916, 0.9901, 0.9893, 0.9893, 0.9891, 0.9881, 0.9877, 0.9877, 0.9874,
         0.9873],
        [0.9868, 0.9862, 0.9856, 0.9849, 0.9839, 0.9836, 0.9835, 0.9835, 0.9833,
         0.9832],
        [0.9930, 0.9926, 0.9925, 0.9924, 0.9924, 0.9918, 0.9917, 0.9917, 0.9917,
         0.9916],
        [0.9917, 0.9909, 0.9909, 0.9906, 0.9905, 0.9904, 0.9904, 0.9903, 0.9902,
         0.9901],
        [0.9910, 0.9908, 0.9908, 0.9906, 0.9905, 0.9905, 0.9902, 0.9901, 0.9901,
         0.9900]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [1, 0, 0, 1, 1, 0, 1, 0, 0, 1],
        [1, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 0, 1, 1, 1],
        [0, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 0, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1465957.2500, 1462565.3750, 1460829.8750, 1459465.1250, 1459056.0000,
         1458936.3750, 1456575.7500, 1455977.1250, 1455800.7500, 1455349.6250],
        [1479968.0000, 1474558.0000, 1469920.5000, 1469373.8750, 1467287.3750,
         1467155.8750, 1465746.2500, 1465704.2500, 1465521.1250, 1465085.1250],
        [1293637.3750, 1273890.0000, 1272005.7500, 1269321.7500, 1264069.2500,
         1261125.2500, 1257919.3750, 1253042.6250, 1231541.2500, 1225596.2500],
        [1402554.3750, 1394058.5000, 1392130.7500, 1388688.5000, 1373305.8750,
         1371378.1250, 1369980.6250, 1368785.7500, 1367792.6250, 1366144.8750],
        [1293957.0000, 1255348.6250, 1226184.3750, 1220942.7500, 1197119.7500,
         1195986.6250, 1195089.3750, 1171122.7500, 1170212.8750, 1167230.3750],
        [1292945.3750, 1269335.0000, 1222030.7500, 1216124.7500, 1206107.5000,
         1201619.6250, 1189014.1250, 1173098.0000, 1163275.2500, 1144560.2500],
        [1272798.2500, 1256376.3750, 1247071.1250, 1240667.8750, 1230495.1250,
         1204012.3750, 1197450.8750, 1177884.8750, 1163621.5000, 1156238.8750],
        [1238117.1250, 1228094.2500, 1208039.0000, 1206067.2500, 1196671.1250,
         1192427.6250, 1173214.3750, 1164718.3750, 1160917.0000, 1155035.3750],
        [1465645.6250, 1463851.8750, 1463031.2500, 1460307.5000, 1460146.0000,
         1459483.2500, 1458446.7500, 1458165.7500, 1456166.0000, 1452705.3750],
        [1385793.8750, 1337607.1250, 1330789.6250, 1326989.0000, 1324550.0000,
         1317354.3750, 1313801.2500, 1311910.6250, 1310682.6250, 1309505.6250],
        [1500383.7500, 1498857.7500, 1493626.7500, 1493521.3750, 1487514.1250,
         1485655.5000, 1485188.1250, 1482523.3750, 1481141.2500, 1481138.5000],
        [1376521.0000, 1373298.0000, 1371231.5000, 1361042.0000, 1358732.2500,
         1354478.5000, 1350272.6250, 1346571.6250, 1346227.5000, 1335586.7500],
        [1374030.2500, 1363081.3750, 1360184.3750, 1350275.2500, 1348451.7500,
         1344223.6250, 1343395.7500, 1339875.8750, 1335605.8750, 1328696.0000],
        [1490570.1250, 1490361.1250, 1489306.8750, 1488633.8750, 1487924.2500,
         1487505.6250, 1487074.3750, 1486802.2500, 1485206.5000, 1484982.6250],
        [1489674.8750, 1489298.3750, 1489234.5000, 1485946.0000, 1484666.8750,
         1484007.2500, 1483007.0000, 1481958.0000, 1480740.1250, 1480270.0000],
        [1492587.2500, 1488149.8750, 1488108.6250, 1483502.1250, 1482345.1250,
         1482078.1250, 1481874.5000, 1481289.6250, 1480412.5000, 1480217.7500],
        [1446861.0000, 1446036.1250, 1445116.5000, 1443116.8750, 1442461.8750,
         1440538.7500, 1439197.0000, 1438022.6250, 1434223.5000, 1433345.6250],
        [1459373.2500, 1448423.7500, 1445691.3750, 1445129.0000, 1443480.2500,
         1437488.0000, 1434613.3750, 1432409.6250, 1430401.5000, 1430113.7500],
        [1433486.5000, 1419965.8750, 1416068.5000, 1415396.2500, 1414104.8750,
         1412735.5000, 1411286.6250, 1411248.7500, 1408139.2500, 1408120.3750],
        [1474923.7500, 1474842.1250, 1474679.0000, 1470906.2500, 1470592.1250,
         1468739.2500, 1468134.2500, 1464093.5000, 1463823.8750, 1463532.2500],
        [1483321.0000, 1478227.3750, 1473664.0000, 1472802.7500, 1470492.5000,
         1469941.6250, 1469518.2500, 1468501.1250, 1468295.2500, 1465645.6250],
        [1397771.3750, 1391175.2500, 1388782.6250, 1387589.7500, 1387288.1250,
         1385266.6250, 1383275.8750, 1381848.0000, 1380767.7500, 1376263.6250],
        [1478627.6250, 1474625.5000, 1469546.2500, 1469340.2500, 1465465.2500,
         1465004.1250, 1464944.0000, 1463916.1250, 1463071.6250, 1462969.8750],
        [1503321.3750, 1498312.0000, 1497230.6250, 1496993.6250, 1495079.0000,
         1494366.1250, 1493126.8750, 1492516.1250, 1492127.6250, 1491046.3750],
        [1445698.3750, 1418285.0000, 1417579.1250, 1414536.6250, 1411003.8750,
         1410272.0000, 1404282.2500, 1401734.7500, 1401484.7500, 1399958.0000],
        [1489980.3750, 1489272.8750, 1486678.7500, 1485562.1250, 1484177.1250,
         1482252.0000, 1481645.6250, 1481086.2500, 1481001.3750, 1480613.0000],
        [1491908.3750, 1489872.3750, 1488547.3750, 1479982.0000, 1476545.0000,
         1474887.1250, 1471564.3750, 1470449.1250, 1469844.7500, 1469139.8750],
        [1499710.0000, 1494096.8750, 1489761.6250, 1489078.2500, 1487446.0000,
         1487232.0000, 1485512.5000, 1484557.8750, 1483986.0000, 1483949.2500],
        [1499399.7500, 1497669.0000, 1494792.3750, 1493702.2500, 1491262.6250,
         1491072.0000, 1489082.6250, 1487911.3750, 1487840.5000, 1486985.1250],
        [1494943.3750, 1494669.8750, 1493463.0000, 1492429.2500, 1492195.8750,
         1491547.1250, 1490523.2500, 1490408.1250, 1489623.7500, 1489271.5000],
        [1494919.2500, 1494228.0000, 1493060.0000, 1492850.6250, 1492825.0000,
         1492785.1250, 1492464.8750, 1491966.7500, 1490311.3750, 1489571.1250],
        [1504899.3750, 1504279.5000, 1500595.5000, 1500298.0000, 1498930.7500,
         1496472.6250, 1494438.8750, 1494078.3750, 1493985.7500, 1493636.7500],
        [1342993.5000, 1317755.1250, 1315293.1250, 1246833.3750, 1244121.6250,
         1227627.0000, 1224404.7500, 1221525.1250, 1218053.8750, 1214885.6250],
        [1468732.2500, 1456275.7500, 1455552.2500, 1454854.2500, 1454034.5000,
         1453761.3750, 1452913.2500, 1452504.5000, 1451727.6250, 1451727.6250],
        [1481949.5000, 1481377.1250, 1479359.7500, 1479128.3750, 1478960.5000,
         1478116.0000, 1477846.6250, 1476340.7500, 1475749.6250, 1474736.6250],
        [1455810.5000, 1452504.5000, 1451216.7500, 1450241.5000, 1448708.3750,
         1448323.0000, 1448262.2500, 1448227.7500, 1448060.6250, 1446065.1250],
        [1343418.8750, 1328707.3750, 1324830.5000, 1317159.6250, 1314188.5000,
         1308257.3750, 1291695.7500, 1279556.5000, 1278278.3750, 1249790.5000],
        [1424068.1250, 1418895.1250, 1418102.5000, 1415976.7500, 1415531.1250,
         1414786.2500, 1414393.5000, 1412541.5000, 1411998.6250, 1411605.5000],
        [1369379.8750, 1364098.3750, 1363383.0000, 1363253.0000, 1361827.5000,
         1359064.1250, 1358175.2500, 1356922.0000, 1344295.3750, 1343073.0000],
        [1481593.2500, 1476370.3750, 1473812.8750, 1473384.2500, 1472087.8750,
         1470897.8750, 1469169.2500, 1468728.1250, 1467837.3750, 1467452.5000],
        [1330065.2500, 1298916.1250, 1296225.7500, 1275186.8750, 1265852.2500,
         1260790.8750, 1240585.0000, 1240557.7500, 1238817.5000, 1233528.8750],
        [1490322.8750, 1486062.2500, 1486026.7500, 1485013.8750, 1484965.7500,
         1484771.6250, 1483872.8750, 1483605.3750, 1483277.2500, 1483257.3750],
        [1491104.7500, 1485069.0000, 1484482.8750, 1483509.1250, 1482817.3750,
         1479867.6250, 1479584.1250, 1479179.1250, 1478512.1250, 1478053.8750],
        [1478211.8750, 1474996.8750, 1474960.2500, 1473808.7500, 1471605.1250,
         1471572.7500, 1470642.6250, 1470334.0000, 1470206.5000, 1470107.0000],
        [1408714.2500, 1406802.2500, 1405194.6250, 1405194.6250, 1404218.0000,
         1400230.2500, 1399773.6250, 1398014.0000, 1398008.7500, 1396875.8750],
        [1229853.5000, 1213176.6250, 1209310.5000, 1207579.5000, 1200509.6250,
         1194239.3750, 1191937.6250, 1187015.5000, 1182921.3750, 1182710.3750],
        [1237780.6250, 1156247.6250, 1114671.6250, 1035535.8125, 1021850.5000,
          992681.8750,  973820.6250,  973796.4375,  895325.5000,  875697.8750],
        [1272617.3750, 1192781.2500, 1181877.1250, 1128700.7500, 1128160.6250,
         1127132.5000, 1086919.5000, 1078917.7500, 1056996.7500, 1055021.7500],
        [1334894.0000, 1334457.5000, 1322443.5000, 1320059.5000, 1313275.1250,
         1310968.8750, 1305422.0000, 1303899.1250, 1303048.8750, 1298517.2500],
        [1400557.5000, 1382198.5000, 1380507.1250, 1380146.2500, 1379526.5000,
         1377904.0000, 1377232.6250, 1376086.5000, 1374684.2500, 1373634.6250],
        [1385470.1250, 1378570.3750, 1372410.2500, 1369965.0000, 1361808.0000,
         1356303.6250, 1354669.6250, 1354499.1250, 1351202.7500, 1350225.0000],
        [1371890.7500, 1369729.8750, 1368531.2500, 1367857.8750, 1363098.2500,
         1359646.1250, 1354050.8750, 1353454.5000, 1352352.6250, 1350055.0000],
        [1363930.6250, 1361971.7500, 1357979.7500, 1345784.6250, 1344048.0000,
         1339152.8750, 1332458.3750, 1327062.3750, 1321751.2500, 1307758.3750],
        [1349094.8750, 1347995.2500, 1326360.2500, 1297387.1250, 1296060.2500,
         1293395.5000, 1292447.3750, 1270067.5000, 1267432.2500, 1257322.0000],
        [1440836.7500, 1439829.8750, 1437837.6250, 1436471.1250, 1436394.3750,
         1434689.8750, 1433434.5000, 1431221.6250, 1430610.2500, 1429511.0000],
        [1456005.0000, 1454067.8750, 1451179.5000, 1447980.6250, 1447217.1250,
         1445118.0000, 1444712.8750, 1444343.7500, 1444044.7500, 1443838.2500],
        [1313906.5000, 1308402.1250, 1293316.6250, 1263990.8750, 1255245.7500,
         1237362.8750, 1236499.3750, 1229086.6250, 1223691.5000, 1222678.8750],
        [1312367.3750, 1271678.3750, 1271444.3750, 1247219.8750, 1218852.1250,
         1209135.1250, 1206981.8750, 1206336.3750, 1191751.2500, 1189621.0000],
        [1364976.7500, 1360439.8750, 1332909.5000, 1327600.3750, 1326508.1250,
         1320475.0000, 1319611.3750, 1310640.0000, 1310632.6250, 1309707.8750],
        [1419604.3750, 1388768.0000, 1374133.8750, 1373150.0000, 1369907.5000,
         1349538.8750, 1341763.3750, 1341530.3750, 1336740.0000, 1334867.3750],
        [1325628.0000, 1313081.0000, 1303219.1250, 1290400.5000, 1270855.1250,
         1265361.0000, 1264961.6250, 1264386.3750, 1260729.6250, 1259177.1250],
        [1447907.3750, 1439895.8750, 1436895.8750, 1435750.6250, 1435685.0000,
         1423683.8750, 1421060.5000, 1420602.5000, 1420552.3750, 1419677.5000],
        [1420666.1250, 1405531.0000, 1404911.8750, 1399872.5000, 1397086.3750,
         1395362.1250, 1394364.2500, 1392278.1250, 1392238.3750, 1388883.2500],
        [1407661.2500, 1402989.2500, 1402860.7500, 1399815.1250, 1397994.1250,
         1397870.0000, 1392022.0000, 1389682.1250, 1389293.8750, 1387327.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1465957.2500,       0.0000],
         [1462565.3750,       0.0000],
         [1460829.8750,       0.0000],
         ...,
         [1455977.1250,       0.0000],
         [1455800.7500,       0.0000],
         [1455349.6250,       0.0000]],

        [[1479968.0000,       0.0000],
         [1474558.0000,       0.0000],
         [1469920.5000,       0.0000],
         ...,
         [1465704.2500,       0.0000],
         [      0.0000, 1465521.1250],
         [1465085.1250,       0.0000]],

        [[      0.0000, 1293637.3750],
         [1273890.0000,       0.0000],
         [1272005.7500,       0.0000],
         ...,
         [      0.0000, 1253042.6250],
         [1231541.2500,       0.0000],
         [1225596.2500,       0.0000]],

        ...,

        [[1447907.3750,       0.0000],
         [1439895.8750,       0.0000],
         [1436895.8750,       0.0000],
         ...,
         [1420602.5000,       0.0000],
         [1420552.3750,       0.0000],
         [1419677.5000,       0.0000]],

        [[1420666.1250,       0.0000],
         [1405531.0000,       0.0000],
         [1404911.8750,       0.0000],
         ...,
         [1392278.1250,       0.0000],
         [1392238.3750,       0.0000],
         [1388883.2500,       0.0000]],

        [[1407661.2500,       0.0000],
         [1402989.2500,       0.0000],
         [      0.0000, 1402860.7500],
         ...,
         [1389682.1250,       0.0000],
         [      0.0000, 1389293.8750],
         [1387327.7500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14590514.0000,        0.0000],
        [13224799.0000,  1465521.1250],
        [ 7536425.0000,  5065724.5000],
        [13794820.0000,        0.0000],
        [ 4732412.0000,  7360783.0000],
        [ 7213445.5000,  4864665.0000],
        [10905949.0000,  1240667.8750],
        [ 5956468.0000,  5966833.5000],
        [14597949.0000,        0.0000],
        [13268984.0000,        0.0000],
        [14889551.0000,        0.0000],
        [10873256.0000,  2700706.0000],
        [10812338.0000,  2675481.7500],
        [14878367.0000,        0.0000],
        [14848804.0000,        0.0000],
        [14840566.0000,        0.0000],
        [11524037.0000,  2884883.5000],
        [10098909.0000,  4308214.5000],
        [14150553.0000,        0.0000],
        [10277844.0000,  4416422.0000],
        [14720410.0000,        0.0000],
        [12474762.0000,  1385266.6250],
        [14677510.0000,        0.0000],
        [14954120.0000,        0.0000],
        [12710299.0000,  1414536.6250],
        [14842270.0000,        0.0000],
        [14782741.0000,        0.0000],
        [14885330.0000,        0.0000],
        [14919718.0000,        0.0000],
        [14919076.0000,        0.0000],
        [14924982.0000,        0.0000],
        [14981616.0000,        0.0000],
        [ 7453737.5000,  5119756.0000],
        [11630846.0000,  2921236.7500],
        [11827864.0000,  2955700.5000],
        [13047179.0000,  1450241.5000],
        [ 9095748.0000,  3940135.0000],
        [ 9916369.0000,  4241530.0000],
        [10849993.0000,  2733478.2500],
        [14721334.0000,        0.0000],
        [ 7614794.0000,  5065732.5000],
        [14851177.0000,        0.0000],
        [14822179.0000,        0.0000],
        [13255803.0000,  1470642.6250],
        [ 9817662.0000,  4205363.5000],
        [ 5986663.5000,  6012590.5000],
        [ 5896738.5000,  4380670.0000],
        [ 3438738.5000,  7870387.0000],
        [ 6574115.5000,  6572870.5000],
        [13802478.0000,        0.0000],
        [12249654.0000,  1385470.1250],
        [ 6789234.0000,  6821433.0000],
        [       0.0000, 13401898.0000],
        [ 6611958.0000,  6385604.0000],
        [10036698.0000,  4314138.5000],
        [14478508.0000,        0.0000],
        [10038416.0000,  2545765.0000],
        [ 3673054.0000,  8652334.0000],
        [ 1309707.8750, 11973794.0000],
        [ 6736810.5000,  6893193.5000],
        [ 8984548.0000,  3833251.5000],
        [14301711.0000,        0.0000],
        [13991194.0000,        0.0000],
        [ 8385345.0000,  5582171.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 57.8125
Top1 accuracy for validation set is 57.8125 size is torch.Size([64, 1])
Epoch 51/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.68s/it]  7%|▋         | 2/29 [00:58<11:03, 24.58s/it] 10%|█         | 3/29 [01:01<06:15, 14.44s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.15s/it] 21%|██        | 6/29 [01:03<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.50s/it] 31%|███       | 9/29 [01:06<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 5.337108135223389
Epoch 52/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:33, 59.04s/it]  7%|▋         | 2/29 [00:59<11:11, 24.85s/it] 10%|█         | 3/29 [01:00<06:02, 13.93s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 5.312823295593262
Epoch 53/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:15, 60.55s/it]  7%|▋         | 2/29 [01:01<11:27, 25.47s/it] 10%|█         | 3/29 [01:02<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 5.26499080657959
Epoch 54/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:08, 60.30s/it]  7%|▋         | 2/29 [01:01<11:25, 25.37s/it] 10%|█         | 3/29 [01:02<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.96s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 5.249862194061279
Epoch 55/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:38, 57.09s/it]  7%|▋         | 2/29 [00:59<11:15, 25.02s/it] 10%|█         | 3/29 [01:00<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.99s/it] 21%|██        | 6/29 [01:03<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 5.211530685424805
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0177, 0.0056, 0.0005,  ..., 0.0026, 0.0027, 0.0204],
        [0.0194, 0.0033, 0.0006,  ..., 0.0013, 0.0036, 0.0231],
        [0.0368, 0.0094, 0.0023,  ..., 0.0102, 0.0154, 0.0182],
        ...,
        [0.0190, 0.0090, 0.0005,  ..., 0.0029, 0.0041, 0.0264],
        [0.0153, 0.0079, 0.0005,  ..., 0.0031, 0.0031, 0.0219],
        [0.0255, 0.0074, 0.0019,  ..., 0.0045, 0.0087, 0.0255]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9947, 0.9946, 0.9944, 0.9944, 0.9943, 0.9942, 0.9941, 0.9940, 0.9940,
         0.9940],
        [0.9949, 0.9949, 0.9947, 0.9947, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944,
         0.9944],
        [0.9855, 0.9853, 0.9831, 0.9831, 0.9828, 0.9817, 0.9817, 0.9817, 0.9816,
         0.9807],
        [0.9915, 0.9912, 0.9905, 0.9903, 0.9900, 0.9899, 0.9897, 0.9897, 0.9897,
         0.9895],
        [0.9863, 0.9822, 0.9818, 0.9811, 0.9808, 0.9799, 0.9797, 0.9797, 0.9795,
         0.9785],
        [0.9853, 0.9833, 0.9809, 0.9805, 0.9802, 0.9797, 0.9777, 0.9773, 0.9770,
         0.9769],
        [0.9809, 0.9805, 0.9802, 0.9791, 0.9788, 0.9781, 0.9749, 0.9743, 0.9742,
         0.9740],
        [0.9858, 0.9819, 0.9811, 0.9808, 0.9808, 0.9799, 0.9799, 0.9792, 0.9788,
         0.9783],
        [0.9949, 0.9945, 0.9943, 0.9942, 0.9941, 0.9941, 0.9941, 0.9941, 0.9941,
         0.9941],
        [0.9901, 0.9884, 0.9884, 0.9877, 0.9874, 0.9874, 0.9873, 0.9871, 0.9867,
         0.9866],
        [0.9960, 0.9957, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953, 0.9953, 0.9953,
         0.9952],
        [0.9904, 0.9901, 0.9892, 0.9892, 0.9890, 0.9889, 0.9887, 0.9886, 0.9884,
         0.9883],
        [0.9901, 0.9896, 0.9891, 0.9891, 0.9889, 0.9889, 0.9881, 0.9878, 0.9877,
         0.9874],
        [0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9955, 0.9953, 0.9953, 0.9952, 0.9952, 0.9952, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9953, 0.9953, 0.9952, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948,
         0.9947],
        [0.9934, 0.9934, 0.9933, 0.9932, 0.9932, 0.9930, 0.9930, 0.9930, 0.9929,
         0.9929],
        [0.9941, 0.9935, 0.9934, 0.9933, 0.9931, 0.9931, 0.9930, 0.9929, 0.9928,
         0.9928],
        [0.9929, 0.9925, 0.9923, 0.9922, 0.9921, 0.9920, 0.9920, 0.9920, 0.9919,
         0.9916],
        [0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9947, 0.9947, 0.9945,
         0.9945],
        [0.9951, 0.9950, 0.9948, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9913, 0.9906, 0.9906, 0.9905, 0.9904, 0.9903, 0.9903, 0.9902, 0.9899,
         0.9899],
        [0.9948, 0.9945, 0.9944, 0.9944, 0.9944, 0.9943, 0.9943, 0.9941, 0.9941,
         0.9940],
        [0.9960, 0.9957, 0.9957, 0.9957, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9955],
        [0.9935, 0.9921, 0.9921, 0.9921, 0.9919, 0.9917, 0.9917, 0.9917, 0.9916,
         0.9916],
        [0.9954, 0.9953, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9950, 0.9949, 0.9949, 0.9948, 0.9947, 0.9945, 0.9944, 0.9943, 0.9942,
         0.9941],
        [0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9950, 0.9949, 0.9949,
         0.9949],
        [0.9958, 0.9958, 0.9957, 0.9956, 0.9954, 0.9954, 0.9954, 0.9953, 0.9952,
         0.9952],
        [0.9959, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9956, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951,
         0.9951],
        [0.9959, 0.9958, 0.9956, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9895, 0.9873, 0.9870, 0.9832, 0.9818, 0.9815, 0.9811, 0.9809, 0.9804,
         0.9803],
        [0.9946, 0.9946, 0.9941, 0.9941, 0.9940, 0.9940, 0.9940, 0.9940, 0.9939,
         0.9939],
        [0.9951, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9947],
        [0.9937, 0.9937, 0.9937, 0.9934, 0.9933, 0.9932, 0.9932, 0.9931, 0.9931,
         0.9930],
        [0.9885, 0.9881, 0.9875, 0.9863, 0.9862, 0.9854, 0.9842, 0.9835, 0.9835,
         0.9812],
        [0.9923, 0.9922, 0.9921, 0.9919, 0.9919, 0.9919, 0.9918, 0.9918, 0.9916,
         0.9915],
        [0.9896, 0.9894, 0.9893, 0.9892, 0.9890, 0.9889, 0.9888, 0.9886, 0.9886,
         0.9885],
        [0.9953, 0.9950, 0.9946, 0.9945, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944,
         0.9944],
        [0.9883, 0.9867, 0.9866, 0.9842, 0.9827, 0.9827, 0.9823, 0.9823, 0.9821,
         0.9804],
        [0.9953, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948, 0.9946, 0.9946,
         0.9946],
        [0.9951, 0.9951, 0.9950, 0.9949, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947,
         0.9947],
        [0.9948, 0.9946, 0.9946, 0.9946, 0.9946, 0.9946, 0.9945, 0.9945, 0.9945,
         0.9944],
        [0.9913, 0.9911, 0.9910, 0.9910, 0.9910, 0.9909, 0.9908, 0.9908, 0.9908,
         0.9907],
        [0.9797, 0.9792, 0.9791, 0.9790, 0.9787, 0.9787, 0.9784, 0.9779, 0.9778,
         0.9777],
        [0.9805, 0.9781, 0.9750, 0.9666, 0.9652, 0.9651, 0.9639, 0.9605, 0.9604,
         0.9599],
        [0.9811, 0.9809, 0.9772, 0.9771, 0.9747, 0.9733, 0.9732, 0.9725, 0.9721,
         0.9720],
        [0.9882, 0.9875, 0.9872, 0.9869, 0.9864, 0.9864, 0.9863, 0.9861, 0.9859,
         0.9857],
        [0.9904, 0.9902, 0.9900, 0.9898, 0.9896, 0.9896, 0.9896, 0.9896, 0.9894,
         0.9893],
        [0.9896, 0.9896, 0.9894, 0.9893, 0.9889, 0.9889, 0.9888, 0.9885, 0.9885,
         0.9884],
        [0.9896, 0.9894, 0.9892, 0.9891, 0.9890, 0.9881, 0.9880, 0.9880, 0.9877,
         0.9873],
        [0.9895, 0.9889, 0.9887, 0.9885, 0.9881, 0.9881, 0.9880, 0.9869, 0.9868,
         0.9860],
        [0.9887, 0.9884, 0.9866, 0.9861, 0.9859, 0.9851, 0.9850, 0.9847, 0.9836,
         0.9833],
        [0.9933, 0.9931, 0.9930, 0.9927, 0.9927, 0.9926, 0.9926, 0.9926, 0.9925,
         0.9925],
        [0.9934, 0.9933, 0.9933, 0.9932, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,
         0.9930],
        [0.9867, 0.9863, 0.9854, 0.9831, 0.9831, 0.9825, 0.9823, 0.9817, 0.9816,
         0.9810],
        [0.9858, 0.9842, 0.9836, 0.9833, 0.9821, 0.9819, 0.9817, 0.9804, 0.9800,
         0.9800],
        [0.9884, 0.9882, 0.9878, 0.9876, 0.9872, 0.9869, 0.9867, 0.9863, 0.9862,
         0.9858],
        [0.9922, 0.9898, 0.9896, 0.9893, 0.9887, 0.9885, 0.9885, 0.9878, 0.9875,
         0.9875],
        [0.9871, 0.9868, 0.9859, 0.9846, 0.9845, 0.9840, 0.9838, 0.9837, 0.9835,
         0.9835],
        [0.9926, 0.9923, 0.9916, 0.9914, 0.9914, 0.9913, 0.9913, 0.9910, 0.9910,
         0.9909],
        [0.9910, 0.9910, 0.9909, 0.9907, 0.9906, 0.9906, 0.9906, 0.9904, 0.9902,
         0.9899],
        [0.9911, 0.9906, 0.9906, 0.9905, 0.9905, 0.9903, 0.9898, 0.9898, 0.9897,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 0],
        [0, 1, 1, 0, 1, 1, 0, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [1, 1, 0, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 1, 0, 0, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 0, 1, 1, 0, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 1, 0, 0, 1, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
        [1, 1, 0, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 0, 1, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1484334.2500, 1480524.1250, 1478286.5000, 1478231.5000, 1474215.0000,
         1473239.5000, 1471595.2500, 1469753.6250, 1469693.5000, 1468754.6250],
        [1488357.0000, 1487094.2500, 1484011.5000, 1483858.6250, 1478739.1250,
         1478548.7500, 1478187.7500, 1478070.7500, 1477886.2500, 1477808.7500],
        [1300847.5000, 1298107.3750, 1257452.7500, 1256512.8750, 1251789.7500,
         1232616.3750, 1232509.3750, 1232290.8750, 1230702.8750, 1214389.8750],
        [1416888.5000, 1410769.8750, 1396287.2500, 1393075.0000, 1386621.3750,
         1384727.7500, 1382008.7500, 1381468.5000, 1380564.8750, 1377130.2500],
        [1315705.8750, 1241604.1250, 1233127.8750, 1221451.6250, 1216600.3750,
         1200664.1250, 1197477.2500, 1197069.5000, 1193798.7500, 1176772.1250],
        [1297025.8750, 1260961.6250, 1218597.6250, 1211121.2500, 1205792.2500,
         1196929.1250, 1163295.2500, 1157318.7500, 1152602.3750, 1150870.2500],
        [1218897.5000, 1211318.8750, 1206336.3750, 1186893.2500, 1182065.3750,
         1170050.0000, 1117571.0000, 1108776.7500, 1107026.0000, 1103822.2500],
        [1306022.2500, 1236492.2500, 1222239.3750, 1216113.1250, 1215612.2500,
         1201675.6250, 1200784.3750, 1188830.3750, 1182719.3750, 1174412.1250],
        [1488273.2500, 1480111.8750, 1475092.5000, 1473922.5000, 1471842.2500,
         1470889.5000, 1470833.3750, 1470754.8750, 1470264.0000, 1470139.2500],
        [1389137.6250, 1356372.1250, 1355937.6250, 1342573.5000, 1336849.6250,
         1336293.8750, 1334900.5000, 1330836.6250, 1324015.7500, 1322384.1250],
        [1511988.6250, 1504204.8750, 1499455.5000, 1498131.8750, 1497692.0000,
         1496959.3750, 1496691.0000, 1496623.8750, 1496135.7500, 1494148.1250],
        [1394275.2500, 1389666.2500, 1372015.1250, 1371779.6250, 1367486.2500,
         1366529.3750, 1361739.2500, 1360408.7500, 1355733.2500, 1354261.5000],
        [1389401.1250, 1379948.8750, 1370213.2500, 1368676.1250, 1366141.0000,
         1366137.1250, 1350879.3750, 1344533.8750, 1342660.5000, 1337451.5000],
        [1502177.7500, 1501241.2500, 1500611.2500, 1500089.1250, 1500086.2500,
         1499208.1250, 1497460.5000, 1497367.7500, 1497076.3750, 1496034.6250],
        [1499629.8750, 1496057.3750, 1495626.5000, 1494533.0000, 1493960.1250,
         1493911.6250, 1493629.5000, 1492326.8750, 1491420.5000, 1491268.3750],
        [1497027.8750, 1495366.8750, 1495184.5000, 1489575.5000, 1488826.8750,
         1486983.7500, 1486566.8750, 1486559.7500, 1485458.6250, 1484550.8750],
        [1456678.6250, 1455521.8750, 1453371.8750, 1451900.6250, 1451582.2500,
         1448752.6250, 1448325.7500, 1447842.3750, 1446421.0000, 1445534.2500],
        [1470003.1250, 1457636.0000, 1456659.1250, 1454402.0000, 1450937.2500,
         1450313.3750, 1448124.1250, 1445590.7500, 1444334.0000, 1444240.3750],
        [1445942.3750, 1436712.1250, 1432904.1250, 1432331.6250, 1428884.1250,
         1428446.6250, 1427964.5000, 1427036.1250, 1424638.7500, 1420006.5000],
        [1486228.0000, 1486016.7500, 1485030.8750, 1484039.7500, 1483947.7500,
         1483280.0000, 1483275.7500, 1483178.1250, 1479320.2500, 1479021.1250],
        [1492854.8750, 1490945.5000, 1484894.8750, 1483980.3750, 1481275.3750,
         1481183.6250, 1478741.8750, 1478677.0000, 1478187.7500, 1477590.2500],
        [1414280.2500, 1399578.7500, 1398567.5000, 1396742.6250, 1394581.1250,
         1394086.3750, 1393581.2500, 1391816.2500, 1386173.2500, 1386105.8750],
        [1486433.6250, 1479066.3750, 1477959.5000, 1477505.6250, 1476774.5000,
         1475053.1250, 1474769.0000, 1471488.6250, 1470109.7500, 1468393.2500],
        [1510459.3750, 1505927.3750, 1505858.3750, 1505858.3750, 1505798.0000,
         1505213.6250, 1504504.7500, 1502865.6250, 1502487.2500, 1500675.7500],
        [1458057.2500, 1429806.8750, 1428976.6250, 1428751.8750, 1424756.8750,
         1421608.1250, 1421438.6250, 1421438.6250, 1418636.6250, 1418405.3750],
        [1498973.6250, 1496656.7500, 1496355.6250, 1494252.2500, 1491796.1250,
         1489788.5000, 1489622.3750, 1489207.5000, 1489187.6250, 1489101.0000],
        [1490901.3750, 1488581.3750, 1486996.5000, 1485536.5000, 1483874.2500,
         1480354.6250, 1477521.1250, 1475124.8750, 1472913.7500, 1471805.7500],
        [1494936.3750, 1494027.0000, 1493065.6250, 1492433.5000, 1491447.5000,
         1491074.8750, 1490071.3750, 1488736.1250, 1487768.1250, 1487569.5000],
        [1507236.2500, 1506496.1250, 1505322.7500, 1503539.3750, 1499223.7500,
         1498170.5000, 1497671.8750, 1495588.0000, 1494206.6250, 1493582.5000],
        [1508959.2500, 1502127.6250, 1500076.2500, 1499534.1250, 1499319.5000,
         1498029.0000, 1497870.3750, 1496495.5000, 1496338.5000, 1495964.6250],
        [1502023.0000, 1497324.7500, 1496918.0000, 1496148.6250, 1496058.7500,
         1495444.0000, 1494533.0000, 1493578.3750, 1492386.5000, 1492200.1250],
        [1509295.8750, 1507325.2500, 1502513.1250, 1499249.6250, 1498606.2500,
         1498362.0000, 1498289.0000, 1497119.2500, 1496719.5000, 1495675.0000],
        [1376597.1250, 1334452.3750, 1329031.8750, 1258089.7500, 1233274.8750,
         1229512.2500, 1221452.8750, 1217777.3750, 1209414.2500, 1206937.0000],
        [1482318.3750, 1480587.7500, 1470426.6250, 1470053.6250, 1469637.3750,
         1469190.2500, 1469037.6250, 1468246.2500, 1467412.0000, 1466835.3750],
        [1492840.6250, 1490764.8750, 1489316.8750, 1486813.5000, 1486294.7500,
         1484695.2500, 1484611.6250, 1484151.6250, 1483969.0000, 1483903.8750],
        [1462370.0000, 1462282.2500, 1461725.8750, 1455655.1250, 1453800.1250,
         1453013.0000, 1451276.3750, 1450666.1250, 1449481.0000, 1448084.0000],
        [1358509.3750, 1349380.5000, 1339174.6250, 1316162.6250, 1313623.2500,
         1299111.7500, 1277571.5000, 1264932.7500, 1263636.6250, 1222867.7500],
        [1432670.5000, 1432268.8750, 1429620.0000, 1426332.6250, 1425916.3750,
         1424672.6250, 1423614.7500, 1422727.0000, 1419519.1250, 1418140.3750],
        [1380250.3750, 1376111.5000, 1373303.2500, 1371388.5000, 1367919.2500,
         1365816.6250, 1362760.3750, 1360187.0000, 1358895.5000, 1357004.8750],
        [1495612.2500, 1489825.5000, 1481842.1250, 1480073.7500, 1478395.0000,
         1478368.2500, 1477880.5000, 1477108.3750, 1477056.3750, 1476809.7500],
        [1354572.7500, 1323789.7500, 1320905.7500, 1276793.1250, 1250017.0000,
         1249487.8750, 1242961.8750, 1242758.0000, 1239541.8750, 1209431.6250],
        [1496599.6250, 1490577.3750, 1487688.6250, 1487314.1250, 1486891.6250,
         1485852.5000, 1484961.5000, 1482458.3750, 1482227.8750, 1481144.1250],
        [1492733.8750, 1491589.7500, 1490443.7500, 1487840.5000, 1486698.7500,
         1486238.0000, 1486111.8750, 1484671.1250, 1484263.3750, 1483773.7500],
        [1484742.0000, 1482544.6250, 1481799.6250, 1481703.5000, 1481510.0000,
         1481477.5000, 1480135.8750, 1479835.2500, 1478476.7500, 1476540.7500],
        [1413869.0000, 1409872.6250, 1408101.7500, 1407282.7500, 1406916.3750,
         1405048.6250, 1402646.6250, 1402546.3750, 1402375.2500, 1400409.2500],
        [1198273.3750, 1189221.6250, 1187476.3750, 1185683.8750, 1180978.0000,
         1180474.7500, 1175016.0000, 1167851.6250, 1165448.3750, 1163900.0000],
        [1211307.3750, 1170181.7500, 1119411.0000,  992615.5625,  973408.3125,
          971665.6250,  954936.0000,  909894.1875,  909041.6250,  902344.2500],
        [1222424.7500, 1218281.5000, 1154934.0000, 1153672.3750, 1115352.1250,
         1092075.1250, 1090830.2500, 1079920.3750, 1073869.2500, 1073339.0000],
        [1351790.5000, 1338695.7500, 1333050.6250, 1326422.1250, 1317475.0000,
         1316914.6250, 1315639.2500, 1312418.6250, 1308026.6250, 1304300.8750],
        [1395177.0000, 1391671.5000, 1388000.0000, 1383975.1250, 1380277.8750,
         1380076.6250, 1378694.0000, 1378415.3750, 1375469.8750, 1374102.3750],
        [1380163.3750, 1379263.5000, 1374941.3750, 1372854.1250, 1365988.6250,
         1365816.6250, 1363228.2500, 1358262.0000, 1356915.5000, 1355924.7500],
        [1379155.5000, 1376200.6250, 1371549.3750, 1370287.7500, 1367633.5000,
         1349385.6250, 1348922.3750, 1347847.5000, 1342378.8750, 1335712.8750],
        [1377144.7500, 1365093.8750, 1361191.2500, 1357942.1250, 1350434.8750,
         1350428.5000, 1347354.0000, 1327032.0000, 1324934.1250, 1309761.7500],
        [1361554.8750, 1355971.2500, 1320827.6250, 1311791.7500, 1309139.7500,
         1293287.0000, 1292175.0000, 1285922.7500, 1265552.8750, 1261201.0000],
        [1455137.3750, 1449298.5000, 1447535.8750, 1441834.7500, 1441540.5000,
         1440692.5000, 1439549.8750, 1439453.7500, 1438280.5000, 1437311.1250],
        [1455854.8750, 1455198.3750, 1454650.2500, 1451792.7500, 1450511.1250,
         1450454.3750, 1450111.5000, 1449527.8750, 1449290.2500, 1448506.7500],
        [1322480.0000, 1315245.3750, 1299111.7500, 1257211.7500, 1256721.5000,
         1246787.0000, 1243290.2500, 1232141.6250, 1229899.2500, 1220527.1250],
        [1306469.3750, 1276759.0000, 1266733.8750, 1259936.2500, 1239445.0000,
         1236190.5000, 1231314.5000, 1210053.3750, 1203280.0000, 1201841.8750],
        [1355847.1250, 1351723.3750, 1343507.2500, 1339974.2500, 1333795.8750,
         1326999.1250, 1323633.2500, 1314934.3750, 1313949.0000, 1305961.1250],
        [1431283.0000, 1383633.3750, 1378797.8750, 1372961.3750, 1360805.7500,
         1358297.0000, 1357253.3750, 1344239.0000, 1339154.1250, 1337820.1250],
        [1330174.3750, 1325663.3750, 1307736.0000, 1283944.8750, 1281840.5000,
         1273739.3750, 1270206.8750, 1268302.8750, 1264908.5000, 1264226.0000],
        [1439729.7500, 1433537.0000, 1420361.3750, 1415143.7500, 1415089.7500,
         1412858.1250, 1412673.5000, 1408186.2500, 1407524.3750, 1404791.3750],
        [1408009.0000, 1407543.1250, 1405895.6250, 1401093.2500, 1399510.7500,
         1399185.1250, 1398250.1250, 1394869.7500, 1390823.7500, 1384875.7500],
        [1408996.2500, 1398967.6250, 1398586.1250, 1398223.3750, 1397026.3750,
         1392449.5000, 1383446.0000, 1382864.2500, 1381169.3750, 1380368.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1484334.2500,       0.0000],
         [1480524.1250,       0.0000],
         [1478286.5000,       0.0000],
         ...,
         [1469753.6250,       0.0000],
         [1469693.5000,       0.0000],
         [1468754.6250,       0.0000]],

        [[1488357.0000,       0.0000],
         [1487094.2500,       0.0000],
         [1484011.5000,       0.0000],
         ...,
         [1478070.7500,       0.0000],
         [1477886.2500,       0.0000],
         [1477808.7500,       0.0000]],

        [[      0.0000, 1300847.5000],
         [1298107.3750,       0.0000],
         [1257452.7500,       0.0000],
         ...,
         [1232290.8750,       0.0000],
         [1230702.8750,       0.0000],
         [      0.0000, 1214389.8750]],

        ...,

        [[1439729.7500,       0.0000],
         [1433537.0000,       0.0000],
         [1420361.3750,       0.0000],
         ...,
         [1408186.2500,       0.0000],
         [1407524.3750,       0.0000],
         [1404791.3750,       0.0000]],

        [[1408009.0000,       0.0000],
         [1407543.1250,       0.0000],
         [1405895.6250,       0.0000],
         ...,
         [1394869.7500,       0.0000],
         [1390823.7500,       0.0000],
         [1384875.7500,       0.0000]],

        [[      0.0000, 1408996.2500],
         [1398967.6250,       0.0000],
         [1398586.1250,       0.0000],
         ...,
         [      0.0000, 1382864.2500],
         [1381169.3750,       0.0000],
         [      0.0000, 1380368.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[11803793.0000,  2944834.7500],
        [14812562.0000,        0.0000],
        [ 6275067.0000,  6232153.0000],
        [12524814.0000,  1384727.7500],
        [ 4771983.0000,  7422288.5000],
        [ 5979631.0000,  6034882.5000],
        [ 8086325.0000,  3526432.0000],
        [ 6057832.5000,  6087068.5000],
        [14742124.0000,        0.0000],
        [13429301.0000,        0.0000],
        [14992030.0000,        0.0000],
        [12326408.0000,  1367486.2500],
        [10896487.0000,  2719555.5000],
        [14991353.0000,        0.0000],
        [14942364.0000,        0.0000],
        [14896101.0000,        0.0000],
        [11604234.0000,  2901697.5000],
        [ 8727070.0000,  5795170.0000],
        [14304866.0000,        0.0000],
        [10385708.0000,  4447631.0000],
        [14828332.0000,        0.0000],
        [11161849.0000,  2793665.0000],
        [14757554.0000,        0.0000],
        [15049649.0000,        0.0000],
        [12842900.0000,  1428976.6250],
        [14924942.0000,        0.0000],
        [14813610.0000,        0.0000],
        [14911130.0000,        0.0000],
        [15001038.0000,        0.0000],
        [14994714.0000,        0.0000],
        [14956615.0000,        0.0000],
        [15003155.0000,        0.0000],
        [ 6254207.0000,  6362333.0000],
        [11761790.0000,  2951955.7500],
        [13376597.0000,  1490764.8750],
        [10173591.0000,  4374762.0000],
        [ 7832399.0000,  5172572.0000],
        [11406344.0000,  2849139.0000],
        [10937338.0000,  2736298.5000],
        [14812972.0000,        0.0000],
        [ 6414604.0000,  6295655.0000],
        [14865716.0000,        0.0000],
        [14874366.0000,        0.0000],
        [13327257.0000,  1481510.0000],
        [ 9837776.0000,  4221293.0000],
        [ 3519228.0000,  8275096.5000],
        [ 4947591.5000,  5167214.0000],
        [ 2269024.5000,  9005674.0000],
        [ 9242141.0000,  3982593.0000],
        [13825860.0000,        0.0000],
        [12317433.0000,  1355924.7500],
        [ 5412236.0000,  8176838.0000],
        [       0.0000, 13471317.0000],
        [ 6623815.5000,  6433608.0000],
        [12975498.0000,  1455137.3750],
        [14515898.0000,        0.0000],
        [ 8840856.0000,  3782559.5000],
        [ 4936081.0000,  7495943.0000],
        [ 2620895.5000, 10689429.0000],
        [ 5413025.5000,  8251219.5000],
        [ 6511745.0000,  6358998.5000],
        [14169895.0000,        0.0000],
        [13990057.0000,        0.0000],
        [ 9749868.0000,  4172229.2500]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 59.375
Top1 accuracy for validation set is 59.375 size is torch.Size([64, 1])
Epoch 56/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.24s/it]  7%|▋         | 2/29 [01:01<11:24, 25.35s/it] 10%|█         | 3/29 [01:02<06:09, 14.19s/it] 14%|█▍        | 4/29 [01:03<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 5.185379981994629
Epoch 57/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:27, 58.84s/it]  7%|▋         | 2/29 [00:59<11:08, 24.77s/it] 10%|█         | 3/29 [01:00<06:00, 13.88s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.76s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 5.140934944152832
Epoch 58/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.14s/it]  7%|▋         | 2/29 [01:01<11:23, 25.30s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 5.107213973999023
Epoch 59/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:59, 57.85s/it]  7%|▋         | 2/29 [00:58<10:57, 24.36s/it] 10%|█         | 3/29 [00:59<05:55, 13.66s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.63s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:36,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.06it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 5.088637828826904
Epoch 60/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:21, 60.78s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 5.06613826751709
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0167, 0.0058, 0.0008,  ..., 0.0024, 0.0030, 0.0200],
        [0.0177, 0.0042, 0.0007,  ..., 0.0024, 0.0030, 0.0229],
        [0.0403, 0.0076, 0.0032,  ..., 0.0090, 0.0181, 0.0184],
        ...,
        [0.0183, 0.0096, 0.0003,  ..., 0.0022, 0.0028, 0.0249],
        [0.0157, 0.0085, 0.0003,  ..., 0.0035, 0.0031, 0.0218],
        [0.0264, 0.0073, 0.0021,  ..., 0.0046, 0.0085, 0.0244]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9951, 0.9942, 0.9942, 0.9942, 0.9941, 0.9941, 0.9940, 0.9940, 0.9940,
         0.9939],
        [0.9950, 0.9950, 0.9950, 0.9950, 0.9948, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9946],
        [0.9849, 0.9841, 0.9833, 0.9833, 0.9829, 0.9820, 0.9811, 0.9809, 0.9799,
         0.9798],
        [0.9914, 0.9910, 0.9909, 0.9909, 0.9904, 0.9903, 0.9902, 0.9897, 0.9897,
         0.9896],
        [0.9859, 0.9825, 0.9816, 0.9816, 0.9808, 0.9805, 0.9802, 0.9799, 0.9790,
         0.9789],
        [0.9866, 0.9822, 0.9810, 0.9808, 0.9800, 0.9800, 0.9797, 0.9791, 0.9764,
         0.9756],
        [0.9819, 0.9810, 0.9795, 0.9790, 0.9783, 0.9778, 0.9765, 0.9755, 0.9741,
         0.9735],
        [0.9850, 0.9818, 0.9814, 0.9798, 0.9793, 0.9792, 0.9791, 0.9788, 0.9788,
         0.9774],
        [0.9948, 0.9946, 0.9944, 0.9943, 0.9943, 0.9942, 0.9941, 0.9941, 0.9941,
         0.9940],
        [0.9890, 0.9876, 0.9874, 0.9871, 0.9871, 0.9871, 0.9862, 0.9861, 0.9860,
         0.9859],
        [0.9960, 0.9957, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9904, 0.9898, 0.9892, 0.9889, 0.9887, 0.9886, 0.9883, 0.9882, 0.9880,
         0.9878],
        [0.9899, 0.9898, 0.9897, 0.9896, 0.9893, 0.9890, 0.9890, 0.9882, 0.9879,
         0.9879],
        [0.9961, 0.9957, 0.9957, 0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9957, 0.9955, 0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9955, 0.9953, 0.9952, 0.9950, 0.9949, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9931, 0.9930, 0.9930, 0.9930, 0.9930, 0.9929, 0.9929, 0.9928, 0.9928,
         0.9927],
        [0.9939, 0.9935, 0.9933, 0.9933, 0.9933, 0.9932, 0.9931, 0.9928, 0.9926,
         0.9924],
        [0.9931, 0.9924, 0.9920, 0.9918, 0.9917, 0.9917, 0.9916, 0.9916, 0.9915,
         0.9914],
        [0.9954, 0.9951, 0.9948, 0.9946, 0.9946, 0.9945, 0.9945, 0.9945, 0.9945,
         0.9945],
        [0.9952, 0.9949, 0.9949, 0.9949, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945,
         0.9945],
        [0.9908, 0.9905, 0.9904, 0.9902, 0.9901, 0.9900, 0.9900, 0.9900, 0.9900,
         0.9899],
        [0.9953, 0.9950, 0.9950, 0.9948, 0.9948, 0.9947, 0.9947, 0.9945, 0.9945,
         0.9944],
        [0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9935, 0.9927, 0.9916, 0.9915, 0.9914, 0.9913, 0.9913, 0.9912, 0.9912,
         0.9912],
        [0.9962, 0.9958, 0.9958, 0.9958, 0.9957, 0.9955, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9957, 0.9956, 0.9955, 0.9955, 0.9955, 0.9954, 0.9952, 0.9950, 0.9949,
         0.9948],
        [0.9959, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9952],
        [0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956,
         0.9956],
        [0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956, 0.9956,
         0.9956],
        [0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9960, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9886, 0.9876, 0.9870, 0.9815, 0.9814, 0.9812, 0.9802, 0.9802, 0.9802,
         0.9800],
        [0.9944, 0.9943, 0.9942, 0.9941, 0.9940, 0.9940, 0.9940, 0.9939, 0.9938,
         0.9938],
        [0.9950, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9942, 0.9937, 0.9936, 0.9936, 0.9936, 0.9934, 0.9932, 0.9932, 0.9932,
         0.9931],
        [0.9894, 0.9889, 0.9877, 0.9867, 0.9864, 0.9858, 0.9857, 0.9843, 0.9838,
         0.9829],
        [0.9931, 0.9926, 0.9925, 0.9924, 0.9923, 0.9922, 0.9922, 0.9921, 0.9921,
         0.9921],
        [0.9898, 0.9897, 0.9895, 0.9890, 0.9887, 0.9887, 0.9887, 0.9886, 0.9885,
         0.9884],
        [0.9951, 0.9950, 0.9949, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9945,
         0.9945],
        [0.9890, 0.9872, 0.9863, 0.9849, 0.9828, 0.9820, 0.9819, 0.9804, 0.9804,
         0.9796],
        [0.9954, 0.9954, 0.9953, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9948],
        [0.9951, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949,
         0.9949],
        [0.9954, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9948,
         0.9948],
        [0.9919, 0.9918, 0.9917, 0.9916, 0.9914, 0.9910, 0.9909, 0.9909, 0.9909,
         0.9907],
        [0.9815, 0.9803, 0.9797, 0.9793, 0.9792, 0.9788, 0.9783, 0.9779, 0.9779,
         0.9775],
        [0.9790, 0.9775, 0.9737, 0.9726, 0.9683, 0.9619, 0.9618, 0.9616, 0.9609,
         0.9604],
        [0.9812, 0.9808, 0.9774, 0.9757, 0.9752, 0.9748, 0.9745, 0.9724, 0.9722,
         0.9717],
        [0.9884, 0.9875, 0.9871, 0.9870, 0.9869, 0.9862, 0.9858, 0.9855, 0.9855,
         0.9854],
        [0.9904, 0.9903, 0.9902, 0.9900, 0.9899, 0.9899, 0.9897, 0.9897, 0.9897,
         0.9896],
        [0.9898, 0.9896, 0.9895, 0.9893, 0.9892, 0.9892, 0.9892, 0.9892, 0.9891,
         0.9886],
        [0.9904, 0.9902, 0.9895, 0.9894, 0.9893, 0.9888, 0.9883, 0.9881, 0.9881,
         0.9879],
        [0.9903, 0.9894, 0.9893, 0.9893, 0.9887, 0.9886, 0.9886, 0.9876, 0.9868,
         0.9867],
        [0.9885, 0.9884, 0.9861, 0.9861, 0.9853, 0.9850, 0.9841, 0.9837, 0.9834,
         0.9832],
        [0.9935, 0.9929, 0.9925, 0.9925, 0.9924, 0.9923, 0.9923, 0.9923, 0.9922,
         0.9922],
        [0.9938, 0.9937, 0.9937, 0.9937, 0.9936, 0.9936, 0.9936, 0.9935, 0.9935,
         0.9935],
        [0.9874, 0.9860, 0.9857, 0.9838, 0.9831, 0.9828, 0.9822, 0.9819, 0.9813,
         0.9809],
        [0.9855, 0.9851, 0.9843, 0.9840, 0.9835, 0.9818, 0.9818, 0.9815, 0.9814,
         0.9812],
        [0.9894, 0.9886, 0.9885, 0.9884, 0.9881, 0.9879, 0.9873, 0.9873, 0.9869,
         0.9861],
        [0.9926, 0.9905, 0.9900, 0.9893, 0.9890, 0.9889, 0.9888, 0.9883, 0.9881,
         0.9881],
        [0.9878, 0.9873, 0.9866, 0.9864, 0.9851, 0.9848, 0.9846, 0.9844, 0.9844,
         0.9842],
        [0.9928, 0.9926, 0.9922, 0.9920, 0.9919, 0.9918, 0.9916, 0.9915, 0.9914,
         0.9912],
        [0.9912, 0.9910, 0.9910, 0.9909, 0.9909, 0.9908, 0.9907, 0.9905, 0.9903,
         0.9901],
        [0.9913, 0.9909, 0.9907, 0.9906, 0.9906, 0.9906, 0.9901, 0.9899, 0.9897,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 1, 0, 1],
        [0, 1, 1, 0, 0, 1, 0, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 1, 1, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 1, 0, 0, 1, 1, 1],
        [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 0, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1491077.7500, 1474009.7500, 1473512.1250, 1473052.7500, 1471777.7500,
         1470829.1250, 1469865.7500, 1468793.8750, 1468751.8750, 1467782.8750],
        [1490439.3750, 1490152.3750, 1489917.7500, 1489111.0000, 1486273.5000,
         1484587.6250, 1484423.3750, 1482123.2500, 1482021.5000, 1481901.3750],
        [1289807.5000, 1275864.3750, 1260522.8750, 1259760.8750, 1254195.1250,
         1237329.7500, 1221606.6250, 1218763.7500, 1201320.3750, 1198488.2500],
        [1415088.3750, 1408026.3750, 1405496.2500, 1404768.6250, 1395066.6250,
         1393460.3750, 1390724.2500, 1381924.3750, 1380632.1250, 1378532.2500],
        [1307827.0000, 1245624.6250, 1230866.1250, 1230014.1250, 1215641.2500,
         1211281.8750, 1206560.7500, 1201337.6250, 1186315.0000, 1183914.3750],
        [1321833.1250, 1241109.2500, 1219856.8750, 1215605.2500, 1202922.0000,
         1202707.6250, 1197710.1250, 1186781.2500, 1142432.5000, 1130125.7500],
        [1235168.7500, 1219243.8750, 1193268.2500, 1184995.5000, 1174014.6250,
         1165265.1250, 1144368.1250, 1127273.3750, 1106102.6250, 1095711.7500],
        [1291547.8750, 1233136.1250, 1227719.5000, 1199817.1250, 1190792.3750,
         1189340.7500, 1187584.0000, 1182056.3750, 1181721.6250, 1159458.6250],
        [1485172.5000, 1482285.8750, 1477223.8750, 1476171.8750, 1475003.8750,
         1473262.0000, 1471199.5000, 1470088.6250, 1469992.0000, 1469358.3750],
        [1366980.2500, 1341273.2500, 1335785.5000, 1331788.7500, 1331565.3750,
         1331015.6250, 1314162.1250, 1312152.1250, 1309529.3750, 1308222.5000],
        [1511230.2500, 1505548.2500, 1499253.7500, 1499165.2500, 1498492.0000,
         1498173.2500, 1497553.3750, 1496241.3750, 1496028.8750, 1495491.0000],
        [1396031.5000, 1384124.3750, 1372229.7500, 1366460.2500, 1362518.7500,
         1358858.0000, 1354526.2500, 1351271.0000, 1348949.5000, 1344432.6250],
        [1384319.7500, 1384171.8750, 1381380.2500, 1378435.0000, 1372656.3750,
         1367933.6250, 1367564.5000, 1351787.7500, 1346676.8750, 1345682.0000],
        [1513236.2500, 1505450.5000, 1505199.2500, 1504847.6250, 1504793.1250,
         1500438.2500, 1500212.1250, 1499505.5000, 1498250.3750, 1498211.8750],
        [1505709.0000, 1501371.5000, 1500983.5000, 1500597.0000, 1499565.6250,
         1499505.5000, 1499072.2500, 1497510.5000, 1497036.5000, 1496501.1250],
        [1499913.1250, 1497427.6250, 1494628.5000, 1489182.0000, 1488412.3750,
         1488359.8750, 1487958.2500, 1487281.6250, 1486508.6250, 1486359.8750],
        [1450641.1250, 1448115.8750, 1447712.7500, 1447647.7500, 1447010.1250,
         1445283.3750, 1445275.1250, 1443970.3750, 1443718.5000, 1440942.6250],
        [1466034.1250, 1458908.5000, 1454587.8750, 1454114.8750, 1453456.3750,
         1452900.7500, 1449552.8750, 1443074.1250, 1438834.8750, 1436690.3750],
        [1451014.7500, 1436513.6250, 1426595.1250, 1422694.3750, 1422071.8750,
         1421806.1250, 1420079.6250, 1419179.3750, 1417725.1250, 1415479.8750],
        [1497811.8750, 1492769.5000, 1486301.7500, 1481144.1250, 1480720.5000,
         1480274.2500, 1479371.1250, 1478851.8750, 1478713.6250, 1478390.7500],
        [1493652.3750, 1488520.2500, 1487734.0000, 1486966.6250, 1483042.3750,
         1483002.8750, 1481118.6250, 1480772.7500, 1479613.7500, 1478537.5000],
        [1403786.8750, 1397170.3750, 1395689.5000, 1391282.7500, 1388893.7500,
         1387599.0000, 1387274.8750, 1386637.3750, 1386313.3750, 1385235.0000],
        [1496107.2500, 1490907.1250, 1490585.8750, 1486198.2500, 1484960.0000,
         1483885.5000, 1483728.3750, 1479263.8750, 1479163.6250, 1477679.0000],
        [1515035.5000, 1514841.8750, 1513372.0000, 1510914.6250, 1510678.3750,
         1510110.8750, 1509634.2500, 1509419.7500, 1507073.7500, 1506315.1250],
        [1457690.2500, 1441789.3750, 1420364.0000, 1417441.2500, 1415663.5000,
         1414221.0000, 1412990.1250, 1412246.5000, 1411930.0000, 1410974.3750],
        [1514787.0000, 1506940.0000, 1506264.8750, 1506203.0000, 1505756.3750,
         1501341.3750, 1500303.6250, 1499760.0000, 1499283.8750, 1498120.3750],
        [1505788.0000, 1502119.1250, 1501407.2500, 1501055.0000, 1500256.5000,
         1498819.2500, 1495252.8750, 1490725.1250, 1488399.6250, 1485815.7500],
        [1509421.2500, 1505182.0000, 1503801.7500, 1500861.7500, 1500266.5000,
         1498429.1250, 1497075.0000, 1496815.1250, 1494882.1250, 1494816.6250],
        [1511507.0000, 1509893.3750, 1507014.7500, 1506616.7500, 1506114.0000,
         1504421.3750, 1503019.0000, 1502814.0000, 1502192.1250, 1501997.3750],
        [1507397.2500, 1506803.6250, 1505220.8750, 1504985.3750, 1504177.5000,
         1504167.6250, 1503449.0000, 1503180.8750, 1502938.6250, 1502891.3750],
        [1509696.1250, 1507115.3750, 1505885.6250, 1505057.1250, 1502472.8750,
         1502239.3750, 1499845.8750, 1499225.2500, 1498620.6250, 1498617.6250],
        [1512063.5000, 1511517.0000, 1511299.5000, 1511073.2500, 1509922.2500,
         1509101.6250, 1507919.1250, 1506145.6250, 1505034.2500, 1504470.2500],
        [1358872.2500, 1341096.7500, 1329957.3750, 1228568.7500, 1227753.5000,
         1222590.3750, 1206876.0000, 1206688.5000, 1205583.1250, 1202401.3750],
        [1476897.0000, 1475818.6250, 1473059.7500, 1471998.1250, 1469892.5000,
         1469121.7500, 1469086.6250, 1466225.6250, 1465581.2500, 1465241.6250],
        [1489976.0000, 1487423.3750, 1487407.7500, 1486834.7500, 1486446.3750,
         1485886.5000, 1485872.2500, 1484805.6250, 1483456.7500, 1482936.2500],
        [1472790.0000, 1463613.2500, 1461038.8750, 1460210.0000, 1460056.7500,
         1455903.5000, 1453010.2500, 1452676.2500, 1452046.1250, 1450798.8750],
        [1375384.6250, 1365851.7500, 1341836.1250, 1323253.3750, 1317353.0000,
         1305723.3750, 1304438.8750, 1279704.2500, 1269889.6250, 1254100.6250],
        [1449631.6250, 1439505.8750, 1438428.6250, 1436483.5000, 1433820.0000,
         1432409.6250, 1431063.2500, 1429828.7500, 1429508.2500, 1428843.1250],
        [1382727.2500, 1381276.1250, 1378229.8750, 1366951.6250, 1361563.8750,
         1360977.1250, 1360813.5000, 1359214.3750, 1358009.5000, 1356200.1250],
        [1492769.5000, 1489829.7500, 1486822.0000, 1486718.6250, 1486613.5000,
         1484518.2500, 1483666.2500, 1482763.7500, 1480069.6250, 1479438.7500],
        [1367093.7500, 1332924.8750, 1316584.3750, 1289977.1250, 1252173.0000,
         1237451.3750, 1236128.0000, 1210028.1250, 1209668.1250, 1195502.0000],
        [1499029.2500, 1497857.5000, 1495563.7500, 1492538.7500, 1492261.3750,
         1490587.1250, 1490506.1250, 1489326.8750, 1488429.5000, 1485615.8750],
        [1492835.0000, 1492232.8750, 1491582.6250, 1490892.8750, 1489534.2500,
         1489291.2500, 1488781.5000, 1488624.0000, 1488416.7500, 1487536.8750],
        [1498883.5000, 1490482.0000, 1490263.1250, 1486975.2500, 1486310.2500,
         1486259.2500, 1485988.6250, 1485988.6250, 1485845.3750, 1485509.6250],
        [1425656.7500, 1424149.7500, 1421643.3750, 1418561.0000, 1415114.1250,
         1406345.0000, 1406129.0000, 1404428.2500, 1404289.0000, 1401434.0000],
        [1228466.7500, 1207150.0000, 1197632.5000, 1190950.2500, 1188828.1250,
         1182458.8750, 1173268.1250, 1167822.7500, 1167371.7500, 1159871.1250],
        [1186129.5000, 1160323.7500, 1099383.6250, 1082469.2500, 1017822.0625,
          929108.2500,  927065.4375,  924358.7500,  915388.8125,  909421.4375],
        [1223760.2500, 1216202.5000, 1158673.8750, 1131422.0000, 1122796.0000,
         1116674.0000, 1111327.0000, 1079518.8750, 1076431.6250, 1067421.3750],
        [1356006.1250, 1339504.1250, 1331686.0000, 1328523.6250, 1326280.5000,
         1314617.1250, 1305942.5000, 1300988.8750, 1300464.2500, 1298490.0000],
        [1395587.0000, 1392379.0000, 1390948.2500, 1387305.2500, 1386224.8750,
         1384612.8750, 1382151.0000, 1381365.7500, 1381002.1250, 1379743.6250],
        [1384276.2500, 1379914.7500, 1378123.3750, 1373260.0000, 1371588.6250,
         1371419.8750, 1371418.6250, 1370614.5000, 1369570.5000, 1360228.3750],
        [1395402.0000, 1391688.7500, 1377287.8750, 1374942.6250, 1373666.1250,
         1364025.5000, 1354729.1250, 1351066.1250, 1349856.7500, 1346560.1250],
        [1392620.7500, 1376405.5000, 1373222.0000, 1372871.1250, 1361227.6250,
         1360185.6250, 1359902.8750, 1341021.2500, 1325090.7500, 1323657.2500],
        [1356907.7500, 1355713.8750, 1312629.0000, 1311502.8750, 1298113.6250,
         1291062.7500, 1275926.5000, 1267703.0000, 1263024.5000, 1258602.1250],
        [1458620.5000, 1445009.1250, 1437710.0000, 1437364.5000, 1434941.7500,
         1433856.8750, 1432921.8750, 1432900.0000, 1432513.3750, 1432069.5000],
        [1465259.7500, 1463309.0000, 1462554.2500, 1462476.0000, 1460783.8750,
         1460406.3750, 1459536.2500, 1459440.1250, 1459124.1250, 1458143.3750],
        [1336463.3750, 1310453.8750, 1305445.6250, 1270067.5000, 1257535.3750,
         1251922.2500, 1240517.6250, 1235894.6250, 1225340.3750, 1219017.2500],
        [1300866.1250, 1293087.2500, 1278541.6250, 1272653.8750, 1263929.3750,
         1234349.1250, 1234129.1250, 1228109.3750, 1227644.5000, 1222752.3750],
        [1374566.3750, 1360491.7500, 1357595.1250, 1355729.5000, 1349323.8750,
         1346804.1250, 1335063.3750, 1335035.3750, 1327115.5000, 1312997.1250],
        [1439857.3750, 1396267.2500, 1387173.0000, 1373025.6250, 1368082.3750,
         1366194.3750, 1362818.8750, 1354548.2500, 1350776.2500, 1349594.1250],
        [1345272.6250, 1335282.3750, 1321760.1250, 1316864.5000, 1293354.8750,
         1287352.2500, 1284335.5000, 1281330.8750, 1280268.1250, 1277581.2500],
        [1443039.8750, 1438797.7500, 1432038.1250, 1427983.6250, 1425671.6250,
         1422550.6250, 1419616.6250, 1417915.8750, 1415240.8750, 1412230.2500],
        [1411821.0000, 1407951.2500, 1407566.0000, 1406029.7500, 1405426.5000,
         1403586.1250, 1400339.8750, 1397025.1250, 1393415.2500, 1388556.1250],
        [1412350.1250, 1406220.1250, 1400513.3750, 1399526.7500, 1399219.7500,
         1399202.3750, 1389282.0000, 1384568.0000, 1381836.0000, 1381352.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1491077.7500,       0.0000],
         [1474009.7500,       0.0000],
         [1473512.1250,       0.0000],
         ...,
         [1468793.8750,       0.0000],
         [1468751.8750,       0.0000],
         [1467782.8750,       0.0000]],

        [[1490439.3750,       0.0000],
         [1490152.3750,       0.0000],
         [1489917.7500,       0.0000],
         ...,
         [1482123.2500,       0.0000],
         [1482021.5000,       0.0000],
         [1481901.3750,       0.0000]],

        [[1289807.5000,       0.0000],
         [      0.0000, 1275864.3750],
         [1260522.8750,       0.0000],
         ...,
         [      0.0000, 1218763.7500],
         [1201320.3750,       0.0000],
         [      0.0000, 1198488.2500]],

        ...,

        [[1443039.8750,       0.0000],
         [1438797.7500,       0.0000],
         [1432038.1250,       0.0000],
         ...,
         [1417915.8750,       0.0000],
         [1415240.8750,       0.0000],
         [1412230.2500,       0.0000]],

        [[1411821.0000,       0.0000],
         [1407951.2500,       0.0000],
         [1407566.0000,       0.0000],
         ...,
         [1397025.1250,       0.0000],
         [1393415.2500,       0.0000],
         [1388556.1250,       0.0000]],

        [[      0.0000, 1412350.1250],
         [1406220.1250,       0.0000],
         [      0.0000, 1400513.3750],
         ...,
         [1384568.0000,       0.0000],
         [      0.0000, 1381836.0000],
         [      0.0000, 1381352.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13257676.0000,  1471777.7500],
        [14860951.0000,        0.0000],
        [ 6233018.5000,  6184641.0000],
        [12573087.0000,  1380632.1250],
        [ 4819799.0000,  7399584.0000],
        [ 6080503.0000,  5980581.0000],
        [ 9225248.0000,  2420164.2500],
        [ 7168239.5000,  4874935.0000],
        [14749758.0000,        0.0000],
        [11972945.0000,  1309529.3750],
        [14997178.0000,        0.0000],
        [12276883.0000,  1362518.7500],
        [12312675.0000,  1367933.6250],
        [15030145.0000,        0.0000],
        [14997852.0000,        0.0000],
        [14906032.0000,        0.0000],
        [13013308.0000,  1447010.1250],
        [ 8687643.0000,  5820512.0000],
        [14253160.0000,        0.0000],
        [11868676.0000,  2965673.0000],
        [14842962.0000,        0.0000],
        [11126075.0000,  2783807.7500],
        [14852478.0000,        0.0000],
        [15107396.0000,        0.0000],
        [12801090.0000,  1414221.0000],
        [15038761.0000,        0.0000],
        [14969638.0000,        0.0000],
        [15001552.0000,        0.0000],
        [15055590.0000,        0.0000],
        [15045212.0000,        0.0000],
        [15028776.0000,        0.0000],
        [15088547.0000,        0.0000],
        [ 6178547.5000,  6351840.0000],
        [11761864.0000,  2941060.2500],
        [13377588.0000,  1483456.7500],
        [11648315.0000,  2933829.0000],
        [ 7933721.5000,  5203814.0000],
        [12913039.0000,  1436483.5000],
        [10924022.0000,  2741941.5000],
        [14853210.0000,        0.0000],
        [ 7671984.0000,  4975546.5000],
        [14921716.0000,        0.0000],
        [14899728.0000,        0.0000],
        [13392243.0000,  1490263.1250],
        [11304673.0000,  2823077.5000],
        [ 3524875.5000,  8338945.0000],
        [ 5958553.0000,  4192918.0000],
        [ 2281470.0000,  9022758.0000],
        [ 7931429.5000,  5271073.5000],
        [12468941.0000,  1392379.0000],
        [10987584.0000,  2742830.5000],
        [ 5457003.5000,  8222221.0000],
        [       0.0000, 13586204.0000],
        [ 6591114.0000,  6400072.0000],
        [10053852.0000,  4324056.0000],
        [14611032.0000,        0.0000],
        [ 7597424.0000,  5055233.5000],
        [ 3734427.5000,  8821635.0000],
        [ 1327115.5000, 12127607.0000],
        [ 4095656.5000,  9652681.0000],
        [ 7890115.5000,  5133287.0000],
        [14255086.0000,        0.0000],
        [14021717.0000,        0.0000],
        [ 8378019.0000,  5576052.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False]], device='cuda:0')
Top 1 acc 60.9375
Top1 accuracy for validation set is 60.9375 size is torch.Size([64, 1])
Epoch 61/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:26, 60.93s/it]  7%|▋         | 2/29 [01:01<11:32, 25.63s/it] 10%|█         | 3/29 [01:02<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 5.026939868927002
Epoch 62/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.44s/it]  7%|▋         | 2/29 [00:58<10:53, 24.20s/it] 10%|█         | 3/29 [01:00<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:01<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:02<02:26,  6.12s/it] 21%|██        | 6/29 [01:03<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.50s/it] 31%|███       | 9/29 [01:06<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.99422025680542
Epoch 63/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:34, 56.95s/it]  7%|▋         | 2/29 [00:57<10:47, 23.99s/it] 10%|█         | 3/29 [00:58<05:49, 13.46s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.51s/it] 17%|█▋        | 5/29 [01:00<02:18,  5.77s/it] 21%|██        | 6/29 [01:01<01:34,  4.12s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.08s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.39s/it] 31%|███       | 9/29 [01:04<00:38,  1.93s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:08<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:09<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:20<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:21<00:00,  1.09it/s]100%|██████████| 29/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.86s/it]
Epoch loss is 4.972204685211182
Epoch 64/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.79s/it]  7%|▋         | 2/29 [01:00<11:19, 25.16s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 4.925373554229736
Epoch 65/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:18, 56.36s/it]  7%|▋         | 2/29 [01:00<11:27, 25.45s/it] 10%|█         | 3/29 [01:01<06:10, 14.25s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.08s/it] 21%|██        | 6/29 [01:03<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.909018516540527
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[1.5870e-02, 5.0306e-03, 7.1866e-04,  ..., 3.0213e-03, 2.9418e-03,
         2.2707e-02],
        [1.8231e-02, 4.4339e-03, 8.7366e-04,  ..., 3.3901e-03, 2.4123e-03,
         2.4220e-02],
        [4.1315e-02, 7.1442e-03, 4.0571e-03,  ..., 9.1296e-03, 1.7975e-02,
         2.1171e-02],
        ...,
        [1.5814e-02, 1.0739e-02, 5.2210e-04,  ..., 2.8209e-03, 3.8124e-03,
         2.4177e-02],
        [1.4930e-02, 9.4060e-03, 8.9700e-05,  ..., 4.0916e-03, 2.4716e-03,
         2.0662e-02],
        [2.6219e-02, 8.1310e-03, 1.7724e-03,  ..., 4.9160e-03, 7.5742e-03,
         2.3163e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9952, 0.9947, 0.9946, 0.9945, 0.9944, 0.9944, 0.9944, 0.9942, 0.9942,
         0.9942],
        [0.9955, 0.9954, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9951],
        [0.9868, 0.9836, 0.9822, 0.9819, 0.9817, 0.9813, 0.9810, 0.9809, 0.9801,
         0.9799],
        [0.9919, 0.9918, 0.9917, 0.9912, 0.9908, 0.9904, 0.9903, 0.9902, 0.9902,
         0.9900],
        [0.9854, 0.9827, 0.9826, 0.9821, 0.9820, 0.9811, 0.9807, 0.9807, 0.9802,
         0.9795],
        [0.9856, 0.9819, 0.9814, 0.9802, 0.9801, 0.9786, 0.9784, 0.9783, 0.9777,
         0.9761],
        [0.9805, 0.9800, 0.9756, 0.9754, 0.9753, 0.9728, 0.9722, 0.9707, 0.9704,
         0.9696],
        [0.9854, 0.9816, 0.9816, 0.9797, 0.9795, 0.9788, 0.9788, 0.9780, 0.9772,
         0.9771],
        [0.9948, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9942, 0.9942,
         0.9942],
        [0.9891, 0.9877, 0.9877, 0.9874, 0.9872, 0.9869, 0.9869, 0.9869, 0.9868,
         0.9867],
        [0.9963, 0.9960, 0.9960, 0.9960, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9910, 0.9908, 0.9906, 0.9899, 0.9895, 0.9894, 0.9892, 0.9891, 0.9886,
         0.9885],
        [0.9909, 0.9908, 0.9905, 0.9905, 0.9903, 0.9902, 0.9902, 0.9898, 0.9896,
         0.9892],
        [0.9965, 0.9964, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958,
         0.9958],
        [0.9960, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9957, 0.9954, 0.9954, 0.9953, 0.9952, 0.9952, 0.9952, 0.9951, 0.9951,
         0.9950],
        [0.9939, 0.9938, 0.9936, 0.9936, 0.9935, 0.9934, 0.9933, 0.9933, 0.9933,
         0.9932],
        [0.9943, 0.9941, 0.9940, 0.9939, 0.9939, 0.9934, 0.9934, 0.9932, 0.9932,
         0.9930],
        [0.9932, 0.9924, 0.9924, 0.9923, 0.9921, 0.9921, 0.9919, 0.9919, 0.9919,
         0.9919],
        [0.9954, 0.9953, 0.9952, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9957, 0.9956, 0.9954, 0.9954, 0.9953, 0.9951, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9909, 0.9909, 0.9909, 0.9908, 0.9908, 0.9908, 0.9905, 0.9902, 0.9900,
         0.9900],
        [0.9955, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949, 0.9948,
         0.9946],
        [0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9945, 0.9931, 0.9923, 0.9920, 0.9920, 0.9919, 0.9919, 0.9919, 0.9918,
         0.9918],
        [0.9963, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9960, 0.9959, 0.9958, 0.9957, 0.9956, 0.9956, 0.9954, 0.9951, 0.9950,
         0.9950],
        [0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9962, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955,
         0.9955],
        [0.9965, 0.9964, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9886, 0.9878, 0.9871, 0.9814, 0.9812, 0.9804, 0.9797, 0.9794, 0.9789,
         0.9788],
        [0.9944, 0.9942, 0.9942, 0.9941, 0.9941, 0.9941, 0.9940, 0.9940, 0.9939,
         0.9939],
        [0.9956, 0.9955, 0.9953, 0.9953, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951,
         0.9951],
        [0.9946, 0.9943, 0.9943, 0.9942, 0.9941, 0.9938, 0.9938, 0.9937, 0.9937,
         0.9936],
        [0.9907, 0.9888, 0.9886, 0.9876, 0.9873, 0.9853, 0.9853, 0.9833, 0.9830,
         0.9828],
        [0.9934, 0.9933, 0.9930, 0.9928, 0.9927, 0.9927, 0.9926, 0.9926, 0.9925,
         0.9924],
        [0.9899, 0.9897, 0.9896, 0.9894, 0.9893, 0.9893, 0.9892, 0.9891, 0.9890,
         0.9887],
        [0.9957, 0.9956, 0.9954, 0.9953, 0.9952, 0.9952, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9895, 0.9874, 0.9873, 0.9848, 0.9836, 0.9827, 0.9824, 0.9806, 0.9795,
         0.9794],
        [0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9955, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9952, 0.9952, 0.9952,
         0.9952],
        [0.9956, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9923, 0.9922, 0.9922, 0.9919, 0.9917, 0.9914, 0.9914, 0.9913, 0.9913,
         0.9912],
        [0.9819, 0.9816, 0.9808, 0.9804, 0.9794, 0.9792, 0.9790, 0.9787, 0.9778,
         0.9772],
        [0.9784, 0.9753, 0.9734, 0.9720, 0.9714, 0.9640, 0.9630, 0.9624, 0.9622,
         0.9602],
        [0.9822, 0.9762, 0.9760, 0.9756, 0.9753, 0.9744, 0.9730, 0.9727, 0.9724,
         0.9720],
        [0.9876, 0.9874, 0.9870, 0.9864, 0.9863, 0.9863, 0.9860, 0.9860, 0.9858,
         0.9856],
        [0.9908, 0.9907, 0.9902, 0.9902, 0.9902, 0.9902, 0.9900, 0.9899, 0.9898,
         0.9898],
        [0.9899, 0.9898, 0.9898, 0.9897, 0.9896, 0.9893, 0.9891, 0.9888, 0.9887,
         0.9886],
        [0.9903, 0.9897, 0.9897, 0.9894, 0.9889, 0.9887, 0.9881, 0.9879, 0.9874,
         0.9872],
        [0.9905, 0.9900, 0.9899, 0.9891, 0.9891, 0.9891, 0.9890, 0.9883, 0.9871,
         0.9870],
        [0.9892, 0.9881, 0.9861, 0.9856, 0.9850, 0.9845, 0.9841, 0.9841, 0.9833,
         0.9830],
        [0.9930, 0.9930, 0.9929, 0.9929, 0.9928, 0.9925, 0.9924, 0.9924, 0.9923,
         0.9922],
        [0.9939, 0.9939, 0.9939, 0.9938, 0.9938, 0.9938, 0.9938, 0.9938, 0.9937,
         0.9937],
        [0.9873, 0.9866, 0.9852, 0.9848, 0.9840, 0.9832, 0.9820, 0.9819, 0.9817,
         0.9816],
        [0.9868, 0.9860, 0.9854, 0.9831, 0.9831, 0.9829, 0.9826, 0.9823, 0.9822,
         0.9821],
        [0.9893, 0.9887, 0.9885, 0.9884, 0.9883, 0.9881, 0.9880, 0.9867, 0.9865,
         0.9865],
        [0.9931, 0.9905, 0.9901, 0.9897, 0.9891, 0.9890, 0.9889, 0.9886, 0.9884,
         0.9884],
        [0.9885, 0.9873, 0.9864, 0.9857, 0.9856, 0.9847, 0.9845, 0.9843, 0.9839,
         0.9838],
        [0.9927, 0.9927, 0.9926, 0.9925, 0.9922, 0.9915, 0.9914, 0.9914, 0.9914,
         0.9912],
        [0.9910, 0.9910, 0.9910, 0.9909, 0.9907, 0.9904, 0.9904, 0.9902, 0.9902,
         0.9901],
        [0.9907, 0.9905, 0.9904, 0.9902, 0.9901, 0.9900, 0.9899, 0.9897, 0.9894,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 0, 1, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 1, 1, 0, 1, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 0, 1, 0, 1, 0, 1, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 1, 1, 1, 1, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 0, 0, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1495220.1250, 1484082.2500, 1481786.8750, 1479437.3750, 1477843.8750,
         1476745.0000, 1476414.1250, 1473737.0000, 1473314.0000, 1473106.1250],
        [1501616.3750, 1498980.7500, 1496928.0000, 1496531.1250, 1494610.0000,
         1493331.8750, 1492494.7500, 1492321.0000, 1491878.5000, 1491601.1250],
        [1325898.5000, 1266189.1250, 1240926.8750, 1234973.2500, 1232956.1250,
         1224561.1250, 1220549.2500, 1217996.8750, 1205116.3750, 1201050.1250],
        [1425364.3750, 1422740.6250, 1422151.8750, 1412172.3750, 1402979.8750,
         1394811.2500, 1393006.0000, 1391966.2500, 1390574.3750, 1388102.0000],
        [1298959.5000, 1249475.8750, 1247914.6250, 1238537.5000, 1237210.6250,
         1221112.7500, 1215444.2500, 1215399.0000, 1206225.8750, 1193393.5000],
        [1303358.3750, 1235634.1250, 1227486.5000, 1205645.1250, 1205102.5000,
         1178588.2500, 1176031.7500, 1174304.6250, 1163344.1250, 1137552.2500],
        [1211754.3750, 1202818.7500, 1129645.1250, 1126895.0000, 1124532.0000,
         1085038.6250, 1075364.5000, 1053211.2500, 1048946.1250, 1037181.3750],
        [1298242.3750, 1231178.3750, 1230841.3750, 1196610.7500, 1193779.3750,
         1182809.6250, 1181627.0000, 1168669.3750, 1156261.8750, 1154598.1250],
        [1485396.2500, 1484659.8750, 1484018.5000, 1482421.6250, 1481339.1250,
         1480404.1250, 1479963.6250, 1473779.1250, 1472951.5000, 1472819.5000],
        [1368699.6250, 1343313.7500, 1341549.6250, 1336787.2500, 1333676.3750,
         1327673.8750, 1327299.1250, 1327108.0000, 1326083.1250, 1324264.6250],
        [1518853.2500, 1512455.7500, 1510672.6250, 1510617.8750, 1506802.1250,
         1505683.1250, 1505453.3750, 1505153.3750, 1503925.1250, 1503416.1250],
        [1407908.3750, 1402807.2500, 1399843.1250, 1385967.0000, 1377240.5000,
         1376037.8750, 1371837.1250, 1368792.2500, 1358865.7500, 1358725.8750],
        [1405268.3750, 1402858.1250, 1397278.2500, 1396874.6250, 1392596.8750,
         1390760.1250, 1390606.2500, 1382627.0000, 1379397.6250, 1371283.8750],
        [1521999.7500, 1519189.3750, 1510463.7500, 1509475.8750, 1509304.6250,
         1507852.8750, 1507438.8750, 1506504.6250, 1506437.2500, 1506182.8750],
        [1511804.0000, 1511740.5000, 1507805.5000, 1506938.6250, 1505552.5000,
         1505462.0000, 1505002.6250, 1503743.0000, 1503397.5000, 1502182.0000],
        [1504853.3750, 1499222.3750, 1499126.5000, 1496304.2500, 1494812.3750,
         1494427.3750, 1494283.6250, 1492963.1250, 1492194.3750, 1490747.8750],
        [1466673.2500, 1463803.0000, 1461253.3750, 1459456.8750, 1458925.2500,
         1455351.1250, 1455049.8750, 1454791.8750, 1453419.0000, 1452555.7500],
        [1474664.8750, 1471015.6250, 1468910.1250, 1467242.6250, 1467104.1250,
         1456436.7500, 1455913.2500, 1452356.2500, 1451334.3750, 1448824.5000],
        [1451614.1250, 1436638.2500, 1435678.1250, 1433267.7500, 1429937.7500,
         1429553.2500, 1425843.0000, 1425698.8750, 1425185.0000, 1424759.6250],
        [1497933.2500, 1496459.7500, 1494171.0000, 1492768.1250, 1491885.6250,
         1490158.0000, 1489493.0000, 1489173.3750, 1488333.0000, 1487888.6250],
        [1504071.3750, 1501868.3750, 1498320.5000, 1498011.8750, 1497314.8750,
         1491215.7500, 1490821.8750, 1490594.3750, 1487836.2500, 1487178.0000],
        [1405480.1250, 1405326.0000, 1405324.6250, 1403990.3750, 1402637.3750,
         1402363.2500, 1398136.7500, 1391119.5000, 1388152.2500, 1388125.7500],
        [1501072.2500, 1496605.2500, 1493836.1250, 1492304.0000, 1490510.5000,
         1489370.8750, 1489369.3750, 1488676.5000, 1484766.0000, 1481928.2500],
        [1522854.8750, 1522134.7500, 1520694.0000, 1519451.6250, 1519187.8750,
         1518402.8750, 1518093.0000, 1517796.2500, 1517120.5000, 1516580.8750],
        [1478918.2500, 1450733.8750, 1434256.3750, 1427636.3750, 1427625.3750,
         1425296.5000, 1425091.1250, 1424494.7500, 1424242.1250, 1422956.3750],
        [1517977.1250, 1512776.0000, 1512527.8750, 1511119.2500, 1509106.0000,
         1509071.3750, 1506111.1250, 1505818.1250, 1504962.5000, 1504389.8750],
        [1510988.1250, 1508434.0000, 1507864.5000, 1505291.2500, 1502869.8750,
         1502558.8750, 1499273.8750, 1491566.8750, 1490735.1250, 1490541.7500],
        [1510285.1250, 1509015.3750, 1507607.1250, 1506994.7500, 1504790.2500,
         1504750.0000, 1502216.3750, 1501272.7500, 1500499.7500, 1499927.5000],
        [1516141.2500, 1514355.1250, 1512034.6250, 1509750.8750, 1508898.7500,
         1508582.2500, 1508448.3750, 1508367.8750, 1507446.0000, 1507367.0000],
        [1513898.8750, 1513473.0000, 1512809.2500, 1510979.5000, 1509894.8750,
         1509729.2500, 1509264.2500, 1509247.0000, 1508649.7500, 1507745.1250],
        [1508953.3750, 1508517.3750, 1506217.3750, 1504586.5000, 1504174.6250,
         1503608.1250, 1502458.6250, 1502219.3750, 1501619.2500, 1501112.2500],
        [1523276.1250, 1519102.3750, 1516291.6250, 1515062.8750, 1514982.0000,
         1514607.7500, 1514070.6250, 1511955.3750, 1511424.8750, 1509592.5000],
        [1359560.5000, 1344766.0000, 1331907.0000, 1227697.2500, 1223413.7500,
         1209000.2500, 1198008.2500, 1191960.2500, 1183896.3750, 1181622.5000],
        [1477800.1250, 1473925.3750, 1473566.8750, 1471981.2500, 1471616.2500,
         1471421.2500, 1469690.6250, 1469683.6250, 1467676.5000, 1467456.7500],
        [1502177.7500, 1499986.1250, 1497066.3750, 1495739.2500, 1494145.2500,
         1492339.6250, 1491999.5000, 1491996.6250, 1491850.0000, 1491679.3750],
        [1481802.3750, 1475734.1250, 1474340.0000, 1473149.7500, 1471707.5000,
         1465104.7500, 1464615.6250, 1462709.0000, 1461877.8750, 1461137.7500],
        [1401221.5000, 1364116.5000, 1359627.8750, 1339599.8750, 1335481.1250,
         1297873.5000, 1297815.2500, 1259989.1250, 1255433.6250, 1251525.8750],
        [1457326.0000, 1453330.3750, 1447919.7500, 1443053.5000, 1442373.8750,
         1441682.1250, 1440722.7500, 1439556.6250, 1438730.5000, 1435879.3750],
        [1384892.8750, 1380612.3750, 1379330.5000, 1375990.7500, 1373512.7500,
         1372968.0000, 1371408.1250, 1368905.7500, 1367258.0000, 1361562.6250],
        [1505070.1250, 1502546.0000, 1498427.6250, 1496305.6250, 1494280.7500,
         1494042.7500, 1493283.5000, 1492023.6250, 1491198.6250, 1491076.3750],
        [1377858.0000, 1336847.1250, 1334524.8750, 1288532.5000, 1266458.3750,
         1249925.1250, 1245219.6250, 1213004.3750, 1194601.6250, 1193096.3750],
        [1505882.7500, 1505278.2500, 1500473.8750, 1500059.0000, 1499271.0000,
         1497290.5000, 1496549.6250, 1494579.8750, 1493990.0000, 1492909.0000],
        [1501234.0000, 1497299.2500, 1496975.1250, 1495780.5000, 1494354.8750,
         1494307.7500, 1494276.3750, 1493719.2500, 1493515.6250, 1493415.8750],
        [1502209.3750, 1494313.5000, 1493149.6250, 1492675.5000, 1491187.2500,
         1491129.0000, 1490645.5000, 1489892.1250, 1489321.1250, 1489038.5000],
        [1433470.0000, 1432129.5000, 1431213.5000, 1425497.6250, 1422259.0000,
         1415160.0000, 1415096.6250, 1413270.3750, 1413243.5000, 1412028.3750],
        [1236546.5000, 1230096.2500, 1215882.3750, 1210123.7500, 1191695.5000,
         1188155.0000, 1185812.7500, 1180245.0000, 1165290.6250, 1156030.5000],
        [1175139.3750, 1125145.6250, 1094295.7500, 1073189.5000, 1064314.0000,
          956834.8750,  943000.0625,  934662.7500,  932261.8125,  905742.9375],
        [1240944.6250, 1138943.8750, 1135593.6250, 1128776.1250, 1123990.6250,
         1109854.7500, 1087770.7500, 1083343.0000, 1078143.2500, 1073049.2500],
        [1341113.3750, 1336098.8750, 1328367.8750, 1317343.0000, 1315881.5000,
         1315597.8750, 1310357.6250, 1310356.3750, 1305786.8750, 1303661.6250],
        [1402771.1250, 1400799.2500, 1392087.0000, 1392053.8750, 1391690.0000,
         1390517.2500, 1387566.0000, 1384459.7500, 1383956.7500, 1383728.3750],
        [1385795.2500, 1383464.6250, 1382741.7500, 1381344.6250, 1379631.7500,
         1372644.6250, 1370299.5000, 1364323.3750, 1362513.3750, 1360218.1250],
        [1392254.2500, 1381861.1250, 1381135.1250, 1375772.8750, 1365993.7500,
         1362053.6250, 1350213.5000, 1347055.8750, 1337100.8750, 1332637.5000],
        [1397592.8750, 1387861.1250, 1386175.8750, 1370244.6250, 1369741.6250,
         1368885.0000, 1367334.8750, 1353449.3750, 1331806.6250, 1328172.7500],
        [1370906.0000, 1349613.5000, 1312937.0000, 1302227.7500, 1292179.8750,
         1282428.7500, 1274948.5000, 1274626.3750, 1261446.5000, 1255528.2500],
        [1448607.6250, 1447304.0000, 1445891.3750, 1445845.8750, 1444362.8750,
         1438347.7500, 1435808.2500, 1434899.2500, 1433955.3750, 1432034.0000],
        [1467035.6250, 1466692.7500, 1466301.2500, 1465030.6250, 1464780.5000,
         1464424.3750, 1464055.7500, 1463935.7500, 1463271.2500, 1463106.6250],
        [1335649.1250, 1320919.6250, 1295271.7500, 1288070.5000, 1272578.5000,
         1258315.2500, 1237032.3750, 1236084.3750, 1232317.8750, 1229939.1250],
        [1326161.6250, 1310762.5000, 1299618.6250, 1257417.8750, 1256771.7500,
         1254217.8750, 1247268.6250, 1242089.6250, 1241308.1250, 1239504.1250],
        [1374267.5000, 1360926.5000, 1357201.5000, 1355730.6250, 1354681.2500,
         1349953.2500, 1348567.5000, 1324326.5000, 1319503.1250, 1319157.1250],
        [1450282.8750, 1397122.2500, 1389278.0000, 1380492.6250, 1370163.6250,
         1367460.1250, 1365485.8750, 1360166.1250, 1355841.8750, 1355782.3750],
        [1357139.3750, 1335249.2500, 1318506.8750, 1305344.8750, 1302106.1250,
         1285318.2500, 1282083.8750, 1279201.5000, 1272147.7500, 1270025.1250],
        [1442094.7500, 1441880.1250, 1440579.8750, 1438722.2500, 1430989.6250,
         1416972.3750, 1415887.6250, 1414964.2500, 1414818.6250, 1411500.6250],
        [1407681.3750, 1406724.5000, 1406665.5000, 1404485.8750, 1401615.7500,
         1396183.3750, 1395157.1250, 1391520.2500, 1390379.3750, 1389878.2500],
        [1401500.7500, 1398100.7500, 1394817.8750, 1391016.0000, 1389825.2500,
         1386733.8750, 1384948.3750, 1381169.3750, 1375416.1250, 1373753.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1495220.1250,       0.0000],
         [1484082.2500,       0.0000],
         [1481786.8750,       0.0000],
         ...,
         [1473737.0000,       0.0000],
         [1473314.0000,       0.0000],
         [1473106.1250,       0.0000]],

        [[1501616.3750,       0.0000],
         [1498980.7500,       0.0000],
         [1496928.0000,       0.0000],
         ...,
         [1492321.0000,       0.0000],
         [1491878.5000,       0.0000],
         [1491601.1250,       0.0000]],

        [[1325898.5000,       0.0000],
         [      0.0000, 1266189.1250],
         [      0.0000, 1240926.8750],
         ...,
         [      0.0000, 1217996.8750],
         [1205116.3750,       0.0000],
         [      0.0000, 1201050.1250]],

        ...,

        [[1442094.7500,       0.0000],
         [1441880.1250,       0.0000],
         [1440579.8750,       0.0000],
         ...,
         [1414964.2500,       0.0000],
         [1414818.6250,       0.0000],
         [1411500.6250,       0.0000]],

        [[1407681.3750,       0.0000],
         [1406724.5000,       0.0000],
         [1406665.5000,       0.0000],
         ...,
         [1391520.2500,       0.0000],
         [1390379.3750,       0.0000],
         [1389878.2500,       0.0000]],

        [[1401500.7500,       0.0000],
         [      0.0000, 1398100.7500],
         [      0.0000, 1394817.8750],
         ...,
         [      0.0000, 1381169.3750],
         [1375416.1250,       0.0000],
         [1373753.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13315274.0000,  1476414.1250],
        [14950293.0000,        0.0000],
        [ 6219493.0000,  6150724.5000],
        [12655766.0000,  1388102.0000],
        [ 6105857.5000,  6217816.0000],
        [ 6082619.5000,  5924428.0000],
        [ 5471465.0000,  5623922.5000],
        [ 7115156.0000,  4879462.0000],
        [14797753.0000,        0.0000],
        [12029347.0000,  1327108.0000],
        [15083033.0000,        0.0000],
        [12422058.0000,  1385967.0000],
        [12518944.0000,  1390606.2500],
        [15104850.0000,        0.0000],
        [15063628.0000,        0.0000],
        [14958936.0000,        0.0000],
        [11665235.0000,  2916045.2500],
        [ 8767105.0000,  5846696.5000],
        [11467718.0000,  2850458.5000],
        [13430376.0000,  1487888.6250],
        [14947232.0000,        0.0000],
        [12585176.0000,  1405480.1250],
        [14908438.0000,        0.0000],
        [15192317.0000,        0.0000],
        [11490659.0000,  2850592.7500],
        [15093860.0000,        0.0000],
        [15010124.0000,        0.0000],
        [15047360.0000,        0.0000],
        [15101392.0000,        0.0000],
        [15105690.0000,        0.0000],
        [15043467.0000,        0.0000],
        [15150366.0000,        0.0000],
        [ 7310808.0000,  5141024.0000],
        [13240893.0000,  1473925.3750],
        [13456980.0000,  1491999.5000],
        [11743295.0000,  2948884.0000],
        [ 7914248.0000,  5248436.0000],
        [12997521.0000,  1443053.5000],
        [10986938.0000,  2749503.5000],
        [14958254.0000,        0.0000],
        [ 6519621.5000,  6180447.0000],
        [14986285.0000,        0.0000],
        [14954880.0000,        0.0000],
        [14923560.0000,        0.0000],
        [12781239.0000,  1432129.5000],
        [ 2371913.0000,  9587966.0000],
        [ 6036195.0000,  4168392.0000],
        [ 3266247.0000,  7934163.0000],
        [ 7919602.0000,  5264963.5000],
        [12506858.0000,  1402771.1250],
        [11008355.0000,  2734623.0000],
        [ 6774259.5000,  6851819.0000],
        [       0.0000, 13661265.0000],
        [ 6587083.0000,  6389759.5000],
        [12958449.0000,  1448607.6250],
        [14648634.0000,        0.0000],
        [ 7629548.5000,  5076630.0000],
        [ 2498080.0000, 10177040.0000],
        [ 2643483.5000, 10820832.0000],
        [ 4103735.0000,  9688341.0000],
        [ 9162844.0000,  3844279.0000],
        [14268410.0000,        0.0000],
        [13990292.0000,        0.0000],
        [ 6922353.5000,  6954929.5000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 59.375
Top1 accuracy for validation set is 59.375 size is torch.Size([64, 1])
Epoch 66/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:04, 58.00s/it]  7%|▋         | 2/29 [01:00<11:19, 25.15s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.02s/it] 21%|██        | 6/29 [01:03<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.889524936676025
Epoch 67/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.80s/it]  7%|▋         | 2/29 [01:00<11:19, 25.17s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 4.859810829162598
Epoch 68/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.43s/it]  7%|▋         | 2/29 [01:02<11:42, 26.03s/it] 10%|█         | 3/29 [01:02<06:18, 14.56s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.20s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 4.823550224304199
Epoch 69/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.56s/it]  7%|▋         | 2/29 [00:58<10:54, 24.24s/it] 10%|█         | 3/29 [01:00<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 4.8030619621276855
Epoch 70/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.12s/it]  7%|▋         | 2/29 [01:01<11:23, 25.30s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 4.788915634155273
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[1.4853e-02, 4.3088e-03, 7.5978e-04,  ..., 2.5518e-03, 2.7979e-03,
         2.2051e-02],
        [1.7609e-02, 4.0241e-03, 9.2274e-04,  ..., 3.4653e-03, 2.3705e-03,
         2.3482e-02],
        [4.0000e-02, 7.8413e-03, 3.3381e-03,  ..., 8.2812e-03, 1.4909e-02,
         2.1242e-02],
        ...,
        [1.4067e-02, 1.0284e-02, 8.1877e-04,  ..., 2.3196e-03, 3.0974e-03,
         2.3998e-02],
        [1.2834e-02, 9.4838e-03, 9.1550e-05,  ..., 3.7264e-03, 2.5048e-03,
         2.0773e-02],
        [2.6804e-02, 7.5948e-03, 1.7497e-03,  ..., 4.0387e-03, 8.8226e-03,
         2.3406e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9954, 0.9953, 0.9951, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947, 0.9946,
         0.9946],
        [0.9956, 0.9953, 0.9953, 0.9952, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9951],
        [0.9861, 0.9828, 0.9823, 0.9822, 0.9815, 0.9812, 0.9806, 0.9805, 0.9800,
         0.9800],
        [0.9923, 0.9920, 0.9920, 0.9917, 0.9917, 0.9910, 0.9909, 0.9907, 0.9907,
         0.9906],
        [0.9850, 0.9848, 0.9841, 0.9834, 0.9834, 0.9830, 0.9829, 0.9823, 0.9822,
         0.9818],
        [0.9842, 0.9813, 0.9813, 0.9804, 0.9802, 0.9798, 0.9779, 0.9777, 0.9745,
         0.9744],
        [0.9804, 0.9779, 0.9747, 0.9746, 0.9744, 0.9744, 0.9730, 0.9719, 0.9715,
         0.9712],
        [0.9857, 0.9822, 0.9815, 0.9807, 0.9806, 0.9805, 0.9799, 0.9797, 0.9790,
         0.9787],
        [0.9954, 0.9953, 0.9952, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9905, 0.9886, 0.9881, 0.9880, 0.9878, 0.9878, 0.9878, 0.9877, 0.9877,
         0.9876],
        [0.9966, 0.9965, 0.9964, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959,
         0.9958],
        [0.9923, 0.9920, 0.9917, 0.9914, 0.9910, 0.9909, 0.9904, 0.9902, 0.9900,
         0.9898],
        [0.9921, 0.9918, 0.9916, 0.9915, 0.9915, 0.9910, 0.9908, 0.9907, 0.9904,
         0.9903],
        [0.9969, 0.9966, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962,
         0.9960],
        [0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959,
         0.9959],
        [0.9957, 0.9956, 0.9955, 0.9954, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9952],
        [0.9942, 0.9941, 0.9940, 0.9939, 0.9939, 0.9939, 0.9938, 0.9938, 0.9938,
         0.9938],
        [0.9949, 0.9945, 0.9945, 0.9944, 0.9943, 0.9942, 0.9940, 0.9939, 0.9938,
         0.9938],
        [0.9930, 0.9930, 0.9928, 0.9925, 0.9925, 0.9925, 0.9924, 0.9924, 0.9924,
         0.9923],
        [0.9958, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954,
         0.9953],
        [0.9961, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954,
         0.9953],
        [0.9920, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9916, 0.9915, 0.9915,
         0.9914],
        [0.9957, 0.9954, 0.9953, 0.9953, 0.9951, 0.9951, 0.9950, 0.9948, 0.9948,
         0.9948],
        [0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9953, 0.9941, 0.9936, 0.9932, 0.9930, 0.9929, 0.9927, 0.9925, 0.9925,
         0.9925],
        [0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9962, 0.9961, 0.9960, 0.9960, 0.9958, 0.9956, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9962, 0.9961, 0.9961, 0.9961, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9966, 0.9966, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9881, 0.9879, 0.9853, 0.9820, 0.9816, 0.9801, 0.9800, 0.9792, 0.9787,
         0.9779],
        [0.9947, 0.9943, 0.9943, 0.9943, 0.9942, 0.9942, 0.9942, 0.9941, 0.9940,
         0.9940],
        [0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9949, 0.9949, 0.9949, 0.9946, 0.9946, 0.9945, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9908, 0.9888, 0.9884, 0.9879, 0.9878, 0.9854, 0.9853, 0.9830, 0.9829,
         0.9827],
        [0.9942, 0.9938, 0.9936, 0.9935, 0.9935, 0.9935, 0.9934, 0.9933, 0.9932,
         0.9930],
        [0.9907, 0.9905, 0.9905, 0.9901, 0.9900, 0.9900, 0.9899, 0.9898, 0.9897,
         0.9897],
        [0.9959, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952, 0.9952,
         0.9952],
        [0.9884, 0.9872, 0.9861, 0.9839, 0.9830, 0.9829, 0.9811, 0.9795, 0.9791,
         0.9787],
        [0.9957, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9956, 0.9956, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,
         0.9954],
        [0.9955, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9951],
        [0.9923, 0.9923, 0.9918, 0.9918, 0.9916, 0.9915, 0.9913, 0.9912, 0.9912,
         0.9911],
        [0.9827, 0.9811, 0.9810, 0.9803, 0.9799, 0.9792, 0.9785, 0.9784, 0.9782,
         0.9778],
        [0.9807, 0.9756, 0.9742, 0.9739, 0.9720, 0.9648, 0.9641, 0.9623, 0.9622,
         0.9617],
        [0.9834, 0.9777, 0.9776, 0.9767, 0.9744, 0.9738, 0.9731, 0.9723, 0.9720,
         0.9716],
        [0.9881, 0.9879, 0.9877, 0.9871, 0.9869, 0.9868, 0.9866, 0.9863, 0.9861,
         0.9861],
        [0.9912, 0.9911, 0.9910, 0.9909, 0.9909, 0.9907, 0.9907, 0.9906, 0.9905,
         0.9903],
        [0.9909, 0.9903, 0.9902, 0.9901, 0.9899, 0.9898, 0.9897, 0.9895, 0.9895,
         0.9894],
        [0.9908, 0.9905, 0.9894, 0.9892, 0.9891, 0.9888, 0.9887, 0.9882, 0.9877,
         0.9872],
        [0.9916, 0.9906, 0.9906, 0.9898, 0.9894, 0.9891, 0.9889, 0.9885, 0.9878,
         0.9877],
        [0.9883, 0.9880, 0.9847, 0.9847, 0.9843, 0.9842, 0.9842, 0.9838, 0.9828,
         0.9826],
        [0.9934, 0.9933, 0.9932, 0.9932, 0.9929, 0.9928, 0.9927, 0.9927, 0.9926,
         0.9925],
        [0.9945, 0.9943, 0.9943, 0.9943, 0.9942, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9940],
        [0.9880, 0.9868, 0.9866, 0.9855, 0.9851, 0.9841, 0.9837, 0.9837, 0.9835,
         0.9832],
        [0.9872, 0.9868, 0.9863, 0.9846, 0.9844, 0.9841, 0.9837, 0.9837, 0.9831,
         0.9828],
        [0.9897, 0.9896, 0.9893, 0.9892, 0.9886, 0.9886, 0.9882, 0.9879, 0.9878,
         0.9873],
        [0.9939, 0.9906, 0.9905, 0.9899, 0.9894, 0.9894, 0.9891, 0.9891, 0.9890,
         0.9890],
        [0.9886, 0.9884, 0.9861, 0.9854, 0.9852, 0.9848, 0.9847, 0.9845, 0.9840,
         0.9834],
        [0.9930, 0.9926, 0.9926, 0.9924, 0.9921, 0.9916, 0.9914, 0.9914, 0.9913,
         0.9911],
        [0.9914, 0.9912, 0.9912, 0.9910, 0.9906, 0.9905, 0.9898, 0.9896, 0.9896,
         0.9895],
        [0.9912, 0.9908, 0.9907, 0.9904, 0.9903, 0.9902, 0.9899, 0.9897, 0.9893,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 1, 0, 0, 1, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 1, 1, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 0, 1, 1, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 1, 0, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1498397.6250, 1496242.8750, 1491239.8750, 1488094.5000, 1486843.2500,
         1486053.7500, 1484989.7500, 1483224.8750, 1482455.5000, 1482242.0000],
        [1502097.6250, 1497039.2500, 1495877.6250, 1494391.8750, 1493613.8750,
         1493239.3750, 1493171.0000, 1492207.2500, 1492117.6250, 1491074.8750],
        [1312423.7500, 1252161.0000, 1242810.0000, 1240483.2500, 1228608.5000,
         1223778.8750, 1212669.0000, 1211338.5000, 1202958.7500, 1201906.0000],
        [1433118.7500, 1427000.7500, 1426592.3750, 1422261.7500, 1422029.7500,
         1406708.3750, 1404629.1250, 1401158.7500, 1400744.5000, 1398748.8750],
        [1290950.7500, 1287747.5000, 1275027.6250, 1262576.5000, 1261582.3750,
         1255055.3750, 1253444.2500, 1242216.3750, 1240292.7500, 1233569.0000],
        [1276986.7500, 1225873.2500, 1225457.2500, 1209254.0000, 1206780.5000,
         1198748.8750, 1166381.3750, 1162942.6250, 1111217.8750, 1109727.7500],
        [1209131.7500, 1167518.7500, 1114224.1250, 1113895.8750, 1110799.3750,
         1109588.1250, 1088012.5000, 1070687.0000, 1065836.5000, 1060746.1250],
        [1304314.5000, 1240399.2500, 1228837.0000, 1214541.6250, 1212376.2500,
         1211866.6250, 1201369.7500, 1196816.1250, 1185153.6250, 1181194.2500],
        [1497811.8750, 1495988.8750, 1495138.8750, 1490409.6250, 1489426.2500,
         1488034.8750, 1487912.8750, 1487849.0000, 1485992.7500, 1485450.1250],
        [1396750.6250, 1358895.5000, 1349783.3750, 1347895.0000, 1345032.8750,
         1344585.2500, 1343671.1250, 1343386.7500, 1342016.7500, 1339846.5000],
        [1523880.5000, 1521535.3750, 1520814.3750, 1512865.5000, 1512532.2500,
         1512323.1250, 1511074.6250, 1510329.7500, 1509376.6250, 1507369.8750],
        [1432794.8750, 1427799.6250, 1421399.2500, 1415887.6250, 1407089.5000,
         1404591.6250, 1395426.0000, 1390724.2500, 1387784.2500, 1383043.7500],
        [1429519.1250, 1422999.7500, 1418717.8750, 1417631.8750, 1416675.1250,
         1407874.7500, 1403948.8750, 1401855.1250, 1394911.0000, 1393677.0000],
        [1530104.6250, 1524435.7500, 1517161.0000, 1517078.5000, 1515214.6250,
         1515184.3750, 1515132.2500, 1515070.1250, 1514888.1250, 1511681.3750],
        [1517551.6250, 1515707.6250, 1515005.1250, 1514359.3750, 1512595.7500,
         1512313.0000, 1512178.8750, 1510146.7500, 1508375.0000, 1508295.8750],
        [1504543.3750, 1502798.1250, 1501722.3750, 1498109.0000, 1495727.7500,
         1495585.1250, 1495565.2500, 1495257.2500, 1494833.7500, 1493330.3750],
        [1474036.3750, 1471429.6250, 1468257.5000, 1467529.5000, 1466985.1250,
         1466231.2500, 1465624.5000, 1464921.6250, 1464875.5000, 1464247.0000],
        [1488225.1250, 1479602.5000, 1478548.7500, 1476435.2500, 1475518.7500,
         1472835.0000, 1468749.1250, 1465841.1250, 1465227.7500, 1465015.2500],
        [1447801.0000, 1447352.3750, 1443432.1250, 1438505.5000, 1438351.8750,
         1437138.3750, 1435442.6250, 1435319.3750, 1434732.3750, 1433002.5000],
        [1506601.0000, 1504916.5000, 1503277.0000, 1502583.2500, 1501748.0000,
         1501132.3750, 1501019.2500, 1500803.1250, 1498767.7500, 1497444.8750],
        [1513906.0000, 1508143.5000, 1507387.1250, 1506695.7500, 1504519.0000,
         1503816.1250, 1503725.7500, 1500245.0000, 1498316.1250, 1495769.2500],
        [1427098.6250, 1424394.1250, 1424214.8750, 1424157.8750, 1423726.0000,
         1423074.3750, 1420150.1250, 1416734.3750, 1416583.1250, 1414764.5000],
        [1505439.0000, 1498221.8750, 1496203.0000, 1496041.6250, 1492254.2500,
         1491877.1250, 1490996.6250, 1486528.5000, 1486303.1250, 1484793.0000],
        [1526312.3750, 1525170.2500, 1524997.1250, 1523433.1250, 1522791.0000,
         1522124.6250, 1521473.0000, 1519467.6250, 1519153.1250, 1518699.7500],
        [1495426.8750, 1471565.7500, 1460914.8750, 1453101.6250, 1448563.3750,
         1445111.0000, 1440894.5000, 1437999.3750, 1437387.8750, 1437089.0000],
        [1515680.0000, 1514011.5000, 1513760.2500, 1511690.0000, 1510694.2500,
         1509987.0000, 1508458.5000, 1508014.0000, 1507325.2500, 1506769.1250],
        [1516677.7500, 1514356.5000, 1512105.2500, 1510861.3750, 1507620.0000,
         1503840.5000, 1499690.0000, 1499315.3750, 1499219.5000, 1498449.1250],
        [1512803.5000, 1511152.3750, 1509693.2500, 1508439.7500, 1508248.5000,
         1507716.3750, 1507351.1250, 1506674.2500, 1506632.5000, 1505509.3750],
        [1516337.8750, 1515735.0000, 1514017.2500, 1513494.6250, 1513380.6250,
         1512771.7500, 1512115.3750, 1512017.2500, 1511834.2500, 1511249.0000],
        [1518203.0000, 1517904.7500, 1516839.7500, 1516239.6250, 1513864.2500,
         1513823.7500, 1513138.1250, 1512851.0000, 1512135.6250, 1512118.2500],
        [1515508.1250, 1514408.6250, 1514249.6250, 1512852.5000, 1509735.1250,
         1509464.3750, 1509321.8750, 1509270.1250, 1508188.0000, 1507223.2500],
        [1524840.1250, 1524039.1250, 1521020.3750, 1520683.7500, 1520498.2500,
         1519576.2500, 1517676.1250, 1517126.2500, 1516945.3750, 1516238.1250],
        [1350437.5000, 1346113.2500, 1297097.6250, 1237027.7500, 1230648.8750,
         1205098.0000, 1203059.7500, 1188321.5000, 1180956.6250, 1167228.1250],
        [1483814.7500, 1475420.2500, 1474854.8750, 1474276.8750, 1473973.1250,
         1472896.7500, 1472637.0000, 1470189.6250, 1469755.1250, 1469320.6250],
        [1508799.5000, 1507978.0000, 1507660.3750, 1504755.8750, 1504153.1250,
         1503176.6250, 1502500.1250, 1500857.5000, 1500814.5000, 1500806.0000],
        [1488279.0000, 1487440.3750, 1487002.1250, 1481614.5000, 1481125.7500,
         1478751.7500, 1474866.0000, 1474032.2500, 1473627.3750, 1471679.5000],
        [1403857.8750, 1364012.5000, 1356593.3750, 1346757.7500, 1344026.2500,
         1299383.2500, 1297426.7500, 1255484.0000, 1253899.7500, 1250171.8750],
        [1474108.1250, 1464850.3750, 1460889.7500, 1458626.0000, 1458303.5000,
         1457409.3750, 1455950.7500, 1454740.6250, 1452183.1250, 1447482.1250],
        [1401456.6250, 1397811.3750, 1397306.2500, 1389260.7500, 1387839.8750,
         1387581.7500, 1386015.8750, 1382521.5000, 1381331.5000, 1380501.7500],
        [1509389.6250, 1502119.1250, 1499944.6250, 1499637.1250, 1498743.5000,
         1496870.7500, 1495058.8750, 1494611.2500, 1494200.8750, 1493997.1250],
        [1355053.3750, 1333087.5000, 1311559.1250, 1271941.6250, 1254418.7500,
         1254038.5000, 1222090.1250, 1193501.6250, 1186418.0000, 1180072.8750],
        [1504959.5000, 1503041.8750, 1500645.6250, 1500339.5000, 1500236.5000,
         1500232.1250, 1500217.7500, 1500036.1250, 1499941.7500, 1499529.7500],
        [1502497.3750, 1502300.8750, 1502252.2500, 1500298.0000, 1498942.1250,
         1498644.8750, 1498627.6250, 1498183.3750, 1498114.7500, 1497790.5000],
        [1501697.8750, 1497243.3750, 1496636.7500, 1495471.1250, 1495234.3750,
         1494478.7500, 1492416.5000, 1492177.3750, 1491787.3750, 1491321.0000],
        [1434642.0000, 1433356.5000, 1424373.7500, 1424311.2500, 1419960.5000,
         1417388.6250, 1413773.2500, 1412025.6250, 1411380.6250, 1409981.5000],
        [1250083.6250, 1222075.0000, 1220374.7500, 1208493.1250, 1201136.0000,
         1188920.0000, 1176381.7500, 1175124.6250, 1172879.8750, 1165969.7500],
        [1213996.1250, 1128880.6250, 1107138.8750, 1102118.1250, 1072418.0000,
          967882.0000,  958131.5625,  933803.8750,  932896.8125,  926221.5000],
        [1261880.7500, 1163486.1250, 1162890.3750, 1146696.1250, 1109992.3750,
         1100438.7500, 1089081.7500, 1077642.6250, 1072336.2500, 1066869.7500],
        [1349989.3750, 1345898.8750, 1341820.8750, 1331366.0000, 1326671.3750,
         1324701.6250, 1322056.2500, 1316481.5000, 1312094.5000, 1311367.7500],
        [1411371.3750, 1408696.7500, 1406484.3750, 1406033.7500, 1405259.0000,
         1402086.3750, 1401926.0000, 1399283.8750, 1396933.2500, 1392950.1250],
        [1404966.8750, 1393200.0000, 1391751.1250, 1389547.0000, 1386257.7500,
         1382631.0000, 1381676.6250, 1377400.7500, 1377312.7500, 1376278.1250],
        [1403792.2500, 1398026.1250, 1374732.7500, 1371620.0000, 1370240.7500,
         1362778.6250, 1360903.1250, 1352003.1250, 1341620.0000, 1333504.6250],
        [1418478.3750, 1399731.0000, 1399033.0000, 1382362.0000, 1376095.6250,
         1369300.1250, 1366112.2500, 1358789.2500, 1343832.7500, 1341945.0000],
        [1353424.8750, 1348140.5000, 1286397.3750, 1285607.5000, 1279122.2500,
         1276893.0000, 1276716.3750, 1269454.8750, 1251216.8750, 1248245.6250],
        [1456998.1250, 1453545.1250, 1452061.3750, 1451193.2500, 1445113.7500,
         1443169.2500, 1441880.1250, 1441317.8750, 1439915.1250, 1438630.3750],
        [1478584.0000, 1475040.5000, 1474612.8750, 1474559.5000, 1473777.7500,
         1471849.2500, 1471526.5000, 1469738.2500, 1469603.7500, 1469563.0000],
        [1348114.7500, 1324710.5000, 1321644.1250, 1301323.8750, 1294358.1250,
         1275079.8750, 1268683.8750, 1267135.0000, 1263547.3750, 1259666.0000],
        [1333531.2500, 1324389.6250, 1315934.1250, 1283398.8750, 1280195.0000,
         1274247.1250, 1268085.1250, 1267872.2500, 1257754.8750, 1252341.3750],
        [1381381.5000, 1379034.6250, 1373723.6250, 1371439.5000, 1360125.8750,
         1359878.2500, 1352342.2500, 1346723.2500, 1345154.6250, 1334374.7500],
        [1467158.7500, 1400082.1250, 1396652.1250, 1386031.8750, 1376145.6250,
         1374803.6250, 1369823.8750, 1368998.6250, 1367619.2500, 1367351.8750],
        [1360618.8750, 1355844.5000, 1311437.7500, 1299332.3750, 1295500.3750,
         1287576.8750, 1286588.7500, 1282883.7500, 1273920.2500, 1261953.0000],
        [1447929.5000, 1440717.2500, 1439770.8750, 1435060.7500, 1429755.1250,
         1419370.1250, 1414941.3750, 1414544.7500, 1412334.0000, 1409587.7500],
        [1414740.3750, 1412161.6250, 1410303.0000, 1407484.0000, 1398419.3750,
         1396645.5000, 1383715.2500, 1378679.5000, 1378492.7500, 1377997.2500],
        [1412192.6250, 1403248.7500, 1400561.6250, 1395378.0000, 1393670.3750,
         1390844.8750, 1384841.3750, 1380695.2500, 1373573.0000, 1373404.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1498397.6250,       0.0000],
         [1496242.8750,       0.0000],
         [1491239.8750,       0.0000],
         ...,
         [1483224.8750,       0.0000],
         [1482455.5000,       0.0000],
         [1482242.0000,       0.0000]],

        [[1502097.6250,       0.0000],
         [1497039.2500,       0.0000],
         [1495877.6250,       0.0000],
         ...,
         [1492207.2500,       0.0000],
         [1492117.6250,       0.0000],
         [1491074.8750,       0.0000]],

        [[1312423.7500,       0.0000],
         [      0.0000, 1252161.0000],
         [1242810.0000,       0.0000],
         ...,
         [      0.0000, 1211338.5000],
         [      0.0000, 1202958.7500],
         [      0.0000, 1201906.0000]],

        ...,

        [[1447929.5000,       0.0000],
         [1440717.2500,       0.0000],
         [1439770.8750,       0.0000],
         ...,
         [1414544.7500,       0.0000],
         [1412334.0000,       0.0000],
         [1409587.7500,       0.0000]],

        [[1414740.3750,       0.0000],
         [1412161.6250,       0.0000],
         [1410303.0000,       0.0000],
         ...,
         [1378679.5000,       0.0000],
         [1378492.7500,       0.0000],
         [1377997.2500,       0.0000]],

        [[1412192.6250,       0.0000],
         [      0.0000, 1403248.7500],
         [      0.0000, 1400561.6250],
         ...,
         [      0.0000, 1380695.2500],
         [1373573.0000,       0.0000],
         [1373404.0000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14879784.0000,        0.0000],
        [14944829.0000,        0.0000],
        [ 6232165.0000,  6096972.5000],
        [14142992.0000,        0.0000],
        [ 6325826.5000,  6276636.0000],
        [ 4935098.0000,  6958272.5000],
        [ 2176636.0000,  8933804.0000],
        [ 7254144.5000,  4922724.0000],
        [14904016.0000,        0.0000],
        [12166832.0000,  1345032.8750],
        [15142102.0000,        0.0000],
        [12650653.0000,  1415887.6250],
        [12691135.0000,  1416675.1250],
        [15175950.0000,        0.0000],
        [15126529.0000,        0.0000],
        [14977472.0000,        0.0000],
        [11731844.0000,  2942294.0000],
        [10308042.0000,  4427956.0000],
        [11515434.0000,  2875644.0000],
        [12014691.0000,  3003602.5000],
        [15042524.0000,        0.0000],
        [11367014.0000,  2847884.0000],
        [14928658.0000,        0.0000],
        [15223623.0000,        0.0000],
        [13087160.0000,  1440894.5000],
        [15106390.0000,        0.0000],
        [15062135.0000,        0.0000],
        [15084220.0000,        0.0000],
        [15132954.0000,        0.0000],
        [15147118.0000,        0.0000],
        [15110220.0000,        0.0000],
        [15198644.0000,        0.0000],
        [ 7275729.0000,  5130259.5000],
        [13263166.0000,  1473973.1250],
        [13539002.0000,  1502500.1250],
        [10351050.0000,  4447368.5000],
        [ 7920774.0000,  5250840.0000],
        [11671470.0000,  2913073.0000],
        [11106481.0000,  2785146.0000],
        [14984572.0000,        0.0000],
        [10028532.0000,  2533649.2500],
        [15009182.0000,        0.0000],
        [14997652.0000,        0.0000],
        [14948464.0000,        0.0000],
        [12776820.0000,  1424373.7500],
        [ 1220374.7500, 10761064.0000],
        [ 7040071.0000,  3303416.5000],
        [ 2210431.0000,  9040884.0000],
        [ 9293870.0000,  3988578.5000],
        [12622328.0000,  1408696.7500],
        [11091870.0000,  2769152.0000],
        [ 5458318.5000,  8210903.0000],
        [ 1341945.0000, 12413734.0000],
        [ 6543011.5000,  6332208.0000],
        [13010279.0000,  1453545.1250],
        [14728856.0000,        0.0000],
        [ 6455138.5000,  6469125.0000],
        [ 2535740.2500, 10322009.0000],
        [ 1334374.7500, 12269804.0000],
        [ 6873875.5000,  7000792.0000],
        [10432579.0000,  2583077.2500],
        [14264012.0000,        0.0000],
        [13958638.0000,        0.0000],
        [ 6937681.5000,  6970728.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 60.9375
Top1 accuracy for validation set is 60.9375 size is torch.Size([64, 1])
Epoch 71/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:34, 56.96s/it]  7%|▋         | 2/29 [01:01<11:49, 26.28s/it] 10%|█         | 3/29 [01:02<06:22, 14.70s/it] 14%|█▍        | 4/29 [01:03<03:51,  9.26s/it] 17%|█▋        | 5/29 [01:04<02:30,  6.25s/it] 21%|██        | 6/29 [01:05<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.54s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:11<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.759850025177002
Epoch 72/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.96s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 4.718728542327881
Epoch 73/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:20, 60.73s/it]  7%|▋         | 2/29 [01:01<11:29, 25.55s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.697381973266602
Epoch 74/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:50, 57.51s/it]  7%|▋         | 2/29 [00:58<11:02, 24.54s/it] 10%|█         | 3/29 [00:59<05:57, 13.75s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.69s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.89s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 4.678982257843018
Epoch 75/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:32, 56.86s/it]  7%|▋         | 2/29 [00:57<10:46, 23.96s/it] 10%|█         | 3/29 [00:59<05:57, 13.73s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.68s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.88s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.42s/it] 31%|███       | 9/29 [01:04<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 4.652425765991211
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0148, 0.0040, 0.0011,  ..., 0.0027, 0.0023, 0.0221],
        [0.0165, 0.0040, 0.0007,  ..., 0.0033, 0.0024, 0.0237],
        [0.0403, 0.0083, 0.0029,  ..., 0.0078, 0.0120, 0.0210],
        ...,
        [0.0126, 0.0101, 0.0010,  ..., 0.0028, 0.0029, 0.0220],
        [0.0121, 0.0094, 0.0001,  ..., 0.0033, 0.0027, 0.0207],
        [0.0271, 0.0075, 0.0018,  ..., 0.0037, 0.0098, 0.0227]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9954, 0.9954, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9955, 0.9954, 0.9953, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9858, 0.9833, 0.9827, 0.9819, 0.9809, 0.9808, 0.9804, 0.9802, 0.9798,
         0.9796],
        [0.9925, 0.9922, 0.9920, 0.9918, 0.9915, 0.9913, 0.9911, 0.9909, 0.9906,
         0.9905],
        [0.9856, 0.9841, 0.9838, 0.9837, 0.9836, 0.9835, 0.9831, 0.9829, 0.9825,
         0.9820],
        [0.9826, 0.9816, 0.9803, 0.9797, 0.9792, 0.9790, 0.9753, 0.9746, 0.9727,
         0.9722],
        [0.9792, 0.9780, 0.9778, 0.9754, 0.9752, 0.9741, 0.9735, 0.9727, 0.9720,
         0.9699],
        [0.9853, 0.9817, 0.9816, 0.9813, 0.9807, 0.9806, 0.9799, 0.9795, 0.9792,
         0.9789],
        [0.9954, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9949, 0.9948,
         0.9948],
        [0.9902, 0.9891, 0.9885, 0.9882, 0.9881, 0.9879, 0.9878, 0.9878, 0.9876,
         0.9875],
        [0.9968, 0.9968, 0.9965, 0.9963, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961,
         0.9960],
        [0.9929, 0.9928, 0.9924, 0.9920, 0.9917, 0.9917, 0.9910, 0.9910, 0.9908,
         0.9905],
        [0.9920, 0.9919, 0.9918, 0.9917, 0.9914, 0.9911, 0.9911, 0.9908, 0.9908,
         0.9907],
        [0.9967, 0.9966, 0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9961],
        [0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9958, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9943, 0.9941, 0.9939, 0.9939, 0.9939, 0.9938, 0.9937, 0.9936, 0.9935,
         0.9935],
        [0.9951, 0.9946, 0.9944, 0.9944, 0.9941, 0.9940, 0.9939, 0.9939, 0.9938,
         0.9937],
        [0.9936, 0.9935, 0.9934, 0.9928, 0.9928, 0.9927, 0.9926, 0.9925, 0.9925,
         0.9924],
        [0.9961, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9963, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9923, 0.9923, 0.9921, 0.9919, 0.9919, 0.9919, 0.9919, 0.9918, 0.9916,
         0.9914],
        [0.9958, 0.9955, 0.9954, 0.9953, 0.9952, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9967, 0.9967, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9956, 0.9946, 0.9944, 0.9939, 0.9938, 0.9936, 0.9932, 0.9932, 0.9932,
         0.9931],
        [0.9964, 0.9963, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960, 0.9958,
         0.9958],
        [0.9963, 0.9963, 0.9961, 0.9961, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9954],
        [0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9965, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962,
         0.9961],
        [0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9968, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9888, 0.9873, 0.9847, 0.9839, 0.9835, 0.9819, 0.9811, 0.9800, 0.9795,
         0.9795],
        [0.9948, 0.9947, 0.9946, 0.9946, 0.9943, 0.9943, 0.9942, 0.9942, 0.9942,
         0.9942],
        [0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9951, 0.9950, 0.9949, 0.9948, 0.9947, 0.9946, 0.9946, 0.9944, 0.9944,
         0.9943],
        [0.9910, 0.9891, 0.9886, 0.9879, 0.9874, 0.9842, 0.9841, 0.9840, 0.9838,
         0.9832],
        [0.9942, 0.9941, 0.9940, 0.9937, 0.9937, 0.9936, 0.9936, 0.9935, 0.9935,
         0.9935],
        [0.9907, 0.9906, 0.9906, 0.9906, 0.9904, 0.9903, 0.9903, 0.9901, 0.9899,
         0.9898],
        [0.9959, 0.9957, 0.9956, 0.9956, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9882, 0.9872, 0.9861, 0.9848, 0.9831, 0.9825, 0.9813, 0.9809, 0.9796,
         0.9788],
        [0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9957],
        [0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952, 0.9951,
         0.9951],
        [0.9924, 0.9922, 0.9918, 0.9913, 0.9913, 0.9913, 0.9912, 0.9911, 0.9909,
         0.9907],
        [0.9829, 0.9801, 0.9799, 0.9798, 0.9796, 0.9785, 0.9784, 0.9781, 0.9777,
         0.9774],
        [0.9815, 0.9762, 0.9739, 0.9732, 0.9727, 0.9646, 0.9634, 0.9612, 0.9608,
         0.9603],
        [0.9835, 0.9787, 0.9786, 0.9779, 0.9755, 0.9740, 0.9739, 0.9737, 0.9729,
         0.9715],
        [0.9879, 0.9879, 0.9874, 0.9871, 0.9869, 0.9865, 0.9861, 0.9860, 0.9860,
         0.9858],
        [0.9913, 0.9913, 0.9912, 0.9911, 0.9911, 0.9911, 0.9911, 0.9907, 0.9906,
         0.9905],
        [0.9910, 0.9907, 0.9902, 0.9902, 0.9898, 0.9896, 0.9895, 0.9895, 0.9893,
         0.9893],
        [0.9914, 0.9901, 0.9894, 0.9894, 0.9884, 0.9881, 0.9876, 0.9873, 0.9869,
         0.9869],
        [0.9918, 0.9914, 0.9899, 0.9893, 0.9892, 0.9892, 0.9891, 0.9883, 0.9876,
         0.9872],
        [0.9883, 0.9878, 0.9852, 0.9840, 0.9839, 0.9838, 0.9835, 0.9833, 0.9824,
         0.9821],
        [0.9934, 0.9932, 0.9929, 0.9927, 0.9925, 0.9925, 0.9925, 0.9924, 0.9924,
         0.9924],
        [0.9944, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9941, 0.9941, 0.9940,
         0.9940],
        [0.9875, 0.9874, 0.9874, 0.9862, 0.9849, 0.9846, 0.9846, 0.9842, 0.9836,
         0.9832],
        [0.9876, 0.9870, 0.9869, 0.9853, 0.9852, 0.9849, 0.9839, 0.9839, 0.9837,
         0.9830],
        [0.9903, 0.9901, 0.9899, 0.9896, 0.9894, 0.9887, 0.9884, 0.9881, 0.9881,
         0.9873],
        [0.9941, 0.9911, 0.9907, 0.9904, 0.9896, 0.9894, 0.9893, 0.9893, 0.9891,
         0.9889],
        [0.9897, 0.9881, 0.9863, 0.9862, 0.9853, 0.9850, 0.9844, 0.9840, 0.9838,
         0.9837],
        [0.9930, 0.9924, 0.9923, 0.9920, 0.9913, 0.9912, 0.9911, 0.9910, 0.9908,
         0.9906],
        [0.9918, 0.9917, 0.9912, 0.9910, 0.9907, 0.9898, 0.9896, 0.9896, 0.9892,
         0.9891],
        [0.9911, 0.9907, 0.9905, 0.9900, 0.9900, 0.9899, 0.9894, 0.9894, 0.9890,
         0.9885]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1],
        [1, 0, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 1, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1499040.8750, 1498842.0000, 1491288.1250, 1490691.0000, 1490547.3750,
         1488829.7500, 1487765.2500, 1487163.8750, 1486002.6250, 1485927.5000],
        [1500864.6250, 1497694.7500, 1496943.6250, 1492583.0000, 1491356.3750,
         1490573.0000, 1489797.0000, 1489660.6250, 1489564.0000, 1489069.7500],
        [1306311.2500, 1261074.7500, 1250480.7500, 1235721.2500, 1218738.2500,
         1216569.0000, 1209779.8750, 1205226.7500, 1198942.1250, 1195864.5000],
        [1437249.3750, 1430619.7500, 1428108.7500, 1424068.1250, 1416872.3750,
         1412344.7500, 1409184.3750, 1405133.0000, 1399432.0000, 1396835.8750],
        [1302019.1250, 1275734.1250, 1269500.8750, 1268485.5000, 1266916.2500,
         1263410.0000, 1257608.6250, 1253287.6250, 1246726.3750, 1238267.1250],
        [1248458.7500, 1230558.6250, 1207535.7500, 1197488.6250, 1189497.2500,
         1186266.3750, 1124483.7500, 1112661.1250, 1084053.0000, 1076144.2500],
        [1188992.6250, 1169215.6250, 1165098.3750, 1126638.1250, 1123046.6250,
         1104744.7500, 1095202.0000, 1083460.7500, 1072181.8750, 1040873.4375],
        [1297976.2500, 1232467.1250, 1229736.2500, 1225944.6250, 1215557.7500,
         1212682.7500, 1200640.1250, 1194674.5000, 1189213.6250, 1183166.1250],
        [1497624.7500, 1496085.8750, 1495677.8750, 1493729.2500, 1493463.0000,
         1492967.3750, 1491198.6250, 1487887.3750, 1486418.0000, 1484848.1250],
        [1391712.6250, 1369007.7500, 1356932.2500, 1352397.7500, 1349500.2500,
         1346370.0000, 1345194.3750, 1343495.6250, 1340390.8750, 1338338.2500],
        [1527746.8750, 1527730.7500, 1523340.0000, 1518135.0000, 1517024.8750,
         1516920.7500, 1516510.0000, 1514002.8750, 1512813.5000, 1512093.7500],
        [1445585.2500, 1444756.8750, 1435122.3750, 1428202.8750, 1421311.2500,
         1420534.7500, 1407698.8750, 1407025.0000, 1402503.5000, 1397756.7500],
        [1428170.1250, 1425216.2500, 1423785.7500, 1421616.2500, 1415747.2500,
         1409810.7500, 1409129.3750, 1402434.0000, 1402244.1250, 1400959.6250],
        [1526165.3750, 1525187.6250, 1524595.7500, 1519231.3750, 1518924.2500,
         1518624.3750, 1515417.0000, 1515350.5000, 1514846.2500, 1514096.6250],
        [1518778.0000, 1517464.8750, 1517153.6250, 1516580.8750, 1515891.0000,
         1515777.0000, 1514612.1250, 1513846.8750, 1513321.5000, 1512543.7500],
        [1507313.7500, 1503771.6250, 1503115.0000, 1502194.8750, 1501172.5000,
         1499928.8750, 1498633.3750, 1497136.3750, 1497126.3750, 1496942.1250],
        [1475592.0000, 1470505.1250, 1467774.5000, 1467705.8750, 1467638.6250,
         1464072.5000, 1462755.1250, 1461243.6250, 1459280.1250, 1458196.3750],
        [1491410.5000, 1480899.7500, 1476471.8750, 1476340.7500, 1470728.1250,
         1469268.8750, 1467246.8750, 1466748.7500, 1465512.7500, 1463124.7500],
        [1460335.2500, 1458702.6250, 1457264.8750, 1444248.6250, 1442979.2500,
         1442426.1250, 1440185.6250, 1437593.3750, 1437163.0000, 1436694.3750],
        [1513022.7500, 1504648.1250, 1503104.8750, 1502175.0000, 1501497.5000,
         1501251.1250, 1501139.5000, 1500723.0000, 1500456.7500, 1500074.7500],
        [1517103.0000, 1514294.5000, 1512444.2500, 1511926.5000, 1510231.7500,
         1510056.1250, 1509182.2500, 1508247.1250, 1506466.0000, 1506241.7500],
        [1434561.2500, 1432786.6250, 1428520.2500, 1426397.8750, 1426204.7500,
         1424997.5000, 1424451.2500, 1422511.2500, 1419356.7500, 1415431.2500],
        [1506388.2500, 1501120.8750, 1498413.3750, 1496097.3750, 1493440.1250,
         1490692.3750, 1489341.0000, 1489247.3750, 1488382.6250, 1488013.6250],
        [1525880.1250, 1525868.5000, 1522761.8750, 1522246.5000, 1522246.5000,
         1521821.2500, 1521165.3750, 1521098.6250, 1521065.2500, 1520960.7500],
        [1502650.6250, 1481618.7500, 1476400.0000, 1467648.5000, 1465236.0000,
         1461307.7500, 1452677.6250, 1452504.5000, 1452208.1250, 1450378.3750],
        [1521037.7500, 1517498.1250, 1513913.2500, 1513064.6250, 1512408.1250,
         1512328.8750, 1510916.1250, 1510553.0000, 1507378.3750, 1507338.2500],
        [1518331.8750, 1517783.2500, 1513768.8750, 1512830.8750, 1507953.6250,
         1507632.8750, 1505777.8750, 1504138.8750, 1502387.0000, 1498813.6250],
        [1511864.5000, 1510894.5000, 1510298.0000, 1509186.5000, 1508914.6250,
         1506284.8750, 1506056.5000, 1505676.0000, 1505434.7500, 1505057.1250],
        [1521741.3750, 1518585.3750, 1517626.8750, 1516421.7500, 1516165.7500,
         1515735.0000, 1515268.1250, 1515227.6250, 1514980.5000, 1514226.6250],
        [1518262.3750, 1516505.7500, 1515430.1250, 1514937.2500, 1514752.3750,
         1513256.5000, 1512101.0000, 1511795.3750, 1511414.7500, 1511303.7500],
        [1516268.5000, 1515307.1250, 1514532.7500, 1511610.8750, 1511443.6250,
         1511397.5000, 1509350.6250, 1507894.6250, 1506672.8750, 1506625.3750],
        [1528259.7500, 1524276.0000, 1523799.1250, 1521650.0000, 1520373.5000,
         1519031.5000, 1518986.5000, 1517938.1250, 1517797.6250, 1517418.5000],
        [1364547.1250, 1335279.8750, 1286767.8750, 1272310.3750, 1263686.0000,
         1236354.3750, 1221995.7500, 1201884.2500, 1194599.3750, 1193648.5000],
        [1485961.5000, 1483946.3750, 1481534.0000, 1480830.6250, 1476128.2500,
         1475160.0000, 1473873.3750, 1473569.8750, 1473156.6250, 1472976.8750],
        [1512171.6250, 1509513.2500, 1509277.2500, 1507791.1250, 1507412.8750,
         1506190.1250, 1505542.3750, 1503192.3750, 1502871.3750, 1501791.1250],
        [1492977.2500, 1489328.2500, 1487956.7500, 1484808.5000, 1483851.5000,
         1481647.0000, 1481477.5000, 1477955.2500, 1477797.3750, 1475566.7500],
        [1406269.7500, 1368613.5000, 1360079.2500, 1346190.2500, 1336072.1250,
         1277237.6250, 1275493.3750, 1274164.5000, 1269198.2500, 1259404.1250],
        [1472884.1250, 1471102.7500, 1469724.2500, 1462558.3750, 1462515.1250,
         1461363.5000, 1460998.3750, 1459031.0000, 1458928.0000, 1457465.0000],
        [1400788.6250, 1398723.5000, 1398720.8750, 1398502.1250, 1394775.3750,
         1393174.7500, 1392618.1250, 1389915.5000, 1385735.6250, 1383913.2500],
        [1509969.7500, 1504531.8750, 1502922.8750, 1502888.5000, 1499601.2500,
         1499316.7500, 1499308.1250, 1498281.8750, 1496372.7500, 1496314.2500],
        [1352226.2500, 1332835.8750, 1312784.2500, 1287224.5000, 1257898.8750,
         1245666.2500, 1224967.6250, 1218604.5000, 1196325.3750, 1182852.5000],
        [1508340.5000, 1507886.1250, 1506839.5000, 1506654.1250, 1505783.6250,
         1505223.6250, 1505101.6250, 1505081.6250, 1504619.5000, 1504355.5000],
        [1503928.0000, 1503579.6250, 1501929.8750, 1500154.8750, 1499953.1250,
         1498747.7500, 1497526.2500, 1497147.7500, 1496967.8750, 1496949.3750],
        [1500461.1250, 1500020.3750, 1499554.1250, 1499352.5000, 1499049.3750,
         1496461.2500, 1496137.2500, 1493572.6250, 1492873.5000, 1492009.5000],
        [1436362.8750, 1432372.6250, 1422978.1250, 1414026.7500, 1413188.2500,
         1412719.3750, 1411514.0000, 1409843.0000, 1404372.1250, 1401007.6250],
        [1253193.1250, 1203979.1250, 1200755.7500, 1198968.3750, 1196576.3750,
         1177086.5000, 1174666.5000, 1170109.1250, 1164243.1250, 1158330.2500],
        [1229244.8750, 1139084.0000, 1101903.8750, 1091566.0000, 1083147.7500,
          965270.5625,  948846.6250,  919034.6250,  914741.2500,  907196.9375],
        [1264122.2500, 1179785.8750, 1178942.3750, 1167414.0000, 1127270.1250,
         1104036.0000, 1102880.5000, 1099106.8750, 1087226.3750, 1064892.6250],
        [1346855.5000, 1345993.8750, 1335999.5000, 1331755.7500, 1327049.7500,
         1319323.1250, 1313013.3750, 1310129.0000, 1309890.2500, 1306278.8750],
        [1413069.6250, 1412948.3750, 1410592.2500, 1409973.5000, 1409767.7500,
         1408995.0000, 1408348.7500, 1401782.8750, 1400016.7500, 1396546.8750],
        [1406508.6250, 1401833.6250, 1392002.0000, 1391311.8750, 1382890.7500,
         1379295.0000, 1378071.0000, 1377395.5000, 1373080.6250, 1372923.5000],
        [1414438.1250, 1388907.0000, 1376320.1250, 1375231.1250, 1355056.0000,
         1350666.7500, 1339944.8750, 1335681.1250, 1327380.0000, 1326644.8750],
        [1422676.7500, 1414579.7500, 1385421.2500, 1374386.7500, 1371805.7500,
         1370919.1250, 1369011.6250, 1354528.8750, 1339868.2500, 1332898.1250],
        [1353720.5000, 1344971.2500, 1294853.1250, 1273255.8750, 1271894.2500,
         1269002.1250, 1263952.3750, 1260251.1250, 1245321.7500, 1238405.2500],
        [1455691.2500, 1452555.7500, 1445476.3750, 1441976.3750, 1437337.1250,
         1436809.5000, 1436753.2500, 1436235.5000, 1435864.3750, 1435723.2500],
        [1477115.3750, 1473561.3750, 1472763.3750, 1472460.0000, 1472380.0000,
         1472016.3750, 1470516.3750, 1469972.3750, 1469672.5000, 1469352.8750],
        [1338282.1250, 1337363.5000, 1336541.1250, 1314444.1250, 1290294.6250,
         1285026.5000, 1283620.3750, 1276616.6250, 1265431.0000, 1258768.8750],
        [1340425.5000, 1328661.7500, 1327561.1250, 1297779.5000, 1295720.3750,
         1290267.6250, 1271894.2500, 1271568.0000, 1267189.3750, 1255977.3750],
        [1392551.7500, 1388519.0000, 1385235.0000, 1378698.0000, 1376048.5000,
         1361700.2500, 1355873.0000, 1350057.6250, 1349966.2500, 1334126.6250],
        [1470041.0000, 1409520.3750, 1401022.3750, 1394511.8750, 1379103.0000,
         1375337.3750, 1374377.6250, 1373560.0000, 1369204.7500, 1365937.7500],
        [1380917.8750, 1349251.8750, 1315689.5000, 1313216.1250, 1297243.6250,
         1290817.7500, 1281445.7500, 1273866.8750, 1269393.1250, 1267196.5000],
        [1448422.5000, 1435565.8750, 1433504.2500, 1427311.0000, 1413825.7500,
         1411571.8750, 1409917.0000, 1407548.3750, 1403741.2500, 1399302.5000],
        [1422501.7500, 1422269.8750, 1412249.2500, 1407237.1250, 1401261.5000,
         1383794.3750, 1379759.3750, 1378857.0000, 1371289.1250, 1370379.2500],
        [1409957.3750, 1402047.6250, 1396344.5000, 1387908.7500, 1387514.3750,
         1385636.6250, 1375704.7500, 1375620.7500, 1368079.7500, 1358825.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1499040.8750,       0.0000],
         [1498842.0000,       0.0000],
         [1491288.1250,       0.0000],
         ...,
         [1487163.8750,       0.0000],
         [1486002.6250,       0.0000],
         [1485927.5000,       0.0000]],

        [[1500864.6250,       0.0000],
         [1497694.7500,       0.0000],
         [1496943.6250,       0.0000],
         ...,
         [1489660.6250,       0.0000],
         [1489564.0000,       0.0000],
         [1489069.7500,       0.0000]],

        [[1306311.2500,       0.0000],
         [1261074.7500,       0.0000],
         [      0.0000, 1250480.7500],
         ...,
         [      0.0000, 1205226.7500],
         [      0.0000, 1198942.1250],
         [1195864.5000,       0.0000]],

        ...,

        [[1448422.5000,       0.0000],
         [1435565.8750,       0.0000],
         [1433504.2500,       0.0000],
         ...,
         [1407548.3750,       0.0000],
         [1403741.2500,       0.0000],
         [1399302.5000,       0.0000]],

        [[1422501.7500,       0.0000],
         [1422269.8750,       0.0000],
         [1412249.2500,       0.0000],
         ...,
         [1378857.0000,       0.0000],
         [1371289.1250,       0.0000],
         [1370379.2500,       0.0000]],

        [[      0.0000, 1409957.3750],
         [1402047.6250,       0.0000],
         [1396344.5000,       0.0000],
         ...,
         [      0.0000, 1375620.7500],
         [1368079.7500,       0.0000],
         [      0.0000, 1358825.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14906099.0000,        0.0000],
        [14928106.0000,        0.0000],
        [ 7434279.0000,  4864429.0000],
        [14159848.0000,        0.0000],
        [ 6347268.0000,  6294687.5000],
        [ 5952195.0000,  5704953.0000],
        [ 2136075.5000,  9033379.0000],
        [ 8457498.0000,  3724561.0000],
        [13432013.0000,  1487887.3750],
        [10826908.0000,  2706432.5000],
        [15186318.0000,        0.0000],
        [12782294.0000,  1428202.8750],
        [12715327.0000,  1423785.7500],
        [15192439.0000,        0.0000],
        [15155970.0000,        0.0000],
        [15007335.0000,        0.0000],
        [11715100.0000,  2939664.5000],
        [10308191.0000,  4419561.5000],
        [11560142.0000,  2897450.5000],
        [13526954.0000,  1501139.5000],
        [15106194.0000,        0.0000],
        [ 8547490.0000,  5707728.0000],
        [14941137.0000,        0.0000],
        [15225114.0000,        0.0000],
        [13212251.0000,  1450378.3750],
        [15126438.0000,        0.0000],
        [15089419.0000,        0.0000],
        [15079666.0000,        0.0000],
        [15165978.0000,        0.0000],
        [15139760.0000,        0.0000],
        [15111104.0000,        0.0000],
        [15209530.0000,        0.0000],
        [ 6211077.0000,  6359997.0000],
        [ 8865634.0000,  5911503.5000],
        [13558340.0000,  1507412.8750],
        [10377752.0000,  4455614.0000],
        [ 7944524.0000,  5228199.0000],
        [11714980.0000,  2921589.5000],
        [11137356.0000,  2799512.0000],
        [15009508.0000,        0.0000],
        [10102276.0000,  2509109.5000],
        [15059885.0000,        0.0000],
        [14996884.0000,        0.0000],
        [14969491.0000,        0.0000],
        [12746870.0000,  1411514.0000],
        [ 2357298.5000,  9540609.0000],
        [ 6986238.5000,  3313797.7500],
        [ 3254999.5000,  8120678.0000],
        [10564296.0000,  2681993.5000],
        [11258956.0000,  2813086.5000],
        [ 9712991.0000,  4142321.0000],
        [ 4051968.0000,  9538302.0000],
        [ 1339868.2500, 12396228.0000],
        [ 6529391.5000,  6286236.0000],
        [11525632.0000,  2888791.2500],
        [14719810.0000,        0.0000],
        [ 3943021.0000,  9043368.0000],
        [ 1290267.6250, 11656778.0000],
        [       0.0000, 13672776.0000],
        [ 6879369.5000,  7033247.0000],
        [ 9182286.0000,  3856753.0000],
        [14190710.0000,        0.0000],
        [13949598.0000,        0.0000],
        [ 4166472.0000,  9681168.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 64.0625
Top1 accuracy for validation set is 64.0625 size is torch.Size([64, 1])
Epoch 76/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:02, 57.96s/it]  7%|▋         | 2/29 [01:00<11:25, 25.40s/it] 10%|█         | 3/29 [01:01<06:09, 14.22s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.642658233642578
Epoch 77/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:28, 61.00s/it]  7%|▋         | 2/29 [01:01<11:32, 25.66s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.621093273162842
Epoch 78/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:50, 59.65s/it]  7%|▋         | 2/29 [01:00<11:17, 25.11s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.602199554443359
Epoch 79/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.88s/it]  7%|▋         | 2/29 [00:58<10:58, 24.38s/it] 10%|█         | 3/29 [00:59<05:55, 13.67s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.64s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 4.595917224884033
Epoch 80/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:20, 60.71s/it]  7%|▋         | 2/29 [01:01<11:29, 25.54s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.578245162963867
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0123, 0.0033, 0.0014,  ..., 0.0029, 0.0022, 0.0227],
        [0.0132, 0.0037, 0.0006,  ..., 0.0035, 0.0023, 0.0224],
        [0.0373, 0.0072, 0.0028,  ..., 0.0061, 0.0101, 0.0221],
        ...,
        [0.0102, 0.0093, 0.0012,  ..., 0.0029, 0.0025, 0.0210],
        [0.0116, 0.0095, 0.0002,  ..., 0.0034, 0.0022, 0.0209],
        [0.0246, 0.0068, 0.0018,  ..., 0.0040, 0.0079, 0.0217]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9959, 0.9957, 0.9956, 0.9955, 0.9953, 0.9953, 0.9952, 0.9952, 0.9952,
         0.9952],
        [0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9863, 0.9849, 0.9832, 0.9831, 0.9831, 0.9828, 0.9828, 0.9824, 0.9820,
         0.9808],
        [0.9929, 0.9928, 0.9927, 0.9925, 0.9920, 0.9917, 0.9914, 0.9912, 0.9912,
         0.9911],
        [0.9852, 0.9851, 0.9842, 0.9842, 0.9839, 0.9839, 0.9830, 0.9829, 0.9824,
         0.9818],
        [0.9835, 0.9833, 0.9818, 0.9808, 0.9784, 0.9776, 0.9732, 0.9726, 0.9718,
         0.9704],
        [0.9798, 0.9784, 0.9773, 0.9772, 0.9747, 0.9736, 0.9731, 0.9728, 0.9715,
         0.9696],
        [0.9853, 0.9838, 0.9828, 0.9827, 0.9817, 0.9814, 0.9805, 0.9803, 0.9800,
         0.9799],
        [0.9956, 0.9956, 0.9956, 0.9956, 0.9956, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9912, 0.9891, 0.9888, 0.9887, 0.9882, 0.9881, 0.9880, 0.9879, 0.9879,
         0.9872],
        [0.9968, 0.9967, 0.9966, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9938, 0.9934, 0.9923, 0.9923, 0.9922, 0.9919, 0.9919, 0.9913, 0.9910,
         0.9907],
        [0.9925, 0.9923, 0.9918, 0.9916, 0.9916, 0.9916, 0.9913, 0.9913, 0.9908,
         0.9907],
        [0.9968, 0.9967, 0.9967, 0.9967, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9944, 0.9942, 0.9942, 0.9941, 0.9940, 0.9940, 0.9939, 0.9939, 0.9938,
         0.9938],
        [0.9955, 0.9950, 0.9947, 0.9945, 0.9943, 0.9941, 0.9941, 0.9941, 0.9941,
         0.9940],
        [0.9939, 0.9938, 0.9936, 0.9935, 0.9934, 0.9932, 0.9930, 0.9930, 0.9929,
         0.9928],
        [0.9960, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957, 0.9956,
         0.9956],
        [0.9966, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9960],
        [0.9926, 0.9926, 0.9926, 0.9924, 0.9924, 0.9922, 0.9921, 0.9920, 0.9920,
         0.9920],
        [0.9964, 0.9961, 0.9961, 0.9957, 0.9955, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9960, 0.9953, 0.9949, 0.9945, 0.9944, 0.9944, 0.9939, 0.9938, 0.9937,
         0.9937],
        [0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9963, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9967, 0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9960, 0.9957, 0.9957,
         0.9957],
        [0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9966, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9972, 0.9971, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9889, 0.9869, 0.9846, 0.9843, 0.9841, 0.9820, 0.9812, 0.9808, 0.9803,
         0.9781],
        [0.9956, 0.9951, 0.9951, 0.9949, 0.9949, 0.9949, 0.9948, 0.9946, 0.9946,
         0.9946],
        [0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9953, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949,
         0.9947],
        [0.9914, 0.9898, 0.9882, 0.9875, 0.9872, 0.9840, 0.9838, 0.9838, 0.9835,
         0.9835],
        [0.9948, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944, 0.9943, 0.9942, 0.9942,
         0.9942],
        [0.9911, 0.9909, 0.9907, 0.9906, 0.9905, 0.9904, 0.9904, 0.9902, 0.9902,
         0.9901],
        [0.9961, 0.9961, 0.9961, 0.9961, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9883, 0.9877, 0.9865, 0.9864, 0.9849, 0.9842, 0.9830, 0.9821, 0.9799,
         0.9797],
        [0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9961, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956, 0.9956,
         0.9955],
        [0.9958, 0.9958, 0.9957, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9925, 0.9919, 0.9919, 0.9917, 0.9910, 0.9909, 0.9909, 0.9908, 0.9904,
         0.9902],
        [0.9838, 0.9808, 0.9806, 0.9801, 0.9799, 0.9793, 0.9781, 0.9780, 0.9775,
         0.9774],
        [0.9816, 0.9779, 0.9728, 0.9721, 0.9715, 0.9665, 0.9630, 0.9618, 0.9613,
         0.9603],
        [0.9834, 0.9794, 0.9790, 0.9786, 0.9756, 0.9753, 0.9752, 0.9734, 0.9703,
         0.9700],
        [0.9885, 0.9885, 0.9884, 0.9882, 0.9881, 0.9879, 0.9879, 0.9874, 0.9874,
         0.9872],
        [0.9916, 0.9915, 0.9915, 0.9914, 0.9913, 0.9911, 0.9909, 0.9909, 0.9907,
         0.9907],
        [0.9915, 0.9911, 0.9905, 0.9905, 0.9904, 0.9900, 0.9899, 0.9899, 0.9896,
         0.9895],
        [0.9920, 0.9905, 0.9905, 0.9897, 0.9888, 0.9884, 0.9882, 0.9881, 0.9871,
         0.9871],
        [0.9918, 0.9914, 0.9902, 0.9897, 0.9897, 0.9896, 0.9896, 0.9894, 0.9877,
         0.9876],
        [0.9890, 0.9883, 0.9850, 0.9849, 0.9844, 0.9843, 0.9841, 0.9836, 0.9832,
         0.9819],
        [0.9932, 0.9930, 0.9929, 0.9928, 0.9927, 0.9926, 0.9926, 0.9925, 0.9924,
         0.9924],
        [0.9946, 0.9944, 0.9942, 0.9942, 0.9942, 0.9942, 0.9941, 0.9941, 0.9941,
         0.9941],
        [0.9887, 0.9882, 0.9877, 0.9868, 0.9855, 0.9855, 0.9850, 0.9849, 0.9848,
         0.9846],
        [0.9883, 0.9878, 0.9874, 0.9867, 0.9863, 0.9851, 0.9850, 0.9845, 0.9843,
         0.9840],
        [0.9909, 0.9908, 0.9908, 0.9906, 0.9892, 0.9892, 0.9891, 0.9878, 0.9876,
         0.9875],
        [0.9946, 0.9924, 0.9917, 0.9904, 0.9901, 0.9901, 0.9899, 0.9898, 0.9895,
         0.9895],
        [0.9898, 0.9878, 0.9871, 0.9859, 0.9859, 0.9858, 0.9858, 0.9856, 0.9849,
         0.9842],
        [0.9934, 0.9925, 0.9924, 0.9920, 0.9913, 0.9910, 0.9907, 0.9907, 0.9907,
         0.9905],
        [0.9917, 0.9914, 0.9913, 0.9909, 0.9908, 0.9901, 0.9896, 0.9894, 0.9892,
         0.9891],
        [0.9913, 0.9908, 0.9908, 0.9906, 0.9903, 0.9903, 0.9902, 0.9896, 0.9895,
         0.9885]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 1, 1, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 1, 1, 0, 0, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 0, 1, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1508205.3750, 1503958.0000, 1502202.1250, 1500680.0000, 1496735.2500,
         1495378.3750, 1494758.1250, 1494483.1250, 1494404.7500, 1493386.1250],
        [1508491.6250, 1506924.2500, 1504889.2500, 1504797.3750, 1502538.7500,
         1501521.8750, 1500119.1250, 1500063.3750, 1499717.1250, 1498573.5000],
        [1316291.8750, 1289468.0000, 1259611.8750, 1257269.2500, 1256720.2500,
         1252155.0000, 1252016.5000, 1244735.1250, 1237752.3750, 1216465.8750],
        [1446386.3750, 1443679.8750, 1441676.6250, 1438618.0000, 1427419.8750,
         1420949.2500, 1414863.1250, 1410970.2500, 1410842.5000, 1410086.3750],
        [1294569.1250, 1294221.0000, 1277327.7500, 1276103.0000, 1271303.6250,
         1270823.6250, 1255979.7500, 1253661.7500, 1244978.5000, 1233904.3750],
        [1263983.7500, 1260730.7500, 1234423.2500, 1215644.6250, 1174644.0000,
         1162736.2500, 1091022.6250, 1081600.5000, 1069433.7500, 1048763.0000],
        [1198576.3750, 1175120.2500, 1156458.2500, 1154983.5000, 1114698.1250,
         1097615.2500, 1089902.6250, 1084942.5000, 1065744.0000, 1036713.6250],
        [1296709.2500, 1270583.6250, 1252433.3750, 1249213.7500, 1232105.1250,
         1226261.5000, 1211638.8750, 1207062.5000, 1202975.8750, 1201548.5000],
        [1502948.6250, 1502546.0000, 1502407.1250, 1502285.1250, 1502141.8750,
         1500612.7500, 1499099.3750, 1497303.3750, 1496776.6250, 1495339.8750],
        [1411460.1250, 1370285.1250, 1363463.6250, 1362479.6250, 1352003.1250,
         1349591.6250, 1347868.0000, 1346158.2500, 1345982.2500, 1332875.1250],
        [1528412.8750, 1526043.1250, 1523931.3750, 1517857.0000, 1516786.2500,
         1515619.3750, 1514258.2500, 1513399.3750, 1513324.3750, 1512967.8750],
        [1465603.5000, 1455406.6250, 1434421.7500, 1434097.6250, 1431801.7500,
         1426012.8750, 1425386.2500, 1413031.8750, 1407482.7500, 1401806.8750],
        [1437600.3750, 1433224.0000, 1423617.3750, 1420213.6250, 1419349.8750,
         1419270.0000, 1413040.0000, 1412699.1250, 1404121.6250, 1401706.7500],
        [1528080.5000, 1527449.6250, 1527117.5000, 1526775.3750, 1522619.6250,
         1521705.1250, 1519529.8750, 1519342.8750, 1519274.8750, 1518864.8750],
        [1523674.2500, 1523495.5000, 1523215.0000, 1522913.0000, 1522121.7500,
         1520609.7500, 1520486.5000, 1520274.8750, 1519637.1250, 1518888.0000],
        [1512292.8750, 1509920.7500, 1508670.0000, 1506269.0000, 1505999.1250,
         1504998.3750, 1504691.2500, 1502594.6250, 1501215.3750, 1500183.3750],
        [1477074.6250, 1473603.5000, 1472718.3750, 1469983.6250, 1469620.6250,
         1469390.7500, 1466684.3750, 1466383.7500, 1465053.0000, 1464362.8750],
        [1501236.8750, 1489656.5000, 1484661.2500, 1479141.1250, 1475100.8750,
         1471802.8750, 1471644.3750, 1471620.5000, 1470384.6250, 1469683.6250],
        [1466133.5000, 1463798.8750, 1460430.0000, 1457394.2500, 1456199.3750,
         1452687.3750, 1448012.2500, 1447010.1250, 1446142.2500, 1443606.8750],
        [1511518.5000, 1510429.2500, 1506339.5000, 1506227.5000, 1506045.0000,
         1506032.1250, 1505519.5000, 1504712.7500, 1502712.2500, 1502235.1250],
        [1523624.7500, 1518003.2500, 1516113.7500, 1516061.6250, 1515771.1250,
         1515156.7500, 1514047.5000, 1513716.8750, 1513630.3750, 1511659.7500],
        [1440695.2500, 1439584.1250, 1439448.3750, 1435694.6250, 1435649.3750,
         1431562.8750, 1430332.0000, 1428304.8750, 1427162.6250, 1426776.1250],
        [1520701.1250, 1514541.5000, 1513027.0000, 1504866.2500, 1501501.7500,
         1500255.1250, 1499997.5000, 1498221.8750, 1497589.1250, 1496662.3750],
        [1529998.1250, 1529128.7500, 1527267.6250, 1526552.6250, 1526235.2500,
         1526140.6250, 1526025.6250, 1525906.3750, 1525814.7500, 1525501.8750],
        [1510851.2500, 1496815.1250, 1487139.6250, 1479532.0000, 1478178.0000,
         1477177.3750, 1466783.6250, 1463666.2500, 1462543.0000, 1461689.6250],
        [1525484.3750, 1523739.6250, 1523078.6250, 1521914.1250, 1521821.2500,
         1518316.0000, 1515771.1250, 1514550.1250, 1514043.2500, 1513898.8750],
        [1526829.2500, 1524470.7500, 1520953.6250, 1518760.5000, 1517975.7500,
         1516207.7500, 1511866.0000, 1506014.8750, 1505859.7500, 1505855.3750],
        [1520443.1250, 1517987.2500, 1517415.6250, 1515551.3750, 1515286.8750,
         1513833.8750, 1513719.7500, 1513037.1250, 1510906.0000, 1510780.7500],
        [1528312.3750, 1527084.1250, 1526644.2500, 1526306.6250, 1525107.7500,
         1524217.7500, 1524008.5000, 1522399.0000, 1521606.3750, 1521458.3750],
        [1523639.3750, 1521129.1250, 1520859.2500, 1520608.3750, 1518395.6250,
         1517450.2500, 1516401.6250, 1516139.8750, 1515185.7500, 1514818.8750],
        [1523592.8750, 1522349.6250, 1521825.5000, 1521745.7500, 1520583.7500,
         1520131.3750, 1518691.0000, 1518685.2500, 1518185.6250, 1518043.7500],
        [1536677.8750, 1534803.1250, 1527005.5000, 1525093.1250, 1525077.1250,
         1525008.7500, 1524116.0000, 1523119.2500, 1522445.3750, 1522378.7500],
        [1366298.6250, 1327866.2500, 1284164.0000, 1278313.6250, 1275252.5000,
         1238284.7500, 1224007.7500, 1215960.1250, 1207608.2500, 1170345.7500],
        [1501944.3750, 1492870.6250, 1491396.2500, 1488900.7500, 1487888.6250,
         1487617.7500, 1485666.8750, 1481733.2500, 1481519.8750, 1481130.0000],
        [1514349.3750, 1512869.7500, 1511188.5000, 1509530.6250, 1508615.2500,
         1508523.2500, 1506750.3750, 1504622.3750, 1504553.3750, 1504256.5000],
        [1496027.3750, 1494579.8750, 1494010.0000, 1491343.6250, 1489508.6250,
         1489285.6250, 1488220.7500, 1487935.5000, 1486892.8750, 1484641.5000],
        [1415431.2500, 1384157.3750, 1353011.7500, 1338983.0000, 1332931.1250,
         1272599.1250, 1270044.6250, 1269965.8750, 1263950.0000, 1263437.6250],
        [1486603.7500, 1481884.5000, 1480565.1250, 1478994.3750, 1477952.3750,
         1476387.2500, 1475497.7500, 1473797.3750, 1472638.3750, 1472499.3750],
        [1409848.5000, 1404649.3750, 1402046.2500, 1399460.0000, 1397832.7500,
         1395568.2500, 1395026.7500, 1391728.6250, 1391688.7500, 1389502.0000],
        [1514230.8750, 1514050.3750, 1513916.1250, 1513601.5000, 1510141.1250,
         1508376.3750, 1507359.7500, 1506761.8750, 1506520.5000, 1505693.1250],
        [1354019.8750, 1343340.7500, 1318968.3750, 1317449.7500, 1288948.0000,
         1276468.1250, 1256064.8750, 1238759.6250, 1201299.8750, 1197389.2500],
        [1517509.6250, 1515081.7500, 1514506.8750, 1513135.2500, 1512835.1250,
         1512437.0000, 1511992.8750, 1511933.7500, 1511854.3750, 1511854.3750],
        [1513421.0000, 1508734.6250, 1507637.2500, 1507092.5000, 1505582.6250,
         1503744.5000, 1503420.2500, 1503257.0000, 1502205.0000, 1501312.7500],
        [1507901.8750, 1506266.2500, 1505176.2500, 1501388.6250, 1499595.6250,
         1498534.7500, 1498383.3750, 1498273.3750, 1497396.2500, 1497102.1250],
        [1436867.0000, 1425707.1250, 1425586.0000, 1422326.8750, 1408107.0000,
         1404839.6250, 1404452.3750, 1403595.3750, 1395750.7500, 1391518.8750],
        [1270204.5000, 1215725.8750, 1213555.0000, 1204207.5000, 1201357.1250,
         1190379.1250, 1170681.7500, 1168173.5000, 1161129.5000, 1159035.2500],
        [1230599.7500, 1166667.2500, 1085121.3750, 1074703.2500, 1065268.5000,
          991730.9375,  942789.6250,  926944.3125,  920847.1875,  908170.8125],
        [1262180.5000, 1191640.8750, 1186198.5000, 1178657.8750, 1128968.8750,
         1124569.6250, 1122949.1250, 1094152.7500, 1047047.1250, 1042967.0625],
        [1357909.7500, 1357860.5000, 1355931.1250, 1352743.5000, 1349743.5000,
         1347022.5000, 1346426.5000, 1337088.0000, 1336112.8750, 1333088.7500],
        [1419712.6250, 1417045.2500, 1416653.3750, 1414498.8750, 1414148.1250,
         1409286.5000, 1405092.7500, 1404946.7500, 1402213.3750, 1400432.0000],
        [1417813.1250, 1409606.5000, 1396958.5000, 1396918.6250, 1394928.2500,
         1386842.3750, 1385129.2500, 1384519.1250, 1379885.7500, 1378307.5000],
        [1427577.7500, 1397440.8750, 1397101.1250, 1381534.3750, 1364133.5000,
         1356320.3750, 1352319.1250, 1350565.0000, 1331204.7500, 1330877.2500],
        [1423200.6250, 1416291.3750, 1390610.1250, 1382149.7500, 1381020.6250,
         1379612.0000, 1379142.3750, 1375291.5000, 1343144.7500, 1341258.0000],
        [1368245.3750, 1353867.5000, 1291179.6250, 1290574.0000, 1280663.8750,
         1279154.0000, 1274243.5000, 1266386.0000, 1259412.5000, 1235127.5000],
        [1453094.7500, 1447616.0000, 1445869.2500, 1443425.1250, 1441672.5000,
         1440783.2500, 1439953.5000, 1437966.5000, 1436388.8750, 1435507.0000],
        [1482519.1250, 1476714.0000, 1473992.8750, 1473482.6250, 1472871.5000,
         1472274.6250, 1471960.1250, 1470581.0000, 1470177.1250, 1470142.0000],
        [1361525.0000, 1351153.7500, 1341664.7500, 1325841.6250, 1301087.0000,
         1300330.2500, 1291871.8750, 1290282.3750, 1288349.3750, 1283425.8750],
        [1354211.0000, 1344944.2500, 1336430.2500, 1323115.7500, 1316270.6250,
         1293731.1250, 1292202.1250, 1281609.5000, 1278397.7500, 1273922.7500],
        [1405531.0000, 1403471.0000, 1403413.5000, 1399550.8750, 1371341.5000,
         1370682.5000, 1368621.2500, 1344746.7500, 1340986.7500, 1338471.1250],
        [1481887.2500, 1436190.2500, 1422078.6250, 1394832.5000, 1390134.1250,
         1388452.8750, 1384323.6250, 1383443.3750, 1377921.1250, 1376485.5000],
        [1383439.5000, 1344723.6250, 1330044.8750, 1308967.5000, 1307479.0000,
         1307228.5000, 1306667.6250, 1302324.6250, 1289682.0000, 1276446.1250],
        [1456459.0000, 1438125.6250, 1434952.6250, 1426486.3750, 1412863.5000,
         1407153.8750, 1401831.0000, 1401451.3750, 1400518.7500, 1397852.6250],
        [1421395.2500, 1414500.1250, 1414164.2500, 1406161.1250, 1404175.1250,
         1388362.7500, 1379708.1250, 1374738.1250, 1370930.8750, 1368976.3750],
        [1413777.3750, 1403954.2500, 1402316.3750, 1399836.5000, 1392883.7500,
         1392843.8750, 1391261.3750, 1379079.2500, 1376648.2500, 1357931.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1508205.3750,       0.0000],
         [1503958.0000,       0.0000],
         [1502202.1250,       0.0000],
         ...,
         [1494483.1250,       0.0000],
         [1494404.7500,       0.0000],
         [1493386.1250,       0.0000]],

        [[1508491.6250,       0.0000],
         [1506924.2500,       0.0000],
         [1504889.2500,       0.0000],
         ...,
         [1500063.3750,       0.0000],
         [1499717.1250,       0.0000],
         [1498573.5000,       0.0000]],

        [[1316291.8750,       0.0000],
         [1289468.0000,       0.0000],
         [1259611.8750,       0.0000],
         ...,
         [      0.0000, 1244735.1250],
         [1237752.3750,       0.0000],
         [1216465.8750,       0.0000]],

        ...,

        [[1456459.0000,       0.0000],
         [1438125.6250,       0.0000],
         [1434952.6250,       0.0000],
         ...,
         [1401451.3750,       0.0000],
         [1400518.7500,       0.0000],
         [1397852.6250,       0.0000]],

        [[1421395.2500,       0.0000],
         [1414500.1250,       0.0000],
         [1414164.2500,       0.0000],
         ...,
         [1374738.1250,       0.0000],
         [1370930.8750,       0.0000],
         [1368976.3750,       0.0000]],

        [[      0.0000, 1413777.3750],
         [      0.0000, 1403954.2500],
         [1402316.3750,       0.0000],
         ...,
         [      0.0000, 1379079.2500],
         [1376648.2500,       0.0000],
         [1357931.7500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13489433.0000,  1494758.1250],
        [15027637.0000,        0.0000],
        [ 8828876.0000,  3753610.5000],
        [14265492.0000,        0.0000],
        [ 6392921.0000,  6279951.0000],
        [ 7114568.0000,  4488414.5000],
        [ 3241314.5000,  7933440.0000],
        [ 8594327.0000,  3756205.0000],
        [13504157.0000,  1497303.3750],
        [10864014.0000,  2718153.0000],
        [15182600.0000,        0.0000],
        [12869040.0000,  1426012.8750],
        [12765493.0000,  1419349.8750],
        [15230760.0000,        0.0000],
        [15215316.0000,        0.0000],
        [15056834.0000,        0.0000],
        [11751652.0000,  2943224.0000],
        [11821130.0000,  2963802.5000],
        [13080984.0000,  1460430.0000],
        [12050220.0000,  3011551.5000],
        [15157786.0000,        0.0000],
        [ 8598036.0000,  5737173.5000],
        [15047364.0000,        0.0000],
        [15268572.0000,        0.0000],
        [14784375.0000,        0.0000],
        [15192618.0000,        0.0000],
        [15154794.0000,        0.0000],
        [15148962.0000,        0.0000],
        [15247146.0000,        0.0000],
        [15184629.0000,        0.0000],
        [15203835.0000,        0.0000],
        [15265726.0000,        0.0000],
        [ 5015858.5000,  7572243.0000],
        [10418851.0000,  4461817.0000],
        [12068978.0000,  3016281.0000],
        [10430422.0000,  4472024.0000],
        [ 7951727.0000,  5212785.0000],
        [11822458.0000,  2954362.5000],
        [ 9777981.0000,  4199370.0000],
        [15100652.0000,        0.0000],
        [10272440.0000,  2520268.2500],
        [15133141.0000,        0.0000],
        [15056408.0000,        0.0000],
        [13511745.0000,  1498273.3750],
        [11331482.0000,  2787269.5000],
        [ 1215725.8750, 10738723.0000],
        [ 6059406.5000,  4253436.0000],
        [ 2141200.0000,  9238132.0000],
        [10769590.0000,  2704336.2500],
        [12684318.0000,  1419712.6250],
        [11154105.0000,  2776804.5000],
        [ 2728318.0000, 10960756.0000],
        [       0.0000, 13811721.0000],
        [ 6553316.5000,  6345537.5000],
        [11533676.0000,  2888601.7500],
        [14734714.0000,        0.0000],
        [ 3968593.5000,  9166939.0000],
        [ 1293731.1250, 11801103.0000],
        [       0.0000, 13746816.0000],
        [ 6921135.5000,  7114614.0000],
        [ 7919637.5000,  5237365.5000],
        [14177694.0000,        0.0000],
        [13943113.0000,        0.0000],
        [ 5529740.0000,  8380792.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 64.0625
Top1 accuracy for validation set is 64.0625 size is torch.Size([64, 1])
Epoch 81/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:23, 60.84s/it]  7%|▋         | 2/29 [01:01<11:31, 25.59s/it] 10%|█         | 3/29 [01:02<06:12, 14.33s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.564866065979004
Epoch 82/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:21, 58.61s/it]  7%|▋         | 2/29 [01:01<11:35, 25.76s/it] 10%|█         | 3/29 [01:02<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.549193859100342
Epoch 83/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:16, 58.45s/it]  7%|▋         | 2/29 [00:59<11:04, 24.61s/it] 10%|█         | 3/29 [01:00<05:58, 13.80s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.72s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 4.52825403213501
Epoch 84/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:28, 58.86s/it]  7%|▋         | 2/29 [00:59<11:09, 24.78s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 4.532522201538086
Epoch 85/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:39, 57.12s/it]  7%|▋         | 2/29 [01:01<11:40, 25.96s/it] 10%|█         | 3/29 [01:02<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:04<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.52035665512085
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0113, 0.0035, 0.0013,  ..., 0.0028, 0.0016, 0.0221],
        [0.0117, 0.0042, 0.0004,  ..., 0.0042, 0.0020, 0.0224],
        [0.0373, 0.0072, 0.0040,  ..., 0.0065, 0.0109, 0.0210],
        ...,
        [0.0092, 0.0100, 0.0013,  ..., 0.0032, 0.0027, 0.0219],
        [0.0113, 0.0093, 0.0003,  ..., 0.0041, 0.0019, 0.0195],
        [0.0261, 0.0078, 0.0021,  ..., 0.0044, 0.0076, 0.0221]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9960, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9962, 0.9962, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9867, 0.9851, 0.9835, 0.9831, 0.9830, 0.9824, 0.9822, 0.9821, 0.9811,
         0.9810],
        [0.9934, 0.9934, 0.9931, 0.9930, 0.9924, 0.9922, 0.9917, 0.9916, 0.9916,
         0.9915],
        [0.9858, 0.9850, 0.9839, 0.9835, 0.9834, 0.9830, 0.9828, 0.9825, 0.9819,
         0.9816],
        [0.9848, 0.9831, 0.9821, 0.9817, 0.9782, 0.9767, 0.9743, 0.9728, 0.9728,
         0.9715],
        [0.9809, 0.9792, 0.9789, 0.9772, 0.9756, 0.9750, 0.9724, 0.9724, 0.9693,
         0.9690],
        [0.9848, 0.9846, 0.9829, 0.9825, 0.9816, 0.9812, 0.9809, 0.9797, 0.9795,
         0.9794],
        [0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9911, 0.9900, 0.9885, 0.9882, 0.9878, 0.9874, 0.9872, 0.9871, 0.9869,
         0.9869],
        [0.9968, 0.9967, 0.9966, 0.9965, 0.9964, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9937, 0.9937, 0.9927, 0.9923, 0.9923, 0.9922, 0.9921, 0.9919, 0.9911,
         0.9906],
        [0.9928, 0.9926, 0.9921, 0.9920, 0.9918, 0.9918, 0.9915, 0.9914, 0.9912,
         0.9908],
        [0.9971, 0.9970, 0.9969, 0.9968, 0.9968, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9964],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9965],
        [0.9962, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9941, 0.9940, 0.9940, 0.9940, 0.9939, 0.9939, 0.9939, 0.9937, 0.9937,
         0.9936],
        [0.9957, 0.9953, 0.9950, 0.9948, 0.9945, 0.9945, 0.9944, 0.9944, 0.9944,
         0.9944],
        [0.9942, 0.9938, 0.9936, 0.9935, 0.9934, 0.9933, 0.9931, 0.9931, 0.9930,
         0.9929],
        [0.9961, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9957],
        [0.9967, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9931, 0.9929, 0.9929, 0.9928, 0.9927, 0.9926, 0.9925, 0.9924, 0.9923,
         0.9923],
        [0.9966, 0.9962, 0.9961, 0.9959, 0.9957, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970, 0.9969,
         0.9969],
        [0.9963, 0.9956, 0.9949, 0.9947, 0.9945, 0.9944, 0.9944, 0.9940, 0.9940,
         0.9939],
        [0.9967, 0.9967, 0.9965, 0.9965, 0.9965, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9962, 0.9960, 0.9959,
         0.9959],
        [0.9966, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9972, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9970, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9972, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9881, 0.9871, 0.9858, 0.9848, 0.9825, 0.9824, 0.9823, 0.9823, 0.9803,
         0.9790],
        [0.9958, 0.9956, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9956, 0.9955, 0.9953, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9913, 0.9895, 0.9876, 0.9861, 0.9861, 0.9844, 0.9842, 0.9841, 0.9838,
         0.9837],
        [0.9949, 0.9947, 0.9947, 0.9946, 0.9946, 0.9946, 0.9945, 0.9945, 0.9945,
         0.9943],
        [0.9907, 0.9907, 0.9906, 0.9905, 0.9903, 0.9902, 0.9901, 0.9899, 0.9896,
         0.9896],
        [0.9966, 0.9965, 0.9965, 0.9963, 0.9962, 0.9962, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9880, 0.9874, 0.9863, 0.9858, 0.9852, 0.9844, 0.9836, 0.9818, 0.9807,
         0.9791],
        [0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9959, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9919, 0.9916, 0.9912, 0.9909, 0.9906, 0.9905, 0.9905, 0.9904, 0.9902,
         0.9900],
        [0.9837, 0.9800, 0.9797, 0.9796, 0.9794, 0.9783, 0.9777, 0.9773, 0.9773,
         0.9770],
        [0.9809, 0.9771, 0.9714, 0.9708, 0.9678, 0.9672, 0.9628, 0.9613, 0.9597,
         0.9596],
        [0.9836, 0.9805, 0.9799, 0.9794, 0.9760, 0.9755, 0.9750, 0.9747, 0.9719,
         0.9718],
        [0.9899, 0.9884, 0.9880, 0.9879, 0.9879, 0.9878, 0.9878, 0.9877, 0.9875,
         0.9872],
        [0.9921, 0.9918, 0.9916, 0.9915, 0.9915, 0.9912, 0.9912, 0.9912, 0.9911,
         0.9910],
        [0.9920, 0.9915, 0.9905, 0.9902, 0.9899, 0.9898, 0.9898, 0.9898, 0.9898,
         0.9895],
        [0.9922, 0.9909, 0.9900, 0.9895, 0.9887, 0.9886, 0.9886, 0.9870, 0.9870,
         0.9866],
        [0.9918, 0.9913, 0.9901, 0.9900, 0.9893, 0.9892, 0.9892, 0.9891, 0.9875,
         0.9875],
        [0.9892, 0.9883, 0.9848, 0.9848, 0.9847, 0.9842, 0.9831, 0.9831, 0.9829,
         0.9821],
        [0.9937, 0.9927, 0.9926, 0.9926, 0.9925, 0.9923, 0.9923, 0.9923, 0.9922,
         0.9921],
        [0.9943, 0.9943, 0.9942, 0.9940, 0.9940, 0.9939, 0.9938, 0.9937, 0.9937,
         0.9937],
        [0.9889, 0.9882, 0.9871, 0.9859, 0.9852, 0.9849, 0.9847, 0.9844, 0.9842,
         0.9842],
        [0.9882, 0.9874, 0.9871, 0.9870, 0.9865, 0.9858, 0.9849, 0.9845, 0.9843,
         0.9838],
        [0.9915, 0.9911, 0.9908, 0.9907, 0.9892, 0.9890, 0.9888, 0.9879, 0.9877,
         0.9874],
        [0.9947, 0.9930, 0.9918, 0.9905, 0.9903, 0.9901, 0.9898, 0.9897, 0.9897,
         0.9897],
        [0.9897, 0.9880, 0.9870, 0.9860, 0.9859, 0.9854, 0.9853, 0.9849, 0.9848,
         0.9847],
        [0.9930, 0.9924, 0.9913, 0.9903, 0.9902, 0.9902, 0.9900, 0.9899, 0.9898,
         0.9895],
        [0.9915, 0.9910, 0.9910, 0.9906, 0.9904, 0.9900, 0.9890, 0.9888, 0.9887,
         0.9882],
        [0.9913, 0.9910, 0.9905, 0.9903, 0.9899, 0.9897, 0.9894, 0.9892, 0.9889,
         0.9887]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 1],
        [0, 1, 1, 1, 0, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 1, 1, 0, 0, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1511685.7500, 1504573.6250, 1504138.8750, 1503906.5000, 1502183.5000,
         1500226.5000, 1498790.6250, 1497907.5000, 1496883.6250, 1496853.7500],
        [1515557.1250, 1514732.1250, 1511087.6250, 1506580.8750, 1506384.0000,
         1505849.6250, 1505523.7500, 1504916.5000, 1504847.6250, 1503798.8750],
        [1323144.8750, 1293068.7500, 1263940.2500, 1257395.1250, 1254861.6250,
         1245408.3750, 1241581.6250, 1238350.8750, 1221084.8750, 1220113.8750],
        [1455886.8750, 1455527.3750, 1449241.8750, 1447574.5000, 1436331.3750,
         1431227.0000, 1422001.3750, 1419538.0000, 1419504.2500, 1416930.3750],
        [1307333.2500, 1292412.7500, 1271737.7500, 1263958.2500, 1262739.0000,
         1255423.0000, 1252368.7500, 1246299.6250, 1235545.7500, 1229570.8750],
        [1288121.0000, 1257517.5000, 1238776.1250, 1232078.0000, 1172538.7500,
         1146607.5000, 1107896.2500, 1085280.8750, 1084364.2500, 1064735.2500],
        [1217748.3750, 1188354.3750, 1183816.2500, 1156099.8750, 1129954.5000,
         1119027.8750, 1079318.0000, 1078118.6250, 1032433.5625, 1027734.9375],
        [1288258.5000, 1284531.5000, 1253749.0000, 1247141.3750, 1230329.7500,
         1223280.7500, 1218820.7500, 1197803.8750, 1194854.6250, 1191745.5000],
        [1511159.6250, 1509070.0000, 1509058.5000, 1508006.7500, 1506016.2500,
         1503625.3750, 1501401.5000, 1500492.5000, 1499920.2500, 1498806.3750],
        [1409337.6250, 1387690.3750, 1357205.5000, 1351365.1250, 1344259.5000,
         1337267.8750, 1332454.5000, 1330719.8750, 1327063.6250, 1326389.2500],
        [1529620.1250, 1527209.3750, 1524102.8750, 1521808.2500, 1520218.3750,
         1515688.7500, 1514983.3750, 1514577.5000, 1513452.7500, 1513429.7500],
        [1463138.6250, 1462988.0000, 1441089.6250, 1434378.0000, 1433531.6250,
         1431280.2500, 1428821.3750, 1424887.3750, 1410149.7500, 1399533.5000],
        [1442969.6250, 1439812.1250, 1428922.2500, 1426797.8750, 1422820.6250,
         1422598.1250, 1417953.6250, 1415739.0000, 1410270.7500, 1403960.8750],
        [1535161.8750, 1532254.0000, 1531758.8750, 1529874.1250, 1528063.1250,
         1525347.6250, 1524829.8750, 1521980.8750, 1521230.6250, 1520994.2500],
        [1527628.8750, 1526945.7500, 1524367.5000, 1524235.2500, 1524021.5000,
         1523809.3750, 1522908.6250, 1522628.3750, 1522088.2500, 1521995.5000],
        [1515870.8750, 1509100.2500, 1508270.0000, 1508226.8750, 1508226.8750,
         1507932.0000, 1507211.7500, 1506411.3750, 1506361.0000, 1504212.0000],
        [1471513.8750, 1469857.3750, 1469673.7500, 1468018.0000, 1467023.0000,
         1466864.8750, 1465813.2500, 1463248.8750, 1462598.8750, 1460661.2500],
        [1505737.7500, 1495455.3750, 1489078.2500, 1484798.6250, 1479248.3750,
         1478710.8750, 1478182.1250, 1476740.7500, 1476726.7500, 1476552.1250],
        [1472575.1250, 1464726.0000, 1459994.1250, 1459363.5000, 1456938.3750,
         1453342.7500, 1450447.5000, 1450368.6250, 1447559.3750, 1446389.1250],
        [1514140.0000, 1512226.5000, 1512039.0000, 1511675.6250, 1510025.8750,
         1509481.6250, 1508422.5000, 1508293.0000, 1506881.1250, 1504817.5000],
        [1526393.8750, 1522952.1250, 1522216.0000, 1521287.1250, 1521243.7500,
         1520910.0000, 1520836.1250, 1519464.7500, 1519277.7500, 1517483.6250],
        [1450816.8750, 1446895.5000, 1446772.7500, 1444671.5000, 1442096.0000,
         1440299.6250, 1437474.1250, 1435856.1250, 1434609.1250, 1434550.3750],
        [1525466.8750, 1515895.5000, 1514464.8750, 1509486.0000, 1504583.6250,
         1501133.7500, 1500275.0000, 1499355.3750, 1498619.1250, 1498277.6250],
        [1535138.3750, 1534662.6250, 1534067.1250, 1534014.3750, 1533473.2500,
         1533186.6250, 1533100.3750, 1532176.6250, 1531351.3750, 1531176.1250],
        [1517004.6250, 1502786.7500, 1488819.8750, 1482732.6250, 1480248.8750,
         1478242.8750, 1476661.8750, 1467987.2500, 1467950.8750, 1467178.2500],
        [1526481.2500, 1525682.2500, 1522661.7500, 1522507.8750, 1521845.8750,
         1517781.7500, 1517741.2500, 1516812.2500, 1516097.8750, 1515739.3750],
        [1526031.5000, 1525629.8750, 1524152.3750, 1523151.2500, 1520496.7500,
         1519454.5000, 1514990.6250, 1511086.2500, 1510272.2500, 1510241.8750],
        [1524527.3750, 1520673.6250, 1519311.0000, 1518962.0000, 1518289.8750,
         1517848.3750, 1513806.5000, 1513214.6250, 1513080.5000, 1512714.0000],
        [1538349.5000, 1533692.6250, 1531367.3750, 1530707.3750, 1529704.8750,
         1528691.2500, 1526589.0000, 1526341.5000, 1526242.5000, 1525759.3750],
        [1532483.5000, 1529413.0000, 1525801.6250, 1524991.2500, 1523723.6250,
         1523363.3750, 1521776.2500, 1521207.3750, 1520156.0000, 1520051.6250],
        [1528366.2500, 1528335.6250, 1528240.8750, 1527117.5000, 1526867.1250,
         1526232.3750, 1526148.0000, 1526049.0000, 1524911.2500, 1524459.1250],
        [1538217.3750, 1529963.1250, 1529244.0000, 1529071.8750, 1527363.7500,
         1527277.7500, 1525864.1250, 1525613.8750, 1525011.6250, 1524924.3750],
        [1350968.1250, 1330752.7500, 1306906.8750, 1287087.0000, 1246328.1250,
         1245382.3750, 1242600.3750, 1242220.0000, 1208149.6250, 1185105.1250],
        [1507484.8750, 1502816.7500, 1494495.8750, 1493374.6250, 1493015.7500,
         1492205.8750, 1490470.6250, 1490062.7500, 1489361.0000, 1488971.8750],
        [1513874.2500, 1512748.6250, 1512719.7500, 1510593.3750, 1509789.7500,
         1508838.2500, 1506816.5000, 1506213.0000, 1505858.3750, 1505365.8750],
        [1502046.0000, 1500159.1250, 1497264.8750, 1495412.6250, 1493354.7500,
         1492470.5000, 1490919.8750, 1489853.8750, 1488511.7500, 1488290.3750],
        [1412941.6250, 1377756.7500, 1341176.1250, 1312518.8750, 1312463.7500,
         1280321.8750, 1276264.8750, 1276053.0000, 1269942.8750, 1268106.8750],
        [1487370.8750, 1483031.0000, 1482908.0000, 1482555.8750, 1481350.3750,
         1481100.2500, 1479462.7500, 1479300.5000, 1479261.0000, 1475734.1250],
        [1400526.8750, 1400379.8750, 1398748.8750, 1396692.1250, 1393653.1250,
         1392008.6250, 1389566.7500, 1386252.5000, 1379212.1250, 1378709.7500],
        [1523716.3750, 1521322.0000, 1521271.2500, 1516933.7500, 1516164.3750,
         1514849.1250, 1512701.0000, 1511744.8750, 1510560.2500, 1509631.3750],
        [1348465.8750, 1335935.8750, 1316089.8750, 1307299.5000, 1295182.8750,
         1280063.0000, 1266550.2500, 1234212.6250, 1214462.7500, 1186642.0000],
        [1516904.8750, 1516742.7500, 1516499.7500, 1515587.6250, 1514607.7500,
         1513011.2500, 1512911.6250, 1512701.0000, 1511926.5000, 1511776.6250],
        [1512054.7500, 1510648.1250, 1509547.8750, 1508658.3750, 1507367.0000,
         1507164.3750, 1506760.5000, 1505476.2500, 1505101.6250, 1503642.6250],
        [1509185.1250, 1501201.1250, 1500997.8750, 1500160.6250, 1500013.2500,
         1499516.8750, 1497826.1250, 1497753.3750, 1497223.5000, 1496962.2500],
        [1424618.3750, 1420155.5000, 1410779.1250, 1405348.7500, 1399062.2500,
         1397262.2500, 1396874.6250, 1396092.7500, 1390570.3750, 1386390.0000],
        [1268172.1250, 1202544.7500, 1198241.3750, 1195865.7500, 1191516.0000,
         1173329.6250, 1164450.7500, 1156852.0000, 1156302.7500, 1152867.3750],
        [1218020.1250, 1154114.7500, 1063389.6250, 1053793.0000, 1010403.1875,
         1002036.5000,  941059.5625,  921153.6875,  899644.4375,  898271.0625],
        [1265775.0000, 1211708.1250, 1201668.7500, 1192124.0000, 1135286.1250,
         1127634.6250, 1120266.5000, 1115692.6250, 1071746.3750, 1069920.3750],
        [1384793.7500, 1356570.1250, 1348522.5000, 1345988.7500, 1345358.6250,
         1344314.6250, 1343498.2500, 1341811.8750, 1338929.3750, 1332984.5000],
        [1429147.0000, 1424270.5000, 1418682.7500, 1417654.8750, 1417598.1250,
         1411841.1250, 1411168.1250, 1410628.5000, 1410182.0000, 1408121.8750],
        [1426920.3750, 1417965.8750, 1397790.1250, 1390351.6250, 1385903.6250,
         1383625.5000, 1382934.2500, 1382811.6250, 1382508.2500, 1377253.7500],
        [1431373.1250, 1404824.8750, 1387759.1250, 1377220.8750, 1361093.8750,
         1359947.0000, 1359762.8750, 1329767.2500, 1329213.1250, 1321791.6250],
        [1423153.1250, 1413665.3750, 1388546.7500, 1388243.6250, 1372877.7500,
         1371656.6250, 1371604.3750, 1369984.6250, 1339338.0000, 1338735.3750],
        [1371300.8750, 1354603.7500, 1288347.0000, 1288088.8750, 1286939.7500,
         1276244.0000, 1257739.3750, 1256680.6250, 1252886.1250, 1239116.3750],
        [1463190.3750, 1441877.3750, 1439661.1250, 1439486.7500, 1438247.6250,
         1433571.1250, 1433172.0000, 1432665.0000, 1432077.6250, 1429674.6250],
        [1475604.6250, 1474847.7500, 1473714.5000, 1469840.6250, 1468488.5000,
         1466499.7500, 1463907.7500, 1463320.1250, 1462904.2500, 1461990.7500],
        [1364854.3750, 1352210.7500, 1330605.7500, 1309089.7500, 1295811.7500,
         1290101.5000, 1286775.2500, 1280434.2500, 1276811.3750, 1276253.8750],
        [1352175.8750, 1336933.7500, 1330349.3750, 1329105.3750, 1319899.5000,
         1305733.2500, 1289073.2500, 1282239.1250, 1278495.2500, 1270437.1250],
        [1417015.5000, 1410090.5000, 1402800.6250, 1401581.0000, 1371257.7500,
         1366963.3750, 1362970.8750, 1345354.7500, 1342693.8750, 1337369.8750],
        [1483803.5000, 1448736.1250, 1423347.2500, 1396811.8750, 1392745.6250,
         1390061.2500, 1382770.7500, 1381598.8750, 1381374.8750, 1380509.7500],
        [1382172.1250, 1349009.8750, 1329957.3750, 1311145.1250, 1308281.0000,
         1299897.6250, 1297851.2500, 1288919.7500, 1287702.1250, 1286721.2500],
        [1447137.0000, 1435323.6250, 1413997.1250, 1392992.6250, 1391737.8750,
         1391345.0000, 1387867.6250, 1385204.6250, 1383776.0000, 1377188.0000],
        [1416415.7500, 1408199.6250, 1407371.3750, 1398235.3750, 1395653.5000,
         1387830.6250, 1368188.0000, 1364453.5000, 1361886.0000, 1352120.5000],
        [1413490.2500, 1406779.5000, 1396404.3750, 1393593.2500, 1385275.8750,
         1380634.7500, 1376152.1250, 1372059.6250, 1366159.2500, 1362665.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1511685.7500,       0.0000],
         [1504573.6250,       0.0000],
         [1504138.8750,       0.0000],
         ...,
         [1497907.5000,       0.0000],
         [1496883.6250,       0.0000],
         [1496853.7500,       0.0000]],

        [[1515557.1250,       0.0000],
         [1514732.1250,       0.0000],
         [1511087.6250,       0.0000],
         ...,
         [1504916.5000,       0.0000],
         [1504847.6250,       0.0000],
         [1503798.8750,       0.0000]],

        [[1323144.8750,       0.0000],
         [1293068.7500,       0.0000],
         [1263940.2500,       0.0000],
         ...,
         [      0.0000, 1238350.8750],
         [1221084.8750,       0.0000],
         [      0.0000, 1220113.8750]],

        ...,

        [[1447137.0000,       0.0000],
         [1435323.6250,       0.0000],
         [1413997.1250,       0.0000],
         ...,
         [1385204.6250,       0.0000],
         [1383776.0000,       0.0000],
         [1377188.0000,       0.0000]],

        [[1416415.7500,       0.0000],
         [1408199.6250,       0.0000],
         [1407371.3750,       0.0000],
         ...,
         [1364453.5000,       0.0000],
         [1361886.0000,       0.0000],
         [1352120.5000,       0.0000]],

        [[      0.0000, 1413490.2500],
         [      0.0000, 1406779.5000],
         [1396404.3750,       0.0000],
         ...,
         [      0.0000, 1372059.6250],
         [      0.0000, 1366159.2500],
         [      0.0000, 1362665.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13516924.0000,  1500226.5000],
        [15079278.0000,        0.0000],
        [ 8843090.0000,  3715860.0000],
        [14353764.0000,        0.0000],
        [ 6389646.0000,  6227743.0000],
        [ 8294034.0000,  3383881.5000],
        [ 2157436.5000,  9055170.0000],
        [ 8593653.0000,  3736862.0000],
        [13541541.0000,  1506016.2500],
        [ 8121011.0000,  5382742.0000],
        [15195091.0000,        0.0000],
        [12904911.0000,  1424887.3750],
        [12821574.0000,  1410270.7500],
        [15271496.0000,        0.0000],
        [15240630.0000,        0.0000],
        [15081823.0000,        0.0000],
        [11730391.0000,  2934883.0000],
        [ 7432668.0000,  7408562.5000],
        [13104766.0000,  1456938.3750],
        [12082698.0000,  3015303.5000],
        [15212064.0000,        0.0000],
        [ 8654764.0000,  5759278.0000],
        [15067558.0000,        0.0000],
        [15332347.0000,        0.0000],
        [11884193.0000,  2945421.0000],
        [15203351.0000,        0.0000],
        [15185508.0000,        0.0000],
        [15172428.0000,        0.0000],
        [15297445.0000,        0.0000],
        [15242968.0000,        0.0000],
        [15266728.0000,        0.0000],
        [15282552.0000,        0.0000],
        [ 6222215.0000,  6423286.0000],
        [ 8983394.0000,  5958866.0000],
        [13583028.0000,  1509789.7500],
        [10446502.0000,  4491781.5000],
        [ 7889911.5000,  5237635.5000],
        [11850219.0000,  2961856.5000],
        [ 9739405.0000,  4176346.0000],
        [15158894.0000,        0.0000],
        [ 9067710.0000,  3717194.5000],
        [15142670.0000,        0.0000],
        [15076420.0000,        0.0000],
        [13499842.0000,  1500997.8750],
        [12628092.0000,  1399062.2500],
        [ 2354544.0000,  9505599.0000],
        [ 5049884.5000,  5112001.5000],
        [ 3276953.0000,  8234869.5000],
        [ 9419636.0000,  4063137.0000],
        [12735024.0000,  1424270.5000],
        [12545254.0000,  1382811.6250],
        [ 2709550.7500, 10953203.0000],
        [       0.0000, 13777806.0000],
        [ 6528413.5000,  6343533.5000],
        [10054784.0000,  4328839.0000],
        [14681118.0000,        0.0000],
        [ 3929797.0000,  9133151.0000],
        [       0.0000, 13094442.0000],
        [ 1337369.8750, 12420728.0000],
        [ 5549847.0000,  8511913.0000],
        [ 7908177.5000,  5233480.0000],
        [14006570.0000,        0.0000],
        [13860355.0000,        0.0000],
        [ 2789997.5000, 11063217.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 65.625
Top1 accuracy for validation set is 65.625 size is torch.Size([64, 1])
Epoch 86/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:36, 59.17s/it]  7%|▋         | 2/29 [01:01<11:39, 25.91s/it] 10%|█         | 3/29 [01:02<06:16, 14.50s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:05<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.5210371017456055
Epoch 87/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:08, 58.16s/it]  7%|▋         | 2/29 [00:59<11:01, 24.49s/it] 10%|█         | 3/29 [01:00<05:57, 13.73s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.68s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.88s/it] 21%|██        | 6/29 [01:02<01:36,  4.19s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 4.4981184005737305
Epoch 88/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:26, 58.81s/it]  7%|▋         | 2/29 [00:59<11:08, 24.76s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.04s/it] 21%|██        | 6/29 [01:03<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.498656749725342
Epoch 89/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.54s/it]  7%|▋         | 2/29 [00:58<10:54, 24.24s/it] 10%|█         | 3/29 [00:59<05:58, 13.77s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.70s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.89s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 4.468323230743408
Epoch 90/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:34, 56.93s/it]  7%|▋         | 2/29 [00:58<10:52, 24.18s/it] 10%|█         | 3/29 [01:01<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:02<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:02<02:28,  6.17s/it] 21%|██        | 6/29 [01:03<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.51s/it] 31%|███       | 9/29 [01:06<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.4764204025268555
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0114, 0.0035, 0.0012,  ..., 0.0023, 0.0018, 0.0226],
        [0.0120, 0.0042, 0.0007,  ..., 0.0034, 0.0015, 0.0218],
        [0.0372, 0.0082, 0.0045,  ..., 0.0073, 0.0113, 0.0230],
        ...,
        [0.0092, 0.0105, 0.0015,  ..., 0.0031, 0.0023, 0.0216],
        [0.0111, 0.0089, 0.0005,  ..., 0.0042, 0.0017, 0.0187],
        [0.0260, 0.0079, 0.0021,  ..., 0.0043, 0.0067, 0.0218]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9960, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9959],
        [0.9865, 0.9858, 0.9843, 0.9831, 0.9831, 0.9824, 0.9819, 0.9807, 0.9806,
         0.9801],
        [0.9937, 0.9937, 0.9934, 0.9932, 0.9928, 0.9924, 0.9923, 0.9922, 0.9919,
         0.9918],
        [0.9860, 0.9849, 0.9847, 0.9843, 0.9830, 0.9825, 0.9823, 0.9822, 0.9820,
         0.9820],
        [0.9862, 0.9820, 0.9819, 0.9813, 0.9780, 0.9757, 0.9755, 0.9738, 0.9723,
         0.9714],
        [0.9808, 0.9787, 0.9786, 0.9768, 0.9760, 0.9756, 0.9729, 0.9721, 0.9700,
         0.9698],
        [0.9850, 0.9841, 0.9830, 0.9825, 0.9822, 0.9818, 0.9816, 0.9812, 0.9808,
         0.9802],
        [0.9964, 0.9963, 0.9962, 0.9961, 0.9961, 0.9960, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9916, 0.9903, 0.9887, 0.9886, 0.9884, 0.9881, 0.9879, 0.9878, 0.9875,
         0.9871],
        [0.9969, 0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9941, 0.9938, 0.9932, 0.9932, 0.9931, 0.9930, 0.9927, 0.9922, 0.9913,
         0.9910],
        [0.9932, 0.9926, 0.9926, 0.9926, 0.9926, 0.9924, 0.9922, 0.9919, 0.9919,
         0.9917],
        [0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9965, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9959],
        [0.9945, 0.9941, 0.9940, 0.9939, 0.9938, 0.9937, 0.9937, 0.9937, 0.9937,
         0.9936],
        [0.9958, 0.9954, 0.9952, 0.9950, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9947],
        [0.9943, 0.9941, 0.9940, 0.9936, 0.9934, 0.9933, 0.9933, 0.9931, 0.9930,
         0.9930],
        [0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9937, 0.9935, 0.9934, 0.9932, 0.9930, 0.9928, 0.9928, 0.9926, 0.9926,
         0.9926],
        [0.9970, 0.9966, 0.9965, 0.9961, 0.9960, 0.9960, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9974, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9965, 0.9958, 0.9950, 0.9949, 0.9946, 0.9946, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9967, 0.9966, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9974, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968,
         0.9968],
        [0.9974, 0.9972, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9973, 0.9970, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9882, 0.9879, 0.9855, 0.9852, 0.9829, 0.9829, 0.9823, 0.9816, 0.9804,
         0.9788],
        [0.9959, 0.9957, 0.9955, 0.9955, 0.9953, 0.9953, 0.9952, 0.9952, 0.9952,
         0.9952],
        [0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9957, 0.9956, 0.9956, 0.9953, 0.9952, 0.9952, 0.9952, 0.9951, 0.9950,
         0.9950],
        [0.9912, 0.9894, 0.9876, 0.9861, 0.9849, 0.9847, 0.9847, 0.9844, 0.9841,
         0.9831],
        [0.9951, 0.9949, 0.9949, 0.9948, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945,
         0.9945],
        [0.9905, 0.9904, 0.9903, 0.9901, 0.9901, 0.9900, 0.9899, 0.9896, 0.9895,
         0.9894],
        [0.9964, 0.9964, 0.9962, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9882, 0.9867, 0.9858, 0.9853, 0.9848, 0.9841, 0.9821, 0.9821, 0.9820,
         0.9798],
        [0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9961, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9959, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9924, 0.9918, 0.9917, 0.9908, 0.9908, 0.9907, 0.9907, 0.9905, 0.9905,
         0.9902],
        [0.9842, 0.9811, 0.9798, 0.9795, 0.9793, 0.9792, 0.9786, 0.9784, 0.9783,
         0.9779],
        [0.9818, 0.9756, 0.9706, 0.9692, 0.9688, 0.9665, 0.9630, 0.9629, 0.9609,
         0.9606],
        [0.9839, 0.9817, 0.9798, 0.9785, 0.9766, 0.9750, 0.9745, 0.9743, 0.9722,
         0.9705],
        [0.9902, 0.9883, 0.9883, 0.9882, 0.9881, 0.9879, 0.9878, 0.9878, 0.9877,
         0.9875],
        [0.9924, 0.9919, 0.9918, 0.9916, 0.9914, 0.9914, 0.9913, 0.9912, 0.9910,
         0.9910],
        [0.9919, 0.9919, 0.9909, 0.9902, 0.9902, 0.9901, 0.9901, 0.9899, 0.9896,
         0.9896],
        [0.9924, 0.9911, 0.9902, 0.9898, 0.9894, 0.9892, 0.9890, 0.9876, 0.9876,
         0.9875],
        [0.9923, 0.9921, 0.9911, 0.9897, 0.9897, 0.9895, 0.9893, 0.9892, 0.9878,
         0.9878],
        [0.9889, 0.9861, 0.9858, 0.9848, 0.9842, 0.9839, 0.9835, 0.9830, 0.9827,
         0.9824],
        [0.9941, 0.9934, 0.9929, 0.9928, 0.9925, 0.9925, 0.9925, 0.9924, 0.9924,
         0.9923],
        [0.9945, 0.9944, 0.9944, 0.9943, 0.9941, 0.9939, 0.9939, 0.9939, 0.9938,
         0.9938],
        [0.9894, 0.9891, 0.9875, 0.9864, 0.9861, 0.9852, 0.9852, 0.9850, 0.9850,
         0.9849],
        [0.9891, 0.9879, 0.9874, 0.9872, 0.9872, 0.9868, 0.9860, 0.9852, 0.9847,
         0.9847],
        [0.9922, 0.9915, 0.9912, 0.9910, 0.9903, 0.9896, 0.9891, 0.9883, 0.9882,
         0.9882],
        [0.9948, 0.9938, 0.9922, 0.9915, 0.9912, 0.9911, 0.9909, 0.9907, 0.9902,
         0.9900],
        [0.9899, 0.9887, 0.9864, 0.9861, 0.9858, 0.9850, 0.9848, 0.9848, 0.9844,
         0.9842],
        [0.9930, 0.9926, 0.9908, 0.9907, 0.9902, 0.9897, 0.9896, 0.9896, 0.9895,
         0.9894],
        [0.9919, 0.9916, 0.9915, 0.9911, 0.9909, 0.9900, 0.9894, 0.9890, 0.9887,
         0.9886],
        [0.9917, 0.9912, 0.9905, 0.9904, 0.9902, 0.9900, 0.9897, 0.9897, 0.9895,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 1, 0, 1],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [0, 1, 1, 1, 0, 0, 0, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 1, 1, 0, 1, 0, 0, 1],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 1, 0, 1],
        [0, 1, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1513646.2500, 1511701.6250, 1505307.0000, 1505068.7500, 1504060.0000,
         1503698.5000, 1503492.0000, 1501299.8750, 1500539.7500, 1500053.2500],
        [1521304.6250, 1518127.7500, 1517022.0000, 1513092.0000, 1511217.2500,
         1510168.5000, 1509291.6250, 1508734.6250, 1508585.1250, 1508375.0000],
        [1319150.8750, 1306726.1250, 1279277.1250, 1257208.0000, 1256722.6250,
         1244359.0000, 1235301.8750, 1215383.8750, 1212924.5000, 1204890.0000],
        [1462965.6250, 1462165.0000, 1456510.5000, 1452978.2500, 1444830.0000,
         1435565.8750, 1433306.0000, 1432102.2500, 1425739.7500, 1424202.6250],
        [1310451.3750, 1289123.6250, 1286118.8750, 1279455.2500, 1254971.6250,
         1245622.2500, 1242382.2500, 1240154.5000, 1236954.6250, 1236694.0000],
        [1314434.1250, 1236844.8750, 1235871.0000, 1224484.1250, 1168301.7500,
         1130250.8750, 1127273.3750, 1100664.5000, 1076879.2500, 1064136.3750],
        [1216145.6250, 1180615.5000, 1179624.0000, 1148510.7500, 1135674.7500,
         1128764.2500, 1086725.6250, 1074212.5000, 1043228.7500, 1039646.2500],
        [1290853.3750, 1274791.7500, 1256045.6250, 1246441.0000, 1241129.3750,
         1233327.7500, 1230219.5000, 1222534.3750, 1216639.8750, 1206865.6250],
        [1519948.6250, 1518394.1250, 1516391.3750, 1514417.2500, 1513666.3750,
         1510717.2500, 1507996.7500, 1507763.8750, 1507047.8750, 1505571.1250],
        [1419987.5000, 1393588.0000, 1362558.8750, 1360088.3750, 1356130.3750,
         1349446.1250, 1346628.1250, 1344207.0000, 1338903.8750, 1330369.7500],
        [1530500.1250, 1530364.3750, 1524267.2500, 1523601.5000, 1522204.5000,
         1519038.6250, 1518560.7500, 1517864.2500, 1517532.7500, 1517347.6250],
        [1471515.2500, 1465644.1250, 1452896.5000, 1451414.7500, 1450873.6250,
         1447556.6250, 1442812.7500, 1432423.1250, 1413881.1250, 1407123.0000],
        [1451139.3750, 1440592.2500, 1439662.3750, 1439633.6250, 1439526.5000,
         1436298.5000, 1432559.8750, 1426436.0000, 1426335.3750, 1421299.0000],
        [1539754.1250, 1535494.2500, 1534272.0000, 1533391.3750, 1531130.7500,
         1527614.2500, 1526296.3750, 1525218.2500, 1524949.2500, 1524546.3750],
        [1535296.6250, 1533255.3750, 1531938.3750, 1531852.2500, 1529875.5000,
         1529262.8750, 1528552.7500, 1528277.3750, 1527920.2500, 1527413.2500],
        [1521464.2500, 1512680.8750, 1512643.2500, 1512191.8750, 1510302.3750,
         1510269.2500, 1509749.3750, 1509684.6250, 1509624.1250, 1509589.6250],
        [1478829.3750, 1470227.5000, 1468872.2500, 1467368.6250, 1464424.3750,
         1463282.3750, 1463278.2500, 1462707.6250, 1461759.3750, 1461115.5000],
        [1506662.7500, 1499243.8750, 1494622.7500, 1490864.5000, 1486566.8750,
         1485349.5000, 1484155.8750, 1483287.0000, 1483026.8750, 1482878.2500],
        [1475267.0000, 1471382.0000, 1468848.5000, 1459694.7500, 1455452.3750,
         1453578.3750, 1453489.6250, 1449395.2500, 1448737.3750, 1448417.0000],
        [1516249.7500, 1513971.0000, 1512904.3750, 1512637.5000, 1512151.5000,
         1510681.2500, 1508131.8750, 1507936.3750, 1505875.5000, 1505106.0000],
        [1526787.1250, 1526562.7500, 1525701.2500, 1524069.5000, 1523607.3750,
         1523186.1250, 1521098.6250, 1520788.2500, 1519493.6250, 1519032.8750],
        [1463320.1250, 1458281.1250, 1456066.1250, 1451232.0000, 1448169.7500,
         1444744.5000, 1443251.7500, 1440695.2500, 1440412.2500, 1440246.0000],
        [1534223.7500, 1523385.1250, 1523064.0000, 1514548.6250, 1511292.2500,
         1510813.7500, 1507714.8750, 1507151.3750, 1505727.6250, 1504849.1250],
        [1541455.5000, 1540710.3750, 1538437.5000, 1536933.0000, 1536088.8750,
         1535574.8750, 1535415.2500, 1535271.7500, 1534553.0000, 1534308.5000],
        [1522262.5000, 1507193.1250, 1490442.2500, 1487033.3750, 1482363.5000,
         1481276.8750, 1476740.7500, 1475782.0000, 1475237.5000, 1474894.2500],
        [1530087.1250, 1529844.8750, 1526664.7500, 1526396.7500, 1526308.0000,
         1524851.6250, 1524626.2500, 1523880.5000, 1523514.3750, 1521760.2500],
        [1531602.5000, 1529115.6250, 1528440.5000, 1525900.6250, 1525325.8750,
         1524305.0000, 1520541.7500, 1519603.7500, 1517754.2500, 1516910.6250],
        [1525968.8750, 1525101.7500, 1520672.2500, 1520482.2500, 1520221.2500,
         1520214.0000, 1519516.8750, 1517945.2500, 1516313.3750, 1515193.0000],
        [1541352.6250, 1538788.2500, 1535296.6250, 1535002.2500, 1534746.1250,
         1534115.5000, 1532824.0000, 1531444.7500, 1529322.6250, 1528767.0000],
        [1542339.2500, 1537476.8750, 1531788.0000, 1530501.5000, 1529543.0000,
         1529283.2500, 1529230.8750, 1529156.3750, 1528738.0000, 1528325.3750],
        [1535860.3750, 1532273.0000, 1532064.1250, 1532005.6250, 1531348.3750,
         1531254.8750, 1531104.5000, 1531027.0000, 1530808.1250, 1529669.8750],
        [1538918.8750, 1532268.7500, 1529704.8750, 1528972.6250, 1528743.7500,
         1527843.0000, 1527194.7500, 1527140.8750, 1526688.0000, 1526603.5000],
        [1351367.6250, 1346629.3750, 1301443.1250, 1295928.0000, 1253861.5000,
         1253775.3750, 1242278.0000, 1230852.0000, 1209522.6250, 1182087.8750],
        [1510040.2500, 1505571.1250, 1501720.8750, 1501236.8750, 1495996.0000,
         1495963.2500, 1495210.1250, 1494883.6250, 1494477.2500, 1494015.6250],
        [1520937.6250, 1519635.6250, 1519482.0000, 1516948.2500, 1515253.7500,
         1515180.0000, 1511951.0000, 1511951.0000, 1511535.8750, 1511251.8750],
        [1505012.7500, 1503115.0000, 1501905.6250, 1496745.1250, 1494621.2500,
         1494262.2500, 1493809.0000, 1491862.8750, 1490701.0000, 1489638.0000],
        [1410897.6250, 1374957.0000, 1339861.8750, 1311968.1250, 1289492.6250,
         1286482.0000, 1285923.8750, 1280688.2500, 1274482.8750, 1257162.6250],
        [1491103.3750, 1488544.5000, 1487050.3750, 1484927.5000, 1484113.5000,
         1483295.6250, 1482316.8750, 1480755.7500, 1479986.2500, 1479898.7500],
        [1396672.0000, 1394756.6250, 1393929.5000, 1389060.6250, 1388805.1250,
         1387992.1250, 1385508.3750, 1378537.5000, 1378106.3750, 1376242.7500],
        [1520176.2500, 1520167.6250, 1514745.1250, 1512467.2500, 1510495.5000,
         1510023.0000, 1509794.1250, 1507180.1250, 1506894.1250, 1506805.0000],
        [1352404.1250, 1323877.0000, 1306449.5000, 1296287.6250, 1288731.6250,
         1274870.7500, 1239876.5000, 1239057.3750, 1237987.1250, 1198590.0000],
        [1525280.7500, 1522420.7500, 1521291.6250, 1521058.0000, 1520472.1250,
         1519005.3750, 1517341.8750, 1517291.2500, 1516961.2500, 1516648.7500],
        [1513582.6250, 1511341.2500, 1511237.3750, 1511074.6250, 1509362.1250,
         1508549.0000, 1508468.5000, 1508242.7500, 1507250.5000, 1506733.1250],
        [1509647.2500, 1505755.0000, 1502680.7500, 1502192.1250, 1501013.6250,
         1500899.0000, 1499640.0000, 1499146.6250, 1498957.8750, 1498320.5000],
        [1436551.8750, 1424017.8750, 1421379.0000, 1403401.3750, 1402709.6250,
         1401494.2500, 1401345.8750, 1398196.7500, 1397147.7500, 1390392.7500],
        [1276874.7500, 1221518.1250, 1198456.2500, 1193552.8750, 1190005.5000,
         1189582.3750, 1179571.0000, 1175366.7500, 1174527.5000, 1167463.0000],
        [1234020.7500, 1128915.0000, 1050819.5000, 1030615.6250, 1024606.1875,
          991736.5625,  942941.6250,  941641.2500,  915187.1875,  911871.3750],
        [1271051.5000, 1232822.1250, 1198807.2500, 1177533.2500, 1144995.7500,
         1119849.8750, 1111234.7500, 1108231.2500, 1075526.6250, 1050508.8750],
        [1390993.5000, 1354810.5000, 1354745.8750, 1352550.0000, 1351054.5000,
         1345332.8750, 1344721.1250, 1343552.0000, 1342979.5000, 1337992.3750],
        [1436394.3750, 1425658.0000, 1423579.2500, 1419659.8750, 1415598.6250,
         1414396.2500, 1413259.6250, 1411379.3750, 1407872.0000, 1407488.1250],
        [1425490.7500, 1424638.7500, 1404863.6250, 1392117.5000, 1391321.2500,
         1389472.7500, 1388957.3750, 1385841.5000, 1379125.3750, 1379033.2500],
        [1435533.0000, 1410204.7500, 1390986.8750, 1383320.7500, 1375813.6250,
         1371264.2500, 1366976.3750, 1341205.5000, 1339923.1250, 1338222.1250],
        [1434238.5000, 1429377.5000, 1408496.5000, 1381573.8750, 1381023.2500,
         1377107.8750, 1373938.5000, 1371650.1250, 1344410.8750, 1343735.3750],
        [1366197.1250, 1312432.3750, 1307198.5000, 1288180.0000, 1277117.1250,
         1271018.8750, 1263363.0000, 1254935.7500, 1250121.8750, 1244323.2500],
        [1471300.5000, 1456159.1250, 1446382.3750, 1443132.0000, 1438301.1250,
         1437446.7500, 1436812.2500, 1436017.7500, 1435602.8750, 1434223.5000],
        [1479492.3750, 1478113.1250, 1477260.5000, 1474667.7500, 1470161.6250,
         1467593.8750, 1466962.8750, 1466354.3750, 1464635.2500, 1464191.2500],
        [1375370.2500, 1369253.1250, 1338931.8750, 1317648.3750, 1312531.3750,
         1296033.0000, 1294838.2500, 1291185.8750, 1290965.3750, 1290498.8750],
        [1369978.1250, 1346565.1250, 1336738.7500, 1333580.8750, 1332936.2500,
         1324351.7500, 1310315.2500, 1295383.0000, 1285786.5000, 1285270.3750],
        [1431388.1250, 1417100.6250, 1411520.7500, 1407586.1250, 1392707.1250,
         1379618.6250, 1370225.0000, 1353819.7500, 1352392.5000, 1351756.8750],
        [1485871.0000, 1465015.2500, 1430887.2500, 1416461.6250, 1411275.7500,
         1409297.3750, 1404331.8750, 1401503.5000, 1391432.6250, 1387679.7500],
        [1384709.3750, 1361680.7500, 1317491.2500, 1312374.8750, 1306657.6250,
         1291821.3750, 1288877.8750, 1288750.1250, 1280270.6250, 1276309.8750],
        [1448792.7500, 1439898.6250, 1403607.5000, 1400287.7500, 1390335.6250,
         1381797.8750, 1379980.5000, 1379973.8750, 1376857.0000, 1375262.6250],
        [1424780.0000, 1419146.8750, 1417990.2500, 1410052.8750, 1406142.3750,
         1388072.7500, 1375248.1250, 1368232.3750, 1361409.3750, 1360111.6250],
        [1420385.7500, 1411090.0000, 1397984.7500, 1394586.5000, 1391707.2500,
         1387984.1250, 1382006.1250, 1380539.8750, 1377285.2500, 1374346.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1513646.2500,       0.0000],
         [1511701.6250,       0.0000],
         [1505307.0000,       0.0000],
         ...,
         [1501299.8750,       0.0000],
         [1500539.7500,       0.0000],
         [1500053.2500,       0.0000]],

        [[1521304.6250,       0.0000],
         [1518127.7500,       0.0000],
         [1517022.0000,       0.0000],
         ...,
         [1508734.6250,       0.0000],
         [1508585.1250,       0.0000],
         [      0.0000, 1508375.0000]],

        [[1319150.8750,       0.0000],
         [1306726.1250,       0.0000],
         [1279277.1250,       0.0000],
         ...,
         [1215383.8750,       0.0000],
         [1212924.5000,       0.0000],
         [1204890.0000,       0.0000]],

        ...,

        [[1448792.7500,       0.0000],
         [1439898.6250,       0.0000],
         [1403607.5000,       0.0000],
         ...,
         [1379973.8750,       0.0000],
         [1376857.0000,       0.0000],
         [1375262.6250,       0.0000]],

        [[1424780.0000,       0.0000],
         [1419146.8750,       0.0000],
         [1417990.2500,       0.0000],
         ...,
         [1368232.3750,       0.0000],
         [1361409.3750,       0.0000],
         [1360111.6250,       0.0000]],

        [[      0.0000, 1420385.7500],
         [      0.0000, 1411090.0000],
         [      0.0000, 1397984.7500],
         ...,
         [      0.0000, 1380539.8750],
         [      0.0000, 1377285.2500],
         [      0.0000, 1374346.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13545168.0000,  1503698.5000],
        [13617542.0000,  1508375.0000],
        [10039434.0000,  2492510.0000],
        [14430364.0000,        0.0000],
        [ 7657075.0000,  4964853.0000],
        [ 9380588.0000,  2298552.5000],
        [ 4243813.0000,  6989335.0000],
        [ 8706971.0000,  3711877.0000],
        [13608248.0000,  1513666.3750],
        [ 8168039.5000,  5433869.0000],
        [15221282.0000,        0.0000],
        [11581461.0000,  2854679.5000],
        [12913850.0000,  1439633.6250],
        [15302668.0000,        0.0000],
        [15303644.0000,        0.0000],
        [15118198.0000,        0.0000],
        [11729710.0000,  2932154.5000],
        [ 7456376.5000,  7440281.5000],
        [13130772.0000,  1453489.6250],
        [13597708.0000,  1507936.3750],
        [15230328.0000,        0.0000],
        [11590442.0000,  2895976.5000],
        [15142771.0000,        0.0000],
        [15368750.0000,        0.0000],
        [11907002.0000,  2966224.2500],
        [15257934.0000,        0.0000],
        [15239500.0000,        0.0000],
        [15201628.0000,        0.0000],
        [15341659.0000,        0.0000],
        [15316383.0000,        0.0000],
        [15317416.0000,        0.0000],
        [15294080.0000,        0.0000],
        [ 5028434.5000,  7639311.0000],
        [10504544.0000,  4484571.0000],
        [13638873.0000,  1515253.7500],
        [10460945.0000,  4500727.0000],
        [ 7851120.0000,  5260797.0000],
        [11870828.0000,  2971164.0000],
        [ 9698370.0000,  4171241.0000],
        [15118748.0000,        0.0000],
        [10230343.0000,  2527789.0000],
        [15197771.0000,        0.0000],
        [15095842.0000,        0.0000],
        [13512498.0000,  1505755.0000],
        [11257061.0000,  2819575.7500],
        [ 2369576.5000,  9597342.0000],
        [ 5108492.5000,  5063863.0000],
        [ 3271031.5000,  8219530.0000],
        [10784187.0000,  2734545.5000],
        [12767797.0000,  1407488.1250],
        [12568744.0000,  1392117.5000],
        [ 1390986.8750, 12362463.0000],
        [       0.0000, 13845552.0000],
        [ 6454706.0000,  6380182.0000],
        [10088965.0000,  4346414.0000],
        [14709432.0000,        0.0000],
        [ 3941962.0000,  9235294.0000],
        [       0.0000, 13220906.0000],
        [       0.0000, 13868116.0000],
        [ 5616338.0000,  8587418.0000],
        [ 7889364.0000,  5219579.5000],
        [12596814.0000,  1379980.5000],
        [13931187.0000,        0.0000],
        [ 2786293.7500, 11131622.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 64.0625
Top1 accuracy for validation set is 64.0625 size is torch.Size([64, 1])
Epoch 91/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:12, 58.30s/it]  7%|▋         | 2/29 [00:59<11:02, 24.55s/it] 10%|█         | 3/29 [01:00<05:57, 13.76s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.69s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.89s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 4.449312210083008
Epoch 92/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:15, 60.56s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.449530601501465
Epoch 93/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:32, 56.88s/it]  7%|▋         | 2/29 [00:57<10:47, 23.97s/it] 10%|█         | 3/29 [00:59<06:01, 13.91s/it] 14%|█▍        | 4/29 [01:00<03:39,  8.78s/it] 17%|█▋        | 5/29 [01:01<02:22,  5.95s/it] 21%|██        | 6/29 [01:02<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 4.456294059753418
Epoch 94/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.53s/it]  7%|▋         | 2/29 [00:59<11:05, 24.64s/it] 10%|█         | 3/29 [01:00<06:02, 13.96s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 4.43044900894165
Epoch 95/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:59, 60.00s/it]  7%|▋         | 2/29 [01:00<11:21, 25.25s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.97s/it]
Epoch loss is 4.420515537261963
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0124, 0.0037, 0.0018,  ..., 0.0022, 0.0020, 0.0214],
        [0.0113, 0.0044, 0.0008,  ..., 0.0036, 0.0015, 0.0222],
        [0.0382, 0.0079, 0.0039,  ..., 0.0075, 0.0126, 0.0227],
        ...,
        [0.0097, 0.0107, 0.0017,  ..., 0.0031, 0.0021, 0.0213],
        [0.0102, 0.0092, 0.0008,  ..., 0.0040, 0.0020, 0.0186],
        [0.0253, 0.0075, 0.0024,  ..., 0.0039, 0.0071, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9960, 0.9958, 0.9956, 0.9955, 0.9955, 0.9955, 0.9954, 0.9954, 0.9954,
         0.9954],
        [0.9965, 0.9964, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959,
         0.9959],
        [0.9855, 0.9851, 0.9837, 0.9835, 0.9823, 0.9804, 0.9803, 0.9788, 0.9787,
         0.9785],
        [0.9933, 0.9932, 0.9931, 0.9927, 0.9926, 0.9925, 0.9924, 0.9923, 0.9920,
         0.9918],
        [0.9854, 0.9847, 0.9842, 0.9840, 0.9827, 0.9825, 0.9824, 0.9821, 0.9820,
         0.9818],
        [0.9868, 0.9825, 0.9822, 0.9810, 0.9770, 0.9766, 0.9747, 0.9744, 0.9739,
         0.9735],
        [0.9822, 0.9792, 0.9784, 0.9778, 0.9764, 0.9754, 0.9743, 0.9742, 0.9722,
         0.9712],
        [0.9846, 0.9838, 0.9823, 0.9821, 0.9809, 0.9807, 0.9803, 0.9795, 0.9788,
         0.9781],
        [0.9964, 0.9963, 0.9962, 0.9962, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9905, 0.9893, 0.9880, 0.9876, 0.9871, 0.9870, 0.9868, 0.9863, 0.9860,
         0.9860],
        [0.9971, 0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9936, 0.9935, 0.9929, 0.9927, 0.9921, 0.9918, 0.9917, 0.9912, 0.9904,
         0.9901],
        [0.9927, 0.9924, 0.9922, 0.9922, 0.9920, 0.9920, 0.9920, 0.9919, 0.9911,
         0.9911],
        [0.9973, 0.9972, 0.9972, 0.9970, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9967],
        [0.9965, 0.9963, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960,
         0.9959],
        [0.9946, 0.9939, 0.9939, 0.9938, 0.9937, 0.9937, 0.9937, 0.9936, 0.9936,
         0.9936],
        [0.9955, 0.9954, 0.9952, 0.9948, 0.9947, 0.9947, 0.9947, 0.9946, 0.9945,
         0.9945],
        [0.9940, 0.9940, 0.9938, 0.9937, 0.9932, 0.9932, 0.9932, 0.9931, 0.9930,
         0.9929],
        [0.9962, 0.9962, 0.9961, 0.9961, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9934, 0.9933, 0.9928, 0.9927, 0.9926, 0.9926, 0.9926, 0.9925, 0.9924,
         0.9923],
        [0.9971, 0.9964, 0.9964, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9964, 0.9955, 0.9948, 0.9947, 0.9946, 0.9943, 0.9942, 0.9942, 0.9941,
         0.9940],
        [0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9969, 0.9969, 0.9968, 0.9968, 0.9967, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9974, 0.9972, 0.9969, 0.9969, 0.9969, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9974, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9884, 0.9876, 0.9870, 0.9855, 0.9846, 0.9836, 0.9817, 0.9811, 0.9803,
         0.9792],
        [0.9960, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9954, 0.9952, 0.9952,
         0.9952],
        [0.9966, 0.9966, 0.9965, 0.9964, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9956, 0.9956, 0.9954, 0.9954, 0.9953, 0.9953, 0.9951, 0.9950, 0.9949,
         0.9949],
        [0.9912, 0.9890, 0.9877, 0.9862, 0.9852, 0.9848, 0.9842, 0.9840, 0.9833,
         0.9825],
        [0.9949, 0.9948, 0.9948, 0.9948, 0.9947, 0.9946, 0.9946, 0.9946, 0.9945,
         0.9945],
        [0.9908, 0.9907, 0.9902, 0.9900, 0.9899, 0.9895, 0.9894, 0.9894, 0.9893,
         0.9893],
        [0.9965, 0.9962, 0.9961, 0.9959, 0.9959, 0.9959, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9882, 0.9869, 0.9865, 0.9857, 0.9850, 0.9843, 0.9835, 0.9827, 0.9824,
         0.9807],
        [0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9958, 0.9956, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953, 0.9953, 0.9953,
         0.9952],
        [0.9924, 0.9921, 0.9911, 0.9907, 0.9904, 0.9904, 0.9900, 0.9899, 0.9898,
         0.9897],
        [0.9840, 0.9816, 0.9797, 0.9792, 0.9790, 0.9790, 0.9789, 0.9786, 0.9778,
         0.9775],
        [0.9815, 0.9743, 0.9693, 0.9688, 0.9681, 0.9645, 0.9630, 0.9629, 0.9620,
         0.9613],
        [0.9839, 0.9823, 0.9803, 0.9788, 0.9766, 0.9763, 0.9746, 0.9743, 0.9727,
         0.9706],
        [0.9902, 0.9885, 0.9883, 0.9883, 0.9880, 0.9879, 0.9877, 0.9877, 0.9876,
         0.9875],
        [0.9922, 0.9917, 0.9916, 0.9916, 0.9913, 0.9910, 0.9910, 0.9909, 0.9909,
         0.9907],
        [0.9919, 0.9918, 0.9912, 0.9907, 0.9906, 0.9905, 0.9902, 0.9902, 0.9900,
         0.9896],
        [0.9922, 0.9911, 0.9898, 0.9897, 0.9897, 0.9892, 0.9892, 0.9887, 0.9878,
         0.9869],
        [0.9926, 0.9922, 0.9909, 0.9898, 0.9895, 0.9895, 0.9894, 0.9892, 0.9881,
         0.9878],
        [0.9879, 0.9855, 0.9846, 0.9845, 0.9842, 0.9839, 0.9834, 0.9824, 0.9824,
         0.9819],
        [0.9939, 0.9932, 0.9926, 0.9922, 0.9921, 0.9921, 0.9921, 0.9919, 0.9918,
         0.9918],
        [0.9945, 0.9945, 0.9941, 0.9940, 0.9940, 0.9939, 0.9938, 0.9937, 0.9936,
         0.9935],
        [0.9889, 0.9887, 0.9868, 0.9863, 0.9853, 0.9850, 0.9850, 0.9849, 0.9847,
         0.9846],
        [0.9893, 0.9883, 0.9881, 0.9878, 0.9876, 0.9869, 0.9861, 0.9852, 0.9849,
         0.9842],
        [0.9925, 0.9913, 0.9910, 0.9910, 0.9904, 0.9899, 0.9893, 0.9886, 0.9885,
         0.9883],
        [0.9947, 0.9942, 0.9926, 0.9920, 0.9911, 0.9910, 0.9908, 0.9905, 0.9902,
         0.9900],
        [0.9897, 0.9881, 0.9860, 0.9859, 0.9852, 0.9851, 0.9850, 0.9843, 0.9840,
         0.9840],
        [0.9933, 0.9924, 0.9908, 0.9908, 0.9905, 0.9901, 0.9901, 0.9897, 0.9894,
         0.9894],
        [0.9921, 0.9915, 0.9915, 0.9914, 0.9912, 0.9899, 0.9890, 0.9888, 0.9886,
         0.9882],
        [0.9915, 0.9910, 0.9907, 0.9904, 0.9903, 0.9903, 0.9900, 0.9897, 0.9896,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 1, 0, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1511240.2500, 1507313.7500, 1502008.7500, 1500511.1250, 1500250.7500,
         1500246.3750, 1499089.3750, 1498650.6250, 1498084.6250, 1497910.3750],
        [1521686.2500, 1519809.5000, 1515541.2500, 1513356.1250, 1512946.2500,
         1511904.8750, 1511266.2500, 1509840.1250, 1509645.7500, 1509638.5000],
        [1301710.0000, 1292933.1250, 1267032.2500, 1264078.8750, 1242989.0000,
         1209206.6250, 1208449.2500, 1181580.7500, 1179710.5000, 1177473.8750],
        [1454335.3750, 1452066.8750, 1449552.8750, 1441466.2500, 1439578.6250,
         1438169.3750, 1434714.6250, 1433892.5000, 1427271.5000, 1422432.6250],
        [1298477.6250, 1285292.5000, 1277638.3750, 1274040.6250, 1250386.6250,
         1246268.7500, 1245043.8750, 1239708.6250, 1237251.8750, 1234315.1250],
        [1324868.3750, 1246832.1250, 1240508.1250, 1219490.3750, 1152394.6250,
         1144998.0000, 1115420.2500, 1110620.2500, 1102675.3750, 1095513.2500],
        [1241601.7500, 1188956.2500, 1175009.3750, 1165341.7500, 1142036.0000,
         1126817.6250, 1108050.6250, 1106193.3750, 1075519.3750, 1060387.1250],
        [1285200.6250, 1270101.5000, 1242518.5000, 1239675.5000, 1218814.8750,
         1214030.8750, 1206986.5000, 1194753.1250, 1182546.8750, 1170711.8750],
        [1519022.7500, 1517323.0000, 1516504.2500, 1515164.1250, 1511498.2500,
         1510146.7500, 1508757.7500, 1507595.5000, 1507086.7500, 1505581.1250],
        [1397968.6250, 1373468.2500, 1348854.3750, 1340761.7500, 1330430.6250,
         1329176.3750, 1325042.8750, 1315930.5000, 1310731.3750, 1309584.3750],
        [1534757.7500, 1530846.0000, 1524156.7500, 1523985.1250, 1521787.8750,
         1520904.2500, 1519603.7500, 1519211.1250, 1518788.1250, 1518634.5000],
        [1460464.8750, 1459156.2500, 1446062.3750, 1442522.3750, 1428591.0000,
         1422842.2500, 1422382.5000, 1410284.1250, 1395456.5000, 1390127.5000],
        [1441032.0000, 1434754.2500, 1431308.8750, 1431082.3750, 1428435.7500,
         1427824.2500, 1426875.5000, 1425022.0000, 1409603.7500, 1409265.1250],
        [1539143.3750, 1537158.6250, 1536776.1250, 1533169.0000, 1529459.7500,
         1526900.6250, 1526455.1250, 1526324.0000, 1525282.2500, 1524888.1250],
        [1536219.2500, 1536014.1250, 1531897.5000, 1531615.6250, 1530847.5000,
         1530667.8750, 1530265.1250, 1529370.8750, 1527792.0000, 1527288.0000],
        [1523213.6250, 1517088.6250, 1514382.6250, 1514199.1250, 1512950.6250,
         1511554.6250, 1511545.8750, 1511374.3750, 1510574.6250, 1510121.0000],
        [1481053.6250, 1466741.7500, 1466505.3750, 1464302.8750, 1463131.7500,
         1462317.0000, 1462156.6250, 1460933.0000, 1460895.2500, 1460778.3750],
        [1500006.0000, 1497810.3750, 1494903.5000, 1485931.8750, 1483175.3750,
         1482732.6250, 1482678.8750, 1481392.6250, 1479965.1250, 1479644.7500],
        [1469352.8750, 1469249.1250, 1464865.7500, 1461550.2500, 1452324.5000,
         1452188.7500, 1451842.5000, 1451074.2500, 1447736.1250, 1446571.3750],
        [1515391.0000, 1514765.3750, 1513395.1250, 1512724.1250, 1509023.8750,
         1509021.1250, 1508963.5000, 1508119.0000, 1508081.6250, 1506470.2500],
        [1529356.1250, 1527532.7500, 1526763.7500, 1525656.1250, 1524389.3750,
         1524203.2500, 1521134.8750, 1520944.8750, 1520837.5000, 1520778.0000],
        [1456987.0000, 1454314.6250, 1444379.5000, 1440829.8750, 1440562.0000,
         1440545.5000, 1440318.8750, 1438504.1250, 1435691.8750, 1433131.0000],
        [1535041.7500, 1520235.7500, 1519808.1250, 1514023.0000, 1510414.7500,
         1510213.0000, 1509624.1250, 1508707.3750, 1506658.3750, 1506514.7500],
        [1540441.6250, 1539009.7500, 1536751.1250, 1536294.0000, 1534965.6250,
         1534797.3750, 1534153.5000, 1534075.8750, 1533444.0000, 1532390.0000],
        [1519154.6250, 1500050.3750, 1484856.6250, 1483963.3750, 1480861.6250,
         1474783.1250, 1473592.2500, 1472506.3750, 1470498.2500, 1468614.6250],
        [1528647.5000, 1528418.6250, 1528383.6250, 1527787.7500, 1527261.7500,
         1526011.1250, 1524761.6250, 1524104.3750, 1523614.6250, 1523324.1250],
        [1531317.6250, 1530349.7500, 1528398.2500, 1527975.6250, 1525976.2500,
         1523287.7500, 1521102.8750, 1518935.8750, 1517939.5000, 1515876.6250],
        [1526430.3750, 1524212.0000, 1524008.5000, 1523306.7500, 1522612.3750,
         1522526.7500, 1522182.6250, 1521512.1250, 1521195.7500, 1519792.1250],
        [1538323.0000, 1537919.6250, 1535587.8750, 1535516.1250, 1533189.6250,
         1532137.1250, 1532004.2500, 1530208.2500, 1529130.1250, 1529112.6250],
        [1540922.0000, 1536760.0000, 1530368.7500, 1530049.2500, 1529977.6250,
         1527390.0000, 1527241.3750, 1526874.3750, 1526803.0000, 1526727.2500],
        [1535448.8750, 1533527.3750, 1533439.6250, 1533270.0000, 1532773.0000,
         1532045.1250, 1531441.7500, 1530876.7500, 1530421.3750, 1529875.5000],
        [1542595.2500, 1535337.5000, 1534826.6250, 1532562.5000, 1531198.0000,
         1531165.8750, 1531089.8750, 1530850.5000, 1529656.7500, 1529159.2500],
        [1355695.8750, 1341283.5000, 1329168.7500, 1300628.0000, 1284011.0000,
         1265632.5000, 1232195.6250, 1221427.2500, 1207143.1250, 1188507.3750],
        [1510532.8750, 1503526.3750, 1503054.7500, 1501098.0000, 1500004.7500,
         1499684.2500, 1498354.7500, 1494731.1250, 1494504.5000, 1494057.0000],
        [1524904.1250, 1523575.5000, 1521680.5000, 1519709.5000, 1514785.5000,
         1514129.8750, 1514090.8750, 1511385.8750, 1510669.7500, 1510113.7500],
        [1502212.1250, 1501771.0000, 1499068.0000, 1498049.0000, 1497319.1250,
         1497072.2500, 1491151.6250, 1489172.0000, 1488700.6250, 1487687.2500],
        [1410847.8750, 1368419.0000, 1341612.3750, 1313565.6250, 1294618.5000,
         1287042.7500, 1277737.1250, 1272669.6250, 1261275.6250, 1246334.0000],
        [1488846.8750, 1486798.0000, 1485741.8750, 1484757.5000, 1484339.8750,
         1482478.1250, 1481755.7500, 1481628.7500, 1480030.1250, 1479826.8750],
        [1403527.2500, 1401499.5000, 1390318.3750, 1386559.3750, 1385529.6250,
         1377611.0000, 1375984.1250, 1374789.2500, 1374226.8750, 1372686.6250],
        [1521758.7500, 1515018.1250, 1513266.5000, 1510110.8750, 1509228.2500,
         1508536.1250, 1507561.0000, 1505631.3750, 1503583.7500, 1503549.3750],
        [1352860.8750, 1327453.5000, 1320317.5000, 1305374.7500, 1291619.3750,
         1278297.7500, 1264486.5000, 1249794.1250, 1245319.3750, 1213836.3750],
        [1527548.7500, 1523986.6250, 1521946.0000, 1521757.3750, 1521117.5000,
         1520309.6250, 1518808.3750, 1518572.2500, 1517069.7500, 1516946.8750],
        [1513475.8750, 1512737.1250, 1511276.3750, 1509952.3750, 1509474.5000,
         1509306.0000, 1508937.6250, 1508224.0000, 1507830.0000, 1507371.3750],
        [1506542.0000, 1502632.0000, 1500007.5000, 1498117.6250, 1497510.5000,
         1496387.0000, 1496374.1250, 1496365.5000, 1495578.0000, 1495024.7500],
        [1436573.7500, 1428567.8750, 1409945.3750, 1402035.5000, 1395782.6250,
         1395682.7500, 1387046.0000, 1384575.8750, 1383955.3750, 1382178.7500],
        [1272969.3750, 1230014.1250, 1198120.3750, 1189426.8750, 1185453.2500,
         1184813.5000, 1183711.2500, 1178901.8750, 1165065.0000, 1161052.0000],
        [1228157.5000, 1109014.7500, 1031585.1875, 1024543.7500, 1014843.5000,
          963488.1875,  942899.3125,  941368.3125,  929296.1250,  920978.0625],
        [1272155.0000, 1243357.7500, 1208418.1250, 1181470.3750, 1145826.0000,
         1140288.3750, 1113404.1250, 1108056.8750, 1083309.8750, 1051272.5000],
        [1391066.5000, 1357177.0000, 1354408.6250, 1353792.7500, 1348351.3750,
         1346727.0000, 1342603.0000, 1341585.3750, 1340558.3750, 1337829.1250],
        [1432069.5000, 1420528.0000, 1419027.7500, 1418356.6250, 1412638.5000,
         1407231.7500, 1406241.6250, 1405407.7500, 1404562.1250, 1400355.8750],
        [1424453.8750, 1423389.3750, 1410307.0000, 1400699.0000, 1399359.8750,
         1397802.1250, 1390738.7500, 1390329.1250, 1387282.7500, 1380047.6250],
        [1431061.8750, 1408656.3750, 1382619.1250, 1382310.6250, 1382185.3750,
         1372299.0000, 1371286.5000, 1361978.1250, 1345290.5000, 1326768.8750],
        [1439534.7500, 1432516.1250, 1404976.2500, 1383761.5000, 1377199.8750,
         1376706.1250, 1375711.1250, 1370951.7500, 1350485.1250, 1344480.0000],
        [1346729.6250, 1300046.3750, 1283656.0000, 1282712.3750, 1277632.3750,
         1272351.6250, 1262274.2500, 1244709.0000, 1244146.6250, 1236383.8750],
        [1467267.8750, 1452314.7500, 1440115.6250, 1432116.0000, 1429977.3750,
         1429519.1250, 1429419.6250, 1425437.7500, 1423179.0000, 1422979.3750],
        [1478749.0000, 1478648.8750, 1471202.2500, 1468554.2500, 1468202.8750,
         1467561.7500, 1465648.3750, 1462141.3750, 1460324.1250, 1459231.3750],
        [1366249.1250, 1361970.3750, 1325193.1250, 1315044.7500, 1296327.2500,
         1292232.8750, 1291841.1250, 1289324.1250, 1285827.0000, 1284763.0000],
        [1373614.8750, 1353304.7500, 1349638.0000, 1343462.3750, 1341391.0000,
         1326444.8750, 1312053.2500, 1295039.6250, 1289557.8750, 1276761.5000],
        [1438096.7500, 1412281.5000, 1407372.7500, 1406322.1250, 1396012.8750,
         1386086.0000, 1374154.8750, 1360737.0000, 1357189.8750, 1354074.1250],
        [1483831.7500, 1472745.1250, 1438759.3750, 1428396.2500, 1408925.1250,
         1406373.1250, 1402530.3750, 1396820.0000, 1390928.3750, 1387221.8750],
        [1381936.2500, 1350031.8750, 1310233.8750, 1309071.1250, 1295920.6250,
         1293752.1250, 1292193.5000, 1279268.6250, 1273364.0000, 1272857.7500],
        [1454219.0000, 1436679.2500, 1403562.0000, 1402792.5000, 1397428.8750,
         1389446.2500, 1388703.1250, 1381008.7500, 1376090.5000, 1375816.2500],
        [1429823.2500, 1417811.7500, 1416500.7500, 1415631.0000, 1412194.0000,
         1385726.5000, 1367671.3750, 1363982.5000, 1360652.6250, 1351651.2500],
        [1418145.7500, 1406642.7500, 1401615.7500, 1395155.8750, 1392587.5000,
         1392280.7500, 1387015.6250, 1380520.2500, 1378836.0000, 1370855.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1511240.2500,       0.0000],
         [1507313.7500,       0.0000],
         [1502008.7500,       0.0000],
         ...,
         [      0.0000, 1498650.6250],
         [1498084.6250,       0.0000],
         [1497910.3750,       0.0000]],

        [[1521686.2500,       0.0000],
         [1519809.5000,       0.0000],
         [1515541.2500,       0.0000],
         ...,
         [1509840.1250,       0.0000],
         [1509645.7500,       0.0000],
         [1509638.5000,       0.0000]],

        [[1301710.0000,       0.0000],
         [1292933.1250,       0.0000],
         [1267032.2500,       0.0000],
         ...,
         [1181580.7500,       0.0000],
         [1179710.5000,       0.0000],
         [1177473.8750,       0.0000]],

        ...,

        [[1454219.0000,       0.0000],
         [1436679.2500,       0.0000],
         [1403562.0000,       0.0000],
         ...,
         [1381008.7500,       0.0000],
         [1376090.5000,       0.0000],
         [1375816.2500,       0.0000]],

        [[1429823.2500,       0.0000],
         [1417811.7500,       0.0000],
         [1416500.7500,       0.0000],
         ...,
         [1363982.5000,       0.0000],
         [1360652.6250,       0.0000],
         [1351651.2500,       0.0000]],

        [[      0.0000, 1418145.7500],
         [      0.0000, 1406642.7500],
         [1401615.7500,       0.0000],
         ...,
         [      0.0000, 1380520.2500],
         [      0.0000, 1378836.0000],
         [      0.0000, 1370855.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13516655.0000,  1498650.6250],
        [15135634.0000,        0.0000],
        [ 9872968.0000,  2452195.5000],
        [14393481.0000,        0.0000],
        [ 8868132.0000,  3720292.5000],
        [ 8382830.0000,  3370490.2500],
        [ 4428066.0000,  6961847.5000],
        [ 9741208.0000,  2484132.5000],
        [13607182.0000,  1511498.2500],
        [ 8038331.0000,  5343618.0000],
        [15232674.0000,        0.0000],
        [12849298.0000,  1428591.0000],
        [12833894.0000,  1431308.8750],
        [15305556.0000,        0.0000],
        [15311978.0000,        0.0000],
        [15137006.0000,        0.0000],
        [13182074.0000,  1466741.7500],
        [ 7443689.5000,  7424551.5000],
        [13114432.0000,  1452324.5000],
        [13597873.0000,  1508081.6250],
        [15241597.0000,        0.0000],
        [11540566.0000,  2884698.5000],
        [15141240.0000,        0.0000],
        [15356322.0000,        0.0000],
        [11870134.0000,  2958746.5000],
        [15262315.0000,        0.0000],
        [15241160.0000,        0.0000],
        [15227780.0000,        0.0000],
        [15333128.0000,        0.0000],
        [15303114.0000,        0.0000],
        [15323121.0000,        0.0000],
        [15328443.0000,        0.0000],
        [ 6255310.0000,  6470383.0000],
        [10506038.0000,  4493510.0000],
        [13645336.0000,  1519709.5000],
        [10451148.0000,  4501055.5000],
        [ 6590885.0000,  6483237.0000],
        [11865728.0000,  2970475.5000],
        [ 9690188.0000,  4152543.2500],
        [15098244.0000,        0.0000],
        [10312422.0000,  2536938.7500],
        [15208064.0000,        0.0000],
        [15098586.0000,        0.0000],
        [13481907.0000,  1502632.0000],
        [ 8410472.0000,  5595872.5000],
        [ 2363185.5000,  9586342.0000],
        [ 5087108.0000,  5019066.5000],
        [ 3280408.5000,  8267150.0000],
        [10782474.0000,  2731625.0000],
        [14126420.0000,        0.0000],
        [12603711.0000,  1400699.0000],
        [ 1372299.0000, 12392157.0000],
        [       0.0000, 13856323.0000],
        [ 6372809.0000,  6377833.0000],
        [10026120.0000,  4326206.5000],
        [14680264.0000,        0.0000],
        [ 3906750.0000,  9202023.0000],
        [       0.0000, 13261268.0000],
        [       0.0000, 13892327.0000],
        [ 6995979.0000,  7220553.0000],
        [ 9137136.0000,  3921494.0000],
        [12616300.0000,  1389446.2500],
        [12553974.0000,  1367671.3750],
        [ 2796771.5000, 11126884.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 65.625
Top1 accuracy for validation set is 65.625 size is torch.Size([64, 1])
Epoch 96/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.68s/it]  7%|▋         | 2/29 [00:57<10:45, 23.90s/it] 10%|█         | 3/29 [00:58<05:48, 13.41s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.48s/it] 17%|█▋        | 5/29 [01:00<02:18,  5.76s/it] 21%|██        | 6/29 [01:01<01:34,  4.11s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.07s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.39s/it] 31%|███       | 9/29 [01:04<00:38,  1.93s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:05<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:06<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:07<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:08<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:09<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:16<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:17<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:18<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:19<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:20<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:21<00:00,  1.09it/s]100%|██████████| 29/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:22<00:00,  2.85s/it]
Epoch loss is 4.399098873138428
Epoch 97/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:09, 60.33s/it]  7%|▋         | 2/29 [01:01<11:25, 25.38s/it] 10%|█         | 3/29 [01:02<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.400895595550537
Epoch 98/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.69s/it]  7%|▋         | 2/29 [00:57<10:44, 23.88s/it] 10%|█         | 3/29 [00:59<06:01, 13.91s/it] 14%|█▍        | 4/29 [01:00<03:39,  8.79s/it] 17%|█▋        | 5/29 [01:01<02:22,  5.95s/it] 21%|██        | 6/29 [01:02<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.45s/it] 31%|███       | 9/29 [01:05<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 4.384907245635986
Epoch 99/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:23, 56.57s/it]  7%|▋         | 2/29 [00:58<10:59, 24.42s/it] 10%|█         | 3/29 [00:59<05:55, 13.69s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:04<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 4.383212566375732
Epoch 100/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:24, 60.87s/it]  7%|▋         | 2/29 [01:01<11:31, 25.61s/it] 10%|█         | 3/29 [01:02<06:12, 14.34s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.3714213371276855
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0120, 0.0039, 0.0014,  ..., 0.0028, 0.0024, 0.0223],
        [0.0114, 0.0043, 0.0011,  ..., 0.0037, 0.0014, 0.0220],
        [0.0370, 0.0075, 0.0039,  ..., 0.0084, 0.0115, 0.0246],
        ...,
        [0.0108, 0.0110, 0.0018,  ..., 0.0027, 0.0022, 0.0203],
        [0.0107, 0.0097, 0.0011,  ..., 0.0043, 0.0023, 0.0185],
        [0.0245, 0.0080, 0.0025,  ..., 0.0038, 0.0077, 0.0217]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9956,
         0.9956],
        [0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9864, 0.9861, 0.9845, 0.9838, 0.9822, 0.9817, 0.9809, 0.9806, 0.9802,
         0.9798],
        [0.9938, 0.9937, 0.9936, 0.9933, 0.9933, 0.9928, 0.9927, 0.9927, 0.9924,
         0.9924],
        [0.9871, 0.9862, 0.9856, 0.9850, 0.9846, 0.9846, 0.9843, 0.9842, 0.9840,
         0.9839],
        [0.9882, 0.9848, 0.9826, 0.9816, 0.9789, 0.9789, 0.9780, 0.9771, 0.9768,
         0.9765],
        [0.9819, 0.9791, 0.9785, 0.9777, 0.9766, 0.9747, 0.9741, 0.9734, 0.9732,
         0.9713],
        [0.9845, 0.9839, 0.9838, 0.9823, 0.9813, 0.9800, 0.9800, 0.9797, 0.9797,
         0.9797],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9961],
        [0.9923, 0.9906, 0.9897, 0.9892, 0.9880, 0.9880, 0.9879, 0.9877, 0.9877,
         0.9877],
        [0.9973, 0.9971, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9944, 0.9943, 0.9942, 0.9933, 0.9932, 0.9928, 0.9926, 0.9922, 0.9920,
         0.9911],
        [0.9940, 0.9935, 0.9933, 0.9929, 0.9928, 0.9927, 0.9925, 0.9921, 0.9916,
         0.9915],
        [0.9975, 0.9974, 0.9973, 0.9972, 0.9970, 0.9970, 0.9970, 0.9970, 0.9969,
         0.9969],
        [0.9972, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9967, 0.9964, 0.9964, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9949, 0.9943, 0.9941, 0.9941, 0.9941, 0.9939, 0.9939, 0.9938, 0.9938,
         0.9937],
        [0.9958, 0.9957, 0.9954, 0.9952, 0.9952, 0.9951, 0.9951, 0.9949, 0.9949,
         0.9948],
        [0.9943, 0.9943, 0.9941, 0.9938, 0.9938, 0.9937, 0.9935, 0.9935, 0.9935,
         0.9934],
        [0.9964, 0.9963, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9958,
         0.9958],
        [0.9972, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9937, 0.9935, 0.9933, 0.9932, 0.9932, 0.9931, 0.9931, 0.9929, 0.9929,
         0.9928],
        [0.9973, 0.9965, 0.9963, 0.9963, 0.9963, 0.9962, 0.9961, 0.9960, 0.9960,
         0.9960],
        [0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9965, 0.9959, 0.9954, 0.9953, 0.9952, 0.9948, 0.9948, 0.9948, 0.9945,
         0.9945],
        [0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9964, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9963],
        [0.9975, 0.9974, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9974, 0.9973, 0.9971, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9975, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9882, 0.9866, 0.9863, 0.9858, 0.9855, 0.9829, 0.9812, 0.9812, 0.9811,
         0.9802],
        [0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9954, 0.9953,
         0.9953],
        [0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9962, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9962, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956, 0.9954, 0.9954, 0.9954,
         0.9952],
        [0.9915, 0.9886, 0.9877, 0.9857, 0.9851, 0.9847, 0.9842, 0.9833, 0.9821,
         0.9821],
        [0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9921, 0.9920, 0.9919, 0.9908, 0.9906, 0.9906, 0.9905, 0.9905, 0.9904,
         0.9903],
        [0.9965, 0.9963, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9879, 0.9872, 0.9869, 0.9857, 0.9856, 0.9851, 0.9840, 0.9834, 0.9833,
         0.9805],
        [0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9963, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959,
         0.9959],
        [0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9924, 0.9921, 0.9909, 0.9908, 0.9904, 0.9899, 0.9898, 0.9897, 0.9896,
         0.9893],
        [0.9853, 0.9838, 0.9826, 0.9823, 0.9816, 0.9816, 0.9814, 0.9809, 0.9808,
         0.9802],
        [0.9809, 0.9739, 0.9702, 0.9691, 0.9665, 0.9659, 0.9641, 0.9636, 0.9626,
         0.9623],
        [0.9837, 0.9824, 0.9807, 0.9794, 0.9780, 0.9760, 0.9760, 0.9751, 0.9720,
         0.9705],
        [0.9911, 0.9896, 0.9893, 0.9891, 0.9889, 0.9888, 0.9886, 0.9883, 0.9882,
         0.9882],
        [0.9926, 0.9925, 0.9920, 0.9919, 0.9919, 0.9917, 0.9916, 0.9914, 0.9912,
         0.9911],
        [0.9921, 0.9921, 0.9912, 0.9910, 0.9910, 0.9908, 0.9908, 0.9906, 0.9903,
         0.9901],
        [0.9912, 0.9911, 0.9901, 0.9898, 0.9895, 0.9894, 0.9893, 0.9886, 0.9879,
         0.9868],
        [0.9928, 0.9922, 0.9913, 0.9904, 0.9897, 0.9894, 0.9891, 0.9889, 0.9886,
         0.9882],
        [0.9868, 0.9860, 0.9849, 0.9848, 0.9847, 0.9847, 0.9836, 0.9832, 0.9826,
         0.9823],
        [0.9937, 0.9933, 0.9922, 0.9922, 0.9920, 0.9919, 0.9917, 0.9917, 0.9916,
         0.9915],
        [0.9943, 0.9943, 0.9940, 0.9940, 0.9938, 0.9937, 0.9937, 0.9936, 0.9934,
         0.9934],
        [0.9884, 0.9884, 0.9864, 0.9860, 0.9858, 0.9853, 0.9852, 0.9850, 0.9849,
         0.9846],
        [0.9904, 0.9892, 0.9890, 0.9884, 0.9876, 0.9873, 0.9872, 0.9860, 0.9859,
         0.9847],
        [0.9928, 0.9915, 0.9910, 0.9910, 0.9909, 0.9901, 0.9899, 0.9894, 0.9887,
         0.9885],
        [0.9946, 0.9946, 0.9927, 0.9925, 0.9914, 0.9909, 0.9908, 0.9906, 0.9905,
         0.9904],
        [0.9891, 0.9885, 0.9865, 0.9861, 0.9856, 0.9856, 0.9853, 0.9851, 0.9851,
         0.9847],
        [0.9932, 0.9926, 0.9911, 0.9904, 0.9901, 0.9900, 0.9899, 0.9898, 0.9893,
         0.9892],
        [0.9924, 0.9918, 0.9917, 0.9914, 0.9913, 0.9900, 0.9889, 0.9888, 0.9882,
         0.9881],
        [0.9915, 0.9909, 0.9907, 0.9906, 0.9904, 0.9903, 0.9900, 0.9895, 0.9893,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 1],
        [1, 1, 0, 1, 1, 1, 1, 0, 1, 0],
        [0, 1, 0, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1513779.0000, 1510080.6250, 1508926.0000, 1507049.2500, 1505743.3750,
         1505627.1250, 1503698.5000, 1503509.2500, 1502673.5000, 1502569.0000],
        [1523508.6250, 1520047.2500, 1517975.7500, 1517880.1250, 1516708.1250,
         1516672.0000, 1514670.0000, 1514278.6250, 1512135.6250, 1511643.8750],
        [1318022.8750, 1312312.2500, 1283154.1250, 1269686.1250, 1240961.2500,
         1232215.6250, 1217535.8750, 1213687.0000, 1205699.1250, 1199929.2500],
        [1465198.2500, 1461953.1250, 1460275.3750, 1453920.8750, 1453511.8750,
         1444338.1250, 1441973.6250, 1441264.2500, 1436672.3750, 1436171.1250],
        [1330745.2500, 1314678.5000, 1303511.2500, 1291470.2500, 1284981.2500,
         1284543.7500, 1278222.2500, 1277694.5000, 1272975.5000, 1271235.8750],
        [1352377.1250, 1288595.2500, 1248143.1250, 1231044.5000, 1184567.2500,
         1184162.8750, 1168211.5000, 1154243.5000, 1148519.5000, 1144359.3750],
        [1236265.8750, 1187431.0000, 1176982.0000, 1163653.6250, 1145873.0000,
         1115096.8750, 1105303.3750, 1093836.6250, 1091894.8750, 1062563.5000],
        [1281855.2500, 1272339.5000, 1270319.5000, 1242920.3750, 1225188.3750,
         1202580.1250, 1201857.8750, 1198091.7500, 1197077.5000, 1197067.2500],
        [1526149.3750, 1525609.5000, 1524063.7500, 1524053.5000, 1520444.6250,
         1517443.0000, 1517100.1250, 1516355.2500, 1514927.1250, 1514551.5000],
        [1432764.7500, 1398334.1250, 1381045.6250, 1371200.1250, 1348657.5000,
         1347922.0000, 1346479.1250, 1343299.6250, 1342431.3750, 1342362.2500],
        [1540586.8750, 1535093.0000, 1528446.3750, 1526360.5000, 1526008.2500,
         1525798.7500, 1525535.3750, 1525144.0000, 1523351.6250, 1523005.8750],
        [1477491.6250, 1474168.5000, 1472394.0000, 1454711.3750, 1452921.5000,
         1443249.0000, 1440145.8750, 1430834.0000, 1427070.0000, 1410200.8750],
        [1469732.6250, 1457544.2500, 1453977.7500, 1446959.0000, 1443858.8750,
         1442389.0000, 1438486.2500, 1429291.6250, 1418477.1250, 1416360.2500],
        [1543706.3750, 1543057.2500, 1540084.6250, 1538389.0000, 1532454.2500,
         1532441.1250, 1532436.7500, 1532317.0000, 1531698.8750, 1530303.1250],
        [1537509.0000, 1533151.6250, 1532409.0000, 1532080.2500, 1531992.5000,
         1531292.8750, 1530345.3750, 1530167.2500, 1528894.0000, 1528748.1250],
        [1525867.0000, 1520666.3750, 1520432.8750, 1515499.5000, 1515126.5000,
         1515042.7500, 1514456.2500, 1514164.5000, 1513920.5000, 1513859.8750],
        [1488672.1250, 1475765.1250, 1470890.8750, 1470519.2500, 1470018.6250,
         1467358.7500, 1465803.5000, 1465714.0000, 1465154.8750, 1462022.8750],
        [1507670.2500, 1505463.5000, 1498587.6250, 1494880.7500, 1493529.8750,
         1492699.7500, 1491737.6250, 1488624.0000, 1488359.8750, 1486807.8750],
        [1476022.6250, 1475191.0000, 1471901.2500, 1465655.2500, 1464025.0000,
         1461986.6250, 1459338.5000, 1459032.2500, 1458648.3750, 1455771.6250],
        [1520534.3750, 1518711.3750, 1514710.3750, 1514180.3750, 1513064.6250,
         1512040.3750, 1511060.2500, 1510609.1250, 1506999.1250, 1506622.6250],
        [1536683.7500, 1530206.7500, 1528634.3750, 1528213.2500, 1527687.1250,
         1527403.1250, 1526386.7500, 1525066.8750, 1524844.5000, 1523934.3750],
        [1463540.6250, 1457391.3750, 1454596.2500, 1453022.6250, 1452378.5000,
         1450844.6250, 1449565.2500, 1446663.7500, 1445211.7500, 1443700.6250],
        [1539899.5000, 1522863.6250, 1518977.8750, 1518518.7500, 1517017.6250,
         1516499.7500, 1512797.6250, 1511583.3750, 1511499.7500, 1511086.2500],
        [1542042.1250, 1540929.2500, 1538940.8750, 1537664.5000, 1537542.7500,
         1536384.7500, 1535327.2500, 1534929.1250, 1534211.8750, 1533308.0000],
        [1521760.2500, 1509375.1250, 1497869.0000, 1496424.1250, 1493532.6250,
         1486263.5000, 1486015.5000, 1485030.8750, 1480342.0000, 1478627.6250],
        [1531625.7500, 1531027.0000, 1528939.1250, 1528256.8750, 1528038.3750,
         1527789.1250, 1527502.0000, 1526398.2500, 1525139.6250, 1525016.0000],
        [1532062.6250, 1530762.7500, 1527382.6250, 1526316.8750, 1524886.5000,
         1519528.3750, 1516984.5000, 1516041.5000, 1515745.1250, 1515732.1250],
        [1527223.8750, 1525164.3750, 1524043.3750, 1523876.2500, 1523874.7500,
         1523620.5000, 1523191.8750, 1522857.7500, 1521964.8750, 1518857.6250],
        [1543248.5000, 1541789.2500, 1537517.8750, 1536084.5000, 1535233.5000,
         1534760.7500, 1533308.0000, 1533194.0000, 1533151.6250, 1533069.6250],
        [1542121.6250, 1540274.1250, 1536321.8750, 1530660.6250, 1529691.7500,
         1529195.7500, 1528952.2500, 1528793.2500, 1528684.0000, 1528095.1250],
        [1534727.1250, 1533441.1250, 1532163.5000, 1532099.2500, 1531082.6250,
         1530634.3750, 1529592.5000, 1529108.2500, 1528719.0000, 1528563.0000],
        [1544243.7500, 1537957.7500, 1535265.7500, 1534484.1250, 1533878.3750,
         1533232.0000, 1532788.8750, 1532723.2500, 1532432.2500, 1532162.0000],
        [1351870.3750, 1322429.6250, 1316253.0000, 1306710.0000, 1300105.8750,
         1253739.5000, 1223646.0000, 1222776.8750, 1220898.5000, 1205319.8750],
        [1511802.6250, 1507463.2500, 1507378.3750, 1505960.2500, 1505017.0000,
         1502259.5000, 1502157.7500, 1497779.1250, 1497429.1250, 1496938.0000],
        [1529912.0000, 1525144.0000, 1524361.7500, 1522917.2500, 1520264.7500,
         1516285.7500, 1516229.3750, 1516041.5000, 1516041.5000, 1515259.5000],
        [1514781.1250, 1507045.0000, 1505085.8750, 1502834.0000, 1502613.3750,
         1502556.0000, 1499322.3750, 1497819.0000, 1497789.0000, 1494806.6250],
        [1417603.5000, 1360705.8750, 1342371.2500, 1304667.8750, 1293741.0000,
         1286777.7500, 1277056.2500, 1260490.3750, 1239339.8750, 1238890.7500],
        [1495409.8750, 1494829.3750, 1491121.8750, 1490069.8750, 1489089.7500,
         1488925.0000, 1488375.5000, 1487268.7500, 1485580.5000, 1484818.3750],
        [1429736.0000, 1428179.7500, 1425266.5000, 1403942.2500, 1399039.6250,
         1398799.6250, 1397834.1250, 1396391.0000, 1394659.6250, 1392607.5000],
        [1522200.1250, 1517720.8750, 1511951.0000, 1511038.6250, 1510769.1250,
         1510325.5000, 1508977.8750, 1508746.2500, 1507239.0000, 1507175.7500],
        [1347215.1250, 1332600.6250, 1326872.5000, 1304766.1250, 1303569.6250,
         1294005.1250, 1273138.1250, 1262520.0000, 1261273.2500, 1211613.5000],
        [1525371.0000, 1524600.2500, 1523957.6250, 1523494.0000, 1522573.1250,
         1521116.0000, 1521072.5000, 1518998.1250, 1517946.7500, 1517540.1250],
        [1517974.2500, 1514261.3750, 1512288.5000, 1512266.8750, 1511587.7500,
         1510903.1250, 1510482.5000, 1509961.1250, 1509583.8750, 1509406.7500],
        [1507759.5000, 1506728.8750, 1505755.0000, 1503603.8750, 1502273.7500,
         1501951.3750, 1501563.3750, 1500976.3750, 1500620.0000, 1500469.6250],
        [1436101.2500, 1429317.5000, 1405248.2500, 1402653.3750, 1394903.0000,
         1385097.6250, 1382561.1250, 1380657.1250, 1379276.5000, 1374044.7500],
        [1297663.1250, 1270163.2500, 1248708.6250, 1243466.8750, 1230697.1250,
         1229961.3750, 1226031.2500, 1217855.2500, 1216956.6250, 1205267.0000],
        [1217702.0000, 1102705.8750, 1045519.4375, 1028986.3125,  992113.1250,
          982633.7500,  958716.5000,  951392.6875,  938356.6875,  933417.4375],
        [1267624.5000, 1244082.5000, 1215481.2500, 1193158.0000, 1169503.3750,
         1136250.1250, 1135797.2500, 1121716.1250, 1073200.7500, 1049347.3750],
        [1409150.8750, 1378946.3750, 1372689.2500, 1369946.7500, 1365178.5000,
         1364209.0000, 1360760.3750, 1353255.7500, 1352924.1250, 1351399.8750],
        [1439703.6250, 1438339.5000, 1426618.2500, 1425852.5000, 1425534.3750,
         1421381.6250, 1419951.0000, 1415806.5000, 1411071.2500, 1409582.2500],
        [1429584.6250, 1429189.2500, 1410822.2500, 1408027.8750, 1406856.0000,
         1403723.8750, 1402951.7500, 1399417.2500, 1392588.8750, 1389605.2500],
        [1411711.8750, 1408356.7500, 1388866.0000, 1383778.6250, 1376870.2500,
         1375304.6250, 1373125.1250, 1359329.7500, 1345820.6250, 1325427.0000],
        [1443404.5000, 1430947.2500, 1413368.8750, 1394856.5000, 1380859.8750,
         1374683.0000, 1370059.1250, 1365976.8750, 1360692.8750, 1351938.7500],
        [1325848.0000, 1310036.5000, 1289034.0000, 1287945.2500, 1286639.1250,
         1286328.6250, 1266634.7500, 1258898.6250, 1248639.6250, 1241977.1250],
        [1461586.5000, 1453708.7500, 1431635.2500, 1431571.0000, 1426953.0000,
         1425392.8750, 1422326.8750, 1420981.8750, 1419699.2500, 1418047.0000],
        [1476135.2500, 1475872.0000, 1469788.7500, 1468956.3750, 1465523.8750,
         1462844.2500, 1462298.8750, 1460481.5000, 1456845.2500, 1456174.3750],
        [1356562.3750, 1355130.8750, 1318581.1250, 1309405.7500, 1306197.8750,
         1296572.0000, 1295368.2500, 1291974.2500, 1290578.8750, 1283548.2500],
        [1394969.5000, 1371291.7500, 1366748.2500, 1356471.7500, 1340090.6250,
         1334209.3750, 1333326.6250, 1311035.1250, 1308299.7500, 1286605.8750],
        [1444069.6250, 1417318.2500, 1407214.3750, 1406386.5000, 1406193.3750,
         1389361.3750, 1386219.5000, 1374531.0000, 1361218.5000, 1358199.8750],
        [1481453.5000, 1480997.2500, 1440985.2500, 1437993.8750, 1416055.0000,
         1405175.8750, 1403902.0000, 1398392.7500, 1396621.5000, 1394779.2500],
        [1369919.3750, 1358530.2500, 1319934.7500, 1311869.3750, 1302734.5000,
         1302224.0000, 1296722.8750, 1293736.1250, 1293496.7500, 1285759.6250],
        [1453060.0000, 1440316.1250, 1408809.5000, 1395033.3750, 1389365.3750,
         1387173.0000, 1386283.0000, 1383009.3750, 1373845.6250, 1372477.1250],
        [1434781.6250, 1422415.0000, 1420395.2500, 1415886.2500, 1412458.0000,
         1386912.3750, 1365580.8750, 1364637.0000, 1352503.5000, 1349919.8750],
        [1417345.2500, 1405737.5000, 1400297.0000, 1399014.3750, 1394371.0000,
         1392729.6250, 1386694.1250, 1378140.5000, 1373274.5000, 1371198.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1513779.0000,       0.0000],
         [1510080.6250,       0.0000],
         [1508926.0000,       0.0000],
         ...,
         [1503509.2500,       0.0000],
         [1502673.5000,       0.0000],
         [1502569.0000,       0.0000]],

        [[1523508.6250,       0.0000],
         [1520047.2500,       0.0000],
         [1517975.7500,       0.0000],
         ...,
         [1514278.6250,       0.0000],
         [1512135.6250,       0.0000],
         [1511643.8750,       0.0000]],

        [[1318022.8750,       0.0000],
         [1312312.2500,       0.0000],
         [1283154.1250,       0.0000],
         ...,
         [1213687.0000,       0.0000],
         [      0.0000, 1205699.1250],
         [1199929.2500,       0.0000]],

        ...,

        [[1453060.0000,       0.0000],
         [1440316.1250,       0.0000],
         [1408809.5000,       0.0000],
         ...,
         [1383009.3750,       0.0000],
         [1373845.6250,       0.0000],
         [1372477.1250,       0.0000]],

        [[1434781.6250,       0.0000],
         [1422415.0000,       0.0000],
         [1420395.2500,       0.0000],
         ...,
         [1364637.0000,       0.0000],
         [1352503.5000,       0.0000],
         [      0.0000, 1349919.8750]],

        [[      0.0000, 1417345.2500],
         [      0.0000, 1405737.5000],
         [1400297.0000,       0.0000],
         ...,
         [      0.0000, 1378140.5000],
         [      0.0000, 1373274.5000],
         [      0.0000, 1371198.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15063656.0000,        0.0000],
        [15165521.0000,        0.0000],
        [10046543.0000,  2446660.5000],
        [14495279.0000,        0.0000],
        [10333572.0000,  2576486.7500],
        [ 9811345.0000,  2292879.0000],
        [ 4446617.5000,  6932283.5000],
        [ 9793790.0000,  2495508.0000],
        [13680253.0000,  1520444.6250],
        [ 8217152.0000,  5437345.0000],
        [13756324.0000,  1523005.8750],
        [13030266.0000,  1452921.5000],
        [12978590.0000,  1438486.2500],
        [15356888.0000,        0.0000],
        [15316590.0000,        0.0000],
        [15169036.0000,        0.0000],
        [13231029.0000,  1470890.8750],
        [ 7485930.5000,  7462430.0000],
        [13181917.0000,  1465655.2500],
        [13617472.0000,  1511060.2500],
        [15279061.0000,        0.0000],
        [11614972.0000,  2901943.7500],
        [15180744.0000,        0.0000],
        [15371280.0000,        0.0000],
        [13441707.0000,  1493532.6250],
        [15279732.0000,        0.0000],
        [15225442.0000,        0.0000],
        [15234675.0000,        0.0000],
        [15361358.0000,        0.0000],
        [15322790.0000,        0.0000],
        [15310132.0000,        0.0000],
        [15349168.0000,        0.0000],
        [ 6335445.0000,  6388305.0000],
        [10522406.0000,  4511779.5000],
        [12165963.0000,  3036494.0000],
        [ 9005685.0000,  6018967.5000],
        [ 7810470.0000,  5211175.0000],
        [11908956.0000,  2986531.7500],
        [11237247.0000,  2829208.7500],
        [15116144.0000,        0.0000],
        [ 9138674.0000,  3778899.5000],
        [15216670.0000,        0.0000],
        [15118716.0000,        0.0000],
        [13525946.0000,  1505755.0000],
        [ 8390938.0000,  5578922.0000],
        [ 3671830.7500,  8714940.0000],
        [ 5137989.0000,  5013554.5000],
        [ 3258345.2500,  8347816.0000],
        [10916386.0000,  2762075.0000],
        [11396916.0000,  2836923.7500],
        [12664739.0000,  1408027.8750],
        [ 1359329.7500, 12389261.0000],
        [       0.0000, 13886788.0000],
        [ 6369738.0000,  6432243.0000],
        [11424923.0000,  2886979.5000],
        [14654920.0000,        0.0000],
        [ 2604774.0000, 10499145.0000],
        [       0.0000, 13403049.0000],
        [       0.0000, 13950712.0000],
        [ 7009751.0000,  7246606.0000],
        [ 7886430.0000,  5248497.5000],
        [12603089.0000,  1386283.0000],
        [11209989.0000,  2715500.7500],
        [ 2799311.5000, 11119492.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 65.625
Top1 accuracy for validation set is 65.625 size is torch.Size([64, 1])
Epoch 101/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:29, 61.04s/it]  7%|▋         | 2/29 [01:01<11:33, 25.68s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 4.366855621337891
Epoch 102/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.54s/it]  7%|▋         | 2/29 [01:00<11:26, 25.44s/it] 10%|█         | 3/29 [01:01<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.08s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.3644700050354
Epoch 103/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.64s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.356384754180908
Epoch 104/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:16, 60.57s/it]  7%|▋         | 2/29 [01:01<11:28, 25.48s/it] 10%|█         | 3/29 [01:02<06:10, 14.27s/it] 14%|█▍        | 4/29 [01:03<03:44,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.3508076667785645
Epoch 105/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.66s/it]  7%|▋         | 2/29 [01:02<11:37, 25.83s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 4.34878396987915
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0111, 0.0038, 0.0012,  ..., 0.0029, 0.0022, 0.0218],
        [0.0112, 0.0041, 0.0011,  ..., 0.0037, 0.0013, 0.0211],
        [0.0379, 0.0078, 0.0035,  ..., 0.0094, 0.0119, 0.0247],
        ...,
        [0.0100, 0.0102, 0.0020,  ..., 0.0028, 0.0031, 0.0201],
        [0.0100, 0.0091, 0.0011,  ..., 0.0042, 0.0020, 0.0175],
        [0.0230, 0.0082, 0.0023,  ..., 0.0038, 0.0068, 0.0213]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9867, 0.9860, 0.9849, 0.9836, 0.9814, 0.9805, 0.9800, 0.9796, 0.9794,
         0.9781],
        [0.9940, 0.9937, 0.9935, 0.9934, 0.9933, 0.9929, 0.9928, 0.9927, 0.9923,
         0.9923],
        [0.9874, 0.9869, 0.9868, 0.9855, 0.9853, 0.9852, 0.9844, 0.9843, 0.9841,
         0.9839],
        [0.9885, 0.9851, 0.9826, 0.9820, 0.9797, 0.9796, 0.9787, 0.9780, 0.9771,
         0.9755],
        [0.9803, 0.9799, 0.9776, 0.9764, 0.9759, 0.9757, 0.9739, 0.9731, 0.9725,
         0.9718],
        [0.9843, 0.9841, 0.9823, 0.9813, 0.9804, 0.9796, 0.9795, 0.9794, 0.9791,
         0.9776],
        [0.9970, 0.9968, 0.9968, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9927, 0.9901, 0.9885, 0.9880, 0.9880, 0.9874, 0.9874, 0.9871, 0.9871,
         0.9870],
        [0.9975, 0.9972, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9942, 0.9939, 0.9928, 0.9925, 0.9924, 0.9920, 0.9920, 0.9919, 0.9919,
         0.9911],
        [0.9935, 0.9932, 0.9931, 0.9930, 0.9926, 0.9924, 0.9909, 0.9906, 0.9905,
         0.9901],
        [0.9977, 0.9975, 0.9975, 0.9975, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9974, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9968, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9951, 0.9947, 0.9945, 0.9943, 0.9942, 0.9941, 0.9941, 0.9940, 0.9939,
         0.9939],
        [0.9962, 0.9958, 0.9956, 0.9954, 0.9953, 0.9952, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9944, 0.9943, 0.9940, 0.9940, 0.9937, 0.9937, 0.9937, 0.9937, 0.9936,
         0.9935],
        [0.9967, 0.9965, 0.9965, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9937, 0.9934, 0.9934, 0.9933, 0.9932, 0.9931, 0.9928, 0.9928, 0.9927,
         0.9927],
        [0.9976, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9972, 0.9972,
         0.9972],
        [0.9963, 0.9957, 0.9954, 0.9951, 0.9950, 0.9948, 0.9947, 0.9946, 0.9946,
         0.9944],
        [0.9972, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9972, 0.9970, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965, 0.9965,
         0.9963],
        [0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9977, 0.9976, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9976, 0.9975, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9974, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9885, 0.9868, 0.9860, 0.9851, 0.9843, 0.9820, 0.9815, 0.9801, 0.9797,
         0.9794],
        [0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9962, 0.9959, 0.9958, 0.9957, 0.9955, 0.9955, 0.9954, 0.9954, 0.9953,
         0.9952],
        [0.9915, 0.9891, 0.9879, 0.9861, 0.9851, 0.9846, 0.9835, 0.9824, 0.9821,
         0.9816],
        [0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9921, 0.9918, 0.9914, 0.9908, 0.9901, 0.9900, 0.9900, 0.9900, 0.9899,
         0.9898],
        [0.9966, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959,
         0.9959],
        [0.9877, 0.9874, 0.9869, 0.9861, 0.9857, 0.9855, 0.9840, 0.9832, 0.9831,
         0.9808],
        [0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9967, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9924, 0.9921, 0.9912, 0.9908, 0.9908, 0.9903, 0.9901, 0.9901, 0.9899,
         0.9899],
        [0.9849, 0.9838, 0.9828, 0.9827, 0.9818, 0.9816, 0.9814, 0.9808, 0.9807,
         0.9801],
        [0.9795, 0.9754, 0.9702, 0.9689, 0.9658, 0.9655, 0.9648, 0.9646, 0.9630,
         0.9615],
        [0.9840, 0.9818, 0.9808, 0.9797, 0.9787, 0.9780, 0.9765, 0.9742, 0.9708,
         0.9704],
        [0.9910, 0.9896, 0.9895, 0.9895, 0.9894, 0.9892, 0.9891, 0.9888, 0.9888,
         0.9887],
        [0.9930, 0.9929, 0.9926, 0.9922, 0.9922, 0.9921, 0.9921, 0.9921, 0.9920,
         0.9918],
        [0.9925, 0.9922, 0.9918, 0.9917, 0.9916, 0.9916, 0.9916, 0.9915, 0.9913,
         0.9911],
        [0.9912, 0.9912, 0.9910, 0.9902, 0.9898, 0.9898, 0.9892, 0.9889, 0.9886,
         0.9878],
        [0.9929, 0.9923, 0.9918, 0.9914, 0.9900, 0.9898, 0.9898, 0.9891, 0.9890,
         0.9889],
        [0.9870, 0.9854, 0.9849, 0.9847, 0.9846, 0.9845, 0.9838, 0.9828, 0.9826,
         0.9820],
        [0.9935, 0.9932, 0.9927, 0.9923, 0.9923, 0.9923, 0.9922, 0.9920, 0.9918,
         0.9918],
        [0.9946, 0.9944, 0.9944, 0.9943, 0.9942, 0.9940, 0.9940, 0.9939, 0.9938,
         0.9938],
        [0.9885, 0.9883, 0.9865, 0.9865, 0.9863, 0.9858, 0.9855, 0.9853, 0.9853,
         0.9852],
        [0.9914, 0.9899, 0.9893, 0.9886, 0.9885, 0.9884, 0.9870, 0.9866, 0.9865,
         0.9854],
        [0.9924, 0.9922, 0.9915, 0.9914, 0.9910, 0.9902, 0.9895, 0.9895, 0.9890,
         0.9888],
        [0.9948, 0.9945, 0.9928, 0.9925, 0.9916, 0.9909, 0.9909, 0.9908, 0.9907,
         0.9906],
        [0.9891, 0.9885, 0.9871, 0.9865, 0.9863, 0.9859, 0.9850, 0.9848, 0.9847,
         0.9847],
        [0.9930, 0.9929, 0.9912, 0.9903, 0.9902, 0.9898, 0.9894, 0.9894, 0.9892,
         0.9892],
        [0.9925, 0.9918, 0.9917, 0.9917, 0.9916, 0.9908, 0.9891, 0.9890, 0.9886,
         0.9882],
        [0.9917, 0.9914, 0.9912, 0.9908, 0.9908, 0.9905, 0.9905, 0.9898, 0.9891,
         0.9891]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 0, 1, 1, 0, 1, 0, 1, 1, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1],
        [0, 1, 0, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 0, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515099.1250, 1510134.0000, 1509319.0000, 1506927.1250, 1505490.7500,
         1505074.3750, 1504101.6250, 1503750.1250, 1503426.1250, 1502428.5000],
        [1520911.5000, 1520820.1250, 1520518.5000, 1520076.2500, 1520047.2500,
         1518749.0000, 1518216.1250, 1517848.3750, 1517042.2500, 1515487.7500],
        [1323440.1250, 1310652.6250, 1289591.0000, 1266903.0000, 1226442.7500,
         1210966.6250, 1202439.1250, 1195119.0000, 1191783.0000, 1170161.6250],
        [1469425.7500, 1463486.1250, 1457548.5000, 1457280.1250, 1454959.7500,
         1445465.2500, 1443419.6250, 1441977.7500, 1434345.2500, 1433400.3750],
        [1336667.3750, 1326718.1250, 1326124.8750, 1301634.2500, 1297168.1250,
         1295942.7500, 1280143.6250, 1279583.3750, 1274469.5000, 1270655.1250],
        [1357830.7500, 1293721.2500, 1248192.0000, 1236824.8750, 1198265.3750,
         1196152.0000, 1181165.0000, 1168812.1250, 1154283.2500, 1127039.0000],
        [1208269.5000, 1200491.2500, 1162771.7500, 1141780.1250, 1133910.8750,
         1131371.2500, 1102284.2500, 1090012.7500, 1080274.7500, 1069152.2500],
        [1278973.3750, 1274497.5000, 1242255.5000, 1225075.1250, 1209578.0000,
         1196206.7500, 1194763.3750, 1192200.2500, 1187230.6250, 1161510.5000],
        [1533860.7500, 1529551.6250, 1528681.1250, 1523664.1250, 1523216.6250,
         1520270.6250, 1520195.1250, 1519057.5000, 1518837.3750, 1518356.5000],
        [1442589.8750, 1389601.2500, 1358458.8750, 1349111.6250, 1347562.0000,
         1337525.5000, 1336761.6250, 1330486.5000, 1330171.7500, 1329911.7500],
        [1544753.3750, 1536508.0000, 1535570.3750, 1531795.2500, 1530533.6250,
         1530454.8750, 1529669.8750, 1529550.1250, 1529245.3750, 1529073.2500],
        [1472177.7500, 1466331.8750, 1443852.0000, 1438583.6250, 1435045.7500,
         1428057.1250, 1427786.1250, 1426422.3750, 1424850.6250, 1409574.2500],
        [1458901.6250, 1451665.3750, 1450967.7500, 1447719.5000, 1438871.7500,
         1434653.0000, 1405460.0000, 1399669.6250, 1397480.7500, 1389438.3750],
        [1547810.2500, 1544510.2500, 1543818.2500, 1543431.1250, 1538650.2500,
         1537910.8750, 1537701.1250, 1537613.1250, 1536657.3750, 1536613.5000],
        [1542212.7500, 1534819.2500, 1533702.8750, 1532553.6250, 1530917.6250,
         1530757.0000, 1530381.8750, 1530307.3750, 1530256.2500, 1529859.5000],
        [1529372.2500, 1521763.1250, 1520591.0000, 1520402.5000, 1519396.5000,
         1517395.3750, 1516398.5000, 1516303.2500, 1515451.7500, 1515360.6250],
        [1491514.2500, 1484322.8750, 1478548.7500, 1474462.3750, 1472813.8750,
         1471445.0000, 1470472.8750, 1469223.8750, 1467197.8750, 1466673.2500],
        [1515229.0000, 1508139.1250, 1502056.0000, 1498529.1250, 1495994.6250,
         1493760.6250, 1490608.5000, 1489037.0000, 1488866.6250, 1488805.6250],
        [1478239.8750, 1475890.3750, 1468813.5000, 1468256.0000, 1463543.5000,
         1463341.0000, 1463279.6250, 1463269.8750, 1460689.1250, 1458399.3750],
        [1527483.1250, 1522788.1250, 1521995.5000, 1518925.6250, 1518882.2500,
         1517289.7500, 1516716.8750, 1516583.7500, 1514625.2500, 1513777.5000],
        [1537054.6250, 1532870.8750, 1531450.5000, 1529737.0000, 1528984.2500,
         1527905.6250, 1527813.8750, 1527567.7500, 1526979.2500, 1526776.8750],
        [1463451.3750, 1457157.8750, 1455953.6250, 1453649.0000, 1453094.7500,
         1450692.3750, 1444426.2500, 1443551.8750, 1442391.7500, 1441253.2500],
        [1546423.3750, 1529092.2500, 1528455.1250, 1528095.1250, 1526654.5000,
         1525493.1250, 1522869.5000, 1521885.0000, 1521689.1250, 1519622.6250],
        [1544254.0000, 1544204.0000, 1543432.5000, 1542902.7500, 1541317.2500,
         1541099.7500, 1540889.6250, 1538236.5000, 1537737.8750, 1537701.1250],
        [1518960.5000, 1503983.8750, 1498542.0000, 1491918.3750, 1489670.6250,
         1486313.1250, 1483642.1250, 1482049.7500, 1480476.1250, 1476400.0000],
        [1537409.3750, 1535385.8750, 1534255.8750, 1532691.0000, 1531411.1250,
         1531084.0000, 1529273.0000, 1529025.1250, 1528758.2500, 1527907.1250],
        [1538628.2500, 1532493.7500, 1532131.3750, 1530160.1250, 1529316.8750,
         1527180.2500, 1523415.6250, 1522500.6250, 1521280.0000, 1518954.6250],
        [1529596.8750, 1528029.5000, 1527920.2500, 1526085.2500, 1525659.0000,
         1525589.1250, 1523019.0000, 1521564.3750, 1520891.1250, 1519571.8750],
        [1547904.7500, 1546967.6250, 1541430.5000, 1541042.5000, 1540706.0000,
         1540438.5000, 1540144.7500, 1539360.6250, 1539188.8750, 1538954.0000],
        [1545394.2500, 1543734.2500, 1538195.5000, 1535967.3750, 1535188.2500,
         1533648.7500, 1533119.3750, 1533014.1250, 1532625.2500, 1532577.0000],
        [1538437.5000, 1537985.6250, 1537308.1250, 1536049.3750, 1535519.1250,
         1535268.6250, 1534185.6250, 1533568.2500, 1533433.7500, 1533344.5000],
        [1541374.6250, 1537580.8750, 1537044.3750, 1536299.8750, 1534630.5000,
         1534576.2500, 1534542.7500, 1534337.7500, 1533708.7500, 1533128.1250],
        [1357561.5000, 1326088.2500, 1309654.2500, 1294279.1250, 1278497.7500,
         1237509.1250, 1228476.1250, 1203904.3750, 1197621.1250, 1192913.2500],
        [1511752.1250, 1511678.5000, 1509857.5000, 1509835.7500, 1506542.0000,
         1502048.8750, 1501520.3750, 1501410.1250, 1500106.2500, 1498183.3750],
        [1531367.3750, 1527840.1250, 1527154.0000, 1525583.3750, 1525503.3750,
         1524853.1250, 1522068.0000, 1522068.0000, 1520456.1250, 1519998.0000],
        [1514704.6250, 1509683.1250, 1508175.1250, 1504290.8750, 1500413.8750,
         1500389.5000, 1499178.1250, 1498832.1250, 1496812.3750, 1495126.0000],
        [1416723.6250, 1370445.8750, 1345539.6250, 1311400.2500, 1294234.6250,
         1284662.6250, 1264549.1250, 1243822.7500, 1239719.2500, 1230323.8750],
        [1495773.5000, 1494086.8750, 1491732.0000, 1490192.1250, 1489666.2500,
         1487921.3750, 1487714.2500, 1487266.0000, 1486254.8750, 1484824.1250],
        [1428809.1250, 1424024.7500, 1415551.3750, 1403048.1250, 1390026.7500,
         1387249.6250, 1386930.8750, 1386794.6250, 1386125.6250, 1383497.5000],
        [1524921.5000, 1518734.5000, 1518111.8750, 1515716.2500, 1514040.3750,
         1512523.5000, 1511775.1250, 1510690.0000, 1510228.8750, 1509333.3750],
        [1342714.3750, 1337067.6250, 1328119.6250, 1312964.6250, 1304532.2500,
         1300592.0000, 1273781.8750, 1259197.5000, 1257627.8750, 1217285.1250],
        [1530615.5000, 1526533.6250, 1525682.2500, 1524741.1250, 1523735.2500,
         1522914.3750, 1522830.2500, 1519221.2500, 1519198.0000, 1518879.3750],
        [1527392.8750, 1520177.7500, 1517061.1250, 1515843.5000, 1515716.2500,
         1515415.5000, 1515399.6250, 1515029.7500, 1514155.8750, 1514053.3750],
        [1509316.1250, 1507354.0000, 1507325.2500, 1507046.3750, 1505519.5000,
         1504846.2500, 1504665.3750, 1503106.3750, 1502718.0000, 1502677.8750],
        [1435185.2500, 1430442.5000, 1411328.2500, 1403588.7500, 1403036.0000,
         1393121.5000, 1389964.5000, 1389931.2500, 1385824.2500, 1385726.5000],
        [1289150.7500, 1269631.6250, 1251726.3750, 1249547.3750, 1233993.7500,
         1230705.2500, 1226231.1250, 1216393.8750, 1215110.3750, 1204330.5000],
        [1194159.6250, 1125913.1250, 1044920.4375, 1026881.6250,  982424.7500,
          977636.6875,  967821.1875,  964541.7500,  942969.4375,  923245.1250],
        [1272761.8750, 1233779.5000, 1216131.7500, 1197356.1250, 1181097.3750,
         1168404.2500, 1144295.0000, 1106454.0000, 1054916.1250, 1048782.1250],
        [1408231.8750, 1380025.2500, 1377776.5000, 1377260.2500, 1376036.6250,
         1370985.7500, 1370095.7500, 1364026.8750, 1363744.5000, 1361983.3750],
        [1448893.6250, 1446436.1250, 1438845.7500, 1432391.8750, 1431479.5000,
         1430254.2500, 1429479.6250, 1428531.1250, 1427291.8750, 1423026.8750],
        [1437806.0000, 1431788.2500, 1424334.5000, 1420682.5000, 1420324.8750,
         1419423.0000, 1418690.8750, 1417150.6250, 1414295.1250, 1408540.8750],
        [1411856.0000, 1410316.5000, 1406276.5000, 1391578.6250, 1383364.2500,
         1383034.5000, 1371185.7500, 1365425.8750, 1360472.3750, 1343830.1250],
        [1445054.6250, 1433917.1250, 1424080.3750, 1414942.7500, 1387162.3750,
         1383951.5000, 1383308.8750, 1369340.6250, 1367604.8750, 1365353.0000],
        [1329176.3750, 1299544.2500, 1290027.6250, 1285892.0000, 1283933.8750,
         1281770.8750, 1270416.3750, 1251018.7500, 1247512.5000, 1237881.0000],
        [1457599.8750, 1452823.1250, 1441003.1250, 1433195.2500, 1433053.1250,
         1432700.5000, 1431920.6250, 1427109.5000, 1424080.3750, 1423683.8750],
        [1481706.5000, 1477450.7500, 1477206.8750, 1475686.3750, 1472747.8750,
         1469048.8750, 1467941.0000, 1466681.6250, 1465185.6250, 1464794.5000],
        [1358745.2500, 1353468.6250, 1320482.5000, 1320118.6250, 1316157.6250,
         1306822.1250, 1300964.1250, 1297718.7500, 1296596.7500, 1295329.8750],
        [1415743.1250, 1386197.0000, 1372872.3750, 1359547.6250, 1358006.8750,
         1356026.7500, 1328375.5000, 1320850.2500, 1319447.7500, 1299465.0000],
        [1434906.1250, 1432189.6250, 1416394.0000, 1416312.8750, 1406500.5000,
         1391043.8750, 1378011.7500, 1376882.1250, 1366859.1250, 1364075.0000],
        [1485169.6250, 1480141.5000, 1444200.3750, 1438574.1250, 1419635.5000,
         1404461.7500, 1404325.2500, 1402529.0000, 1400509.3750, 1398340.6250],
        [1369901.0000, 1357149.7500, 1331387.5000, 1320364.1250, 1315274.2500,
         1307864.3750, 1292107.2500, 1288877.8750, 1286906.6250, 1286583.8750],
        [1447747.1250, 1445739.6250, 1411333.7500, 1393445.7500, 1390693.6250,
         1382723.2500, 1376401.5000, 1375805.6250, 1372225.8750, 1371247.2500],
        [1438020.0000, 1423107.0000, 1420987.3750, 1420441.2500, 1418352.6250,
         1404074.7500, 1368981.6250, 1367848.8750, 1359139.1250, 1352686.7500],
        [1421305.8750, 1414659.3750, 1411997.2500, 1403414.7500, 1403175.1250,
         1397547.5000, 1397352.8750, 1384127.1250, 1369936.2500, 1369621.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515099.1250,       0.0000],
         [1510134.0000,       0.0000],
         [1509319.0000,       0.0000],
         ...,
         [1503750.1250,       0.0000],
         [1503426.1250,       0.0000],
         [1502428.5000,       0.0000]],

        [[1520911.5000,       0.0000],
         [1520820.1250,       0.0000],
         [1520518.5000,       0.0000],
         ...,
         [1517848.3750,       0.0000],
         [1517042.2500,       0.0000],
         [1515487.7500,       0.0000]],

        [[1323440.1250,       0.0000],
         [1310652.6250,       0.0000],
         [1289591.0000,       0.0000],
         ...,
         [1195119.0000,       0.0000],
         [1191783.0000,       0.0000],
         [      0.0000, 1170161.6250]],

        ...,

        [[1447747.1250,       0.0000],
         [1445739.6250,       0.0000],
         [1411333.7500,       0.0000],
         ...,
         [1375805.6250,       0.0000],
         [1372225.8750,       0.0000],
         [1371247.2500,       0.0000]],

        [[1438020.0000,       0.0000],
         [1423107.0000,       0.0000],
         [1420987.3750,       0.0000],
         ...,
         [      0.0000, 1367848.8750],
         [      0.0000, 1359139.1250],
         [1352686.7500,       0.0000]],

        [[      0.0000, 1421305.8750],
         [      0.0000, 1414659.3750],
         [      0.0000, 1411997.2500],
         ...,
         [      0.0000, 1384127.1250],
         [      0.0000, 1369936.2500],
         [1369621.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15065751.0000,        0.0000],
        [15189716.0000,        0.0000],
        [ 9990894.0000,  2396604.5000],
        [14501309.0000,        0.0000],
        [ 7794157.0000,  5194950.0000],
        [ 9836981.0000,  2325304.5000],
        [ 4505839.0000,  6814480.0000],
        [ 8563762.0000,  3598529.5000],
        [13712474.0000,  1523216.6250],
        [ 9488292.0000,  4063888.5000],
        [13797603.0000,  1529550.1250],
        [12928829.0000,  1443852.0000],
        [12869368.0000,  1405460.0000],
        [15404716.0000,        0.0000],
        [15325769.0000,        0.0000],
        [15192436.0000,        0.0000],
        [13273860.0000,  1472813.8750],
        [ 7504524.0000,  7466502.0000],
        [13200444.0000,  1463279.6250],
        [13670186.0000,  1518882.2500],
        [15297141.0000,        0.0000],
        [10157625.0000,  4347997.0000],
        [15270280.0000,        0.0000],
        [15411775.0000,        0.0000],
        [11938644.0000,  2973312.7500],
        [15317201.0000,        0.0000],
        [15276062.0000,        0.0000],
        [15247926.0000,        0.0000],
        [15416138.0000,        0.0000],
        [15363464.0000,        0.0000],
        [15355100.0000,        0.0000],
        [15357224.0000,        0.0000],
        [ 6308943.5000,  6317561.0000],
        [12031347.0000,  3021588.0000],
        [12200932.0000,  3045959.5000],
        [ 8999749.0000,  6027857.0000],
        [ 7820420.0000,  5181001.5000],
        [11909612.0000,  2985819.0000],
        [11190382.0000,  2801677.0000],
        [15146075.0000,        0.0000],
        [ 9152868.0000,  3781015.0000],
        [15234350.0000,        0.0000],
        [15170246.0000,        0.0000],
        [13547528.0000,  1507046.3750],
        [ 7033155.0000,  6994993.5000],
        [ 3681051.5000,  8705770.0000],
        [ 5104504.0000,  5046010.5000],
        [ 3210152.2500,  8413826.0000],
        [12341935.0000,  1408231.8750],
        [12890195.0000,  1446436.1250],
        [12795886.0000,  1417150.6250],
        [ 1365425.8750, 12461915.0000],
        [       0.0000, 13974716.0000],
        [ 5119245.0000,  7657929.0000],
        [11475886.0000,  2881283.7500],
        [13253264.0000,  1465185.6250],
        [ 2621082.7500, 10545321.0000],
        [       0.0000, 13516532.0000],
        [       0.0000, 13983175.0000],
        [ 7029292.0000,  7248595.0000],
        [ 7884021.0000,  5272395.5000],
        [12573917.0000,  1393445.7500],
        [11246651.0000,  2726988.0000],
        [ 4176211.2500,  9796926.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 65.625
Top1 accuracy for validation set is 65.625 size is torch.Size([64, 1])
Epoch 106/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:26, 58.79s/it]  7%|▋         | 2/29 [00:59<11:08, 24.75s/it] 10%|█         | 3/29 [01:00<06:00, 13.87s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.76s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 4.328295707702637
Epoch 107/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.61s/it]  7%|▋         | 2/29 [01:00<11:19, 25.15s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.3352580070495605
Epoch 108/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:07, 58.11s/it]  7%|▋         | 2/29 [00:59<11:00, 24.47s/it] 10%|█         | 3/29 [01:00<06:02, 13.93s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.79s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.95s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 4.327401638031006
Epoch 109/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:24, 60.86s/it]  7%|▋         | 2/29 [01:01<11:31, 25.60s/it] 10%|█         | 3/29 [01:02<06:12, 14.33s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.04s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.3151679039001465
Epoch 110/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:33, 56.90s/it]  7%|▋         | 2/29 [01:00<11:30, 25.57s/it] 10%|█         | 3/29 [01:01<06:12, 14.31s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.10s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.298616409301758
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0097, 0.0038, 0.0013,  ..., 0.0032, 0.0021, 0.0208],
        [0.0101, 0.0044, 0.0014,  ..., 0.0037, 0.0015, 0.0207],
        [0.0366, 0.0076, 0.0033,  ..., 0.0091, 0.0112, 0.0249],
        ...,
        [0.0091, 0.0102, 0.0025,  ..., 0.0028, 0.0032, 0.0192],
        [0.0093, 0.0088, 0.0015,  ..., 0.0045, 0.0023, 0.0159],
        [0.0219, 0.0082, 0.0021,  ..., 0.0035, 0.0065, 0.0202]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9866, 0.9864, 0.9849, 0.9832, 0.9825, 0.9809, 0.9804, 0.9803, 0.9791,
         0.9790],
        [0.9941, 0.9938, 0.9937, 0.9936, 0.9934, 0.9931, 0.9930, 0.9929, 0.9926,
         0.9926],
        [0.9878, 0.9865, 0.9861, 0.9856, 0.9854, 0.9850, 0.9837, 0.9836, 0.9836,
         0.9836],
        [0.9885, 0.9854, 0.9829, 0.9802, 0.9787, 0.9781, 0.9778, 0.9770, 0.9767,
         0.9746],
        [0.9799, 0.9784, 0.9771, 0.9760, 0.9746, 0.9736, 0.9731, 0.9725, 0.9722,
         0.9718],
        [0.9850, 0.9841, 0.9827, 0.9819, 0.9812, 0.9801, 0.9799, 0.9797, 0.9787,
         0.9786],
        [0.9972, 0.9969, 0.9969, 0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9930, 0.9902, 0.9893, 0.9892, 0.9888, 0.9882, 0.9882, 0.9880, 0.9876,
         0.9872],
        [0.9976, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969,
         0.9969],
        [0.9945, 0.9944, 0.9938, 0.9929, 0.9928, 0.9927, 0.9927, 0.9926, 0.9920,
         0.9914],
        [0.9941, 0.9938, 0.9933, 0.9932, 0.9930, 0.9922, 0.9912, 0.9912, 0.9904,
         0.9904],
        [0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9973, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9969, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9950, 0.9949, 0.9947, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9961, 0.9959, 0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9953, 0.9951,
         0.9950],
        [0.9946, 0.9944, 0.9944, 0.9940, 0.9938, 0.9938, 0.9938, 0.9937, 0.9936,
         0.9936],
        [0.9968, 0.9966, 0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9972, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9938, 0.9938, 0.9936, 0.9935, 0.9934, 0.9933, 0.9932, 0.9932, 0.9929,
         0.9929],
        [0.9977, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966,
         0.9965],
        [0.9976, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9964, 0.9958, 0.9953, 0.9952, 0.9950, 0.9949, 0.9948, 0.9947, 0.9946,
         0.9945],
        [0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967,
         0.9967],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9968, 0.9967, 0.9967, 0.9967, 0.9965,
         0.9965],
        [0.9967, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9977, 0.9976, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9977, 0.9976, 0.9974, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9970],
        [0.9891, 0.9872, 0.9856, 0.9855, 0.9850, 0.9825, 0.9823, 0.9800, 0.9799,
         0.9795],
        [0.9961, 0.9960, 0.9958, 0.9958, 0.9957, 0.9956, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9963, 0.9961, 0.9961, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9918, 0.9892, 0.9880, 0.9863, 0.9857, 0.9852, 0.9838, 0.9825, 0.9824,
         0.9817],
        [0.9952, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948,
         0.9948],
        [0.9918, 0.9913, 0.9907, 0.9902, 0.9902, 0.9901, 0.9900, 0.9900, 0.9898,
         0.9898],
        [0.9964, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9880, 0.9879, 0.9876, 0.9866, 0.9862, 0.9862, 0.9855, 0.9836, 0.9824,
         0.9814],
        [0.9968, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9968, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9920, 0.9918, 0.9913, 0.9907, 0.9905, 0.9905, 0.9904, 0.9899, 0.9898,
         0.9898],
        [0.9847, 0.9832, 0.9828, 0.9821, 0.9819, 0.9815, 0.9812, 0.9806, 0.9806,
         0.9802],
        [0.9782, 0.9778, 0.9699, 0.9696, 0.9674, 0.9651, 0.9637, 0.9636, 0.9634,
         0.9611],
        [0.9847, 0.9819, 0.9807, 0.9803, 0.9798, 0.9783, 0.9758, 0.9749, 0.9716,
         0.9699],
        [0.9912, 0.9903, 0.9899, 0.9899, 0.9897, 0.9896, 0.9895, 0.9893, 0.9892,
         0.9890],
        [0.9934, 0.9931, 0.9926, 0.9926, 0.9925, 0.9923, 0.9922, 0.9921, 0.9921,
         0.9918],
        [0.9925, 0.9919, 0.9915, 0.9915, 0.9915, 0.9915, 0.9913, 0.9910, 0.9910,
         0.9907],
        [0.9916, 0.9911, 0.9907, 0.9901, 0.9899, 0.9896, 0.9892, 0.9889, 0.9887,
         0.9886],
        [0.9931, 0.9926, 0.9921, 0.9916, 0.9903, 0.9901, 0.9901, 0.9893, 0.9892,
         0.9886],
        [0.9866, 0.9854, 0.9854, 0.9853, 0.9853, 0.9845, 0.9830, 0.9829, 0.9824,
         0.9823],
        [0.9935, 0.9933, 0.9927, 0.9925, 0.9921, 0.9920, 0.9919, 0.9918, 0.9917,
         0.9917],
        [0.9946, 0.9945, 0.9944, 0.9942, 0.9940, 0.9939, 0.9937, 0.9937, 0.9937,
         0.9937],
        [0.9892, 0.9886, 0.9873, 0.9872, 0.9865, 0.9861, 0.9858, 0.9857, 0.9857,
         0.9856],
        [0.9919, 0.9908, 0.9900, 0.9891, 0.9891, 0.9888, 0.9875, 0.9872, 0.9866,
         0.9857],
        [0.9928, 0.9916, 0.9915, 0.9915, 0.9909, 0.9909, 0.9895, 0.9894, 0.9893,
         0.9891],
        [0.9946, 0.9944, 0.9927, 0.9923, 0.9916, 0.9913, 0.9908, 0.9908, 0.9905,
         0.9904],
        [0.9893, 0.9882, 0.9875, 0.9871, 0.9868, 0.9864, 0.9849, 0.9848, 0.9846,
         0.9843],
        [0.9929, 0.9925, 0.9911, 0.9904, 0.9896, 0.9893, 0.9892, 0.9892, 0.9890,
         0.9889],
        [0.9923, 0.9917, 0.9916, 0.9916, 0.9914, 0.9910, 0.9893, 0.9886, 0.9885,
         0.9881],
        [0.9917, 0.9915, 0.9914, 0.9909, 0.9908, 0.9902, 0.9899, 0.9898, 0.9895,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1517081.3750, 1510172.7500, 1508120.5000, 1507417.2500, 1507415.8750,
         1506681.5000, 1506240.3750, 1505050.0000, 1503850.5000, 1503757.3750],
        [1524560.8750, 1523930.0000, 1523735.2500, 1521637.0000, 1521425.1250,
         1520518.5000, 1519912.5000, 1519853.1250, 1518788.1250, 1518450.6250],
        [1320928.3750, 1318004.0000, 1290121.2500, 1258552.8750, 1246563.5000,
         1218752.1250, 1208991.1250, 1207610.6250, 1187586.2500, 1184873.3750],
        [1470018.6250, 1464906.2500, 1461796.8750, 1460941.2500, 1456842.5000,
         1450631.5000, 1448901.8750, 1446511.8750, 1440750.2500, 1440137.5000],
        [1344158.2500, 1318888.0000, 1311936.8750, 1303546.0000, 1298449.2500,
         1290780.7500, 1268330.6250, 1266597.3750, 1266523.6250, 1266072.0000],
        [1358606.6250, 1298284.5000, 1253653.5000, 1206718.3750, 1181312.6250,
         1170773.2500, 1164698.5000, 1152300.1250, 1146854.6250, 1112563.5000],
        [1200563.3750, 1175625.7500, 1154192.8750, 1135405.1250, 1113956.3750,
         1097979.6250, 1089947.2500, 1081123.0000, 1076126.7500, 1069730.6250],
        [1291472.7500, 1274269.0000, 1250266.1250, 1235933.5000, 1223931.7500,
         1204599.2500, 1201454.5000, 1197887.2500, 1179779.1250, 1178301.7500],
        [1538613.5000, 1531043.1250, 1530919.0000, 1528931.8750, 1524015.7500,
         1523540.6250, 1521798.0000, 1521696.3750, 1521230.6250, 1520804.2500],
        [1448563.3750, 1390982.8750, 1372885.5000, 1372108.0000, 1363479.2500,
         1352297.1250, 1351245.1250, 1348352.7500, 1340015.1250, 1332103.8750],
        [1546725.7500, 1538038.5000, 1537070.7500, 1535445.8750, 1534845.6250,
         1533153.0000, 1533134.0000, 1532106.5000, 1530994.8750, 1530440.2500],
        [1480068.1250, 1476777.3750, 1464650.6250, 1445746.6250, 1443897.3750,
         1441111.6250, 1441042.8750, 1438806.0000, 1427196.6250, 1416119.8750],
        [1471411.3750, 1465315.7500, 1454083.1250, 1452623.6250, 1447189.3750,
         1431041.3750, 1410900.2500, 1410494.0000, 1395416.6250, 1394961.6250],
        [1548620.8750, 1548096.7500, 1547016.3750, 1544009.6250, 1541729.0000,
         1539843.7500, 1539278.5000, 1538860.1250, 1538776.3750, 1538471.2500],
        [1538993.7500, 1533985.1250, 1530174.6250, 1529928.1250, 1529885.7500,
         1528885.1250, 1528729.1250, 1527883.7500, 1527751.2500, 1527748.3750],
        [1530158.6250, 1522603.6250, 1521169.6250, 1520114.0000, 1519389.2500,
         1518071.3750, 1517512.5000, 1517391.0000, 1516465.1250, 1515970.6250],
        [1489030.0000, 1487287.2500, 1483811.8750, 1480190.8750, 1476355.0000,
         1475345.8750, 1475267.0000, 1473290.1250, 1472118.7500, 1470707.1250],
        [1514641.1250, 1509379.5000, 1501646.3750, 1500765.8750, 1499518.3750,
         1498624.8750, 1498166.1250, 1495579.5000, 1491783.2500, 1490341.3750],
        [1481857.5000, 1477704.3750, 1476364.8750, 1469596.6250, 1464099.0000,
         1463819.8750, 1463740.2500, 1462767.5000, 1461535.0000, 1461284.0000],
        [1528373.5000, 1524309.3750, 1523571.0000, 1520811.5000, 1517939.5000,
         1516857.1250, 1516496.8750, 1515383.7500, 1514163.1250, 1514043.2500],
        [1538116.2500, 1532578.6250, 1531198.0000, 1531142.3750, 1530485.5000,
         1530397.8750, 1530160.1250, 1529277.5000, 1528687.0000, 1528125.7500],
        [1464754.0000, 1464152.1250, 1459994.1250, 1459044.8750, 1457327.5000,
         1454606.0000, 1452377.0000, 1451553.1250, 1446541.0000, 1446070.6250],
        [1547955.0000, 1532685.2500, 1530989.1250, 1530470.8750, 1529802.5000,
         1528933.2500, 1528220.3750, 1525992.2500, 1524049.1250, 1522761.8750],
        [1546992.7500, 1546072.5000, 1545836.6250, 1543014.5000, 1542612.8750,
         1541667.1250, 1541257.0000, 1540841.1250, 1540489.8750, 1537076.6250],
        [1520301.0000, 1507072.2500, 1495745.0000, 1493910.2500, 1489747.2500,
         1488514.6250, 1486328.7500, 1484027.1250, 1480767.0000, 1480359.0000],
        [1538019.3750, 1535456.1250, 1535444.3750, 1533729.2500, 1532410.3750,
         1532055.3750, 1531275.2500, 1528880.8750, 1527554.6250, 1527550.1250],
        [1536361.3750, 1534613.0000, 1534295.3750, 1532524.3750, 1527770.1250,
         1527430.7500, 1527130.6250, 1526749.1250, 1522846.2500, 1521732.7500],
        [1526476.8750, 1526425.8750, 1525580.5000, 1524824.1250, 1523075.6250,
         1520093.7500, 1519277.7500, 1518727.2500, 1518718.6250, 1517327.2500],
        [1547571.2500, 1547121.1250, 1542133.3750, 1541587.8750, 1540836.7500,
         1540661.8750, 1539983.2500, 1539557.3750, 1539061.1250, 1539008.3750],
        [1548229.5000, 1546542.8750, 1542496.7500, 1539086.1250, 1536962.1250,
         1536406.7500, 1535667.0000, 1535580.6250, 1535259.8750, 1534722.6250],
        [1540109.5000, 1540096.2500, 1537821.3750, 1537188.0000, 1534879.2500,
         1534832.5000, 1534589.5000, 1534245.6250, 1533580.0000, 1533479.1250],
        [1538780.8750, 1537179.2500, 1536349.6250, 1535469.3750, 1535109.1250,
         1535002.2500, 1534782.7500, 1534560.2500, 1534327.5000, 1533644.3750],
        [1369723.2500, 1332655.3750, 1301922.2500, 1301664.1250, 1292453.5000,
         1246132.0000, 1243385.0000, 1201793.7500, 1200667.6250, 1194618.6250],
        [1512738.5000, 1512431.2500, 1507870.2500, 1507007.6250, 1504302.3750,
         1502935.7500, 1499189.5000, 1497130.7500, 1496591.1250, 1495937.5000],
        [1530203.8750, 1528538.1250, 1526765.1250, 1525739.1250, 1525692.3750,
         1524608.8750, 1520591.0000, 1520440.2500, 1520440.2500, 1519153.1250],
        [1517297.0000, 1514037.5000, 1513550.8750, 1504598.0000, 1502679.2500,
         1501282.6250, 1500428.1250, 1499283.8750, 1497844.6250, 1496685.2500],
        [1423709.6250, 1372021.6250, 1347978.6250, 1315663.2500, 1303706.3750,
         1295978.6250, 1270263.7500, 1245706.6250, 1244256.8750, 1231659.8750],
        [1494950.6250, 1494534.3750, 1494115.3750, 1491338.0000, 1490578.6250,
         1489001.6250, 1488723.3750, 1486487.3750, 1485435.8750, 1484962.8750],
        [1423796.6250, 1413550.8750, 1401177.3750, 1392223.7500, 1391070.3750,
         1389980.3750, 1386866.0000, 1386681.0000, 1383353.6250, 1383316.7500],
        [1519899.3750, 1513462.8750, 1512240.8750, 1509886.1250, 1509405.3750,
         1507893.1250, 1506708.7500, 1505799.3750, 1505597.0000, 1505057.1250],
        [1347855.1250, 1347127.7500, 1341077.5000, 1321097.1250, 1314595.8750,
         1313748.6250, 1300459.2500, 1265381.5000, 1245219.6250, 1226869.7500],
        [1529474.3750, 1526148.0000, 1523807.8750, 1522333.6250, 1521258.1250,
         1521253.8750, 1521000.0000, 1520763.6250, 1520096.6250, 1520044.3750],
        [1528988.7500, 1520815.7500, 1519879.1250, 1517082.8750, 1515804.3750,
         1515330.2500, 1514999.3750, 1514568.8750, 1514277.1250, 1512791.8750],
        [1512070.6250, 1512053.3750, 1511218.6250, 1509835.7500, 1508993.7500,
         1508897.2500, 1508625.3750, 1506690.0000, 1506207.3750, 1505954.6250],
        [1427648.5000, 1423999.0000, 1413230.0000, 1400367.8750, 1397596.7500,
         1396871.8750, 1395428.6250, 1384562.6250, 1382649.3750, 1382379.1250],
        [1285868.7500, 1258161.6250, 1252348.5000, 1239355.2500, 1235981.7500,
         1229060.8750, 1223481.3750, 1213376.8750, 1212980.0000, 1205226.7500],
        [1172803.8750, 1165644.0000, 1041089.8125, 1036833.3125, 1003938.0000,
          972534.2500,  952479.4375,  950969.1250,  948510.0000,  918316.1875],
        [1285727.6250, 1235683.6250, 1214960.8750, 1208086.3750, 1199117.1250,
         1174395.3750, 1132328.7500, 1117899.3750, 1066189.2500, 1041394.6875],
        [1411239.5000, 1393227.7500, 1385980.2500, 1384343.6250, 1382314.6250,
         1379284.3750, 1377691.1250, 1373219.5000, 1372054.3750, 1367826.6250],
        [1455839.7500, 1450974.6250, 1440211.7500, 1440012.6250, 1436993.1250,
         1433225.2500, 1430612.8750, 1429175.6250, 1428663.2500, 1424401.0000],
        [1437882.8750, 1424796.3750, 1417645.3750, 1417575.0000, 1417417.0000,
         1416323.8750, 1412514.5000, 1407964.6250, 1406454.8750, 1402202.7500],
        [1419084.6250, 1409373.8750, 1400806.0000, 1389951.1250, 1385916.8750,
         1379237.1250, 1371558.6250, 1365802.2500, 1361821.1250, 1359226.1250],
        [1449941.3750, 1440379.3750, 1428858.1250, 1420060.6250, 1393081.7500,
         1389317.6250, 1388765.3750, 1372585.7500, 1371069.3750, 1360282.8750],
        [1322358.8750, 1298543.2500, 1298386.0000, 1296612.8750, 1296311.1250,
         1282612.1250, 1255589.3750, 1253704.8750, 1245312.2500, 1241889.5000],
        [1457745.8750, 1453272.1250, 1442475.7500, 1437152.1250, 1429715.5000,
         1427978.0000, 1425284.2500, 1423776.2500, 1420966.8750, 1420601.1250],
        [1482233.6250, 1480370.2500, 1476476.0000, 1472743.6250, 1468511.0000,
         1467323.7500, 1462713.1250, 1462240.3750, 1462177.6250, 1461967.1250],
        [1371542.8750, 1358922.7500, 1335269.7500, 1332361.8750, 1319481.7500,
         1312501.2500, 1305686.0000, 1304034.6250, 1303769.8750, 1303692.7500],
        [1426206.0000, 1403020.0000, 1387255.0000, 1369954.5000, 1368962.0000,
         1364428.7500, 1338820.8750, 1332396.1250, 1321670.6250, 1305363.6250],
        [1443696.3750, 1419540.7500, 1417711.6250, 1417598.1250, 1405304.5000,
         1404914.6250, 1376888.6250, 1375915.8750, 1372871.1250, 1368774.0000],
        [1481152.5000, 1477949.6250, 1442085.0000, 1434264.5000, 1419585.3750,
         1413108.7500, 1404204.6250, 1403438.8750, 1396569.6250, 1395577.6250],
        [1373150.0000, 1352239.1250, 1338552.7500, 1330396.2500, 1324980.8750,
         1317995.1250, 1290074.3750, 1287271.1250, 1284000.0000, 1278325.8750],
        [1446561.6250, 1437211.0000, 1408708.7500, 1394972.2500, 1378512.6250,
         1373320.3750, 1371750.7500, 1370640.7500, 1367825.3750, 1365868.7500],
        [1434120.8750, 1421351.8750, 1419616.6250, 1418510.8750, 1414617.5000,
         1408002.3750, 1372643.3750, 1359301.2500, 1358070.3750, 1350686.0000],
        [1421360.1250, 1418240.3750, 1415413.7500, 1404467.1250, 1403600.8750,
         1391850.7500, 1385906.2500, 1382702.1250, 1376732.3750, 1372051.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1517081.3750,       0.0000],
         [1510172.7500,       0.0000],
         [1508120.5000,       0.0000],
         ...,
         [1505050.0000,       0.0000],
         [1503850.5000,       0.0000],
         [1503757.3750,       0.0000]],

        [[1524560.8750,       0.0000],
         [1523930.0000,       0.0000],
         [1523735.2500,       0.0000],
         ...,
         [1519853.1250,       0.0000],
         [1518788.1250,       0.0000],
         [1518450.6250,       0.0000]],

        [[1320928.3750,       0.0000],
         [1318004.0000,       0.0000],
         [1290121.2500,       0.0000],
         ...,
         [1207610.6250,       0.0000],
         [1187586.2500,       0.0000],
         [1184873.3750,       0.0000]],

        ...,

        [[1446561.6250,       0.0000],
         [1437211.0000,       0.0000],
         [1408708.7500,       0.0000],
         ...,
         [1370640.7500,       0.0000],
         [1367825.3750,       0.0000],
         [1365868.7500,       0.0000]],

        [[1434120.8750,       0.0000],
         [1421351.8750,       0.0000],
         [1419616.6250,       0.0000],
         ...,
         [      0.0000, 1359301.2500],
         [      0.0000, 1358070.3750],
         [1350686.0000,       0.0000]],

        [[      0.0000, 1421360.1250],
         [      0.0000, 1418240.3750],
         [      0.0000, 1415413.7500],
         ...,
         [      0.0000, 1382702.1250],
         [      0.0000, 1376732.3750],
         [      0.0000, 1372051.7500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15075788.0000,        0.0000],
        [15212811.0000,        0.0000],
        [11195420.0000,  1246563.5000],
        [14541438.0000,        0.0000],
        [ 7753737.5000,  5181545.5000],
        [10864452.0000,  1181312.6250],
        [ 4433283.0000,  6761367.5000],
        [ 9763697.0000,  2474198.0000],
        [13740897.0000,  1521696.3750],
        [ 8245452.0000,  5426581.0000],
        [13818822.0000,  1533134.0000],
        [13010766.0000,  1464650.6250],
        [12922536.0000,  1410900.2500],
        [15424703.0000,        0.0000],
        [15303966.0000,        0.0000],
        [15198845.0000,        0.0000],
        [13308059.0000,  1475345.8750],
        [ 7522471.0000,  7477975.5000],
        [13218670.0000,  1464099.0000],
        [13674009.0000,  1517939.5000],
        [15310169.0000,        0.0000],
        [10193977.0000,  4362443.0000],
        [15301859.0000,        0.0000],
        [15425862.0000,        0.0000],
        [11954230.0000,  2972541.7500],
        [15322376.0000,        0.0000],
        [15291454.0000,        0.0000],
        [15220528.0000,        0.0000],
        [15417521.0000,        0.0000],
        [15390955.0000,        0.0000],
        [15360822.0000,        0.0000],
        [15355206.0000,        0.0000],
        [ 6342176.0000,  6342839.0000],
        [12016696.0000,  3019439.0000],
        [13716432.0000,  1525739.1250],
        [ 9013246.0000,  6034442.0000],
        [ 7855340.5000,  5195605.0000],
        [11911478.0000,  2988649.7500],
        [12550839.0000,  1401177.3750],
        [15095950.0000,        0.0000],
        [ 9217432.0000,  3806000.0000],
        [15226181.0000,        0.0000],
        [15174538.0000,        0.0000],
        [13578476.0000,  1512070.6250],
        [ 8397466.0000,  5607267.5000],
        [ 3670555.2500,  8685286.0000],
        [ 6038386.5000,  4124731.5000],
        [ 3225483.5000,  8450300.0000],
        [12415942.0000,  1411239.5000],
        [11494734.0000,  2875375.5000],
        [12743132.0000,  1417645.3750],
        [ 1361821.1250, 12480956.0000],
        [       0.0000, 14014342.0000],
        [ 6361651.5000,  6429669.0000],
        [11455938.0000,  2883030.0000],
        [13228245.0000,  1468511.0000],
        [ 2609456.0000, 10637808.0000],
        [       0.0000, 13618078.0000],
        [       0.0000, 14003216.0000],
        [ 7019376.0000,  7248560.5000],
        [ 6586785.0000,  6590200.5000],
        [11148650.0000,  2766723.0000],
        [11239550.0000,  2717371.5000],
        [ 2795451.5000, 11176873.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 67.1875
Top1 accuracy for validation set is 67.1875 size is torch.Size([64, 1])
Epoch 111/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:48, 59.59s/it]  7%|▋         | 2/29 [01:01<11:39, 25.91s/it] 10%|█         | 3/29 [01:02<06:16, 14.50s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:05<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.30139684677124
Epoch 112/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:22, 56.53s/it]  7%|▋         | 2/29 [00:58<11:04, 24.60s/it] 10%|█         | 3/29 [01:00<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:01<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.05s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 4.287227153778076
Epoch 113/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:54, 57.67s/it]  7%|▋         | 2/29 [01:01<11:44, 26.09s/it] 10%|█         | 3/29 [01:02<06:19, 14.60s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.20s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.21s/it] 21%|██        | 6/29 [01:05<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.281555652618408
Epoch 114/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:30, 61.10s/it]  7%|▋         | 2/29 [01:02<11:33, 25.70s/it] 10%|█         | 3/29 [01:02<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 4.280858516693115
Epoch 115/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:23, 60.83s/it]  7%|▋         | 2/29 [01:01<11:30, 25.59s/it] 10%|█         | 3/29 [01:02<06:12, 14.33s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.04s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 4.263518333435059
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0090, 0.0039, 0.0015,  ..., 0.0037, 0.0018, 0.0214],
        [0.0099, 0.0044, 0.0016,  ..., 0.0034, 0.0013, 0.0211],
        [0.0353, 0.0078, 0.0026,  ..., 0.0094, 0.0123, 0.0259],
        ...,
        [0.0094, 0.0100, 0.0023,  ..., 0.0026, 0.0033, 0.0191],
        [0.0085, 0.0092, 0.0015,  ..., 0.0045, 0.0026, 0.0157],
        [0.0208, 0.0075, 0.0020,  ..., 0.0033, 0.0066, 0.0193]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9962, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9967, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9871, 0.9858, 0.9854, 0.9820, 0.9816, 0.9809, 0.9808, 0.9793, 0.9790,
         0.9785],
        [0.9941, 0.9940, 0.9937, 0.9936, 0.9936, 0.9936, 0.9930, 0.9929, 0.9928,
         0.9928],
        [0.9880, 0.9863, 0.9862, 0.9857, 0.9853, 0.9852, 0.9844, 0.9842, 0.9841,
         0.9839],
        [0.9877, 0.9858, 0.9833, 0.9792, 0.9792, 0.9781, 0.9777, 0.9773, 0.9772,
         0.9744],
        [0.9784, 0.9774, 0.9749, 0.9747, 0.9731, 0.9723, 0.9721, 0.9714, 0.9710,
         0.9693],
        [0.9843, 0.9838, 0.9832, 0.9830, 0.9821, 0.9814, 0.9809, 0.9803, 0.9803,
         0.9801],
        [0.9975, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9933, 0.9907, 0.9897, 0.9892, 0.9891, 0.9890, 0.9886, 0.9885, 0.9878,
         0.9878],
        [0.9977, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9948, 0.9946, 0.9940, 0.9935, 0.9933, 0.9932, 0.9928, 0.9926, 0.9924,
         0.9921],
        [0.9947, 0.9940, 0.9935, 0.9935, 0.9927, 0.9924, 0.9923, 0.9908, 0.9907,
         0.9906],
        [0.9979, 0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9971, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9968, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9960,
         0.9960],
        [0.9950, 0.9948, 0.9947, 0.9947, 0.9947, 0.9945, 0.9945, 0.9943, 0.9943,
         0.9942],
        [0.9959, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9945, 0.9945, 0.9942, 0.9940, 0.9938, 0.9936, 0.9936, 0.9936, 0.9935,
         0.9934],
        [0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9963, 0.9963, 0.9962, 0.9961,
         0.9960],
        [0.9972, 0.9972, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9967],
        [0.9942, 0.9941, 0.9939, 0.9939, 0.9937, 0.9935, 0.9935, 0.9935, 0.9935,
         0.9934],
        [0.9976, 0.9970, 0.9970, 0.9970, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9966, 0.9956, 0.9953, 0.9953, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9967],
        [0.9972, 0.9971, 0.9971, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9977, 0.9975, 0.9975, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9977, 0.9975, 0.9975, 0.9974, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9889, 0.9878, 0.9869, 0.9855, 0.9848, 0.9819, 0.9817, 0.9799, 0.9794,
         0.9792],
        [0.9960, 0.9960, 0.9959, 0.9958, 0.9957, 0.9955, 0.9954, 0.9954, 0.9954,
         0.9954],
        [0.9969, 0.9969, 0.9969, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9963, 0.9961, 0.9961, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9915, 0.9893, 0.9879, 0.9860, 0.9856, 0.9853, 0.9851, 0.9833, 0.9825,
         0.9815],
        [0.9954, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9950, 0.9950, 0.9950,
         0.9948],
        [0.9918, 0.9911, 0.9909, 0.9908, 0.9907, 0.9907, 0.9906, 0.9904, 0.9901,
         0.9900],
        [0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9957, 0.9957, 0.9957, 0.9956,
         0.9956],
        [0.9878, 0.9877, 0.9875, 0.9865, 0.9861, 0.9857, 0.9855, 0.9827, 0.9818,
         0.9805],
        [0.9967, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9969, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958,
         0.9958],
        [0.9922, 0.9916, 0.9916, 0.9908, 0.9907, 0.9906, 0.9904, 0.9901, 0.9900,
         0.9897],
        [0.9856, 0.9840, 0.9834, 0.9830, 0.9828, 0.9826, 0.9820, 0.9815, 0.9813,
         0.9812],
        [0.9794, 0.9767, 0.9701, 0.9692, 0.9685, 0.9669, 0.9634, 0.9633, 0.9629,
         0.9595],
        [0.9839, 0.9808, 0.9805, 0.9795, 0.9787, 0.9773, 0.9739, 0.9731, 0.9707,
         0.9704],
        [0.9916, 0.9913, 0.9907, 0.9906, 0.9898, 0.9898, 0.9894, 0.9894, 0.9893,
         0.9892],
        [0.9934, 0.9932, 0.9927, 0.9924, 0.9923, 0.9922, 0.9921, 0.9920, 0.9920,
         0.9919],
        [0.9921, 0.9918, 0.9916, 0.9916, 0.9915, 0.9914, 0.9911, 0.9910, 0.9910,
         0.9910],
        [0.9916, 0.9905, 0.9898, 0.9897, 0.9897, 0.9894, 0.9893, 0.9886, 0.9884,
         0.9884],
        [0.9935, 0.9924, 0.9922, 0.9915, 0.9904, 0.9902, 0.9897, 0.9897, 0.9895,
         0.9885],
        [0.9865, 0.9856, 0.9854, 0.9853, 0.9852, 0.9851, 0.9835, 0.9834, 0.9818,
         0.9817],
        [0.9933, 0.9932, 0.9929, 0.9924, 0.9919, 0.9918, 0.9918, 0.9914, 0.9913,
         0.9912],
        [0.9945, 0.9941, 0.9941, 0.9941, 0.9940, 0.9936, 0.9935, 0.9935, 0.9932,
         0.9932],
        [0.9893, 0.9883, 0.9877, 0.9877, 0.9867, 0.9863, 0.9860, 0.9858, 0.9856,
         0.9854],
        [0.9919, 0.9907, 0.9903, 0.9893, 0.9885, 0.9884, 0.9875, 0.9871, 0.9860,
         0.9854],
        [0.9928, 0.9917, 0.9916, 0.9910, 0.9908, 0.9907, 0.9899, 0.9896, 0.9894,
         0.9889],
        [0.9947, 0.9946, 0.9928, 0.9924, 0.9913, 0.9910, 0.9908, 0.9906, 0.9906,
         0.9903],
        [0.9894, 0.9877, 0.9870, 0.9869, 0.9869, 0.9865, 0.9849, 0.9846, 0.9846,
         0.9844],
        [0.9927, 0.9924, 0.9910, 0.9900, 0.9892, 0.9891, 0.9888, 0.9886, 0.9885,
         0.9884],
        [0.9921, 0.9914, 0.9913, 0.9912, 0.9912, 0.9911, 0.9893, 0.9886, 0.9881,
         0.9873],
        [0.9919, 0.9915, 0.9913, 0.9909, 0.9905, 0.9896, 0.9894, 0.9893, 0.9889,
         0.9889]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 1, 1, 0, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 0, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 0, 1, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 0, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1519744.3750, 1516403.0000, 1510802.2500, 1509997.1250, 1509428.3750,
         1508482.8750, 1508221.1250, 1507280.7500, 1507070.8750, 1506605.2500],
        [1526491.5000, 1520215.5000, 1520158.8750, 1519803.7500, 1519698.0000,
         1519609.6250, 1519311.0000, 1518046.6250, 1517564.6250, 1517132.0000],
        [1330306.2500, 1307274.6250, 1299357.2500, 1237957.7500, 1230741.6250,
         1217339.7500, 1216183.8750, 1191427.2500, 1185886.2500, 1177373.8750],
        [1470314.5000, 1469149.7500, 1463376.0000, 1461420.6250, 1460130.6250,
         1459866.1250, 1447192.1250, 1445014.6250, 1444528.2500, 1442988.8750],
        [1347447.7500, 1316230.3750, 1314311.2500, 1304372.8750, 1296670.8750,
         1295173.0000, 1281400.5000, 1276768.7500, 1274346.8750, 1271617.7500],
        [1342002.6250, 1305602.5000, 1260525.2500, 1189099.2500, 1188551.5000,
         1170914.0000, 1163191.0000, 1156382.1250, 1155453.8750, 1109788.1250],
        [1174689.8750, 1159017.5000, 1117768.2500, 1114905.5000, 1089419.3750,
         1077053.8750, 1074712.5000, 1063526.5000, 1058029.5000, 1032826.5000],
        [1278648.8750, 1270425.0000, 1258701.7500, 1255464.7500, 1239637.6250,
         1226458.0000, 1217658.8750, 1208626.7500, 1207904.2500, 1204281.1250],
        [1543700.5000, 1532712.8750, 1532156.1250, 1531931.2500, 1529935.2500,
         1529069.0000, 1528466.7500, 1527968.3750, 1526605.0000, 1526351.7500],
        [1455279.0000, 1401689.3750, 1382220.8750, 1370568.7500, 1368857.5000,
         1368019.7500, 1360247.8750, 1357507.0000, 1345111.1250, 1343814.7500],
        [1548179.3750, 1537669.0000, 1536982.7500, 1536466.8750, 1535605.5000,
         1534727.1250, 1534677.3750, 1534655.3750, 1533868.1250, 1532352.0000],
        [1484869.3750, 1482466.7500, 1468198.6250, 1458046.2500, 1453913.8750,
         1452510.0000, 1444729.3750, 1438937.6250, 1434951.3750, 1429756.3750],
        [1484518.2500, 1468835.8750, 1458417.5000, 1457925.1250, 1441456.6250,
         1435764.3750, 1433255.3750, 1402606.6250, 1400520.1250, 1398566.1250],
        [1552478.8750, 1552410.7500, 1549103.8750, 1546603.2500, 1544234.8750,
         1543407.5000, 1541937.7500, 1541743.6250, 1540205.0000, 1539724.7500],
        [1536450.7500, 1531341.1250, 1529547.2500, 1527044.7500, 1526539.5000,
         1526427.5000, 1525686.6250, 1525659.0000, 1525573.1250, 1524645.1250],
        [1527822.6250, 1519117.0000, 1518137.8750, 1518013.3750, 1515954.7500,
         1515804.3750, 1515732.1250, 1513628.8750, 1512478.8750, 1512207.7500],
        [1490339.8750, 1486056.6250, 1484487.1250, 1484232.2500, 1483792.1250,
         1479829.6250, 1478513.5000, 1474165.7500, 1474161.6250, 1473499.5000],
        [1510354.2500, 1505263.8750, 1504666.8750, 1503646.8750, 1500668.6250,
         1498503.3750, 1495743.5000, 1493797.6250, 1493726.5000, 1492235.7500],
        [1479254.0000, 1479225.7500, 1473890.2500, 1468630.0000, 1464477.5000,
         1460813.1250, 1460680.7500, 1460186.2500, 1458695.6250, 1456964.7500],
        [1527078.2500, 1523569.6250, 1521875.0000, 1521735.6250, 1521245.2500,
         1517337.5000, 1516857.1250, 1515164.1250, 1512970.7500, 1512351.8750],
        [1537287.7500, 1536644.2500, 1532737.8750, 1531902.0000, 1531565.8750,
         1530453.5000, 1530357.1250, 1529117.0000, 1528157.7500, 1526575.8750],
        [1472087.8750, 1471029.7500, 1466214.5000, 1465983.8750, 1461691.0000,
         1459409.5000, 1459135.3750, 1459117.2500, 1457862.6250, 1456734.1250],
        [1546575.2500, 1533378.2500, 1532487.8750, 1532166.3750, 1529092.2500,
         1527630.2500, 1527349.2500, 1523979.3750, 1523640.7500, 1523436.0000],
        [1549146.7500, 1547144.7500, 1546905.7500, 1544956.7500, 1544374.8750,
         1541098.3750, 1540913.1250, 1540804.3750, 1540766.1250, 1540438.5000],
        [1524225.1250, 1502730.8750, 1496605.2500, 1495742.1250, 1492746.6250,
         1490371.1250, 1489647.8750, 1489316.8750, 1487893.0000, 1487820.6250],
        [1536052.2500, 1535424.0000, 1535419.5000, 1533738.0000, 1531592.2500,
         1531400.8750, 1531231.5000, 1529823.0000, 1529420.3750, 1527659.5000],
        [1537623.5000, 1535858.8750, 1534990.6250, 1531799.7500, 1529636.2500,
         1527757.0000, 1526557.0000, 1526297.8750, 1524770.2500, 1524210.5000],
        [1528754.0000, 1526944.2500, 1524158.2500, 1523667.0000, 1522499.1250,
         1520620.0000, 1519929.8750, 1518811.2500, 1517974.2500, 1517013.3750],
        [1548109.8750, 1543264.6250, 1543261.7500, 1540814.6250, 1540212.3750,
         1539987.6250, 1539448.6250, 1538566.6250, 1538287.8750, 1538188.1250],
        [1548872.0000, 1543974.2500, 1543479.6250, 1542049.5000, 1537311.1250,
         1536944.6250, 1536295.3750, 1535971.6250, 1535806.1250, 1534618.7500],
        [1538782.3750, 1537487.0000, 1537469.5000, 1536540.2500, 1536310.0000,
         1535292.1250, 1534194.3750, 1534008.6250, 1533783.3750, 1533324.1250],
        [1535551.3750, 1534794.3750, 1534371.3750, 1533958.8750, 1533631.1250,
         1533255.3750, 1532857.7500, 1532192.7500, 1532124.0000, 1532015.8750],
        [1366081.0000, 1344115.8750, 1326605.6250, 1301676.5000, 1287268.7500,
         1235660.0000, 1232402.5000, 1201423.6250, 1191892.1250, 1188845.1250],
        [1511478.2500, 1510754.7500, 1510129.6250, 1506234.6250, 1505486.3750,
         1501304.2500, 1498952.1250, 1498612.0000, 1498179.0000, 1498106.2500],
        [1531903.3750, 1530851.8750, 1530046.1250, 1526212.0000, 1523553.6250,
         1521899.6250, 1521805.2500, 1519313.8750, 1519090.8750, 1519090.8750],
        [1517925.1250, 1514210.7500, 1513233.3750, 1503758.7500, 1501970.0000,
         1501958.6250, 1500970.5000, 1500777.3750, 1500776.0000, 1500308.0000],
        [1416534.5000, 1373553.3750, 1346558.8750, 1309732.8750, 1302076.2500,
         1296677.1250, 1293403.0000, 1260352.1250, 1245657.8750, 1228678.8750],
        [1499409.6250, 1496195.7500, 1496098.7500, 1496026.0000, 1493572.6250,
         1493203.7500, 1490747.8750, 1489818.3750, 1489419.1250, 1486511.5000],
        [1423857.7500, 1408406.6250, 1404894.5000, 1403220.7500, 1402151.8750,
         1400497.5000, 1399861.8750, 1394598.5000, 1390122.2500, 1387613.5000],
        [1514394.1250, 1513252.1250, 1510800.7500, 1509969.7500, 1509238.3750,
         1505354.2500, 1505005.5000, 1504342.6250, 1502189.2500, 1502172.1250],
        [1343716.0000, 1342691.2500, 1339211.6250, 1319344.5000, 1312969.6250,
         1304345.6250, 1301648.0000, 1249194.6250, 1233411.3750, 1210910.0000],
        [1527320.0000, 1523023.3750, 1522563.0000, 1520427.1250, 1520090.7500,
         1518838.8750, 1518578.1250, 1518498.3750, 1517964.1250, 1517926.5000],
        [1530828.6250, 1519542.8750, 1519089.3750, 1517842.6250, 1517663.1250,
         1517592.1250, 1517101.6250, 1516550.3750, 1516269.8750, 1516261.2500],
        [1512923.1250, 1510385.8750, 1510017.2500, 1508858.5000, 1508274.3750,
         1507980.8750, 1507799.7500, 1507332.5000, 1507070.8750, 1506757.6250],
        [1432319.3750, 1419504.2500, 1418486.5000, 1403239.3750, 1400632.2500,
         1399925.8750, 1394349.6250, 1388369.3750, 1387861.1250, 1381588.3750],
        [1302715.8750, 1273048.3750, 1262498.2500, 1256112.6250, 1252236.2500,
         1248332.5000, 1237781.7500, 1229114.7500, 1225749.3750, 1222694.1250],
        [1191677.3750, 1147641.3750, 1044604.5625, 1030140.0000, 1019896.5000,
          997115.6250,  948623.1250,  947050.3125,  941352.1875,  896827.0000],
        [1271723.2500, 1217037.8750, 1211465.6250, 1194756.6250, 1180528.7500,
         1157103.6250, 1102320.0000, 1089748.8750, 1053650.2500, 1047999.1250],
        [1420121.6250, 1413120.8750, 1401401.8750, 1399029.0000, 1383665.1250,
         1383575.3750, 1375608.8750, 1374995.1250, 1373873.0000, 1370614.5000],
        [1457295.5000, 1451644.6250, 1441711.0000, 1436149.2500, 1434484.7500,
         1431463.2500, 1429691.0000, 1427792.8750, 1426860.5000, 1426234.7500],
        [1429587.3750, 1422575.1250, 1419132.0000, 1418466.2500, 1417415.5000,
         1414973.7500, 1409875.2500, 1408229.2500, 1408214.5000, 1406279.1250],
        [1418797.7500, 1396942.5000, 1383826.1250, 1380961.2500, 1380513.6250,
         1375700.7500, 1373176.2500, 1359722.6250, 1356856.1250, 1356769.2500],
        [1458769.3750, 1435078.6250, 1431836.0000, 1418033.5000, 1395159.7500,
         1392153.3750, 1381920.5000, 1381340.6250, 1377525.6250, 1358810.1250],
        [1320498.8750, 1302929.6250, 1299636.0000, 1297252.2500, 1294740.7500,
         1292608.8750, 1264579.2500, 1262759.5000, 1234259.7500, 1231863.0000],
        [1453649.0000, 1452544.6250, 1446038.8750, 1436156.0000, 1426164.0000,
         1424023.3750, 1423268.5000, 1414413.8750, 1413994.3750, 1411196.3750],
        [1479244.0000, 1470927.3750, 1470178.3750, 1469976.5000, 1469533.6250,
         1461399.7500, 1458014.1250, 1457990.5000, 1453049.0000, 1452679.0000],
        [1373501.0000, 1354224.0000, 1342230.3750, 1341565.0000, 1322848.2500,
         1316372.2500, 1310980.1250, 1305850.3750, 1302577.8750, 1298973.1250],
        [1425913.7500, 1401170.7500, 1393440.5000, 1372889.3750, 1357903.2500,
         1355967.2500, 1338217.1250, 1330716.1250, 1311077.6250, 1299865.3750],
        [1444203.1250, 1422111.2500, 1419321.3750, 1407544.5000, 1403034.6250,
         1402046.2500, 1385412.0000, 1380285.8750, 1375594.5000, 1366370.3750],
        [1484264.8750, 1481979.1250, 1444419.3750, 1435761.6250, 1413116.8750,
         1407651.8750, 1402925.0000, 1398986.3750, 1398953.0000, 1394214.1250],
        [1376018.2500, 1342681.1250, 1328626.2500, 1327624.5000, 1326434.8750,
         1318823.7500, 1289967.3750, 1283873.8750, 1283379.2500, 1281218.3750],
        [1442332.6250, 1435594.6250, 1408015.7500, 1387998.7500, 1370930.8750,
         1368749.1250, 1363364.7500, 1360257.0000, 1358799.6250, 1355415.2500],
        [1429213.8750, 1414818.6250, 1414106.3750, 1411422.5000, 1410865.2500,
         1409984.2500, 1374300.2500, 1359354.3750, 1350879.3750, 1334356.8750],
        [1425388.8750, 1417508.8750, 1413479.3750, 1404358.6250, 1398079.3750,
         1378960.8750, 1374638.3750, 1373253.5000, 1366383.3750, 1365948.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1519744.3750,       0.0000],
         [1516403.0000,       0.0000],
         [1510802.2500,       0.0000],
         ...,
         [1507280.7500,       0.0000],
         [1507070.8750,       0.0000],
         [1506605.2500,       0.0000]],

        [[1526491.5000,       0.0000],
         [1520215.5000,       0.0000],
         [1520158.8750,       0.0000],
         ...,
         [1518046.6250,       0.0000],
         [1517564.6250,       0.0000],
         [1517132.0000,       0.0000]],

        [[1330306.2500,       0.0000],
         [1307274.6250,       0.0000],
         [1299357.2500,       0.0000],
         ...,
         [1191427.2500,       0.0000],
         [1185886.2500,       0.0000],
         [1177373.8750,       0.0000]],

        ...,

        [[1442332.6250,       0.0000],
         [1435594.6250,       0.0000],
         [1408015.7500,       0.0000],
         ...,
         [1360257.0000,       0.0000],
         [1358799.6250,       0.0000],
         [1355415.2500,       0.0000]],

        [[1429213.8750,       0.0000],
         [1414818.6250,       0.0000],
         [1414106.3750,       0.0000],
         ...,
         [      0.0000, 1359354.3750],
         [      0.0000, 1350879.3750],
         [1334356.8750,       0.0000]],

        [[      0.0000, 1425388.8750],
         [      0.0000, 1417508.8750],
         [      0.0000, 1413479.3750],
         ...,
         [      0.0000, 1373253.5000],
         [      0.0000, 1366383.3750],
         [      0.0000, 1365948.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15104036.0000,        0.0000],
        [15198032.0000,        0.0000],
        [11177665.0000,  1216183.8750],
        [14563981.0000,        0.0000],
        [ 7810506.0000,  5167834.5000],
        [10852958.0000,  1188551.5000],
        [ 3294101.0000,  7667848.5000],
        [ 8649360.0000,  3718447.7500],
        [13780929.0000,  1527968.3750],
        [10981058.0000,  2772258.0000],
        [13828716.0000,  1536466.8750],
        [13080181.0000,  1468198.6250],
        [14381867.0000,        0.0000],
        [15451851.0000,        0.0000],
        [15278915.0000,        0.0000],
        [15168898.0000,        0.0000],
        [13334916.0000,  1474161.6250],
        [ 9013402.0000,  5985205.0000],
        [13202632.0000,  1460186.2500],
        [13673328.0000,  1516857.1250],
        [15314798.0000,        0.0000],
        [10247138.0000,  4382127.5000],
        [15299735.0000,        0.0000],
        [15436549.0000,        0.0000],
        [11981386.0000,  2975713.5000],
        [15321762.0000,        0.0000],
        [15299502.0000,        0.0000],
        [15220370.0000,        0.0000],
        [15410141.0000,        0.0000],
        [15395323.0000,        0.0000],
        [15357192.0000,        0.0000],
        [15334752.0000,        0.0000],
        [ 5116981.0000,  7558990.0000],
        [12017630.0000,  3021608.0000],
        [13717556.0000,  1526212.0000],
        [10522976.0000,  4532912.0000],
        [ 7870982.5000,  5202242.5000],
        [10445750.0000,  4485254.0000],
        [ 9816908.0000,  4198317.0000],
        [15076718.0000,        0.0000],
        [ 9184368.0000,  3773074.0000],
        [15205230.0000,        0.0000],
        [15188742.0000,        0.0000],
        [13579127.0000,  1508274.3750],
        [ 8402930.0000,  5623346.0000],
        [ 3722974.0000,  8787310.0000],
        [ 6011923.0000,  4153005.5000],
        [ 2143399.0000,  9382935.0000],
        [12475884.0000,  1420121.6250],
        [11485448.0000,  2877879.5000],
        [12737332.0000,  1417415.5000],
        [ 1359722.6250, 12423543.0000],
        [       0.0000, 14030626.0000],
        [ 6322695.0000,  6478433.0000],
        [11423777.0000,  2877672.5000],
        [13172065.0000,  1470927.3750],
        [ 1305850.3750, 11963272.0000],
        [       0.0000, 13587162.0000],
        [       0.0000, 14005924.0000],
        [ 5613981.5000,  8648291.0000],
        [ 6560315.5000,  6598332.5000],
        [11094711.0000,  2756748.0000],
        [11199068.0000,  2710233.7500],
        [ 2778997.0000, 11139002.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 67.1875
Top1 accuracy for validation set is 67.1875 size is torch.Size([64, 1])
Epoch 116/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:02, 57.95s/it]  7%|▋         | 2/29 [01:00<11:25, 25.40s/it] 10%|█         | 3/29 [01:02<06:20, 14.64s/it] 14%|█▍        | 4/29 [01:03<03:50,  9.22s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.23s/it] 21%|██        | 6/29 [01:05<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:06<00:53,  2.53s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.259765625
Epoch 117/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:13, 58.36s/it]  7%|▋         | 2/29 [01:01<11:42, 26.00s/it] 10%|█         | 3/29 [01:02<06:18, 14.55s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.19s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.250689506530762
Epoch 118/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:16, 58.46s/it]  7%|▋         | 2/29 [00:59<11:04, 24.61s/it] 10%|█         | 3/29 [01:01<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.05s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.237912654876709
Epoch 119/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:41, 61.49s/it]  7%|▋         | 2/29 [01:02<11:38, 25.86s/it] 10%|█         | 3/29 [01:03<06:16, 14.47s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.12s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 4.242722511291504
Epoch 120/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:51, 61.84s/it]  7%|▋         | 2/29 [01:02<11:42, 26.00s/it] 10%|█         | 3/29 [01:03<06:18, 14.55s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 4.23951530456543
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0084, 0.0036, 0.0013,  ..., 0.0035, 0.0018, 0.0218],
        [0.0094, 0.0044, 0.0017,  ..., 0.0032, 0.0016, 0.0226],
        [0.0352, 0.0065, 0.0033,  ..., 0.0086, 0.0129, 0.0265],
        ...,
        [0.0081, 0.0094, 0.0026,  ..., 0.0029, 0.0028, 0.0200],
        [0.0077, 0.0088, 0.0013,  ..., 0.0049, 0.0025, 0.0160],
        [0.0183, 0.0069, 0.0014,  ..., 0.0029, 0.0053, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9968, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9863, 0.9858, 0.9853, 0.9826, 0.9816, 0.9811, 0.9807, 0.9790, 0.9782,
         0.9781],
        [0.9939, 0.9937, 0.9935, 0.9932, 0.9932, 0.9932, 0.9924, 0.9923, 0.9922,
         0.9921],
        [0.9880, 0.9866, 0.9855, 0.9850, 0.9848, 0.9845, 0.9842, 0.9841, 0.9838,
         0.9836],
        [0.9887, 0.9866, 0.9827, 0.9818, 0.9802, 0.9794, 0.9788, 0.9778, 0.9757,
         0.9740],
        [0.9793, 0.9780, 0.9750, 0.9748, 0.9734, 0.9732, 0.9730, 0.9725, 0.9722,
         0.9706],
        [0.9840, 0.9839, 0.9825, 0.9814, 0.9813, 0.9811, 0.9793, 0.9791, 0.9790,
         0.9786],
        [0.9974, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9930, 0.9888, 0.9886, 0.9885, 0.9869, 0.9869, 0.9868, 0.9866, 0.9864,
         0.9858],
        [0.9977, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971,
         0.9971],
        [0.9944, 0.9939, 0.9931, 0.9929, 0.9929, 0.9928, 0.9927, 0.9916, 0.9915,
         0.9915],
        [0.9941, 0.9934, 0.9932, 0.9926, 0.9922, 0.9920, 0.9910, 0.9901, 0.9900,
         0.9898],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9974, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9968, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9950, 0.9949, 0.9949, 0.9946, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9941],
        [0.9963, 0.9961, 0.9957, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9944, 0.9944, 0.9942, 0.9938, 0.9937, 0.9937, 0.9936, 0.9935, 0.9934,
         0.9934],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9973, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9941, 0.9938, 0.9938, 0.9936, 0.9934, 0.9933, 0.9931, 0.9930, 0.9930,
         0.9928],
        [0.9978, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9963, 0.9954, 0.9954, 0.9952, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9979, 0.9977, 0.9977, 0.9976, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9888, 0.9878, 0.9867, 0.9866, 0.9841, 0.9818, 0.9808, 0.9804, 0.9790,
         0.9787],
        [0.9960, 0.9959, 0.9959, 0.9958, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9971, 0.9970, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9964],
        [0.9965, 0.9961, 0.9961, 0.9957, 0.9956, 0.9956, 0.9956, 0.9956, 0.9955,
         0.9955],
        [0.9916, 0.9893, 0.9885, 0.9865, 0.9856, 0.9852, 0.9844, 0.9837, 0.9827,
         0.9825],
        [0.9955, 0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9952, 0.9952, 0.9950,
         0.9950],
        [0.9917, 0.9916, 0.9908, 0.9906, 0.9905, 0.9904, 0.9901, 0.9901, 0.9900,
         0.9899],
        [0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9954,
         0.9954],
        [0.9879, 0.9877, 0.9876, 0.9872, 0.9861, 0.9859, 0.9846, 0.9835, 0.9824,
         0.9821],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9971, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9928, 0.9925, 0.9916, 0.9916, 0.9910, 0.9909, 0.9908, 0.9907, 0.9906,
         0.9905],
        [0.9850, 0.9838, 0.9830, 0.9827, 0.9821, 0.9819, 0.9813, 0.9811, 0.9810,
         0.9808],
        [0.9822, 0.9763, 0.9721, 0.9702, 0.9699, 0.9667, 0.9666, 0.9662, 0.9655,
         0.9599],
        [0.9836, 0.9798, 0.9796, 0.9795, 0.9781, 0.9763, 0.9720, 0.9713, 0.9705,
         0.9696],
        [0.9917, 0.9910, 0.9910, 0.9908, 0.9908, 0.9905, 0.9902, 0.9898, 0.9898,
         0.9898],
        [0.9935, 0.9933, 0.9928, 0.9925, 0.9924, 0.9923, 0.9922, 0.9921, 0.9921,
         0.9921],
        [0.9919, 0.9918, 0.9917, 0.9917, 0.9915, 0.9913, 0.9913, 0.9912, 0.9912,
         0.9911],
        [0.9917, 0.9907, 0.9903, 0.9900, 0.9898, 0.9897, 0.9895, 0.9895, 0.9891,
         0.9885],
        [0.9937, 0.9931, 0.9926, 0.9923, 0.9912, 0.9908, 0.9905, 0.9901, 0.9899,
         0.9894],
        [0.9877, 0.9862, 0.9858, 0.9854, 0.9850, 0.9843, 0.9835, 0.9829, 0.9829,
         0.9816],
        [0.9936, 0.9932, 0.9928, 0.9927, 0.9919, 0.9916, 0.9916, 0.9913, 0.9912,
         0.9911],
        [0.9946, 0.9943, 0.9939, 0.9939, 0.9939, 0.9936, 0.9935, 0.9933, 0.9933,
         0.9932],
        [0.9896, 0.9888, 0.9881, 0.9878, 0.9876, 0.9869, 0.9867, 0.9865, 0.9862,
         0.9860],
        [0.9925, 0.9911, 0.9910, 0.9902, 0.9896, 0.9888, 0.9881, 0.9877, 0.9866,
         0.9866],
        [0.9931, 0.9921, 0.9919, 0.9914, 0.9912, 0.9911, 0.9902, 0.9899, 0.9897,
         0.9896],
        [0.9951, 0.9950, 0.9932, 0.9931, 0.9912, 0.9909, 0.9909, 0.9909, 0.9908,
         0.9907],
        [0.9897, 0.9882, 0.9878, 0.9872, 0.9867, 0.9866, 0.9854, 0.9853, 0.9850,
         0.9849],
        [0.9928, 0.9926, 0.9912, 0.9901, 0.9893, 0.9890, 0.9890, 0.9889, 0.9886,
         0.9886],
        [0.9919, 0.9915, 0.9914, 0.9912, 0.9910, 0.9908, 0.9892, 0.9886, 0.9881,
         0.9868],
        [0.9925, 0.9922, 0.9913, 0.9912, 0.9909, 0.9903, 0.9900, 0.9898, 0.9895,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 1, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 0, 0, 1, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 1, 1, 1],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 1, 0, 1],
        [1, 0, 0, 1, 0, 1, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1516861.5000, 1515924.3750, 1514674.2500, 1512803.5000, 1512712.5000,
         1510736.0000, 1508900.1250, 1508257.0000, 1508235.5000, 1507809.8750],
        [1528220.3750, 1522477.3750, 1521020.3750, 1520520.0000, 1520427.1250,
         1519164.6250, 1518042.3750, 1517917.8750, 1516975.7500, 1516904.8750],
        [1315204.0000, 1306275.1250, 1296698.1250, 1248924.2500, 1231217.1250,
         1221102.2500, 1214164.0000, 1185207.8750, 1171359.6250, 1171103.8750],
        [1465853.7500, 1462261.2500, 1458820.8750, 1453193.1250, 1452831.5000,
         1451457.7500, 1435791.7500, 1432803.0000, 1431724.0000, 1429312.0000],
        [1348900.6250, 1321781.5000, 1300936.7500, 1292273.6250, 1287570.7500,
         1283062.3750, 1276210.0000, 1275902.1250, 1268840.0000, 1265970.6250],
        [1361376.8750, 1320883.0000, 1250431.8750, 1233792.5000, 1205959.1250,
         1191731.8750, 1182341.6250, 1165566.2500, 1130689.6250, 1104479.3750],
        [1190560.6250, 1169301.5000, 1119224.1250, 1116600.6250, 1094219.6250,
         1090678.3750, 1087871.5000, 1080739.5000, 1075452.7500, 1051583.3750],
        [1274067.3750, 1271959.7500, 1245818.2500, 1227153.0000, 1224394.1250,
         1221205.8750, 1191243.2500, 1187021.1250, 1186363.6250, 1179405.6250],
        [1542623.1250, 1532094.7500, 1531208.2500, 1530311.8750, 1528853.0000,
         1527087.0000, 1526466.6250, 1525950.0000, 1525619.6250, 1525372.3750],
        [1447727.8750, 1362804.6250, 1360778.6250, 1357173.0000, 1327723.1250,
         1327239.6250, 1325663.3750, 1320569.3750, 1317580.3750, 1305750.7500],
        [1548483.5000, 1541039.5000, 1540058.1250, 1539018.6250, 1538053.1250,
         1537689.3750, 1537645.5000, 1536272.0000, 1535079.8750, 1534633.3750],
        [1476791.5000, 1467312.6250, 1450922.0000, 1445510.7500, 1445006.3750,
         1443162.2500, 1441008.6250, 1418677.3750, 1417809.0000, 1416806.1250],
        [1470139.2500, 1455710.6250, 1451525.5000, 1440320.1250, 1430917.2500,
         1428300.8750, 1407119.0000, 1390135.3750, 1387190.1250, 1383646.6250],
        [1552489.2500, 1552064.3750, 1550147.2500, 1548894.1250, 1544617.8750,
         1544454.3750, 1543033.6250, 1541905.3750, 1541467.3750, 1541323.1250],
        [1541942.1250, 1535148.6250, 1534787.1250, 1531417.0000, 1531091.2500,
         1530970.1250, 1529359.1250, 1529357.6250, 1529111.1250, 1528705.8750],
        [1529490.3750, 1524408.2500, 1522462.8750, 1521705.1250, 1520009.6250,
         1519671.8750, 1518536.0000, 1518237.7500, 1517891.7500, 1515977.8750],
        [1490223.3750, 1488676.5000, 1488076.1250, 1481754.3750, 1479158.0000,
         1477811.5000, 1477232.3750, 1475371.0000, 1474288.0000, 1470519.2500],
        [1517305.6250, 1512966.5000, 1505073.0000, 1503231.1250, 1500103.3750,
         1499208.1250, 1498883.5000, 1497890.5000, 1496231.5000, 1495790.6250],
        [1477529.7500, 1477219.6250, 1472353.3750, 1464851.8750, 1463455.3750,
         1461788.6250, 1460268.3750, 1457495.6250, 1457331.6250, 1456784.1250],
        [1526826.3750, 1526753.5000, 1525112.0000, 1524861.8750, 1523242.7500,
         1519982.1250, 1519784.8750, 1519686.3750, 1519408.1250, 1517376.6250],
        [1538964.3750, 1537469.5000, 1535703.6250, 1534754.8750, 1531484.1250,
         1530740.8750, 1530370.2500, 1529766.0000, 1529697.5000, 1529048.5000],
        [1470582.2500, 1465621.7500, 1464713.5000, 1459635.0000, 1455527.3750,
         1453718.3750, 1450058.8750, 1448943.3750, 1448400.3750, 1444710.1250],
        [1550959.1250, 1540199.1250, 1537429.8750, 1536150.3750, 1535381.5000,
         1533011.2500, 1531726.6250, 1529875.5000, 1528475.5000, 1527945.0000],
        [1552003.7500, 1549986.1250, 1548022.8750, 1546130.0000, 1544939.0000,
         1544492.6250, 1543760.8750, 1543757.8750, 1543067.5000, 1542367.2500],
        [1518879.3750, 1499199.5000, 1498217.6250, 1494431.7500, 1488773.0000,
         1487467.3750, 1486595.1250, 1484846.7500, 1483799.1250, 1483282.8750],
        [1539674.8750, 1539671.8750, 1538811.6250, 1536798.1250, 1536513.7500,
         1536280.8750, 1535270.2500, 1535115.0000, 1534165.1250, 1533271.3750],
        [1542176.0000, 1540629.6250, 1539042.0000, 1537147.0000, 1535592.3750,
         1532941.0000, 1529815.7500, 1529416.0000, 1528423.1250, 1526299.2500],
        [1531906.2500, 1529136.0000, 1526568.6250, 1525910.6250, 1525555.6250,
         1525381.1250, 1524971.0000, 1524232.3750, 1523322.6250, 1523032.1250],
        [1548585.5000, 1548384.6250, 1544030.2500, 1543122.0000, 1543098.3750,
         1541931.8750, 1541812.7500, 1541664.2500, 1541379.1250, 1541329.1250],
        [1553893.5000, 1548056.8750, 1547522.5000, 1547199.2500, 1540732.5000,
         1539645.5000, 1539378.2500, 1539061.1250, 1538786.7500, 1538000.3750],
        [1542274.5000, 1540791.1250, 1539698.2500, 1539693.8750, 1539441.3750,
         1538888.0000, 1538830.7500, 1538371.5000, 1537727.5000, 1537456.2500],
        [1540055.1250, 1540008.2500, 1538820.5000, 1538327.5000, 1538031.1250,
         1537623.5000, 1537374.2500, 1537227.6250, 1537017.8750, 1536550.3750],
        [1364413.2500, 1344233.8750, 1324033.5000, 1321916.3750, 1274760.1250,
         1234649.3750, 1217133.0000, 1209311.6250, 1185894.2500, 1181091.7500],
        [1511249.0000, 1510197.2500, 1508937.6250, 1507451.7500, 1503586.6250,
         1502308.1250, 1501401.5000, 1500431.0000, 1500275.0000, 1500017.6250],
        [1535825.1250, 1533951.5000, 1528175.3750, 1526539.5000, 1524992.7500,
         1524803.6250, 1524395.1250, 1523358.8750, 1522240.7500, 1520788.2500],
        [1521670.2500, 1513691.0000, 1513399.3750, 1504367.0000, 1503156.6250,
         1502937.2500, 1502316.7500, 1502057.3750, 1500030.5000, 1499861.6250],
        [1419279.5000, 1372838.3750, 1356950.5000, 1319922.2500, 1302014.2500,
         1295664.7500, 1280203.3750, 1267963.0000, 1250554.7500, 1245498.7500],
        [1500731.5000, 1500272.2500, 1499694.2500, 1498676.3750, 1498041.8750,
         1497621.8750, 1494330.6250, 1494038.5000, 1490595.7500, 1489362.2500],
        [1421331.5000, 1419157.7500, 1402785.8750, 1399740.3750, 1396624.1250,
         1395688.1250, 1389710.0000, 1389255.5000, 1387752.5000, 1386179.7500],
        [1509389.6250, 1509071.3750, 1508982.1250, 1507676.1250, 1507217.5000,
         1505151.8750, 1503347.2500, 1502558.8750, 1499036.5000, 1499030.7500],
        [1345988.7500, 1343088.3750, 1340835.8750, 1333512.2500, 1311975.7500,
         1308665.3750, 1284730.0000, 1263536.5000, 1245083.1250, 1239874.1250],
        [1532083.1250, 1528379.2500, 1527566.1250, 1526011.1250, 1525675.0000,
         1525453.7500, 1524927.2500, 1524741.1250, 1524111.7500, 1524033.1250],
        [1534624.6250, 1523979.3750, 1523773.0000, 1523452.0000, 1522850.6250,
         1522718.3750, 1522706.7500, 1520843.3750, 1520256.0000, 1519635.6250],
        [1515897.0000, 1515061.5000, 1513083.3750, 1513070.3750, 1513014.1250,
         1512794.7500, 1511630.8750, 1511308.1250, 1511181.2500, 1510942.0000],
        [1444379.5000, 1437035.6250, 1419248.3750, 1418855.8750, 1407531.0000,
         1405423.8750, 1403215.3750, 1400949.0000, 1399620.2500, 1397371.6250],
        [1291302.8750, 1269429.3750, 1254659.2500, 1250714.5000, 1239648.3750,
         1236543.0000, 1225487.6250, 1220917.1250, 1219419.5000, 1215681.8750],
        [1241511.7500, 1140961.6250, 1074589.5000, 1045999.2500, 1041409.6250,
          993920.0000,  992864.6250,  987951.2500,  977170.6250,  901856.5000],
        [1265627.7500, 1198739.7500, 1195186.2500, 1193738.3750, 1170041.1250,
         1140102.3750, 1073145.5000, 1062322.3750, 1049787.7500, 1037117.0625],
        [1421087.6250, 1407821.0000, 1406558.2500, 1403720.0000, 1402804.5000,
         1397566.1250, 1392053.8750, 1383694.1250, 1383575.3750, 1383005.3750],
        [1457978.0000, 1453394.1250, 1443159.5000, 1437157.5000, 1434728.2500,
         1433036.7500, 1431356.6250, 1430476.5000, 1429579.2500, 1429055.7500],
        [1426119.1250, 1424079.1250, 1421819.6250, 1420682.5000, 1417833.3750,
         1414207.5000, 1413941.8750, 1411632.5000, 1410644.6250, 1408551.6250],
        [1421412.8750, 1401633.1250, 1392616.7500, 1386774.8750, 1383046.3750,
         1380950.7500, 1377414.0000, 1376538.1250, 1370308.6250, 1357886.5000],
        [1463269.8750, 1449163.0000, 1439875.2500, 1432699.2500, 1410518.1250,
         1403175.1250, 1397627.5000, 1389596.0000, 1385837.5000, 1374742.0000],
        [1342531.3750, 1313936.6250, 1307328.2500, 1299359.6250, 1291599.6250,
         1279138.1250, 1265059.3750, 1252886.1250, 1252643.5000, 1230638.5000],
        [1459728.2500, 1453050.2500, 1444369.8750, 1441667.0000, 1426251.0000,
         1419117.1250, 1418893.7500, 1412728.7500, 1411520.7500, 1409663.0000],
        [1480839.0000, 1474982.8750, 1467558.8750, 1467557.5000, 1466196.3750,
         1460470.3750, 1458591.3750, 1455020.7500, 1453649.0000, 1452749.7500],
        [1379971.2500, 1363058.0000, 1349946.8750, 1344213.3750, 1339594.7500,
         1326437.3750, 1323258.3750, 1318911.8750, 1314765.1250, 1311002.6250],
        [1436799.8750, 1409093.0000, 1408241.3750, 1390932.5000, 1378400.8750,
         1363585.8750, 1349692.0000, 1341948.8750, 1321238.3750, 1320594.6250],
        [1450695.1250, 1429411.5000, 1425323.6250, 1415155.8750, 1411213.8750,
         1409032.6250, 1391503.0000, 1386280.2500, 1381986.3750, 1379346.2500],
        [1492228.5000, 1490133.8750, 1451939.3750, 1450172.3750, 1411654.0000,
         1405982.7500, 1405438.6250, 1405273.7500, 1404066.7500, 1401162.6250],
        [1381298.5000, 1352058.6250, 1344835.2500, 1333792.0000, 1323639.6250,
         1321216.8750, 1299351.0000, 1298066.5000, 1290810.3750, 1288959.0000],
        [1443436.2500, 1440614.1250, 1411193.6250, 1389535.0000, 1373904.5000,
         1367427.5000, 1367271.1250, 1365982.0000, 1360489.2500, 1360421.7500],
        [1426388.3750, 1416807.5000, 1414721.3750, 1411631.1250, 1408192.8750,
         1404123.0000, 1371788.7500, 1360717.5000, 1350326.7500, 1324830.5000],
        [1437603.0000, 1430789.0000, 1412622.3750, 1410569.3750, 1404362.6250,
         1394126.2500, 1387030.1250, 1382909.2500, 1378091.8750, 1376713.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1516861.5000,       0.0000],
         [1515924.3750,       0.0000],
         [1514674.2500,       0.0000],
         ...,
         [1508257.0000,       0.0000],
         [1508235.5000,       0.0000],
         [1507809.8750,       0.0000]],

        [[1528220.3750,       0.0000],
         [1522477.3750,       0.0000],
         [1521020.3750,       0.0000],
         ...,
         [1517917.8750,       0.0000],
         [1516975.7500,       0.0000],
         [1516904.8750,       0.0000]],

        [[1315204.0000,       0.0000],
         [1306275.1250,       0.0000],
         [1296698.1250,       0.0000],
         ...,
         [1185207.8750,       0.0000],
         [      0.0000, 1171359.6250],
         [      0.0000, 1171103.8750]],

        ...,

        [[1443436.2500,       0.0000],
         [1440614.1250,       0.0000],
         [1411193.6250,       0.0000],
         ...,
         [1365982.0000,       0.0000],
         [1360489.2500,       0.0000],
         [1360421.7500,       0.0000]],

        [[1426388.3750,       0.0000],
         [1416807.5000,       0.0000],
         [1414721.3750,       0.0000],
         ...,
         [      0.0000, 1360717.5000],
         [      0.0000, 1350326.7500],
         [      0.0000, 1324830.5000]],

        [[      0.0000, 1437603.0000],
         [      0.0000, 1430789.0000],
         [      0.0000, 1412622.3750],
         ...,
         [      0.0000, 1382909.2500],
         [1378091.8750,       0.0000],
         [      0.0000, 1376713.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15116914.0000,        0.0000],
        [15201671.0000,        0.0000],
        [ 8797690.0000,  3563565.5000],
        [14474048.0000,        0.0000],
        [ 9057039.0000,  3864409.5000],
        [10941293.0000,  1205959.1250],
        [ 3356692.0000,  7719540.0000],
        [ 9738419.0000,  2470212.5000],
        [13769967.0000,  1525619.6250],
        [ 9441914.0000,  4011097.0000],
        [13850284.0000,  1537689.3750],
        [12972085.0000,  1450922.0000],
        [14245004.0000,        0.0000],
        [15460396.0000,        0.0000],
        [15321890.0000,        0.0000],
        [15208392.0000,        0.0000],
        [14803110.0000,        0.0000],
        [ 9036570.0000,  5990113.5000],
        [14649078.0000,        0.0000],
        [13698172.0000,  1524861.8750],
        [15328000.0000,        0.0000],
        [10197830.0000,  4364081.0000],
        [15351154.0000,        0.0000],
        [15458528.0000,        0.0000],
        [13438026.0000,  1487467.3750],
        [15365573.0000,        0.0000],
        [15341483.0000,        0.0000],
        [15260017.0000,        0.0000],
        [15435337.0000,        0.0000],
        [15432278.0000,        0.0000],
        [15393172.0000,        0.0000],
        [15381036.0000,        0.0000],
        [ 5058670.5000,  7598766.5000],
        [12028206.0000,  3017649.0000],
        [13740676.0000,  1524395.1250],
        [10528264.0000,  4535223.0000],
        [ 7897945.0000,  5212944.5000],
        [10471012.0000,  4492352.5000],
        [11167154.0000,  2821072.0000],
        [15051463.0000,        0.0000],
        [ 9196695.0000,  3820595.5000],
        [15262982.0000,        0.0000],
        [15234840.0000,        0.0000],
        [13614900.0000,  1513083.3750],
        [ 8459648.0000,  5673982.0000],
        [ 4912801.0000,  7511002.0000],
        [ 7040723.5000,  3357511.0000],
        [ 2099439.5000,  9286369.0000],
        [12575328.0000,  1406558.2500],
        [11497472.0000,  2882450.0000],
        [12757878.0000,  1411632.5000],
        [ 1383046.3750, 12465536.0000],
        [       0.0000, 14146504.0000],
        [ 3835797.0000,  8999324.0000],
        [11418368.0000,  2878622.0000],
        [13171419.0000,  1466196.3750],
        [       0.0000, 13371159.0000],
        [ 1320594.6250, 12399934.0000],
        [       0.0000, 14079948.0000],
        [ 5627142.0000,  8690910.0000],
        [ 6607558.5000,  6626469.0000],
        [11123469.0000,  2756806.0000],
        [ 9853653.0000,  4035874.7500],
        [ 2788661.2500, 11226156.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 67.1875
Top1 accuracy for validation set is 67.1875 size is torch.Size([64, 1])
Epoch 121/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:11, 58.25s/it]  7%|▋         | 2/29 [01:00<11:22, 25.26s/it] 10%|█         | 3/29 [01:01<06:07, 14.15s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.04s/it] 21%|██        | 6/29 [01:04<01:39,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.219748497009277
Epoch 122/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:58, 59.96s/it]  7%|▋         | 2/29 [01:00<11:21, 25.23s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 4.224608898162842
Epoch 123/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:56, 57.74s/it]  7%|▋         | 2/29 [00:58<10:56, 24.32s/it] 10%|█         | 3/29 [00:59<05:54, 13.63s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.62s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.84s/it] 21%|██        | 6/29 [01:02<01:35,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 4.217835903167725
Epoch 124/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:40, 57.16s/it]  7%|▋         | 2/29 [01:01<11:46, 26.17s/it] 10%|█         | 3/29 [01:02<06:20, 14.64s/it] 14%|█▍        | 4/29 [01:03<03:50,  9.22s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.23s/it] 21%|██        | 6/29 [01:05<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.193863391876221
Epoch 125/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.53s/it]  7%|▋         | 2/29 [00:59<11:05, 24.64s/it] 10%|█         | 3/29 [01:00<06:00, 13.86s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.75s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 4.1890411376953125
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0075, 0.0038, 0.0013,  ..., 0.0037, 0.0018, 0.0226],
        [0.0077, 0.0046, 0.0015,  ..., 0.0029, 0.0017, 0.0240],
        [0.0331, 0.0063, 0.0031,  ..., 0.0079, 0.0111, 0.0282],
        ...,
        [0.0062, 0.0092, 0.0023,  ..., 0.0035, 0.0022, 0.0211],
        [0.0060, 0.0091, 0.0012,  ..., 0.0049, 0.0020, 0.0166],
        [0.0162, 0.0070, 0.0010,  ..., 0.0029, 0.0046, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958,
         0.9957],
        [0.9968, 0.9967, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9962, 0.9962,
         0.9962],
        [0.9875, 0.9866, 0.9852, 0.9828, 0.9815, 0.9806, 0.9800, 0.9799, 0.9795,
         0.9793],
        [0.9936, 0.9936, 0.9935, 0.9928, 0.9928, 0.9924, 0.9919, 0.9919, 0.9916,
         0.9915],
        [0.9886, 0.9874, 0.9866, 0.9860, 0.9852, 0.9851, 0.9850, 0.9847, 0.9846,
         0.9845],
        [0.9893, 0.9877, 0.9833, 0.9825, 0.9807, 0.9803, 0.9801, 0.9795, 0.9773,
         0.9759],
        [0.9771, 0.9768, 0.9738, 0.9737, 0.9735, 0.9728, 0.9724, 0.9721, 0.9719,
         0.9716],
        [0.9838, 0.9830, 0.9814, 0.9814, 0.9805, 0.9804, 0.9797, 0.9789, 0.9787,
         0.9786],
        [0.9975, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9932, 0.9887, 0.9882, 0.9874, 0.9874, 0.9869, 0.9862, 0.9862, 0.9861,
         0.9859],
        [0.9979, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9948, 0.9934, 0.9933, 0.9931, 0.9931, 0.9931, 0.9929, 0.9923, 0.9923,
         0.9919],
        [0.9943, 0.9938, 0.9935, 0.9928, 0.9926, 0.9925, 0.9920, 0.9911, 0.9910,
         0.9906],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9976, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9969, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9962],
        [0.9953, 0.9952, 0.9950, 0.9947, 0.9946, 0.9946, 0.9946, 0.9945, 0.9945,
         0.9944],
        [0.9962, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9951],
        [0.9943, 0.9942, 0.9941, 0.9940, 0.9939, 0.9938, 0.9937, 0.9936, 0.9935,
         0.9934],
        [0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964,
         0.9964],
        [0.9973, 0.9972, 0.9972, 0.9971, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9941, 0.9939, 0.9939, 0.9938, 0.9935, 0.9933, 0.9932, 0.9932, 0.9929,
         0.9928],
        [0.9978, 0.9973, 0.9973, 0.9973, 0.9972, 0.9970, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9964, 0.9956, 0.9955, 0.9952, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950,
         0.9948],
        [0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9974, 0.9974, 0.9973, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9968,
         0.9967],
        [0.9969, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9980, 0.9978, 0.9977, 0.9976, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9974, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9891, 0.9877, 0.9877, 0.9868, 0.9836, 0.9808, 0.9806, 0.9804, 0.9789,
         0.9774],
        [0.9962, 0.9962, 0.9961, 0.9960, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9974, 0.9972, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9965, 0.9962, 0.9962, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9913, 0.9890, 0.9882, 0.9852, 0.9852, 0.9847, 0.9833, 0.9829, 0.9826,
         0.9824],
        [0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9952],
        [0.9915, 0.9914, 0.9907, 0.9906, 0.9906, 0.9904, 0.9904, 0.9904, 0.9904,
         0.9902],
        [0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9879, 0.9875, 0.9873, 0.9867, 0.9858, 0.9842, 0.9838, 0.9823, 0.9818,
         0.9811],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9971, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9965],
        [0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9927, 0.9925, 0.9916, 0.9913, 0.9911, 0.9909, 0.9906, 0.9906, 0.9904,
         0.9903],
        [0.9848, 0.9843, 0.9841, 0.9832, 0.9830, 0.9827, 0.9825, 0.9824, 0.9822,
         0.9818],
        [0.9835, 0.9769, 0.9711, 0.9707, 0.9693, 0.9688, 0.9682, 0.9670, 0.9658,
         0.9591],
        [0.9835, 0.9790, 0.9789, 0.9785, 0.9781, 0.9749, 0.9722, 0.9701, 0.9689,
         0.9685],
        [0.9921, 0.9914, 0.9911, 0.9911, 0.9909, 0.9907, 0.9905, 0.9905, 0.9905,
         0.9905],
        [0.9935, 0.9934, 0.9929, 0.9927, 0.9926, 0.9926, 0.9924, 0.9922, 0.9922,
         0.9922],
        [0.9924, 0.9921, 0.9921, 0.9920, 0.9920, 0.9919, 0.9919, 0.9918, 0.9917,
         0.9915],
        [0.9914, 0.9899, 0.9897, 0.9894, 0.9893, 0.9893, 0.9892, 0.9891, 0.9889,
         0.9888],
        [0.9939, 0.9931, 0.9924, 0.9919, 0.9912, 0.9909, 0.9907, 0.9901, 0.9898,
         0.9893],
        [0.9885, 0.9870, 0.9861, 0.9847, 0.9838, 0.9837, 0.9835, 0.9833, 0.9829,
         0.9827],
        [0.9936, 0.9934, 0.9931, 0.9926, 0.9922, 0.9917, 0.9915, 0.9915, 0.9911,
         0.9911],
        [0.9945, 0.9945, 0.9940, 0.9938, 0.9937, 0.9935, 0.9935, 0.9933, 0.9933,
         0.9932],
        [0.9896, 0.9888, 0.9881, 0.9880, 0.9875, 0.9870, 0.9869, 0.9864, 0.9863,
         0.9859],
        [0.9925, 0.9911, 0.9909, 0.9902, 0.9897, 0.9886, 0.9877, 0.9877, 0.9867,
         0.9864],
        [0.9933, 0.9922, 0.9916, 0.9916, 0.9916, 0.9912, 0.9902, 0.9902, 0.9900,
         0.9892],
        [0.9955, 0.9950, 0.9934, 0.9931, 0.9912, 0.9911, 0.9911, 0.9911, 0.9910,
         0.9909],
        [0.9901, 0.9885, 0.9878, 0.9871, 0.9867, 0.9860, 0.9856, 0.9854, 0.9848,
         0.9848],
        [0.9929, 0.9928, 0.9912, 0.9903, 0.9894, 0.9892, 0.9890, 0.9889, 0.9888,
         0.9888],
        [0.9918, 0.9915, 0.9914, 0.9911, 0.9904, 0.9901, 0.9890, 0.9880, 0.9877,
         0.9875],
        [0.9923, 0.9923, 0.9912, 0.9911, 0.9910, 0.9905, 0.9902, 0.9896, 0.9895,
         0.9891]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 0, 1],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 0, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1521143.6250, 1516510.0000, 1514983.3750, 1514612.1250, 1512004.5000,
         1510422.0000, 1509513.2500, 1508824.0000, 1507667.3750, 1505846.7500],
        [1528307.8750, 1526854.0000, 1522982.7500, 1522905.7500, 1520289.5000,
         1519744.3750, 1519038.6250, 1516721.1250, 1516520.1250, 1516319.1250],
        [1339479.7500, 1321624.0000, 1294866.7500, 1250968.6250, 1228990.6250,
         1212331.2500, 1203461.3750, 1200128.5000, 1194422.7500, 1190424.3750],
        [1461292.3750, 1461111.2500, 1459000.3750, 1444364.3750, 1443276.5000,
         1436520.3750, 1425678.3750, 1425439.2500, 1418872.2500, 1418324.2500],
        [1360657.8750, 1336274.7500, 1320983.7500, 1309463.1250, 1295328.6250,
         1293282.1250, 1291099.6250, 1286017.1250, 1284031.8750, 1282171.8750],
        [1373415.8750, 1342763.1250, 1260108.1250, 1245995.3750, 1213890.7500,
         1207953.7500, 1203634.6250, 1193382.1250, 1157561.6250, 1133525.8750],
        [1153018.0000, 1148907.2500, 1100739.0000, 1099006.2500, 1096562.7500,
         1084384.8750, 1078946.6250, 1073885.6250, 1070624.6250, 1065928.0000],
        [1270197.1250, 1254828.0000, 1227774.5000, 1227397.6250, 1211836.5000,
         1209866.5000, 1196780.7500, 1183494.5000, 1180089.7500, 1178082.6250],
        [1545098.2500, 1539313.7500, 1537265.7500, 1534892.5000, 1532251.1250,
         1532151.7500, 1531275.2500, 1530720.5000, 1530719.0000, 1529907.6250],
        [1452830.0000, 1362036.7500, 1352827.3750, 1337548.5000, 1335928.2500,
         1326476.6250, 1314357.6250, 1314224.7500, 1312890.7500, 1308256.1250],
        [1553232.6250, 1544884.5000, 1544036.1250, 1543105.7500, 1542587.8750,
         1539507.3750, 1539241.7500, 1539224.1250, 1538480.0000, 1538031.1250],
        [1485723.5000, 1456548.0000, 1453338.6250, 1450965.0000, 1450159.8750,
         1449830.7500, 1446539.5000, 1433353.7500, 1432773.0000, 1426335.3750],
        [1474861.7500, 1465498.7500, 1459040.7500, 1442905.0000, 1439271.2500,
         1437641.3750, 1427298.7500, 1408524.7500, 1407949.8750, 1400180.8750],
        [1556178.7500, 1553499.3750, 1551355.6250, 1550173.8750, 1547498.8750,
         1547051.7500, 1546500.1250, 1546411.6250, 1545902.8750, 1545201.2500],
        [1545493.1250, 1537932.8750, 1537727.5000, 1536711.6250, 1535955.5000,
         1534920.3750, 1534529.5000, 1533977.8750, 1533698.5000, 1533561.0000],
        [1530815.3750, 1527181.6250, 1525312.7500, 1522730.1250, 1521716.7500,
         1521645.6250, 1520868.0000, 1520760.7500, 1520153.1250, 1516789.1250],
        [1496549.6250, 1494889.3750, 1488984.5000, 1483935.0000, 1482410.2500,
         1480935.1250, 1480627.2500, 1479966.5000, 1478469.8750, 1476739.3750],
        [1515258.0000, 1505661.5000, 1502842.6250, 1501003.5000, 1500313.7500,
         1498875.0000, 1497087.7500, 1496148.6250, 1494257.8750, 1492399.3750],
        [1474411.7500, 1472075.2500, 1471130.7500, 1468494.1250, 1466573.8750,
         1465353.3750, 1462413.3750, 1459669.8750, 1457950.2500, 1457294.1250],
        [1529747.1250, 1528694.1250, 1528324.0000, 1527799.3750, 1527494.8750,
         1525245.8750, 1524581.2500, 1521755.8750, 1520833.2500, 1520059.0000],
        [1540554.6250, 1537932.8750, 1537792.1250, 1536393.6250, 1531637.6250,
         1531272.3750, 1530865.0000, 1529942.6250, 1528542.6250, 1528246.6250],
        [1471480.2500, 1466688.6250, 1465941.7500, 1464315.5000, 1457563.7500,
         1454446.5000, 1452891.0000, 1451600.2500, 1446340.8750, 1443528.3750],
        [1551275.6250, 1540122.7500, 1538995.1250, 1538980.5000, 1537215.7500,
         1533230.5000, 1531831.8750, 1531161.3750, 1529528.2500, 1528831.2500],
        [1553726.0000, 1552262.7500, 1550553.8750, 1547643.5000, 1547400.0000,
         1546945.5000, 1545979.5000, 1545519.6250, 1543881.5000, 1543788.7500],
        [1521127.6250, 1503667.0000, 1499934.5000, 1494890.6250, 1494461.6250,
         1493344.7500, 1491074.8750, 1490341.3750, 1489021.5000, 1486096.2500],
        [1539645.5000, 1539313.7500, 1538923.2500, 1538883.6250, 1537343.3750,
         1535601.1250, 1535298.0000, 1535182.2500, 1534027.6250, 1533844.7500],
        [1542596.6250, 1542405.5000, 1539820.1250, 1536732.0000, 1535238.0000,
         1534703.6250, 1531417.0000, 1530110.3750, 1527975.6250, 1526578.8750],
        [1531189.1250, 1529738.3750, 1529544.3750, 1528778.7500, 1526973.3750,
         1526708.3750, 1526596.3750, 1526017.0000, 1525480.0000, 1524302.1250],
        [1549526.5000, 1548352.1250, 1544385.1250, 1544093.5000, 1543076.3750,
         1542826.2500, 1542780.6250, 1542764.3750, 1542704.1250, 1542349.5000],
        [1554416.6250, 1550259.5000, 1547620.0000, 1547066.6250, 1542867.3750,
         1541548.1250, 1540982.2500, 1539718.8750, 1539645.5000, 1538616.5000],
        [1542530.5000, 1542490.7500, 1541595.2500, 1540757.3750, 1540184.5000,
         1539890.6250, 1539842.2500, 1539404.6250, 1539291.6250, 1539234.3750],
        [1541881.8750, 1541495.2500, 1541404.0000, 1540913.1250, 1540822.1250,
         1540269.6250, 1540122.7500, 1539918.6250, 1539896.6250, 1539735.0000],
        [1369153.8750, 1342029.5000, 1341700.6250, 1326228.6250, 1266971.8750,
         1215684.1250, 1213428.8750, 1208690.1250, 1183823.0000, 1158102.7500],
        [1515625.1250, 1514966.1250, 1514547.2500, 1511867.3750, 1506527.7500,
         1505940.1250, 1505506.5000, 1504553.3750, 1504207.7500, 1503893.5000],
        [1541224.7500, 1538546.0000, 1530444.6250, 1529353.2500, 1528934.7500,
         1526184.2500, 1525926.6250, 1525474.2500, 1525192.0000, 1525192.0000],
        [1523205.0000, 1516362.5000, 1515788.5000, 1507939.2500, 1507060.8750,
         1505775.0000, 1505340.0000, 1504857.6250, 1502190.7500, 1500763.0000],
        [1412716.6250, 1368162.0000, 1351278.7500, 1295804.3750, 1295595.5000,
         1286850.1250, 1261374.2500, 1253634.2500, 1248194.3750, 1243733.6250],
        [1507295.1250, 1506338.0000, 1504800.2500, 1504124.5000, 1502106.1250,
         1499821.5000, 1499785.8750, 1498567.7500, 1496873.6250, 1495301.3750],
        [1417095.2500, 1415035.7500, 1401165.3750, 1399672.2500, 1399508.0000,
         1395995.6250, 1395865.1250, 1395670.7500, 1395407.2500, 1390929.7500],
        [1513024.1250, 1511762.2500, 1510145.3750, 1508530.3750, 1508457.1250,
         1508106.1250, 1507663.1250, 1505065.8750, 1504169.0000, 1502477.2500],
        [1346801.5000, 1338587.2500, 1334205.5000, 1323692.6250, 1306818.3750,
         1276823.5000, 1268863.0000, 1242389.3750, 1233317.1250, 1222372.2500],
        [1537023.7500, 1532302.2500, 1530771.6250, 1529392.7500, 1528402.6250,
         1528004.7500, 1526948.7500, 1526335.7500, 1526123.2500, 1525758.0000],
        [1535539.6250, 1526149.3750, 1524915.6250, 1524235.2500, 1523951.7500,
         1522533.8750, 1522417.7500, 1522165.2500, 1521776.2500, 1521438.1250],
        [1517412.7500, 1514895.2500, 1513374.8750, 1513068.8750, 1512817.8750,
         1512376.3750, 1512215.0000, 1512095.2500, 1511649.6250, 1511469.6250],
        [1442166.2500, 1437393.2500, 1420167.6250, 1412369.0000, 1410051.5000,
         1405466.7500, 1399691.0000, 1399408.0000, 1395822.5000, 1393514.8750],
        [1288095.1250, 1279436.8750, 1274842.6250, 1259518.2500, 1254999.1250,
         1249411.5000, 1245972.7500, 1245313.5000, 1241653.8750, 1234051.3750],
        [1263665.5000, 1150741.8750, 1058385.7500, 1053321.7500, 1032210.0625,
         1025421.5000, 1016190.6875,  998687.8750,  981811.2500,  892658.6875],
        [1264307.8750, 1185878.3750, 1183125.5000, 1176749.7500, 1170103.6250,
         1118674.7500, 1076546.6250, 1044346.5625, 1026415.5625, 1019749.6250],
        [1430285.5000, 1415157.2500, 1409844.3750, 1408593.2500, 1404674.7500,
         1401780.2500, 1397984.7500, 1397560.8750, 1397122.2500, 1396588.1250],
        [1457686.0000, 1455517.6250, 1445098.6250, 1442402.7500, 1440258.3750,
         1439543.0000, 1436393.0000, 1432009.3750, 1432005.2500, 1431661.1250],
        [1435131.8750, 1429954.1250, 1429738.6250, 1427946.7500, 1427010.1250,
         1424993.3750, 1424951.1250, 1422921.1250, 1421248.8750, 1417465.5000],
        [1414637.7500, 1384700.0000, 1381248.3750, 1375653.5000, 1373359.6250,
         1372995.5000, 1372083.1250, 1369548.3750, 1364778.8750, 1363234.7500],
        [1466161.3750, 1450632.8750, 1434687.1250, 1426106.8750, 1411347.1250,
         1405035.2500, 1401724.1250, 1390087.7500, 1382815.5000, 1372732.2500],
        [1356994.3750, 1328838.0000, 1312162.1250, 1286042.8750, 1270073.6250,
         1268683.8750, 1264257.3750, 1260266.7500, 1253030.6250, 1249253.1250],
        [1461062.5000, 1457282.8750, 1450206.8750, 1440409.6250, 1431033.2500,
         1421861.6250, 1417898.2500, 1417606.2500, 1409550.0000, 1408511.2500],
        [1479533.2500, 1479009.8750, 1469582.7500, 1464846.2500, 1463455.3750,
         1459095.0000, 1457783.3750, 1454252.2500, 1453909.7500, 1452259.2500],
        [1378670.3750, 1363666.5000, 1350405.2500, 1348258.8750, 1338457.0000,
         1329287.8750, 1327661.2500, 1317926.0000, 1315153.8750, 1307856.8750],
        [1438033.6250, 1409520.3750, 1405592.7500, 1391158.0000, 1381945.5000,
         1360425.6250, 1342548.0000, 1342485.1250, 1323084.3750, 1318227.7500],
        [1454833.5000, 1430557.0000, 1420312.6250, 1420202.8750, 1419512.3750,
         1410323.2500, 1392129.3750, 1391489.6250, 1388176.1250, 1371948.3750],
        [1500569.8750, 1489562.6250, 1456899.5000, 1449890.1250, 1411850.5000,
         1409477.3750, 1408966.6250, 1408507.2500, 1406548.7500, 1406197.3750],
        [1389120.3750, 1357100.6250, 1345190.5000, 1331785.1250, 1323964.0000,
         1309516.8750, 1303084.8750, 1299642.2500, 1288047.2500, 1287155.7500],
        [1445327.5000, 1443797.0000, 1410387.7500, 1392954.2500, 1375900.1250,
         1370827.6250, 1367872.2500, 1366503.2500, 1363562.3750, 1363491.0000],
        [1423678.5000, 1417372.3750, 1416109.1250, 1409222.0000, 1394905.7500,
         1389399.8750, 1367422.3750, 1347641.7500, 1341854.1250, 1338522.1250],
        [1433856.8750, 1432692.3750, 1410360.8750, 1410095.8750, 1408104.3750,
         1397602.1250, 1391899.8750, 1379301.6250, 1377144.7500, 1369076.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1521143.6250,       0.0000],
         [1516510.0000,       0.0000],
         [1514983.3750,       0.0000],
         ...,
         [1508824.0000,       0.0000],
         [      0.0000, 1507667.3750],
         [1505846.7500,       0.0000]],

        [[1528307.8750,       0.0000],
         [1526854.0000,       0.0000],
         [1522982.7500,       0.0000],
         ...,
         [1516721.1250,       0.0000],
         [1516520.1250,       0.0000],
         [1516319.1250,       0.0000]],

        [[1339479.7500,       0.0000],
         [1321624.0000,       0.0000],
         [1294866.7500,       0.0000],
         ...,
         [      0.0000, 1200128.5000],
         [1194422.7500,       0.0000],
         [1190424.3750,       0.0000]],

        ...,

        [[1445327.5000,       0.0000],
         [1443797.0000,       0.0000],
         [1410387.7500,       0.0000],
         ...,
         [1366503.2500,       0.0000],
         [1363562.3750,       0.0000],
         [      0.0000, 1363491.0000]],

        [[1423678.5000,       0.0000],
         [1417372.3750,       0.0000],
         [1416109.1250,       0.0000],
         ...,
         [      0.0000, 1347641.7500],
         [      0.0000, 1341854.1250],
         [      0.0000, 1338522.1250]],

        [[      0.0000, 1433856.8750],
         [      0.0000, 1432692.3750],
         [1410360.8750,       0.0000],
         ...,
         [      0.0000, 1379301.6250],
         [1377144.7500,       0.0000],
         [      0.0000, 1369076.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13613860.0000,  1507667.3750],
        [15209683.0000,        0.0000],
        [10033109.0000,  2403590.0000],
        [14393880.0000,        0.0000],
        [ 7876795.0000,  5182516.0000],
        [11128596.0000,  1203634.6250],
        [ 4378166.5000,  6593836.5000],
        [ 9703084.0000,  2437264.0000],
        [13811344.0000,  1532251.1250],
        [ 9440615.0000,  3976762.5000],
        [13883852.0000,  1538480.0000],
        [13035737.0000,  1449830.7500],
        [14363174.0000,        0.0000],
        [15489774.0000,        0.0000],
        [15364508.0000,        0.0000],
        [15227974.0000,        0.0000],
        [14843508.0000,        0.0000],
        [ 9015370.0000,  5988478.5000],
        [14655366.0000,        0.0000],
        [13724787.0000,  1529747.1250],
        [15333180.0000,        0.0000],
        [10212506.0000,  4362290.5000],
        [15361173.0000,        0.0000],
        [15477701.0000,        0.0000],
        [13469498.0000,  1494461.6250],
        [15368063.0000,        0.0000],
        [15347578.0000,        0.0000],
        [15275329.0000,        0.0000],
        [15442859.0000,        0.0000],
        [15442742.0000,        0.0000],
        [15405222.0000,        0.0000],
        [15406459.0000,        0.0000],
        [ 5050523.0000,  7575290.5000],
        [12060142.0000,  3027492.5000],
        [13767119.0000,  1529353.2500],
        [10545431.0000,  4543851.0000],
        [ 7845885.5000,  5171459.0000],
        [ 9009110.0000,  6005904.0000],
        [ 8405464.0000,  5600881.0000],
        [15079400.0000,        0.0000],
        [ 9111346.0000,  3782525.0000],
        [15291064.0000,        0.0000],
        [15245124.0000,        0.0000],
        [13618999.0000,  1512376.3750],
        [ 8435881.0000,  5680169.5000],
        [ 3746064.5000,  8827231.0000],
        [ 7130686.0000,  3342408.7500],
        [ 2046165.2500,  9219733.0000],
        [12654916.0000,  1404674.7500],
        [11512485.0000,  2900088.7500],
        [12831408.0000,  1429954.1250],
        [ 1372995.5000, 12399244.0000],
        [       0.0000, 14141330.0000],
        [ 3793208.0000,  9056394.0000],
        [11432498.0000,  2882924.0000],
        [11714970.0000,  2918756.0000],
        [       0.0000, 13377345.0000],
        [ 1323084.3750, 12389937.0000],
        [       0.0000, 14099484.0000],
        [ 5633500.0000,  8714970.0000],
        [ 6565469.0000,  6669138.0000],
        [11144177.0000,  2756445.2500],
        [ 9818110.0000,  4028018.0000],
        [ 2787505.5000, 11222630.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 67.1875
Top1 accuracy for validation set is 67.1875 size is torch.Size([64, 1])
Epoch 126/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:53, 59.77s/it]  7%|▋         | 2/29 [01:00<11:19, 25.15s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 4.192825794219971
Epoch 127/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:31, 56.84s/it]  7%|▋         | 2/29 [00:58<10:59, 24.43s/it] 10%|█         | 3/29 [00:59<05:56, 13.69s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 4.18319845199585
Epoch 128/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:20, 56.44s/it]  7%|▋         | 2/29 [00:57<10:42, 23.78s/it] 10%|█         | 3/29 [00:58<05:46, 13.34s/it] 14%|█▍        | 4/29 [00:59<03:30,  8.44s/it] 17%|█▋        | 5/29 [01:01<02:32,  6.35s/it] 21%|██        | 6/29 [01:02<01:43,  4.51s/it] 24%|██▍       | 7/29 [01:03<01:13,  3.33s/it] 28%|██▊       | 8/29 [01:04<00:53,  2.57s/it] 31%|███       | 9/29 [01:05<00:41,  2.05s/it] 34%|███▍      | 10/29 [01:06<00:32,  1.70s/it] 38%|███▊      | 11/29 [01:07<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:08<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 4.170442581176758
Epoch 129/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:20, 56.43s/it]  7%|▋         | 2/29 [00:58<10:58, 24.37s/it] 10%|█         | 3/29 [01:01<06:22, 14.71s/it] 14%|█▍        | 4/29 [01:02<03:51,  9.27s/it] 17%|█▋        | 5/29 [01:03<02:30,  6.26s/it] 21%|██        | 6/29 [01:04<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:05<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:06<00:53,  2.54s/it] 31%|███       | 9/29 [01:07<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:08<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.1624369621276855
Epoch 130/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:10, 60.39s/it]  7%|▋         | 2/29 [01:01<11:28, 25.49s/it] 10%|█         | 3/29 [01:02<06:11, 14.27s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.157641887664795
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0066, 0.0039, 0.0013,  ..., 0.0040, 0.0017, 0.0230],
        [0.0063, 0.0049, 0.0014,  ..., 0.0027, 0.0013, 0.0242],
        [0.0321, 0.0067, 0.0027,  ..., 0.0074, 0.0126, 0.0287],
        ...,
        [0.0058, 0.0087, 0.0024,  ..., 0.0035, 0.0018, 0.0217],
        [0.0058, 0.0092, 0.0014,  ..., 0.0046, 0.0019, 0.0176],
        [0.0150, 0.0070, 0.0011,  ..., 0.0026, 0.0043, 0.0223]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959,
         0.9958],
        [0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9875, 0.9866, 0.9844, 0.9821, 0.9820, 0.9803, 0.9794, 0.9790, 0.9788,
         0.9785],
        [0.9940, 0.9940, 0.9939, 0.9933, 0.9929, 0.9928, 0.9924, 0.9922, 0.9922,
         0.9921],
        [0.9889, 0.9881, 0.9878, 0.9865, 0.9864, 0.9862, 0.9861, 0.9856, 0.9852,
         0.9850],
        [0.9898, 0.9883, 0.9848, 0.9829, 0.9829, 0.9824, 0.9816, 0.9803, 0.9798,
         0.9779],
        [0.9800, 0.9752, 0.9748, 0.9744, 0.9738, 0.9737, 0.9731, 0.9730, 0.9729,
         0.9726],
        [0.9834, 0.9833, 0.9817, 0.9816, 0.9809, 0.9798, 0.9797, 0.9795, 0.9791,
         0.9790],
        [0.9976, 0.9974, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9936, 0.9891, 0.9890, 0.9884, 0.9880, 0.9870, 0.9867, 0.9865, 0.9864,
         0.9861],
        [0.9980, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9973],
        [0.9946, 0.9934, 0.9933, 0.9931, 0.9931, 0.9929, 0.9927, 0.9926, 0.9923,
         0.9923],
        [0.9945, 0.9945, 0.9934, 0.9933, 0.9929, 0.9924, 0.9924, 0.9919, 0.9913,
         0.9910],
        [0.9981, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9976, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9970],
        [0.9970, 0.9970, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9965,
         0.9965],
        [0.9954, 0.9954, 0.9950, 0.9947, 0.9947, 0.9947, 0.9947, 0.9947, 0.9947,
         0.9946],
        [0.9962, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957, 0.9955, 0.9954, 0.9953,
         0.9953],
        [0.9942, 0.9941, 0.9940, 0.9939, 0.9937, 0.9937, 0.9936, 0.9936, 0.9935,
         0.9935],
        [0.9971, 0.9970, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9943, 0.9941, 0.9938, 0.9938, 0.9935, 0.9934, 0.9934, 0.9932, 0.9930,
         0.9929],
        [0.9979, 0.9974, 0.9974, 0.9974, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9969],
        [0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9964, 0.9956, 0.9955, 0.9952, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950,
         0.9949],
        [0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9974, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9968,
         0.9968],
        [0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9977, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9889, 0.9880, 0.9873, 0.9862, 0.9835, 0.9805, 0.9800, 0.9794, 0.9776,
         0.9769],
        [0.9965, 0.9964, 0.9962, 0.9961, 0.9959, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9974, 0.9974, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9967, 0.9963, 0.9962, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9913, 0.9890, 0.9880, 0.9851, 0.9849, 0.9843, 0.9838, 0.9837, 0.9832,
         0.9826],
        [0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9954],
        [0.9921, 0.9917, 0.9914, 0.9911, 0.9911, 0.9909, 0.9907, 0.9907, 0.9906,
         0.9906],
        [0.9961, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9957, 0.9957,
         0.9956],
        [0.9881, 0.9881, 0.9874, 0.9860, 0.9848, 0.9846, 0.9836, 0.9835, 0.9824,
         0.9821],
        [0.9973, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9972, 0.9968, 0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9930, 0.9921, 0.9919, 0.9917, 0.9911, 0.9909, 0.9908, 0.9908, 0.9906,
         0.9903],
        [0.9855, 0.9855, 0.9846, 0.9845, 0.9841, 0.9836, 0.9836, 0.9829, 0.9826,
         0.9825],
        [0.9858, 0.9773, 0.9711, 0.9711, 0.9694, 0.9686, 0.9679, 0.9677, 0.9658,
         0.9602],
        [0.9822, 0.9784, 0.9773, 0.9765, 0.9751, 0.9731, 0.9710, 0.9699, 0.9696,
         0.9680],
        [0.9925, 0.9917, 0.9913, 0.9912, 0.9910, 0.9908, 0.9906, 0.9906, 0.9904,
         0.9904],
        [0.9937, 0.9937, 0.9935, 0.9931, 0.9929, 0.9926, 0.9925, 0.9925, 0.9924,
         0.9924],
        [0.9928, 0.9926, 0.9925, 0.9924, 0.9924, 0.9924, 0.9924, 0.9920, 0.9918,
         0.9918],
        [0.9908, 0.9899, 0.9896, 0.9893, 0.9892, 0.9892, 0.9886, 0.9882, 0.9881,
         0.9878],
        [0.9944, 0.9937, 0.9928, 0.9921, 0.9915, 0.9912, 0.9908, 0.9900, 0.9898,
         0.9894],
        [0.9889, 0.9878, 0.9869, 0.9855, 0.9844, 0.9843, 0.9843, 0.9839, 0.9834,
         0.9833],
        [0.9937, 0.9936, 0.9932, 0.9925, 0.9923, 0.9916, 0.9915, 0.9912, 0.9912,
         0.9911],
        [0.9948, 0.9947, 0.9943, 0.9942, 0.9940, 0.9939, 0.9937, 0.9937, 0.9936,
         0.9934],
        [0.9899, 0.9888, 0.9882, 0.9881, 0.9876, 0.9875, 0.9873, 0.9865, 0.9864,
         0.9859],
        [0.9929, 0.9918, 0.9912, 0.9908, 0.9897, 0.9892, 0.9879, 0.9877, 0.9870,
         0.9867],
        [0.9938, 0.9924, 0.9921, 0.9918, 0.9918, 0.9915, 0.9913, 0.9909, 0.9904,
         0.9896],
        [0.9955, 0.9954, 0.9934, 0.9931, 0.9918, 0.9915, 0.9913, 0.9912, 0.9912,
         0.9912],
        [0.9910, 0.9893, 0.9880, 0.9879, 0.9878, 0.9859, 0.9858, 0.9857, 0.9854,
         0.9853],
        [0.9930, 0.9930, 0.9910, 0.9907, 0.9900, 0.9898, 0.9895, 0.9895, 0.9892,
         0.9891],
        [0.9917, 0.9916, 0.9914, 0.9912, 0.9902, 0.9897, 0.9894, 0.9883, 0.9878,
         0.9877],
        [0.9929, 0.9926, 0.9916, 0.9915, 0.9912, 0.9909, 0.9906, 0.9899, 0.9897,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 1, 0, 1, 1, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 1, 1, 0],
        [0, 1, 1, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1525357.8750, 1515203.1250, 1514862.1250, 1513870.0000, 1513783.2500,
         1511619.5000, 1511050.1250, 1510547.2500, 1509156.3750, 1507750.8750],
        [1528850.1250, 1526354.6250, 1524860.3750, 1524367.5000, 1524002.6250,
         1523877.6250, 1521982.3750, 1520841.8750, 1520569.2500, 1520446.0000],
        [1339505.3750, 1322140.8750, 1279833.5000, 1239385.8750, 1238322.5000,
         1207177.6250, 1192812.0000, 1186236.8750, 1182404.7500, 1177723.1250],
        [1469663.8750, 1467879.3750, 1465853.7500, 1453617.2500, 1445195.1250,
         1443978.6250, 1434970.3750, 1432562.6250, 1430636.1250, 1429685.5000],
        [1365418.1250, 1350031.8750, 1343477.7500, 1320553.0000, 1318465.3750,
         1314376.5000, 1311764.2500, 1302419.0000, 1295528.7500, 1292555.8750],
        [1383797.0000, 1353730.7500, 1288740.1250, 1253816.0000, 1253311.5000,
         1245422.7500, 1230052.8750, 1207167.2500, 1198764.8750, 1167531.0000],
        [1201837.3750, 1122512.2500, 1117041.5000, 1110260.2500, 1100728.5000,
         1098351.3750, 1089001.8750, 1087544.6250, 1086538.0000, 1081602.5000],
        [1261793.0000, 1260804.1250, 1232300.2500, 1229779.6250, 1218953.2500,
         1199937.2500, 1197866.6250, 1193391.2500, 1186583.1250, 1186142.0000],
        [1545751.0000, 1541176.1250, 1536803.8750, 1534497.2500, 1534349.5000,
         1530453.5000, 1530252.0000, 1529868.1250, 1529592.5000, 1529017.8750],
        [1460456.5000, 1368935.8750, 1368002.7500, 1356398.0000, 1347772.8750,
         1328756.8750, 1323464.1250, 1318835.1250, 1318394.8750, 1311477.7500],
        [1555475.5000, 1547721.7500, 1547140.3750, 1545745.1250, 1544542.7500,
         1543691.5000, 1543235.2500, 1542380.5000, 1542046.6250, 1540225.6250],
        [1482324.0000, 1455517.6250, 1453358.0000, 1450646.6250, 1450215.1250,
         1445739.6250, 1441563.8750, 1439559.3750, 1434350.6250, 1433306.0000],
        [1479553.1250, 1479002.7500, 1456075.7500, 1454918.1250, 1446861.0000,
         1434963.6250, 1434932.1250, 1425977.6250, 1412680.2500, 1406751.3750],
        [1557577.5000, 1553869.7500, 1551747.6250, 1550500.6250, 1549662.5000,
         1548925.1250, 1547072.5000, 1545532.8750, 1545279.3750, 1545045.1250],
        [1546683.0000, 1542536.3750, 1542376.0000, 1540285.7500, 1539021.6250,
         1537646.8750, 1536985.6250, 1536499.1250, 1534551.5000, 1534181.2500],
        [1532382.6250, 1532296.5000, 1529047.0000, 1528764.1250, 1527713.3750,
         1525890.3750, 1525771.1250, 1524399.5000, 1522401.8750, 1521268.3750],
        [1499319.5000, 1497586.1250, 1490747.8750, 1484624.3750, 1484618.7500,
         1484447.3750, 1483683.2500, 1483432.7500, 1483192.2500, 1482239.2500],
        [1515453.1250, 1507519.3750, 1505559.6250, 1504775.8750, 1504626.6250,
         1504204.8750, 1500471.0000, 1498120.3750, 1496946.5000, 1496244.2500],
        [1472493.7500, 1471014.3750, 1468757.5000, 1466501.1250, 1463510.0000,
         1461720.3750, 1460327.0000, 1460065.1250, 1459438.7500, 1459351.1250],
        [1534411.0000, 1534241.2500, 1529573.5000, 1528936.1250, 1528532.3750,
         1528316.6250, 1527760.0000, 1527215.2500, 1527009.7500, 1526118.8750],
        [1542911.5000, 1539901.0000, 1539621.8750, 1538135.3750, 1535800.2500,
         1534008.6250, 1531469.5000, 1531368.7500, 1531218.3750, 1530670.8750],
        [1475039.0000, 1471074.6250, 1464713.5000, 1464060.0000, 1457380.2500,
         1457032.8750, 1455412.1250, 1452656.8750, 1448975.1250, 1445803.1250],
        [1552459.6250, 1542601.1250, 1542351.0000, 1541417.2500, 1539071.3750,
         1535404.8750, 1534405.1250, 1534301.1250, 1532134.2500, 1531881.5000],
        [1555256.0000, 1554728.0000, 1554653.8750, 1553087.5000, 1552797.2500,
         1548356.6250, 1547476.7500, 1546985.3750, 1545319.2500, 1544878.6250],
        [1520611.2500, 1502624.8750, 1499744.2500, 1494627.0000, 1494283.6250,
         1493500.0000, 1492203.0000, 1490968.2500, 1489802.6250, 1488773.0000],
        [1543088.1250, 1542665.8750, 1541964.2500, 1539804.0000, 1539682.2500,
         1538896.8750, 1538155.7500, 1537846.3750, 1537208.5000, 1537136.6250],
        [1542311.2500, 1539130.1250, 1538613.5000, 1536365.7500, 1534090.5000,
         1532811.0000, 1532512.7500, 1531507.6250, 1529578.0000, 1529274.5000],
        [1537362.3750, 1536664.7500, 1535328.7500, 1534734.3750, 1532506.8750,
         1531700.3750, 1531106.0000, 1530574.5000, 1530243.2500, 1529238.0000],
        [1552512.8750, 1552215.2500, 1549064.0000, 1548177.8750, 1547255.3750,
         1546647.6250, 1546626.8750, 1545655.2500, 1545073.1250, 1544930.2500],
        [1556429.6250, 1551604.1250, 1550824.5000, 1550716.5000, 1548068.6250,
         1543158.7500, 1543063.1250, 1542196.6250, 1541358.3750, 1540999.8750],
        [1549554.5000, 1547188.8750, 1546635.7500, 1546585.6250, 1544189.2500,
         1543806.5000, 1543525.2500, 1543210.2500, 1542662.8750, 1542655.5000],
        [1545518.1250, 1545497.5000, 1545130.5000, 1544805.0000, 1543501.7500,
         1543419.2500, 1543233.8750, 1542314.2500, 1542058.2500, 1541002.7500],
        [1366065.5000, 1347729.2500, 1334404.0000, 1314222.2500, 1264104.2500,
         1211106.2500, 1203362.6250, 1192905.2500, 1161903.7500, 1150912.0000],
        [1521671.7500, 1519890.7500, 1516054.5000, 1514012.8750, 1509920.7500,
         1509084.3750, 1508677.2500, 1508530.3750, 1508090.2500, 1508067.2500],
        [1541634.8750, 1540911.7500, 1533988.1250, 1533072.6250, 1532998.0000,
         1530492.7500, 1530492.7500, 1529353.2500, 1528682.5000, 1528535.2500],
        [1526759.3750, 1516949.7500, 1515885.2500, 1510999.6250, 1509401.0000,
         1507933.5000, 1507371.3750, 1504806.1250, 1503500.6250, 1502286.6250],
        [1413904.1250, 1368425.5000, 1348876.1250, 1292774.0000, 1289593.3750,
         1278823.3750, 1269703.0000, 1268092.3750, 1258159.2500, 1247825.5000],
        [1510614.8750, 1509221.1250, 1508416.7500, 1508130.5000, 1508014.0000,
         1505766.3750, 1505686.0000, 1503725.7500, 1501623.3750, 1499029.2500],
        [1429718.2500, 1421323.3750, 1414506.8750, 1409316.1250, 1408546.2500,
         1405326.0000, 1401986.1250, 1400427.8750, 1399605.5000, 1399191.7500],
        [1513431.1250, 1511233.1250, 1510999.6250, 1510707.1250, 1510244.7500,
         1510051.8750, 1509863.2500, 1505370.1250, 1504592.2500, 1503664.0000],
        [1349847.7500, 1349294.3750, 1335756.2500, 1310051.5000, 1288150.5000,
         1284730.0000, 1266386.0000, 1263688.3750, 1244943.0000, 1239130.6250],
        [1540573.7500, 1537602.8750, 1536327.6250, 1534570.5000, 1531714.8750,
         1531690.1250, 1531019.8750, 1529633.3750, 1529567.7500, 1529420.3750],
        [1538103.0000, 1529839.1250, 1529214.7500, 1527898.3750, 1525384.0000,
         1525097.5000, 1524888.1250, 1524813.8750, 1524811.0000, 1524027.3750],
        [1518678.0000, 1517572.0000, 1516971.3750, 1516524.5000, 1516379.7500,
         1516271.3750, 1515931.6250, 1515612.1250, 1514287.2500, 1513923.3750],
        [1447839.6250, 1429268.2500, 1425255.7500, 1421751.7500, 1408894.1250,
         1404930.6250, 1402879.5000, 1402327.1250, 1399262.5000, 1393650.5000],
        [1301256.8750, 1300763.1250, 1283893.5000, 1281657.1250, 1274906.0000,
         1266625.1250, 1266512.7500, 1253469.2500, 1247379.2500, 1247029.5000],
        [1307293.2500, 1156369.0000, 1059628.8750, 1059096.5000, 1033105.2500,
         1022596.2500, 1012233.7500, 1009482.4375,  981487.3750,  906327.0625],
        [1240373.2500, 1175457.6250, 1156927.1250, 1143453.8750, 1121716.1250,
         1089434.0000, 1057246.7500, 1041167.2500, 1035929.9375, 1013587.1250],
        [1437009.6250, 1420903.2500, 1412429.6250, 1410652.6250, 1407552.5000,
         1403556.6250, 1398819.5000, 1398474.1250, 1394667.6250, 1394262.0000],
        [1463389.8750, 1463169.3750, 1459444.2500, 1450606.6250, 1445931.2500,
         1439760.0000, 1437880.1250, 1437097.2500, 1436013.6250, 1435301.6250],
        [1443763.8750, 1439213.5000, 1437359.1250, 1435995.7500, 1435419.3750,
         1435416.6250, 1435011.5000, 1428499.7500, 1423826.5000, 1423351.3750],
        [1404100.2500, 1386000.1250, 1379339.7500, 1373155.2500, 1372318.7500,
         1372118.5000, 1358886.5000, 1352143.7500, 1349898.0000, 1345123.8750],
        [1476973.2500, 1461914.1250, 1442898.1250, 1429441.5000, 1417041.1250,
         1410909.7500, 1403295.6250, 1386911.1250, 1382355.3750, 1374992.5000],
        [1365104.2500, 1343684.1250, 1327334.5000, 1300604.3750, 1279819.0000,
         1279324.6250, 1278861.2500, 1270957.0000, 1263347.3750, 1261533.0000],
        [1462112.1250, 1460924.5000, 1451778.7500, 1438013.0000, 1433861.0000,
         1419054.8750, 1418041.5000, 1411469.5000, 1410483.2500, 1409297.3750],
        [1486619.3750, 1483565.7500, 1475233.1250, 1472801.2500, 1468645.3750,
         1467232.8750, 1462580.6250, 1461933.6250, 1460778.3750, 1457366.3750],
        [1384496.6250, 1364666.8750, 1352007.1250, 1350974.6250, 1340508.5000,
         1339534.8750, 1334376.0000, 1320004.0000, 1317708.7500, 1308234.8750],
        [1446389.1250, 1422793.5000, 1410897.6250, 1403715.8750, 1381315.6250,
         1371110.0000, 1347086.6250, 1341932.2500, 1328916.5000, 1322977.1250],
        [1463826.7500, 1435819.1250, 1429408.7500, 1424164.6250, 1423002.5000,
         1416766.8750, 1412432.3750, 1404377.3750, 1395618.8750, 1379035.8750],
        [1499981.7500, 1498039.0000, 1456767.3750, 1450191.6250, 1424402.3750,
         1416664.1250, 1412542.8750, 1412176.5000, 1411415.7500, 1411177.5000],
        [1406476.3750, 1373291.5000, 1348100.6250, 1345590.8750, 1343613.6250,
         1309154.7500, 1307101.2500, 1305329.8750, 1299924.8750, 1297953.8750],
        [1447548.3750, 1447248.8750, 1406689.6250, 1401841.6250, 1387166.3750,
         1382729.8750, 1377069.8750, 1376455.3750, 1372384.1250, 1368849.7500],
        [1421101.1250, 1420224.6250, 1414374.7500, 1411388.8750, 1391479.0000,
         1380380.6250, 1375935.6250, 1353765.6250, 1344018.5000, 1343299.6250],
        [1446970.0000, 1440204.8750, 1420035.0000, 1418086.2500, 1410366.2500,
         1406019.0000, 1399808.3750, 1386215.5000, 1380522.7500, 1380291.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1525357.8750,       0.0000],
         [1515203.1250,       0.0000],
         [1514862.1250,       0.0000],
         ...,
         [1510547.2500,       0.0000],
         [1509156.3750,       0.0000],
         [1507750.8750,       0.0000]],

        [[1528850.1250,       0.0000],
         [1526354.6250,       0.0000],
         [1524860.3750,       0.0000],
         ...,
         [1520841.8750,       0.0000],
         [      0.0000, 1520569.2500],
         [1520446.0000,       0.0000]],

        [[1339505.3750,       0.0000],
         [1322140.8750,       0.0000],
         [1279833.5000,       0.0000],
         ...,
         [1186236.8750,       0.0000],
         [      0.0000, 1182404.7500],
         [      0.0000, 1177723.1250]],

        ...,

        [[1447548.3750,       0.0000],
         [1447248.8750,       0.0000],
         [1406689.6250,       0.0000],
         ...,
         [1376455.3750,       0.0000],
         [1372384.1250,       0.0000],
         [1368849.7500,       0.0000]],

        [[1421101.1250,       0.0000],
         [1420224.6250,       0.0000],
         [1414374.7500,       0.0000],
         ...,
         [      0.0000, 1353765.6250],
         [      0.0000, 1344018.5000],
         [      0.0000, 1343299.6250]],

        [[      0.0000, 1446970.0000],
         [      0.0000, 1440204.8750],
         [      0.0000, 1420035.0000],
         ...,
         [      0.0000, 1386215.5000],
         [      0.0000, 1380522.7500],
         [1380291.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13622150.0000,  1511050.1250],
        [13715584.0000,  1520569.2500],
        [ 8812603.0000,  3552940.0000],
        [14474042.0000,        0.0000],
        [ 6643443.0000,  6571148.0000],
        [11329023.0000,  1253311.5000],
        [ 6692576.5000,  4402842.0000],
        [ 9716297.0000,  2451253.5000],
        [13807264.0000,  1534497.2500],
        [ 9492193.0000,  4010302.0000],
        [13908514.0000,  1543691.5000],
        [13045016.0000,  1441563.8750],
        [14431716.0000,        0.0000],
        [13949934.0000,  1545279.3750],
        [15390767.0000,        0.0000],
        [15269936.0000,        0.0000],
        [14873892.0000,        0.0000],
        [ 9023605.0000,  6010315.5000],
        [14643178.0000,        0.0000],
        [13757704.0000,  1534411.0000],
        [13823636.0000,  1531469.5000],
        [11678459.0000,  2913688.5000],
        [15386026.0000,        0.0000],
        [15503539.0000,        0.0000],
        [11981886.0000,  2985252.0000],
        [15396448.0000,        0.0000],
        [15346196.0000,        0.0000],
        [15329460.0000,        0.0000],
        [15478158.0000,        0.0000],
        [15468421.0000,        0.0000],
        [15450015.0000,        0.0000],
        [15436481.0000,        0.0000],
        [ 3885495.7500,  8661220.0000],
        [12090096.0000,  3033903.5000],
        [12266822.0000,  3063341.5000],
        [ 9050750.0000,  6055143.0000],
        [ 7817197.5000,  5218979.5000],
        [ 9032836.0000,  6027391.5000],
        [12660230.0000,  1429718.2500],
        [15090157.0000,        0.0000],
        [ 9113295.0000,  3818683.0000],
        [15332122.0000,        0.0000],
        [15274077.0000,        0.0000],
        [13645880.0000,  1516271.3750],
        [ 7042631.5000,  7093428.0000],
        [ 3788448.2500,  8935044.0000],
        [ 7168996.5000,  3378623.5000],
        [ 1013587.1250, 10061706.0000],
        [12684065.0000,  1394262.0000],
        [10106220.0000,  4362374.0000],
        [12894094.0000,  1443763.8750],
        [ 1349898.0000, 12343187.0000],
        [       0.0000, 14186732.0000],
        [ 3834909.0000,  9135661.0000],
        [11435056.0000,  2879979.5000],
        [11768746.0000,  2928011.2500],
        [       0.0000, 13412512.0000],
        [ 1328916.5000, 12448217.0000],
        [       0.0000, 14184453.0000],
        [ 2829207.0000, 11564152.0000],
        [ 7908744.0000,  5427793.5000],
        [11189073.0000,  2778911.5000],
        [ 9814885.0000,  4041083.5000],
        [ 2786310.0000, 11302210.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 131/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.81s/it]  7%|▋         | 2/29 [01:00<11:19, 25.17s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 4.13425350189209
Epoch 132/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.56s/it]  7%|▋         | 2/29 [00:58<11:01, 24.49s/it] 10%|█         | 3/29 [00:59<05:58, 13.78s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.70s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.90s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 4.13096809387207
Epoch 133/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:41, 59.34s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 4.120770454406738
Epoch 134/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:32, 59.03s/it]  7%|▋         | 2/29 [01:00<11:21, 25.24s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.0892720222473145
Epoch 135/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:16, 58.45s/it]  7%|▋         | 2/29 [01:00<11:20, 25.20s/it] 10%|█         | 3/29 [01:01<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.108734607696533
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0063, 0.0047, 0.0015,  ..., 0.0043, 0.0019, 0.0237],
        [0.0062, 0.0054, 0.0015,  ..., 0.0030, 0.0015, 0.0245],
        [0.0338, 0.0070, 0.0028,  ..., 0.0078, 0.0148, 0.0289],
        ...,
        [0.0058, 0.0088, 0.0024,  ..., 0.0037, 0.0017, 0.0224],
        [0.0060, 0.0096, 0.0013,  ..., 0.0050, 0.0027, 0.0177],
        [0.0151, 0.0069, 0.0012,  ..., 0.0024, 0.0047, 0.0212]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956,
         0.9955],
        [0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9866, 0.9850, 0.9850, 0.9797, 0.9791, 0.9790, 0.9783, 0.9780, 0.9776,
         0.9773],
        [0.9940, 0.9940, 0.9939, 0.9932, 0.9926, 0.9925, 0.9923, 0.9921, 0.9918,
         0.9917],
        [0.9884, 0.9883, 0.9878, 0.9865, 0.9863, 0.9862, 0.9858, 0.9855, 0.9854,
         0.9854],
        [0.9900, 0.9878, 0.9842, 0.9827, 0.9824, 0.9811, 0.9809, 0.9791, 0.9787,
         0.9778],
        [0.9802, 0.9758, 0.9756, 0.9743, 0.9743, 0.9743, 0.9740, 0.9732, 0.9731,
         0.9726],
        [0.9828, 0.9824, 0.9819, 0.9814, 0.9797, 0.9796, 0.9795, 0.9792, 0.9786,
         0.9785],
        [0.9975, 0.9972, 0.9972, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9930, 0.9886, 0.9878, 0.9875, 0.9875, 0.9864, 0.9863, 0.9862, 0.9860,
         0.9855],
        [0.9978, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9945, 0.9935, 0.9934, 0.9931, 0.9930, 0.9930, 0.9930, 0.9929, 0.9928,
         0.9921],
        [0.9949, 0.9947, 0.9935, 0.9934, 0.9930, 0.9927, 0.9926, 0.9923, 0.9914,
         0.9913],
        [0.9980, 0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9975, 0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9968],
        [0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9949, 0.9949, 0.9946, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942, 0.9941,
         0.9941],
        [0.9958, 0.9958, 0.9955, 0.9954, 0.9954, 0.9952, 0.9951, 0.9950, 0.9949,
         0.9949],
        [0.9937, 0.9936, 0.9934, 0.9934, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932,
         0.9932],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9963],
        [0.9973, 0.9973, 0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9942, 0.9937, 0.9936, 0.9936, 0.9933, 0.9933, 0.9932, 0.9930, 0.9929,
         0.9927],
        [0.9979, 0.9975, 0.9974, 0.9973, 0.9973, 0.9971, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9964, 0.9958, 0.9955, 0.9953, 0.9952, 0.9952, 0.9950, 0.9949, 0.9948,
         0.9948],
        [0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9973, 0.9972, 0.9971, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967,
         0.9966],
        [0.9973, 0.9972, 0.9972, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9976, 0.9975, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9898, 0.9873, 0.9870, 0.9866, 0.9845, 0.9806, 0.9802, 0.9797, 0.9786,
         0.9773],
        [0.9961, 0.9960, 0.9960, 0.9959, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955,
         0.9955],
        [0.9972, 0.9972, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9967, 0.9961, 0.9959, 0.9958, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954,
         0.9954],
        [0.9915, 0.9892, 0.9877, 0.9853, 0.9850, 0.9844, 0.9844, 0.9841, 0.9832,
         0.9821],
        [0.9957, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9951],
        [0.9923, 0.9915, 0.9915, 0.9915, 0.9910, 0.9908, 0.9905, 0.9903, 0.9903,
         0.9903],
        [0.9956, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9878, 0.9873, 0.9871, 0.9854, 0.9848, 0.9845, 0.9831, 0.9822, 0.9818,
         0.9814],
        [0.9973, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9969, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9961, 0.9960, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9959],
        [0.9926, 0.9916, 0.9915, 0.9910, 0.9903, 0.9902, 0.9900, 0.9900, 0.9899,
         0.9899],
        [0.9856, 0.9854, 0.9852, 0.9847, 0.9845, 0.9844, 0.9836, 0.9835, 0.9834,
         0.9827],
        [0.9851, 0.9770, 0.9712, 0.9700, 0.9699, 0.9663, 0.9663, 0.9660, 0.9626,
         0.9610],
        [0.9825, 0.9784, 0.9774, 0.9762, 0.9762, 0.9737, 0.9715, 0.9709, 0.9703,
         0.9666],
        [0.9921, 0.9911, 0.9908, 0.9908, 0.9907, 0.9905, 0.9903, 0.9901, 0.9900,
         0.9899],
        [0.9934, 0.9931, 0.9931, 0.9928, 0.9924, 0.9923, 0.9922, 0.9920, 0.9917,
         0.9915],
        [0.9923, 0.9922, 0.9922, 0.9921, 0.9919, 0.9919, 0.9916, 0.9915, 0.9915,
         0.9914],
        [0.9908, 0.9901, 0.9898, 0.9893, 0.9891, 0.9890, 0.9882, 0.9880, 0.9880,
         0.9878],
        [0.9943, 0.9936, 0.9928, 0.9923, 0.9915, 0.9909, 0.9907, 0.9894, 0.9894,
         0.9890],
        [0.9881, 0.9873, 0.9867, 0.9859, 0.9848, 0.9838, 0.9835, 0.9834, 0.9832,
         0.9827],
        [0.9935, 0.9933, 0.9922, 0.9920, 0.9919, 0.9913, 0.9913, 0.9906, 0.9906,
         0.9904],
        [0.9943, 0.9943, 0.9939, 0.9939, 0.9937, 0.9936, 0.9935, 0.9932, 0.9932,
         0.9931],
        [0.9893, 0.9886, 0.9876, 0.9873, 0.9873, 0.9872, 0.9869, 0.9855, 0.9854,
         0.9850],
        [0.9930, 0.9917, 0.9910, 0.9908, 0.9895, 0.9891, 0.9876, 0.9871, 0.9870,
         0.9866],
        [0.9937, 0.9926, 0.9921, 0.9916, 0.9913, 0.9913, 0.9911, 0.9909, 0.9904,
         0.9897],
        [0.9954, 0.9953, 0.9935, 0.9925, 0.9918, 0.9912, 0.9912, 0.9912, 0.9911,
         0.9908],
        [0.9901, 0.9886, 0.9883, 0.9873, 0.9868, 0.9868, 0.9861, 0.9859, 0.9858,
         0.9854],
        [0.9928, 0.9928, 0.9908, 0.9903, 0.9903, 0.9902, 0.9900, 0.9897, 0.9896,
         0.9896],
        [0.9916, 0.9913, 0.9913, 0.9904, 0.9896, 0.9893, 0.9891, 0.9878, 0.9876,
         0.9874],
        [0.9930, 0.9924, 0.9916, 0.9914, 0.9910, 0.9905, 0.9902, 0.9900, 0.9896,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 1, 0, 1, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1520466.3750, 1509917.8750, 1509781.1250, 1509539.2500, 1508196.7500,
         1507548.1250, 1507351.1250, 1505976.1250, 1502110.3750, 1500798.7500],
        [1523369.1250, 1522570.2500, 1520347.3750, 1519899.3750, 1519399.3750,
         1518624.3750, 1518237.7500, 1518135.0000, 1518011.8750, 1517935.2500],
        [1320993.8750, 1291752.3750, 1290911.2500, 1197223.6250, 1186551.5000,
         1185787.8750, 1173595.8750, 1168636.0000, 1161467.3750, 1156799.1250],
        [1468946.5000, 1468078.2500, 1465957.2500, 1451598.8750, 1439475.6250,
         1437840.2500, 1432661.0000, 1429295.6250, 1424350.7500, 1422103.0000],
        [1355059.8750, 1354658.0000, 1343972.3750, 1318765.8750, 1315384.6250,
         1313206.2500, 1306655.1250, 1300005.3750, 1299736.3750, 1299119.2500],
        [1386522.3750, 1344037.7500, 1277632.3750, 1249080.2500, 1244652.1250,
         1220936.8750, 1217756.5000, 1187176.3750, 1179695.8750, 1165669.6250],
        [1205696.8750, 1133089.2500, 1129912.5000, 1109295.0000, 1108755.6250,
         1107850.7500, 1104357.1250, 1091733.5000, 1089903.7500, 1081525.1250],
        [1251087.8750, 1243910.5000, 1235386.6250, 1226816.0000, 1196996.5000,
         1195957.0000, 1194359.0000, 1189623.2500, 1178287.1250, 1177432.2500],
        [1544207.0000, 1538177.7500, 1537583.8750, 1533914.8750, 1533033.1250,
         1532761.2500, 1531601.0000, 1531275.2500, 1530684.0000, 1530543.8750],
        [1447505.5000, 1359397.1250, 1344681.3750, 1339359.7500, 1337787.0000,
         1318079.3750, 1316059.7500, 1313811.2500, 1310060.2500, 1301640.5000],
        [1551158.7500, 1544093.5000, 1541489.3750, 1540563.3750, 1540027.2500,
         1539205.1250, 1538836.6250, 1538311.3750, 1538242.3750, 1538207.1250],
        [1479032.5000, 1459348.2500, 1457121.7500, 1449754.6250, 1448516.5000,
         1447132.8750, 1447063.8750, 1446347.8750, 1444265.1250, 1429324.2500],
        [1487203.5000, 1483795.0000, 1457687.5000, 1455857.8750, 1448866.0000,
         1442545.7500, 1439784.6250, 1432870.0000, 1415358.3750, 1414048.3750],
        [1556067.5000, 1553576.3750, 1549230.8750, 1548798.1250, 1548191.1250,
         1547835.5000, 1545260.2500, 1543356.0000, 1542437.8750, 1542362.7500],
        [1543603.2500, 1538744.1250, 1538742.7500, 1536544.5000, 1535878.0000,
         1534160.7500, 1533131.0000, 1531945.7500, 1530265.1250, 1529754.3750],
        [1529777.7500, 1529203.0000, 1524039.1250, 1523869.0000, 1523376.3750,
         1522696.6250, 1519950.1250, 1519805.2500, 1517585.0000, 1516981.6250],
        [1488598.3750, 1488220.7500, 1481363.0000, 1480064.0000, 1477564.8750,
         1474511.6250, 1474382.3750, 1472641.2500, 1471769.2500, 1470686.1250],
        [1507697.6250, 1507387.1250, 1500614.1250, 1498913.6250, 1497502.0000,
         1494245.0000, 1493108.3750, 1490703.8750, 1487854.6250, 1487677.3750],
        [1462034.0000, 1461277.0000, 1456967.5000, 1456836.8750, 1455957.7500,
         1454854.2500, 1453606.1250, 1452810.6250, 1451860.5000, 1451585.0000],
        [1530581.7500, 1528135.8750, 1525899.0000, 1525525.1250, 1525068.3750,
         1523299.3750, 1523267.3750, 1522133.2500, 1521387.3750, 1518395.6250],
        [1539620.5000, 1539073.0000, 1537767.1250, 1532359.2500, 1531717.8750,
         1529820.1250, 1528420.2500, 1526883.1250, 1526618.1250, 1526615.2500],
        [1473170.7500, 1461721.6250, 1460736.3750, 1460638.8750, 1454825.2500,
         1454712.7500, 1452231.6250, 1447959.8750, 1445880.2500, 1442794.8750],
        [1552388.6250, 1543563.5000, 1541677.5000, 1539651.2500, 1538820.5000,
         1534757.7500, 1531647.8750, 1531057.7500, 1530913.2500, 1530762.7500],
        [1552837.2500, 1551977.0000, 1551842.3750, 1550855.6250, 1549958.0000,
         1547922.5000, 1546447.0000, 1545462.1250, 1543475.2500, 1543044.0000],
        [1519935.7500, 1506129.7500, 1500853.2500, 1495622.2500, 1494342.0000,
         1493673.7500, 1491056.3750, 1487456.0000, 1486276.2500, 1486240.7500],
        [1542217.2500, 1540159.5000, 1540058.1250, 1538013.6250, 1537614.6250,
         1536556.2500, 1536357.0000, 1536233.8750, 1536099.2500, 1535445.8750],
        [1538858.6250, 1538521.1250, 1535079.8750, 1534061.3750, 1531999.8750,
         1529144.7500, 1529124.2500, 1527946.5000, 1526494.3750, 1525413.1250],
        [1539068.5000, 1538007.7500, 1537003.2500, 1534228.0000, 1534191.5000,
         1531609.7500, 1531377.5000, 1531155.6250, 1530850.5000, 1530119.2500],
        [1552262.7500, 1551170.6250, 1548409.6250, 1547742.5000, 1546270.0000,
         1545596.3750, 1545310.3750, 1544981.7500, 1543940.3750, 1543570.8750],
        [1555141.7500, 1550879.1250, 1549726.0000, 1549656.5000, 1547614.0000,
         1541995.1250, 1541590.7500, 1540761.8750, 1539146.3750, 1538125.0000],
        [1548768.6250, 1546742.0000, 1545771.7500, 1544436.6250, 1543824.1250,
         1543806.5000, 1543108.7500, 1542504.0000, 1542437.8750, 1541552.5000],
        [1545841.0000, 1543703.3750, 1540729.5000, 1540685.3750, 1540197.7500,
         1539908.3750, 1539190.3750, 1539071.3750, 1538973.1250, 1538937.8750],
        [1382522.7500, 1333859.5000, 1329457.8750, 1321666.7500, 1283214.0000,
         1212145.1250, 1206861.0000, 1196780.7500, 1178993.0000, 1157782.5000],
        [1512719.7500, 1512256.7500, 1510821.0000, 1508651.2500, 1504524.7500,
         1503443.2500, 1502659.2500, 1502428.5000, 1501221.1250, 1500492.5000],
        [1537383.0000, 1536869.8750, 1533069.6250, 1531606.7500, 1530565.7500,
         1528774.3750, 1528774.3750, 1527966.8750, 1527108.8750, 1526459.5000],
        [1526814.7500, 1513701.0000, 1509736.5000, 1506444.2500, 1504625.1250,
         1503787.5000, 1502804.0000, 1500438.2500, 1499516.8750, 1499163.7500],
        [1418148.3750, 1372216.6250, 1341869.5000, 1297639.5000, 1290729.1250,
         1281426.1250, 1280052.0000, 1274587.5000, 1258621.2500, 1239143.6250],
        [1504774.5000, 1504034.1250, 1503887.8750, 1500650.0000, 1499875.8750,
         1498907.7500, 1498129.0000, 1497136.3750, 1496779.3750, 1491852.8750],
        [1432678.7500, 1417664.3750, 1416456.2500, 1416407.5000, 1408178.1250,
         1403543.2500, 1397591.5000, 1394179.5000, 1393824.5000, 1393681.0000],
        [1502187.8750, 1501839.7500, 1499672.7500, 1499355.3750, 1498770.6250,
         1498070.3750, 1497850.5000, 1497144.8750, 1495880.3750, 1495632.2500],
        [1344114.7500, 1335449.2500, 1330096.8750, 1299145.2500, 1287863.0000,
         1282691.6250, 1257262.1250, 1240719.8750, 1233591.2500, 1226924.7500],
        [1539498.6250, 1534746.1250, 1533313.8750, 1531586.3750, 1530005.3750,
         1529993.7500, 1528826.8750, 1528064.5000, 1527333.1250, 1527190.5000],
        [1530463.6250, 1523589.8750, 1521873.5000, 1521362.6250, 1520689.6250,
         1519166.1250, 1519108.1250, 1517134.8750, 1516922.2500, 1516761.6250],
        [1512604.3750, 1512314.5000, 1511505.5000, 1510691.3750, 1510457.8750,
         1510108.0000, 1510087.7500, 1509903.5000, 1508864.2500, 1508688.6250],
        [1439069.3750, 1420177.1250, 1416657.5000, 1407744.5000, 1393839.1250,
         1391686.1250, 1387108.1250, 1387060.5000, 1385692.0000, 1384743.6250],
        [1302508.3750, 1298373.6250, 1294876.6250, 1285379.5000, 1282081.3750,
         1280087.5000, 1266313.3750, 1264812.1250, 1262125.0000, 1250265.0000],
        [1293758.2500, 1152630.8750, 1060611.6250, 1041795.0625, 1041568.5000,
          988486.5000,  988163.1875,  984487.2500,  937358.5000,  916171.3125],
        [1246847.6250, 1175837.7500, 1159493.0000, 1139242.6250, 1138967.8750,
         1099675.1250, 1064590.0000, 1055826.0000, 1047604.5000,  992863.6250],
        [1429686.8750, 1408855.1250, 1403825.7500, 1403461.6250, 1401926.0000,
         1397952.7500, 1392975.3750, 1388850.1250, 1386633.3750, 1385031.6250],
        [1457294.1250, 1450677.1250, 1449147.7500, 1444812.1250, 1435033.3750,
         1433541.0000, 1431997.0000, 1428471.1250, 1421312.6250, 1418224.1250],
        [1433572.6250, 1431973.8750, 1430737.1250, 1429748.2500, 1424789.5000,
         1424445.7500, 1420230.0000, 1418080.7500, 1416722.3750, 1414467.7500],
        [1403849.7500, 1389112.3750, 1383229.6250, 1373560.0000, 1369549.6250,
         1368095.3750, 1352332.0000, 1348536.6250, 1348503.1250, 1344619.7500],
        [1475520.2500, 1460906.3750, 1443192.6250, 1433362.0000, 1417075.0000,
         1404807.5000, 1400289.0000, 1376061.6250, 1375925.1250, 1367591.8750],
        [1350302.2500, 1334616.6250, 1322964.3750, 1308258.6250, 1288333.5000,
         1270166.8750, 1264091.0000, 1262462.1250, 1258596.1250, 1249807.2500],
        [1457930.7500, 1454619.8750, 1431184.7500, 1428386.7500, 1424561.2500,
         1413754.3750, 1412402.7500, 1400194.2500, 1398287.3750, 1395994.2500],
        [1475599.0000, 1475499.1250, 1467775.8750, 1466364.1250, 1463373.1250,
         1460107.0000, 1458720.6250, 1452276.0000, 1451445.2500, 1449716.0000],
        [1373413.2500, 1359740.8750, 1340503.5000, 1335645.3750, 1334271.6250,
         1332062.0000, 1326252.6250, 1301005.0000, 1298750.1250, 1291594.7500],
        [1447113.6250, 1420809.8750, 1407685.5000, 1402864.8750, 1376893.7500,
         1370076.1250, 1340558.3750, 1331631.3750, 1329219.5000, 1320708.0000],
        [1463395.5000, 1439856.0000, 1428873.1250, 1419735.6250, 1413610.1250,
         1413314.8750, 1408335.3750, 1404552.8750, 1395026.7500, 1381853.2500],
        [1498537.6250, 1496516.8750, 1459024.0000, 1438663.2500, 1423854.8750,
         1411998.6250, 1411215.2500, 1411022.7500, 1409750.3750, 1404168.5000],
        [1388781.2500, 1359227.3750, 1354546.8750, 1334903.0000, 1326119.8750,
         1325322.0000, 1312461.2500, 1308117.6250, 1307287.1250, 1299772.3750],
        [1444682.5000, 1443199.5000, 1402602.6250, 1393860.5000, 1393372.6250,
         1390989.5000, 1387554.0000, 1381568.6250, 1380234.5000, 1379460.7500],
        [1419249.7500, 1413177.5000, 1412354.2500, 1394804.6250, 1378913.6250,
         1374146.8750, 1369028.5000, 1344327.5000, 1341353.8750, 1336225.1250],
        [1448697.3750, 1435300.3750, 1419379.7500, 1416268.5000, 1407775.3750,
         1397396.8750, 1391887.8750, 1387128.0000, 1379666.0000, 1378879.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1520466.3750,       0.0000],
         [1509917.8750,       0.0000],
         [1509781.1250,       0.0000],
         ...,
         [1505976.1250,       0.0000],
         [      0.0000, 1502110.3750],
         [1500798.7500,       0.0000]],

        [[1523369.1250,       0.0000],
         [1522570.2500,       0.0000],
         [1520347.3750,       0.0000],
         ...,
         [1518135.0000,       0.0000],
         [1518011.8750,       0.0000],
         [1517935.2500,       0.0000]],

        [[1320993.8750,       0.0000],
         [1291752.3750,       0.0000],
         [1290911.2500,       0.0000],
         ...,
         [1168636.0000,       0.0000],
         [1161467.3750,       0.0000],
         [1156799.1250,       0.0000]],

        ...,

        [[1444682.5000,       0.0000],
         [1443199.5000,       0.0000],
         [      0.0000, 1402602.6250],
         ...,
         [1381568.6250,       0.0000],
         [1380234.5000,       0.0000],
         [1379460.7500,       0.0000]],

        [[1419249.7500,       0.0000],
         [1413177.5000,       0.0000],
         [1412354.2500,       0.0000],
         ...,
         [      0.0000, 1344327.5000],
         [      0.0000, 1341353.8750],
         [      0.0000, 1336225.1250]],

        [[      0.0000, 1448697.3750],
         [      0.0000, 1435300.3750],
         [      0.0000, 1419379.7500],
         ...,
         [      0.0000, 1387128.0000],
         [      0.0000, 1379666.0000],
         [      0.0000, 1378879.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[12072028.0000,  3009658.5000],
        [15196530.0000,        0.0000],
        [10947932.0000,  1185787.8750],
        [14440306.0000,        0.0000],
        [ 6650523.5000,  6556040.0000],
        [11252224.0000,  1220936.8750],
        [ 5621340.0000,  5540780.0000],
        [ 9666043.0000,  2423812.5000],
        [13812181.0000,  1531601.0000],
        [ 9409594.0000,  3978787.2500],
        [13871298.0000,  1538836.6250],
        [13061559.0000,  1446347.8750],
        [14478017.0000,        0.0000],
        [13934754.0000,  1542362.7500],
        [15352770.0000,        0.0000],
        [15227283.0000,        0.0000],
        [14779801.0000,        0.0000],
        [10469714.0000,  4495989.0000],
        [14557790.0000,        0.0000],
        [13713112.0000,  1530581.7500],
        [15318894.0000,        0.0000],
        [11645977.0000,  2908696.2500],
        [15375241.0000,        0.0000],
        [15483822.0000,        0.0000],
        [10489911.0000,  4471674.5000],
        [15378754.0000,        0.0000],
        [15316644.0000,        0.0000],
        [15337612.0000,        0.0000],
        [15469255.0000,        0.0000],
        [15454636.0000,        0.0000],
        [15442952.0000,        0.0000],
        [15407239.0000,        0.0000],
        [ 3867671.2500,  8735612.0000],
        [12039746.0000,  3019472.2500],
        [13778014.0000,  1530565.7500],
        [10525856.0000,  4541176.5000],
        [ 7789542.5000,  5264891.0000],
        [ 8991321.0000,  6004706.5000],
        [12641526.0000,  1432678.7500],
        [14986404.0000,        0.0000],
        [ 9064402.0000,  3773456.2500],
        [15310560.0000,        0.0000],
        [15207072.0000,        0.0000],
        [13592621.0000,  1512604.3750],
        [ 6961444.0000,  7052334.0000],
        [ 3810520.0000,  8976302.0000],
        [ 6164820.0000,  4240211.0000],
        [  992863.6250, 10128084.0000],
        [12601246.0000,  1397952.7500],
        [10035652.0000,  4334858.0000],
        [11393114.0000,  2851653.5000],
        [       0.0000, 13681388.0000],
        [       0.0000, 14154732.0000],
        [ 2558066.0000, 10351533.0000],
        [11345631.0000,  2871685.0000],
        [11700824.0000,  2920052.0000],
        [       0.0000, 13293240.0000],
        [ 1320708.0000, 12426853.0000],
        [       0.0000, 14168552.0000],
        [ 4227382.0000, 10137370.0000],
        [ 9247888.0000,  4068650.0000],
        [12594923.0000,  1402602.6250],
        [ 9761676.0000,  4021906.5000],
        [ 1391887.8750, 12670492.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 136/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:35, 59.11s/it]  7%|▋         | 2/29 [01:00<11:11, 24.88s/it] 10%|█         | 3/29 [01:00<06:02, 13.94s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 4.094082832336426
Epoch 137/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:48, 59.59s/it]  7%|▋         | 2/29 [01:01<11:40, 25.93s/it] 10%|█         | 3/29 [01:02<06:17, 14.51s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:05<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 4.080378532409668
Epoch 138/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:19, 60.71s/it]  7%|▋         | 2/29 [01:01<11:29, 25.54s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 4.053592205047607
Epoch 139/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.49s/it]  7%|▋         | 2/29 [01:00<11:16, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.03s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.050294876098633
Epoch 140/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:44, 59.46s/it]  7%|▋         | 2/29 [01:00<11:15, 25.02s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 4.054737091064453
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0059, 0.0047, 0.0014,  ..., 0.0040, 0.0020, 0.0240],
        [0.0054, 0.0052, 0.0015,  ..., 0.0032, 0.0014, 0.0241],
        [0.0302, 0.0068, 0.0027,  ..., 0.0078, 0.0138, 0.0268],
        ...,
        [0.0056, 0.0086, 0.0028,  ..., 0.0036, 0.0019, 0.0245],
        [0.0055, 0.0096, 0.0012,  ..., 0.0051, 0.0028, 0.0186],
        [0.0138, 0.0061, 0.0010,  ..., 0.0025, 0.0046, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9874, 0.9860, 0.9843, 0.9812, 0.9806, 0.9800, 0.9799, 0.9798, 0.9798,
         0.9794],
        [0.9941, 0.9939, 0.9939, 0.9933, 0.9928, 0.9927, 0.9922, 0.9921, 0.9920,
         0.9919],
        [0.9881, 0.9875, 0.9874, 0.9873, 0.9863, 0.9863, 0.9859, 0.9855, 0.9855,
         0.9854],
        [0.9901, 0.9882, 0.9840, 0.9838, 0.9821, 0.9799, 0.9795, 0.9783, 0.9772,
         0.9771],
        [0.9794, 0.9753, 0.9748, 0.9741, 0.9740, 0.9738, 0.9736, 0.9722, 0.9715,
         0.9713],
        [0.9837, 0.9833, 0.9822, 0.9812, 0.9809, 0.9806, 0.9799, 0.9798, 0.9788,
         0.9788],
        [0.9975, 0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9934, 0.9897, 0.9890, 0.9884, 0.9871, 0.9871, 0.9870, 0.9866, 0.9863,
         0.9862],
        [0.9980, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9949, 0.9944, 0.9942, 0.9941, 0.9937, 0.9936, 0.9936, 0.9934, 0.9934,
         0.9933],
        [0.9953, 0.9948, 0.9942, 0.9942, 0.9939, 0.9935, 0.9931, 0.9929, 0.9916,
         0.9911],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9970, 0.9969, 0.9968, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9950, 0.9947, 0.9947, 0.9946, 0.9944, 0.9943, 0.9943, 0.9941, 0.9941,
         0.9940],
        [0.9960, 0.9959, 0.9956, 0.9956, 0.9953, 0.9953, 0.9953, 0.9950, 0.9950,
         0.9950],
        [0.9940, 0.9940, 0.9937, 0.9936, 0.9936, 0.9936, 0.9935, 0.9934, 0.9934,
         0.9932],
        [0.9970, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9975, 0.9975, 0.9973, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968,
         0.9968],
        [0.9943, 0.9941, 0.9938, 0.9938, 0.9938, 0.9934, 0.9934, 0.9934, 0.9932,
         0.9931],
        [0.9981, 0.9975, 0.9975, 0.9974, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971,
         0.9970],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9960, 0.9958, 0.9957, 0.9957, 0.9954, 0.9953, 0.9953, 0.9951, 0.9950,
         0.9950],
        [0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9974, 0.9974, 0.9972, 0.9971, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9967],
        [0.9974, 0.9974, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9982, 0.9980, 0.9979, 0.9978, 0.9978, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9901, 0.9878, 0.9858, 0.9854, 0.9844, 0.9805, 0.9800, 0.9795, 0.9787,
         0.9784],
        [0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9975, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9968, 0.9964, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9912, 0.9886, 0.9876, 0.9848, 0.9848, 0.9843, 0.9833, 0.9832, 0.9826,
         0.9825],
        [0.9957, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9920, 0.9911, 0.9909, 0.9908, 0.9907, 0.9907, 0.9905, 0.9905, 0.9905,
         0.9902],
        [0.9956, 0.9954, 0.9953, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9878, 0.9876, 0.9870, 0.9855, 0.9846, 0.9832, 0.9826, 0.9826, 0.9821,
         0.9819],
        [0.9975, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970, 0.9969,
         0.9969],
        [0.9969, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9963, 0.9963, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9926, 0.9922, 0.9917, 0.9913, 0.9906, 0.9903, 0.9901, 0.9901, 0.9900,
         0.9900],
        [0.9862, 0.9858, 0.9853, 0.9845, 0.9844, 0.9841, 0.9840, 0.9836, 0.9835,
         0.9832],
        [0.9859, 0.9772, 0.9717, 0.9713, 0.9704, 0.9673, 0.9670, 0.9662, 0.9639,
         0.9599],
        [0.9827, 0.9774, 0.9770, 0.9768, 0.9757, 0.9737, 0.9716, 0.9713, 0.9710,
         0.9668],
        [0.9924, 0.9912, 0.9909, 0.9909, 0.9908, 0.9908, 0.9908, 0.9907, 0.9906,
         0.9905],
        [0.9937, 0.9934, 0.9933, 0.9931, 0.9927, 0.9927, 0.9924, 0.9923, 0.9918,
         0.9918],
        [0.9923, 0.9922, 0.9921, 0.9920, 0.9918, 0.9918, 0.9917, 0.9917, 0.9916,
         0.9916],
        [0.9909, 0.9904, 0.9897, 0.9894, 0.9890, 0.9890, 0.9881, 0.9881, 0.9879,
         0.9879],
        [0.9945, 0.9938, 0.9933, 0.9927, 0.9916, 0.9914, 0.9907, 0.9900, 0.9893,
         0.9890],
        [0.9884, 0.9883, 0.9874, 0.9865, 0.9851, 0.9846, 0.9836, 0.9834, 0.9833,
         0.9831],
        [0.9933, 0.9927, 0.9924, 0.9917, 0.9917, 0.9916, 0.9915, 0.9911, 0.9910,
         0.9909],
        [0.9944, 0.9943, 0.9941, 0.9937, 0.9937, 0.9937, 0.9936, 0.9932, 0.9932,
         0.9931],
        [0.9895, 0.9884, 0.9882, 0.9881, 0.9879, 0.9875, 0.9869, 0.9853, 0.9853,
         0.9853],
        [0.9933, 0.9919, 0.9913, 0.9912, 0.9900, 0.9893, 0.9879, 0.9876, 0.9873,
         0.9869],
        [0.9940, 0.9927, 0.9922, 0.9916, 0.9916, 0.9915, 0.9912, 0.9909, 0.9906,
         0.9901],
        [0.9955, 0.9954, 0.9941, 0.9930, 0.9923, 0.9915, 0.9915, 0.9913, 0.9912,
         0.9912],
        [0.9902, 0.9892, 0.9879, 0.9878, 0.9870, 0.9870, 0.9868, 0.9867, 0.9863,
         0.9859],
        [0.9926, 0.9925, 0.9909, 0.9904, 0.9903, 0.9902, 0.9900, 0.9900, 0.9899,
         0.9897],
        [0.9921, 0.9914, 0.9913, 0.9901, 0.9896, 0.9894, 0.9892, 0.9883, 0.9877,
         0.9874],
        [0.9934, 0.9926, 0.9919, 0.9916, 0.9916, 0.9911, 0.9905, 0.9903, 0.9900,
         0.9900]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1522277.0000, 1513771.7500, 1512039.0000, 1510089.2500, 1509801.2500,
         1509602.6250, 1507451.7500, 1506846.6250, 1504333.8750, 1504319.6250],
        [1526657.3750, 1523512.8750, 1523481.0000, 1522930.3750, 1521090.0000,
         1520756.2500, 1520021.1250, 1519744.3750, 1519047.3750, 1517845.5000],
        [1337433.6250, 1309756.6250, 1278056.5000, 1223914.3750, 1213536.6250,
         1202746.5000, 1200697.3750, 1199191.3750, 1198516.7500, 1191584.1250],
        [1470174.2500, 1466990.8750, 1466783.6250, 1454976.3750, 1443251.7500,
         1442107.1250, 1430802.6250, 1429647.3750, 1426491.7500, 1425530.2500],
        [1350161.8750, 1337907.0000, 1337131.3750, 1334522.3750, 1316378.5000,
         1315105.0000, 1307718.5000, 1300016.6250, 1300012.8750, 1298338.8750],
        [1388904.3750, 1351974.7500, 1273286.3750, 1270349.8750, 1238862.3750,
         1200290.8750, 1194498.0000, 1174199.3750, 1154820.5000, 1153628.3750],
        [1192714.2500, 1124922.5000, 1115888.3750, 1104640.5000, 1103204.5000,
         1100674.0000, 1096848.1250, 1076045.7500, 1065673.8750, 1061476.7500],
        [1267287.2500, 1261208.2500, 1240658.2500, 1223768.5000, 1218187.3750,
         1212185.5000, 1201562.2500, 1199162.7500, 1182319.0000, 1181980.8750],
        [1545127.6250, 1540902.8750, 1539404.6250, 1539313.7500, 1537869.8750,
         1535466.5000, 1533855.0000, 1532951.2500, 1532388.5000, 1531348.3750],
        [1456912.0000, 1381842.6250, 1367194.1250, 1355231.7500, 1331571.7500,
         1330988.8750, 1328739.0000, 1321150.1250, 1315500.0000, 1314719.8750],
        [1554138.0000, 1546789.2500, 1543213.1250, 1542308.3750, 1541346.7500,
         1541176.1250, 1540886.7500, 1539707.1250, 1539244.6250, 1538863.0000],
        [1488670.8750, 1478113.1250, 1472763.3750, 1470688.8750, 1462974.1250,
         1460028.8750, 1459506.8750, 1456806.2500, 1456493.8750, 1453592.2500],
        [1496419.7500, 1485747.6250, 1472967.0000, 1472408.1250, 1466692.7500,
         1457370.5000, 1450049.1250, 1445699.6250, 1418362.0000, 1408660.3750],
        [1554037.1250, 1553843.1250, 1551897.1250, 1550806.7500, 1546749.3750,
         1546427.8750, 1544813.7500, 1544420.5000, 1542517.2500, 1542505.5000],
        [1542941.0000, 1539191.8750, 1538736.8750, 1537915.2500, 1535800.2500,
         1535097.3750, 1533702.8750, 1531688.7500, 1531355.6250, 1529999.5000],
        [1533408.8750, 1530752.6250, 1528117.0000, 1523831.1250, 1523639.3750,
         1523492.6250, 1523178.8750, 1521754.5000, 1521558.6250, 1520446.0000],
        [1490382.5000, 1483110.2500, 1482714.2500, 1480630.0000, 1476470.3750,
         1476059.2500, 1474387.8750, 1470867.0000, 1470252.7500, 1469786.0000],
        [1511793.8750, 1509251.3750, 1503266.8750, 1501927.1250, 1497219.1250,
         1496339.8750, 1495866.2500, 1490954.0000, 1489917.7500, 1489717.5000],
        [1469654.2500, 1469430.0000, 1462600.1250, 1461472.1250, 1461013.7500,
         1460006.7500, 1457479.0000, 1456887.0000, 1455313.6250, 1452421.3750],
        [1532211.7500, 1530311.8750, 1526011.1250, 1525541.1250, 1525359.2500,
         1524792.1250, 1522733.0000, 1521307.5000, 1519850.2500, 1519158.8750],
        [1544500.1250, 1544031.6250, 1539720.3750, 1536003.8750, 1534538.2500,
         1532312.5000, 1532201.5000, 1531528.0000, 1529328.5000, 1529244.0000],
        [1475023.6250, 1471370.6250, 1465370.2500, 1465328.2500, 1463801.6250,
         1456696.6250, 1456303.5000, 1455777.2500, 1451940.8750, 1449657.8750],
        [1556579.5000, 1545261.7500, 1544894.8750, 1540944.0000, 1540454.6250,
         1537199.6250, 1535601.1250, 1535601.1250, 1534383.2500, 1534253.0000],
        [1553757.1250, 1551971.1250, 1551729.8750, 1550975.3750, 1548959.1250,
         1547684.7500, 1546144.7500, 1545509.3750, 1545282.3750, 1545273.5000],
        [1511522.8750, 1507313.7500, 1504312.3750, 1504006.8750, 1498702.0000,
         1497260.6250, 1495568.1250, 1491653.7500, 1489548.3750, 1488994.5000],
        [1545112.8750, 1541715.7500, 1541007.2500, 1540335.7500, 1540246.1250,
         1539642.5000, 1539385.6250, 1539216.7500, 1538734.0000, 1538192.5000],
        [1542945.3750, 1541621.6250, 1537498.8750, 1535019.7500, 1531726.6250,
         1531339.5000, 1531094.2500, 1530488.5000, 1528743.7500, 1527538.5000],
        [1542665.8750, 1542083.2500, 1540257.8750, 1536270.5000, 1535979.0000,
         1534870.5000, 1533824.2500, 1533237.8750, 1532802.1250, 1531742.7500],
        [1554768.0000, 1551510.8750, 1550070.3750, 1549253.1250, 1549043.3750,
         1548312.2500, 1547510.7500, 1547413.3750, 1546118.1250, 1545612.5000],
        [1558757.3750, 1555643.1250, 1552037.6250, 1551749.1250, 1550426.7500,
         1546096.0000, 1545036.2500, 1545024.3750, 1542573.1250, 1541185.1250],
        [1552619.5000, 1549962.5000, 1548758.2500, 1546876.2500, 1544853.6250,
         1544774.0000, 1544606.1250, 1544388.1250, 1544349.7500, 1544092.1250],
        [1549132.0000, 1545939.7500, 1543884.3750, 1542502.6250, 1542351.0000,
         1541952.3750, 1541895.1250, 1541446.7500, 1541445.1250, 1540714.7500],
        [1388570.6250, 1344389.0000, 1306587.8750, 1298252.2500, 1279714.0000,
         1211635.3750, 1202730.3750, 1194188.2500, 1181269.7500, 1175429.6250],
        [1515859.2500, 1514267.1250, 1512154.3750, 1510724.5000, 1509008.1250,
         1508710.2500, 1508160.7500, 1507095.3750, 1505499.3750, 1505273.8750],
        [1543406.0000, 1539200.6250, 1536028.8750, 1535327.2500, 1534832.5000,
         1534200.2500, 1534200.2500, 1531665.2500, 1531609.7500, 1531411.1250],
        [1528210.2500, 1520549.0000, 1510211.6250, 1510095.0000, 1509540.6250,
         1506996.1250, 1506475.8750, 1504015.5000, 1503016.1250, 1502308.1250],
        [1411874.7500, 1358884.0000, 1340768.1250, 1287592.8750, 1287087.0000,
         1279177.1250, 1259802.8750, 1259040.2500, 1248537.2500, 1247123.5000],
        [1506019.1250, 1504514.7500, 1503853.3750, 1503000.3750, 1502511.6250,
         1501732.2500, 1500995.0000, 1500652.8750, 1500617.1250, 1498069.1250],
        [1426776.1250, 1408415.8750, 1406028.5000, 1403382.6250, 1401778.8750,
         1401317.7500, 1397999.3750, 1397379.5000, 1397107.7500, 1391404.7500],
        [1502601.8750, 1499452.6250, 1497404.8750, 1494722.6250, 1494551.5000,
         1491999.5000, 1490911.3750, 1490668.2500, 1490447.8750, 1489993.1250],
        [1343980.1250, 1340736.1250, 1329102.8750, 1300797.8750, 1284192.2500,
         1258771.3750, 1248218.1250, 1247650.5000, 1239578.6250, 1235177.0000],
        [1543818.2500, 1537251.0000, 1537173.2500, 1536247.1250, 1536225.1250,
         1534961.3750, 1534678.7500, 1533297.7500, 1532053.8750, 1531999.8750],
        [1531969.2500, 1525398.6250, 1523556.6250, 1522927.5000, 1522666.1250,
         1520914.3750, 1520718.6250, 1519312.5000, 1518459.3750, 1518308.6250],
        [1517204.3750, 1516965.6250, 1514629.6250, 1514553.0000, 1514223.6250,
         1513331.6250, 1512500.5000, 1512409.6250, 1512154.3750, 1511984.2500],
        [1440148.6250, 1431097.5000, 1421450.8750, 1412420.2500, 1398362.0000,
         1393670.3750, 1389847.7500, 1389097.7500, 1387550.0000, 1386944.1250],
        [1313573.2500, 1305626.2500, 1297783.1250, 1282310.0000, 1281087.6250,
         1274845.2500, 1272504.5000, 1265451.5000, 1263841.5000, 1258106.5000],
        [1308674.1250, 1155236.8750, 1068279.8750, 1061673.1250, 1048994.1250,
         1002464.6250,  998851.6875,  986984.0625,  956079.6250,  902051.7500],
        [1250306.7500, 1158312.6250, 1152583.6250, 1148107.6250, 1131159.7500,
         1099045.0000, 1066898.2500, 1061970.8750, 1057466.5000,  996084.3750],
        [1435731.5000, 1411905.8750, 1404618.5000, 1404473.8750, 1402954.3750,
         1402899.6250, 1402303.0000, 1401901.8750, 1399053.1250, 1398138.0000],
        [1462596.0000, 1455367.7500, 1453291.5000, 1450511.1250, 1441711.0000,
         1441315.1250, 1435511.1250, 1433180.1250, 1423787.0000, 1423787.0000],
        [1434074.3750, 1431960.2500, 1429970.5000, 1426544.7500, 1423853.6250,
         1423704.2500, 1421989.1250, 1421628.5000, 1419804.7500, 1419017.0000],
        [1404745.8750, 1394763.3750, 1381693.7500, 1375231.1250, 1368503.8750,
         1367479.6250, 1350793.0000, 1349300.7500, 1346787.3750, 1345851.3750],
        [1478671.3750, 1463681.6250, 1454503.2500, 1441315.1250, 1419848.0000,
         1414374.7500, 1401885.7500, 1387130.6250, 1373688.3750, 1368554.7500],
        [1356091.3750, 1353768.2500, 1336681.3750, 1319662.8750, 1293090.8750,
         1283573.8750, 1265236.6250, 1262068.5000, 1260469.8750, 1256489.0000],
        [1455176.2500, 1441667.0000, 1434843.2500, 1422096.2500, 1421421.0000,
         1419134.7500, 1416456.2500, 1408303.1250, 1407618.3750, 1405433.1250],
        [1476546.5000, 1475642.6250, 1470480.0000, 1462958.7500, 1462543.0000,
         1462519.2500, 1461423.3750, 1452832.7500, 1451814.7500, 1449152.0000],
        [1376698.2500, 1355605.3750, 1351870.3750, 1349535.0000, 1345386.8750,
         1338887.2500, 1326475.2500, 1297694.0000, 1297191.6250, 1296795.8750],
        [1454213.5000, 1426161.1250, 1413173.3750, 1411437.2500, 1388226.3750,
         1373449.8750, 1346371.2500, 1341226.0000, 1335230.2500, 1326512.0000],
        [1469331.8750, 1442529.3750, 1431182.0000, 1418608.3750, 1418540.6250,
         1418322.8750, 1410628.5000, 1404984.2500, 1398696.8750, 1388968.0000],
        [1501604.8750, 1499454.0000, 1470673.3750, 1447378.6250, 1434049.7500,
         1418225.5000, 1416734.3750, 1413222.0000, 1411110.2500, 1410621.7500],
        [1391955.6250, 1372020.3750, 1347036.6250, 1345009.7500, 1329989.1250,
         1329353.8750, 1324589.1250, 1324038.5000, 1315311.8750, 1308782.7500],
        [1439882.1250, 1437049.2500, 1405966.7500, 1395841.1250, 1393654.3750,
         1391747.1250, 1387519.6250, 1387109.5000, 1384628.7500, 1382322.5000],
        [1429126.6250, 1414810.5000, 1412452.6250, 1389166.7500, 1379539.7500,
         1375618.1250, 1371382.0000, 1353493.1250, 1342829.6250, 1337537.0000],
        [1456310.5000, 1439368.6250, 1425611.8750, 1418860.0000, 1418366.1250,
         1409695.2500, 1397207.6250, 1393696.8750, 1388087.3750, 1386435.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1522277.0000,       0.0000],
         [1513771.7500,       0.0000],
         [1512039.0000,       0.0000],
         ...,
         [1506846.6250,       0.0000],
         [1504333.8750,       0.0000],
         [1504319.6250,       0.0000]],

        [[1526657.3750,       0.0000],
         [1523512.8750,       0.0000],
         [1523481.0000,       0.0000],
         ...,
         [1519744.3750,       0.0000],
         [1519047.3750,       0.0000],
         [1517845.5000,       0.0000]],

        [[1337433.6250,       0.0000],
         [1309756.6250,       0.0000],
         [1278056.5000,       0.0000],
         ...,
         [1199191.3750,       0.0000],
         [1198516.7500,       0.0000],
         [1191584.1250,       0.0000]],

        ...,

        [[1439882.1250,       0.0000],
         [1437049.2500,       0.0000],
         [      0.0000, 1405966.7500],
         ...,
         [1387109.5000,       0.0000],
         [1384628.7500,       0.0000],
         [1382322.5000,       0.0000]],

        [[1429126.6250,       0.0000],
         [1414810.5000,       0.0000],
         [1412452.6250,       0.0000],
         ...,
         [      0.0000, 1353493.1250],
         [      0.0000, 1342829.6250],
         [      0.0000, 1337537.0000]],

        [[      0.0000, 1456310.5000],
         [      0.0000, 1439368.6250],
         [      0.0000, 1425611.8750],
         ...,
         [      0.0000, 1393696.8750],
         [      0.0000, 1388087.3750],
         [      0.0000, 1386435.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13593081.0000,  1507451.7500],
        [15215087.0000,        0.0000],
        [12355434.0000,        0.0000],
        [14456756.0000,        0.0000],
        [ 7946363.0000,  5250930.5000],
        [11206316.0000,  1194498.0000],
        [ 6616439.0000,  4425649.0000],
        [ 9746365.0000,  2441956.0000],
        [13830759.0000,  1537869.8750],
        [10817629.0000,  2686220.5000],
        [13888810.0000,  1538863.0000],
        [13181525.0000,  1478113.1250],
        [14574377.0000,        0.0000],
        [15478018.0000,        0.0000],
        [15356430.0000,        0.0000],
        [15250180.0000,        0.0000],
        [14774661.0000,        0.0000],
        [10480239.0000,  4506015.0000],
        [14606278.0000,        0.0000],
        [13715064.0000,  1532211.7500],
        [15353409.0000,        0.0000],
        [11696284.0000,  2914986.0000],
        [15405173.0000,        0.0000],
        [15487287.0000,        0.0000],
        [10497352.0000,  4491530.5000],
        [15403590.0000,        0.0000],
        [15338017.0000,        0.0000],
        [15363734.0000,        0.0000],
        [15489612.0000,        0.0000],
        [15488528.0000,        0.0000],
        [15465280.0000,        0.0000],
        [15431264.0000,        0.0000],
        [ 3761731.5000,  8821036.0000],
        [12073874.0000,  3022879.0000],
        [13820470.0000,  1531411.1250],
        [10556118.0000,  4545301.5000],
        [ 7742203.0000,  5237685.0000],
        [ 9009602.0000,  6012363.5000],
        [11198786.0000,  2832804.5000],
        [14942753.0000,        0.0000],
        [10296362.0000,  2531842.7500],
        [15357707.0000,        0.0000],
        [13705923.0000,  1518308.6250],
        [13622752.0000,  1517204.3750],
        [ 6965860.0000,  7084729.5000],
        [ 5077150.0000,  7737979.0000],
        [ 6229907.0000,  4259383.0000],
        [  996084.3750, 10125851.0000],
        [14063980.0000,        0.0000],
        [10071083.0000,  4349974.5000],
        [11396483.0000,  2856063.5000],
        [ 1345851.3750, 12339299.0000],
        [       0.0000, 14203654.0000],
        [ 3838220.5000,  9148912.0000],
        [11360518.0000,  2871632.5000],
        [11711657.0000,  2914256.0000],
        [       0.0000, 13336139.0000],
        [       0.0000, 13816001.0000],
        [       0.0000, 14201792.0000],
        [ 4238466.5000, 10184608.0000],
        [ 9321768.0000,  4066319.2500],
        [12599754.0000,  1405966.7500],
        [ 9772096.0000,  4033859.5000],
        [ 1397207.6250, 12736432.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 141/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:04, 58.00s/it]  7%|▋         | 2/29 [01:00<11:17, 25.08s/it] 10%|█         | 3/29 [01:00<06:05, 14.05s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.00s/it] 21%|██        | 6/29 [01:03<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 4.02979040145874
Epoch 142/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:32, 61.17s/it]  7%|▋         | 2/29 [01:02<11:34, 25.73s/it] 10%|█         | 3/29 [01:03<06:14, 14.41s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 4.022222518920898
Epoch 143/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:34, 61.24s/it]  7%|▋         | 2/29 [01:02<11:35, 25.76s/it] 10%|█         | 3/29 [01:03<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 4.01259708404541
Epoch 144/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:54, 61.96s/it]  7%|▋         | 2/29 [01:02<11:43, 26.06s/it] 10%|█         | 3/29 [01:03<06:19, 14.58s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.19s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.21s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 3.9961743354797363
Epoch 145/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.86s/it]  7%|▋         | 2/29 [00:58<10:57, 24.37s/it] 10%|█         | 3/29 [00:59<05:55, 13.66s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 3.9720187187194824
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0049, 0.0046, 0.0014,  ..., 0.0039, 0.0021, 0.0239],
        [0.0039, 0.0050, 0.0015,  ..., 0.0029, 0.0012, 0.0235],
        [0.0277, 0.0070, 0.0026,  ..., 0.0069, 0.0126, 0.0265],
        ...,
        [0.0050, 0.0092, 0.0034,  ..., 0.0036, 0.0020, 0.0265],
        [0.0041, 0.0098, 0.0013,  ..., 0.0049, 0.0023, 0.0192],
        [0.0130, 0.0064, 0.0010,  ..., 0.0026, 0.0046, 0.0215]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9968, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9960],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9872, 0.9856, 0.9842, 0.9799, 0.9793, 0.9789, 0.9788, 0.9786, 0.9786,
         0.9783],
        [0.9943, 0.9941, 0.9940, 0.9931, 0.9931, 0.9928, 0.9925, 0.9924, 0.9919,
         0.9918],
        [0.9876, 0.9876, 0.9875, 0.9869, 0.9869, 0.9859, 0.9858, 0.9856, 0.9853,
         0.9849],
        [0.9899, 0.9873, 0.9832, 0.9830, 0.9826, 0.9814, 0.9809, 0.9784, 0.9779,
         0.9769],
        [0.9807, 0.9749, 0.9746, 0.9743, 0.9739, 0.9728, 0.9704, 0.9703, 0.9701,
         0.9696],
        [0.9829, 0.9825, 0.9818, 0.9806, 0.9798, 0.9797, 0.9796, 0.9782, 0.9781,
         0.9779],
        [0.9978, 0.9975, 0.9975, 0.9974, 0.9974, 0.9972, 0.9972, 0.9971, 0.9971,
         0.9971],
        [0.9932, 0.9891, 0.9890, 0.9878, 0.9870, 0.9869, 0.9863, 0.9862, 0.9860,
         0.9857],
        [0.9980, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9973],
        [0.9950, 0.9940, 0.9938, 0.9938, 0.9936, 0.9935, 0.9933, 0.9931, 0.9926,
         0.9925],
        [0.9949, 0.9943, 0.9940, 0.9938, 0.9938, 0.9935, 0.9931, 0.9926, 0.9925,
         0.9921],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969,
         0.9969],
        [0.9970, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9954, 0.9951, 0.9951, 0.9950, 0.9949, 0.9946, 0.9946, 0.9946, 0.9945,
         0.9945],
        [0.9963, 0.9961, 0.9959, 0.9958, 0.9956, 0.9956, 0.9955, 0.9954, 0.9954,
         0.9952],
        [0.9945, 0.9943, 0.9937, 0.9936, 0.9936, 0.9935, 0.9934, 0.9934, 0.9934,
         0.9934],
        [0.9972, 0.9971, 0.9969, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9965],
        [0.9977, 0.9977, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9969,
         0.9969],
        [0.9946, 0.9943, 0.9940, 0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9930],
        [0.9980, 0.9974, 0.9974, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9953, 0.9952,
         0.9952],
        [0.9975, 0.9975, 0.9975, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9974, 0.9973, 0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9975, 0.9975, 0.9974, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9980, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9898, 0.9876, 0.9862, 0.9850, 0.9848, 0.9801, 0.9800, 0.9787, 0.9782,
         0.9772],
        [0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9960],
        [0.9975, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9968, 0.9966, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9958,
         0.9958],
        [0.9908, 0.9878, 0.9871, 0.9847, 0.9838, 0.9836, 0.9835, 0.9823, 0.9813,
         0.9811],
        [0.9961, 0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9920, 0.9911, 0.9909, 0.9906, 0.9905, 0.9905, 0.9904, 0.9901, 0.9901,
         0.9900],
        [0.9959, 0.9956, 0.9955, 0.9954, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9950],
        [0.9884, 0.9876, 0.9875, 0.9855, 0.9841, 0.9838, 0.9830, 0.9825, 0.9825,
         0.9821],
        [0.9976, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9970, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9964, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9924, 0.9923, 0.9919, 0.9906, 0.9905, 0.9903, 0.9897, 0.9896, 0.9896,
         0.9895],
        [0.9873, 0.9865, 0.9850, 0.9850, 0.9841, 0.9840, 0.9837, 0.9834, 0.9834,
         0.9834],
        [0.9840, 0.9757, 0.9698, 0.9681, 0.9679, 0.9667, 0.9658, 0.9657, 0.9607,
         0.9579],
        [0.9820, 0.9760, 0.9760, 0.9749, 0.9734, 0.9719, 0.9709, 0.9699, 0.9683,
         0.9651],
        [0.9925, 0.9915, 0.9914, 0.9910, 0.9910, 0.9909, 0.9909, 0.9909, 0.9909,
         0.9908],
        [0.9940, 0.9940, 0.9936, 0.9936, 0.9930, 0.9929, 0.9929, 0.9928, 0.9923,
         0.9923],
        [0.9931, 0.9928, 0.9928, 0.9924, 0.9923, 0.9922, 0.9922, 0.9922, 0.9921,
         0.9920],
        [0.9910, 0.9907, 0.9898, 0.9895, 0.9894, 0.9886, 0.9882, 0.9882, 0.9880,
         0.9879],
        [0.9943, 0.9939, 0.9934, 0.9929, 0.9918, 0.9914, 0.9909, 0.9901, 0.9893,
         0.9892],
        [0.9893, 0.9892, 0.9874, 0.9869, 0.9852, 0.9847, 0.9835, 0.9830, 0.9830,
         0.9830],
        [0.9929, 0.9926, 0.9922, 0.9917, 0.9915, 0.9915, 0.9915, 0.9912, 0.9911,
         0.9911],
        [0.9946, 0.9945, 0.9941, 0.9940, 0.9939, 0.9939, 0.9937, 0.9936, 0.9935,
         0.9933],
        [0.9896, 0.9889, 0.9883, 0.9880, 0.9877, 0.9877, 0.9870, 0.9856, 0.9856,
         0.9854],
        [0.9936, 0.9921, 0.9916, 0.9914, 0.9905, 0.9888, 0.9879, 0.9877, 0.9876,
         0.9869],
        [0.9940, 0.9927, 0.9923, 0.9917, 0.9917, 0.9915, 0.9911, 0.9908, 0.9907,
         0.9901],
        [0.9958, 0.9957, 0.9943, 0.9935, 0.9927, 0.9918, 0.9918, 0.9918, 0.9917,
         0.9916],
        [0.9902, 0.9893, 0.9890, 0.9877, 0.9876, 0.9874, 0.9864, 0.9862, 0.9862,
         0.9861],
        [0.9916, 0.9910, 0.9905, 0.9897, 0.9894, 0.9893, 0.9891, 0.9889, 0.9889,
         0.9889],
        [0.9928, 0.9915, 0.9915, 0.9903, 0.9898, 0.9897, 0.9892, 0.9886, 0.9883,
         0.9873],
        [0.9932, 0.9926, 0.9922, 0.9913, 0.9912, 0.9912, 0.9911, 0.9908, 0.9907,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],
        [1, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 0, 1, 0, 0, 1, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1527741.0000, 1520108.1250, 1518706.8750, 1517480.7500, 1515119.2500,
         1513509.0000, 1513441.2500, 1513353.2500, 1513156.8750, 1512491.8750],
        [1531421.3750, 1528324.0000, 1526912.2500, 1526318.2500, 1526092.6250,
         1525213.8750, 1523746.8750, 1523693.1250, 1523033.6250, 1522407.6250],
        [1332696.0000, 1303619.3750, 1276703.1250, 1201140.6250, 1190551.6250,
         1184230.6250, 1181881.6250, 1179413.5000, 1179140.2500, 1174379.6250],
        [1474570.6250, 1470306.0000, 1469680.8750, 1449734.0000, 1449207.3750,
         1444601.2500, 1438166.7500, 1435179.8750, 1426012.8750, 1423813.0000],
        [1339827.3750, 1339660.0000, 1338227.2500, 1326508.1250, 1326257.7500,
         1308016.5000, 1305603.8750, 1302084.8750, 1298055.3750, 1290687.2500],
        [1384803.0000, 1334173.6250, 1258681.2500, 1254428.3750, 1247880.1250,
         1226121.1250, 1217609.0000, 1175322.0000, 1166670.5000, 1151130.3750],
        [1214911.1250, 1118689.6250, 1113296.8750, 1107954.3750, 1101583.3750,
         1085420.5000, 1049003.1250, 1047689.4375, 1043662.5625, 1036249.0625],
        [1252945.8750, 1246930.8750, 1234470.3750, 1212443.3750, 1199635.2500,
         1197958.1250, 1196269.6250, 1171287.0000, 1169988.6250, 1167764.8750],
        [1550020.1250, 1544958.1250, 1544417.5000, 1542671.7500, 1542087.7500,
         1538427.1250, 1536651.5000, 1536129.8750, 1535040.3750, 1534891.0000],
        [1452776.0000, 1368977.6250, 1366773.0000, 1344330.1250, 1329019.1250,
         1326273.0000, 1316204.0000, 1314612.1250, 1309690.5000, 1305527.8750],
        [1556137.1250, 1550808.1250, 1546094.6250, 1545583.0000, 1544942.0000,
         1544363.0000, 1543613.6250, 1542877.7500, 1542618.7500, 1540822.1250],
        [1489182.0000, 1469176.3750, 1464791.7500, 1464121.3750, 1461332.7500,
         1457751.3750, 1454391.0000, 1450432.2500, 1439186.1250, 1436778.0000],
        [1488227.8750, 1474839.3750, 1467949.5000, 1464935.6250, 1464749.7500,
         1457818.1250, 1450107.2500, 1439510.0000, 1438620.7500, 1429945.8750],
        [1556394.0000, 1555911.6250, 1554295.1250, 1554219.5000, 1550586.3750,
         1549641.7500, 1549105.3750, 1548761.1250, 1548557.5000, 1548059.7500],
        [1542487.7500, 1540315.1250, 1538568.0000, 1536877.2500, 1536806.8750,
         1535951.2500, 1535208.6250, 1533420.5000, 1530619.7500, 1530605.2500],
        [1533444.0000, 1533052.1250, 1530916.1250, 1529478.7500, 1526692.3750,
         1525436.3750, 1525353.5000, 1524645.1250, 1524316.6250, 1524220.6250],
        [1498284.7500, 1492934.6250, 1491352.2500, 1490361.1250, 1488849.6250,
         1482014.5000, 1481911.2500, 1480803.6250, 1480169.7500, 1478606.5000],
        [1518292.7500, 1513838.2500, 1510193.0000, 1508038.5000, 1503821.8750,
         1502126.1250, 1499738.6250, 1499308.1250, 1498556.2500, 1495154.5000],
        [1479489.5000, 1475703.1250, 1462757.8750, 1461194.8750, 1460970.5000,
         1459171.5000, 1456642.5000, 1456220.2500, 1455774.5000, 1455742.6250],
        [1537837.6250, 1534621.7500, 1530946.8750, 1527060.7500, 1526673.3750,
         1526530.7500, 1526198.8750, 1525320.1250, 1523746.8750, 1523191.8750],
        [1548761.1250, 1548237.0000, 1537971.0000, 1536741.0000, 1535752.0000,
         1535440.1250, 1534558.7500, 1532569.7500, 1531085.5000, 1530882.6250],
        [1481221.8750, 1475178.3750, 1467995.6250, 1458303.5000, 1457413.6250,
         1457084.2500, 1454690.6250, 1454503.2500, 1452379.7500, 1449011.1250],
        [1555795.8750, 1541895.1250, 1541536.3750, 1538437.5000, 1535853.1250,
         1535478.1250, 1534689.0000, 1534201.7500, 1533893.0000, 1533115.0000],
        [1554974.1250, 1551519.7500, 1551253.3750, 1548935.5000, 1548812.8750,
         1547447.2500, 1547202.2500, 1546517.7500, 1546491.2500, 1546214.1250],
        [1509369.3750, 1506349.6250, 1505539.5000, 1504204.8750, 1501793.8750,
         1500854.6250, 1498553.3750, 1496358.5000, 1495185.8750, 1494782.3750],
        [1545183.6250, 1544405.7500, 1543161.6250, 1540704.3750, 1540002.3750,
         1539887.7500, 1539051.0000, 1538907.1250, 1538042.8750, 1537359.5000],
        [1542702.5000, 1540779.3750, 1536907.8750, 1532773.0000, 1531110.2500,
         1529516.6250, 1528449.2500, 1527225.3750, 1527089.8750, 1527044.7500],
        [1544830.0000, 1544363.0000, 1540992.5000, 1537362.3750, 1535634.8750,
         1534013.0000, 1533087.2500, 1533047.7500, 1532898.6250, 1531536.7500],
        [1555847.8750, 1550828.8750, 1550673.6250, 1549600.3750, 1549470.2500,
         1549009.3750, 1548352.1250, 1547618.3750, 1547587.5000, 1546258.2500],
        [1558796.0000, 1557663.5000, 1554949.0000, 1553457.8750, 1551170.6250,
         1548036.1250, 1547466.3750, 1545683.2500, 1545143.7500, 1544774.0000],
        [1554161.7500, 1551092.1250, 1548579.6250, 1548127.7500, 1545789.5000,
         1545777.6250, 1545566.8750, 1544759.2500, 1543124.8750, 1542643.7500],
        [1550281.8750, 1546678.5000, 1545574.1250, 1545445.8750, 1545432.6250,
         1544719.5000, 1543481.1250, 1540979.2500, 1540509.0000, 1540368.0000],
        [1384171.8750, 1340121.2500, 1314505.6250, 1291715.5000, 1287743.8750,
         1203881.5000, 1202181.1250, 1180743.7500, 1171540.6250, 1154665.2500],
        [1519425.5000, 1517951.1250, 1517431.5000, 1516661.8750, 1515869.3750,
         1514607.7500, 1513168.5000, 1511195.7500, 1511158.2500, 1510568.8750],
        [1545023.0000, 1541549.6250, 1539883.3750, 1539572.0000, 1538480.0000,
         1537777.5000, 1537777.5000, 1537743.6250, 1535139.8750, 1534956.8750],
        [1528761.2500, 1525256.0000, 1514618.0000, 1513587.1250, 1513431.1250,
         1512738.5000, 1512282.7500, 1509899.1250, 1506661.2500, 1506612.5000],
        [1403677.0000, 1343508.5000, 1331802.7500, 1286950.7500, 1269557.7500,
         1265577.0000, 1264385.1250, 1242251.8750, 1225176.7500, 1220844.8750],
        [1512748.6250, 1511527.1250, 1508829.6250, 1507677.5000, 1507576.8750,
         1507559.6250, 1506020.6250, 1505340.0000, 1502917.1250, 1501437.3750],
        [1428028.5000, 1409634.7500, 1405165.1250, 1398238.1250, 1397799.5000,
         1396953.2500, 1395089.3750, 1389633.1250, 1388566.6250, 1387764.3750],
        [1510070.6250, 1503550.8750, 1499820.1250, 1499355.3750, 1494528.6250,
         1494192.3750, 1493128.3750, 1491732.0000, 1491621.0000, 1490432.2500],
        [1355920.7500, 1340328.3750, 1338682.8750, 1300259.6250, 1275422.8750,
         1268896.8750, 1255591.7500, 1247054.6250, 1245788.6250, 1238798.6250],
        [1545926.5000, 1539485.3750, 1537852.1250, 1537783.2500, 1537231.8750,
         1536966.6250, 1536770.2500, 1536525.5000, 1535826.7500, 1535794.5000],
        [1533584.3750, 1529042.6250, 1527802.2500, 1527288.0000, 1525461.1250,
         1523731.0000, 1522731.5000, 1522416.3750, 1521702.2500, 1520129.8750],
        [1519034.3750, 1516734.1250, 1516365.3750, 1515031.1250, 1514837.6250,
         1514424.5000, 1513907.5000, 1513409.5000, 1512944.8750, 1512640.3750],
        [1436121.8750, 1434609.1250, 1425640.3750, 1398583.5000, 1396853.2500,
         1392903.6250, 1380637.3750, 1379784.3750, 1378477.1250, 1378107.7500],
        [1335667.1250, 1320487.5000, 1291625.5000, 1291424.7500, 1275773.1250,
         1273921.5000, 1268734.7500, 1263048.5000, 1262081.7500, 1261559.5000],
        [1272429.2500, 1130879.3750, 1039945.7500, 1014351.9375, 1011519.6875,
          994187.3125,  981461.1875,  980947.5000,  912794.5625,  876778.3750],
        [1237644.8750, 1136599.0000, 1135214.6250, 1118405.8750, 1093776.1250,
         1071288.6250, 1055711.2500, 1041221.8750, 1017466.8750,  972238.4375],
        [1437711.3750, 1416452.1250, 1415740.3750, 1407639.7500, 1406937.8750,
         1405744.1250, 1405327.3750, 1405171.8750, 1404397.5000, 1403750.7500],
        [1469104.8750, 1468537.5000, 1461031.8750, 1460301.8750, 1448426.6250,
         1446078.8750, 1445534.2500, 1443236.6250, 1433513.7500, 1433513.7500],
        [1450288.5000, 1444318.8750, 1443129.2500, 1434870.6250, 1432695.1250,
         1432185.5000, 1431643.3750, 1431628.3750, 1429835.5000, 1428483.3750],
        [1407810.2500, 1402067.6250, 1383406.5000, 1377097.3750, 1374638.3750,
         1360342.6250, 1351697.6250, 1351674.3750, 1347886.0000, 1346642.2500],
        [1475810.1250, 1466133.5000, 1455327.5000, 1445186.8750, 1422533.0000,
         1414449.0000, 1404890.5000, 1389777.5000, 1374178.3750, 1371562.5000],
        [1373046.5000, 1370592.2500, 1337049.7500, 1326584.1250, 1294439.5000,
         1285334.2500, 1264432.1250, 1255842.0000, 1255070.8750, 1254666.3750],
        [1445892.6250, 1438993.8750, 1432391.8750, 1420668.8750, 1417787.3750,
         1417326.3750, 1416472.3750, 1411534.1250, 1408942.6250, 1408600.0000],
        [1481649.8750, 1478977.5000, 1471325.7500, 1467850.0000, 1467535.1250,
         1467011.8750, 1463440.1250, 1460008.1250, 1457472.0000, 1453315.0000],
        [1379706.7500, 1365229.2500, 1354658.0000, 1348090.3750, 1343199.7500,
         1341541.8750, 1329574.3750, 1302571.7500, 1302512.1250, 1298454.1250],
        [1460317.1250, 1428648.2500, 1418473.0000, 1415930.7500, 1397971.3750,
         1362902.0000, 1346479.1250, 1342432.7500, 1340425.5000, 1326811.7500],
        [1469528.0000, 1442716.3750, 1434311.0000, 1421922.6250, 1421373.6250,
         1416477.8750, 1408471.0000, 1403373.3750, 1402022.2500, 1389507.2500],
        [1506665.6250, 1505489.2500, 1476219.7500, 1458967.0000, 1441225.6250,
         1423492.5000, 1423039.1250, 1422808.5000, 1420632.3750, 1419429.7500],
        [1391372.8750, 1374181.0000, 1368054.8750, 1342553.0000, 1341000.8750,
         1336989.8750, 1317676.0000, 1314254.8750, 1313163.6250, 1312664.1250],
        [1419819.6250, 1408029.1250, 1398100.7500, 1380840.2500, 1374787.8750,
         1372774.2500, 1369387.6250, 1366544.8750, 1365884.3750, 1365819.1250],
        [1443012.2500, 1417000.6250, 1416384.5000, 1393534.7500, 1382938.2500,
         1381359.1250, 1371277.3750, 1359613.7500, 1354408.6250, 1335498.8750],
        [1452503.1250, 1438830.6250, 1431590.1250, 1412856.7500, 1412258.6250,
         1411080.6250, 1409707.3750, 1404057.2500, 1401339.1250, 1385426.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1527741.0000,       0.0000],
         [1520108.1250,       0.0000],
         [1518706.8750,       0.0000],
         ...,
         [      0.0000, 1513353.2500],
         [1513156.8750,       0.0000],
         [1512491.8750,       0.0000]],

        [[1531421.3750,       0.0000],
         [1528324.0000,       0.0000],
         [1526912.2500,       0.0000],
         ...,
         [1523693.1250,       0.0000],
         [1523033.6250,       0.0000],
         [1522407.6250,       0.0000]],

        [[1332696.0000,       0.0000],
         [1303619.3750,       0.0000],
         [1276703.1250,       0.0000],
         ...,
         [1179413.5000,       0.0000],
         [1179140.2500,       0.0000],
         [1174379.6250,       0.0000]],

        ...,

        [[1419819.6250,       0.0000],
         [1408029.1250,       0.0000],
         [      0.0000, 1398100.7500],
         ...,
         [      0.0000, 1366544.8750],
         [1365884.3750,       0.0000],
         [1365819.1250,       0.0000]],

        [[1443012.2500,       0.0000],
         [1417000.6250,       0.0000],
         [1416384.5000,       0.0000],
         ...,
         [      0.0000, 1359613.7500],
         [      0.0000, 1354408.6250],
         [      0.0000, 1335498.8750]],

        [[      0.0000, 1452503.1250],
         [      0.0000, 1438830.6250],
         [      0.0000, 1431590.1250],
         ...,
         [      0.0000, 1404057.2500],
         [1401339.1250,       0.0000],
         [      0.0000, 1385426.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13651755.0000,  1513353.2500],
        [15257164.0000,        0.0000],
        [11002616.0000,  1201140.6250],
        [14481272.0000,        0.0000],
        [ 9219756.0000,  3955172.2500],
        [10039568.0000,  2377251.5000],
        [ 6635804.0000,  4282656.0000],
        [ 9667262.0000,  2382432.0000],
        [13863208.0000,  1542087.7500],
        [ 9443108.0000,  3991075.5000],
        [15457860.0000,        0.0000],
        [13136711.0000,  1450432.2500],
        [14576704.0000,        0.0000],
        [13966772.0000,  1548761.1250],
        [15360860.0000,        0.0000],
        [15277556.0000,        0.0000],
        [14865289.0000,        0.0000],
        [10521274.0000,  4527794.0000],
        [14623667.0000,        0.0000],
        [13747507.0000,  1534621.7500],
        [15371999.0000,        0.0000],
        [11690775.0000,  2917006.7500],
        [15384895.0000,        0.0000],
        [15489367.0000,        0.0000],
        [10504694.0000,  4508298.0000],
        [15406706.0000,        0.0000],
        [15323600.0000,        0.0000],
        [15367766.0000,        0.0000],
        [15495247.0000,        0.0000],
        [15507141.0000,        0.0000],
        [15469623.0000,        0.0000],
        [15443470.0000,        0.0000],
        [ 3773790.0000,  8757480.0000],
        [12113946.0000,  3034093.5000],
        [13850160.0000,  1537743.6250],
        [ 9082760.0000,  6061088.0000],
        [ 7650535.5000,  5203197.0000],
        [ 9043480.0000,  6028154.0000],
        [11159209.0000,  2837663.2500],
        [14968432.0000,        0.0000],
        [ 9089942.0000,  3776803.2500],
        [15380163.0000,        0.0000],
        [15253890.0000,        0.0000],
        [13632964.0000,  1516365.3750],
        [ 2775330.5000, 11226388.0000],
        [ 5103402.0000,  7740922.0000],
        [ 6070274.5000,  4145020.7500],
        [       0.0000, 10879568.0000],
        [14108874.0000,        0.0000],
        [10134362.0000,  4374918.5000],
        [11473919.0000,  2885159.0000],
        [ 1346642.2500, 12356621.0000],
        [       0.0000, 14219848.0000],
        [ 5092163.0000,  7924894.5000],
        [11355391.0000,  2863219.0000],
        [11747673.0000,  2920912.0000],
        [       0.0000, 13365538.0000],
        [ 1326811.7500, 12513580.0000],
        [       0.0000, 14209704.0000],
        [ 2843441.0000, 11654529.0000],
        [ 7997266.5000,  5414645.0000],
        [11057342.0000,  2764645.5000],
        [ 9805507.0000,  4049521.2500],
        [ 1401339.1250, 12758312.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 146/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.14s/it]  7%|▋         | 2/29 [01:01<11:23, 25.31s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.9787676334381104
Epoch 147/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:11, 60.42s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.955695390701294
Epoch 148/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:28, 61.02s/it]  7%|▋         | 2/29 [01:01<11:33, 25.67s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 3.950015068054199
Epoch 149/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:40, 57.15s/it]  7%|▋         | 2/29 [00:58<10:53, 24.20s/it] 10%|█         | 3/29 [01:00<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:01<03:44,  8.96s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.06s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.9322478771209717
Epoch 150/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:34, 59.08s/it]  7%|▋         | 2/29 [00:59<11:11, 24.87s/it] 10%|█         | 3/29 [01:00<06:02, 13.93s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 3.9169650077819824
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0050, 0.0055, 0.0016,  ..., 0.0042, 0.0023, 0.0241],
        [0.0040, 0.0053, 0.0014,  ..., 0.0032, 0.0014, 0.0233],
        [0.0298, 0.0062, 0.0023,  ..., 0.0070, 0.0141, 0.0274],
        ...,
        [0.0047, 0.0089, 0.0040,  ..., 0.0034, 0.0022, 0.0268],
        [0.0038, 0.0108, 0.0016,  ..., 0.0048, 0.0030, 0.0192],
        [0.0139, 0.0065, 0.0011,  ..., 0.0026, 0.0050, 0.0225]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9968, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9851, 0.9846, 0.9844, 0.9813, 0.9776, 0.9773, 0.9768, 0.9765, 0.9765,
         0.9757],
        [0.9941, 0.9938, 0.9938, 0.9928, 0.9925, 0.9923, 0.9921, 0.9920, 0.9916,
         0.9914],
        [0.9874, 0.9869, 0.9869, 0.9868, 0.9862, 0.9858, 0.9857, 0.9854, 0.9854,
         0.9844],
        [0.9900, 0.9862, 0.9832, 0.9824, 0.9824, 0.9821, 0.9797, 0.9786, 0.9781,
         0.9764],
        [0.9810, 0.9750, 0.9749, 0.9745, 0.9743, 0.9743, 0.9715, 0.9712, 0.9707,
         0.9695],
        [0.9831, 0.9822, 0.9814, 0.9800, 0.9795, 0.9795, 0.9794, 0.9792, 0.9769,
         0.9767],
        [0.9977, 0.9975, 0.9973, 0.9973, 0.9972, 0.9972, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9923, 0.9881, 0.9879, 0.9872, 0.9870, 0.9860, 0.9852, 0.9852, 0.9851,
         0.9851],
        [0.9979, 0.9976, 0.9974, 0.9974, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9945, 0.9939, 0.9933, 0.9931, 0.9926, 0.9922, 0.9919, 0.9918, 0.9917,
         0.9913],
        [0.9942, 0.9935, 0.9931, 0.9930, 0.9927, 0.9927, 0.9925, 0.9917, 0.9916,
         0.9915],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9966,
         0.9966],
        [0.9969, 0.9969, 0.9967, 0.9966, 0.9966, 0.9966, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9952, 0.9949, 0.9949, 0.9947, 0.9947, 0.9944, 0.9943, 0.9942, 0.9941,
         0.9941],
        [0.9962, 0.9960, 0.9958, 0.9958, 0.9957, 0.9956, 0.9953, 0.9952, 0.9951,
         0.9950],
        [0.9942, 0.9938, 0.9934, 0.9932, 0.9930, 0.9929, 0.9929, 0.9928, 0.9927,
         0.9927],
        [0.9969, 0.9968, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9976, 0.9976, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9944, 0.9939, 0.9938, 0.9933, 0.9932, 0.9931, 0.9930, 0.9930, 0.9930,
         0.9926],
        [0.9979, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9970, 0.9969,
         0.9969],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9957, 0.9956, 0.9955, 0.9953, 0.9953, 0.9953, 0.9952, 0.9951, 0.9950,
         0.9950],
        [0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9974, 0.9974, 0.9971, 0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9975, 0.9975, 0.9973, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9980, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9978, 0.9975, 0.9975, 0.9975, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9901, 0.9882, 0.9860, 0.9854, 0.9841, 0.9817, 0.9796, 0.9787, 0.9784,
         0.9761],
        [0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9957,
         0.9957],
        [0.9972, 0.9972, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9967, 0.9965, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9910, 0.9879, 0.9868, 0.9858, 0.9841, 0.9840, 0.9827, 0.9822, 0.9815,
         0.9813],
        [0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9952],
        [0.9928, 0.9907, 0.9904, 0.9904, 0.9903, 0.9903, 0.9902, 0.9902, 0.9899,
         0.9898],
        [0.9956, 0.9954, 0.9953, 0.9951, 0.9950, 0.9949, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9890, 0.9881, 0.9880, 0.9854, 0.9853, 0.9850, 0.9832, 0.9829, 0.9826,
         0.9821],
        [0.9974, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9969],
        [0.9967, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9927, 0.9922, 0.9922, 0.9905, 0.9904, 0.9903, 0.9898, 0.9897, 0.9896,
         0.9894],
        [0.9868, 0.9856, 0.9843, 0.9842, 0.9837, 0.9835, 0.9834, 0.9833, 0.9833,
         0.9831],
        [0.9835, 0.9755, 0.9679, 0.9664, 0.9643, 0.9628, 0.9621, 0.9599, 0.9595,
         0.9581],
        [0.9824, 0.9766, 0.9761, 0.9760, 0.9753, 0.9714, 0.9708, 0.9704, 0.9698,
         0.9656],
        [0.9922, 0.9910, 0.9910, 0.9908, 0.9907, 0.9905, 0.9905, 0.9904, 0.9904,
         0.9904],
        [0.9937, 0.9934, 0.9932, 0.9930, 0.9924, 0.9924, 0.9920, 0.9917, 0.9917,
         0.9917],
        [0.9928, 0.9927, 0.9926, 0.9922, 0.9922, 0.9918, 0.9918, 0.9918, 0.9917,
         0.9916],
        [0.9912, 0.9905, 0.9900, 0.9899, 0.9890, 0.9886, 0.9885, 0.9877, 0.9877,
         0.9873],
        [0.9941, 0.9937, 0.9933, 0.9927, 0.9918, 0.9912, 0.9906, 0.9900, 0.9896,
         0.9892],
        [0.9898, 0.9896, 0.9873, 0.9856, 0.9856, 0.9855, 0.9834, 0.9834, 0.9833,
         0.9828],
        [0.9926, 0.9920, 0.9918, 0.9914, 0.9912, 0.9907, 0.9906, 0.9905, 0.9905,
         0.9904],
        [0.9940, 0.9940, 0.9938, 0.9938, 0.9938, 0.9935, 0.9933, 0.9932, 0.9931,
         0.9931],
        [0.9894, 0.9889, 0.9887, 0.9874, 0.9873, 0.9868, 0.9858, 0.9854, 0.9854,
         0.9852],
        [0.9935, 0.9921, 0.9915, 0.9912, 0.9904, 0.9878, 0.9876, 0.9873, 0.9871,
         0.9863],
        [0.9938, 0.9926, 0.9924, 0.9913, 0.9913, 0.9908, 0.9906, 0.9906, 0.9904,
         0.9896],
        [0.9957, 0.9957, 0.9941, 0.9936, 0.9921, 0.9915, 0.9915, 0.9914, 0.9911,
         0.9911],
        [0.9891, 0.9891, 0.9890, 0.9878, 0.9877, 0.9872, 0.9868, 0.9867, 0.9866,
         0.9864],
        [0.9915, 0.9914, 0.9904, 0.9897, 0.9896, 0.9895, 0.9894, 0.9894, 0.9891,
         0.9891],
        [0.9925, 0.9913, 0.9904, 0.9894, 0.9893, 0.9892, 0.9882, 0.9882, 0.9879,
         0.9867],
        [0.9932, 0.9922, 0.9920, 0.9913, 0.9913, 0.9911, 0.9910, 0.9903, 0.9897,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 0, 0, 1, 1],
        [1, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1522783.7500, 1514187.6250, 1511932.2500, 1511641.0000, 1508576.5000,
         1508388.0000, 1507371.3750, 1507203.1250, 1507011.8750, 1506009.1250],
        [1529229.2500, 1525916.6250, 1524095.7500, 1523247.0000, 1523213.6250,
         1522368.5000, 1520934.7500, 1520022.6250, 1519422.6250, 1519128.5000],
        [1294080.3750, 1284667.5000, 1280745.6250, 1225401.1250, 1162488.0000,
         1156757.1250, 1149123.1250, 1144196.8750, 1143674.2500, 1131307.6250],
        [1470703.0000, 1465230.5000, 1464117.1250, 1444846.5000, 1437341.2500,
         1434242.6250, 1429456.5000, 1428115.6250, 1419612.5000, 1415420.5000],
        [1337118.6250, 1327386.3750, 1327073.7500, 1324679.0000, 1313132.2500,
         1307051.3750, 1305077.2500, 1298518.5000, 1298211.5000, 1281031.5000],
        [1388020.0000, 1313073.5000, 1259071.5000, 1244424.1250, 1244128.7500,
         1239676.7500, 1197959.1250, 1178442.1250, 1170872.6250, 1142378.0000],
        [1219898.7500, 1118924.3750, 1117358.0000, 1111259.2500, 1108673.1250,
         1108112.8750, 1064808.3750, 1061292.5000, 1053718.6250, 1035050.0000],
        [1256720.2500, 1241863.5000, 1227046.5000, 1201896.8750, 1193571.0000,
         1193445.8750, 1192374.2500, 1188865.6250, 1150631.0000, 1147022.0000],
        [1547726.2500, 1544628.2500, 1540761.8750, 1539597.0000, 1537227.6250,
         1536565.1250, 1533397.2500, 1532846.0000, 1532750.8750, 1531805.5000],
        [1433412.5000, 1350987.5000, 1346027.2500, 1332539.6250, 1328892.3750,
         1310247.6250, 1295851.2500, 1295270.6250, 1293256.2500, 1293176.1250],
        [1553057.7500, 1546212.5000, 1542724.7500, 1542192.2500, 1538562.1250,
         1538387.6250, 1538327.5000, 1537218.7500, 1537176.2500, 1536450.7500],
        [1479726.6250, 1467140.6250, 1454897.3750, 1450967.7500, 1440145.8750,
         1431580.6250, 1425822.6250, 1424349.3750, 1420828.7500, 1413773.2500],
        [1473402.5000, 1457584.6250, 1450865.3750, 1448429.3750, 1442589.8750,
         1441158.3750, 1437234.3750, 1420435.8750, 1419930.6250, 1417100.6250],
        [1555935.3750, 1552529.1250, 1551490.1250, 1549830.8750, 1549194.0000,
         1545979.5000, 1545673.0000, 1545531.5000, 1545248.5000, 1544899.2500],
        [1536395.1250, 1536223.7500, 1535066.7500, 1533599.1250, 1531881.5000,
         1531443.2500, 1528988.7500, 1528915.8750, 1523805.0000, 1523408.2500],
        [1531119.0000, 1530236.0000, 1527288.0000, 1525311.2500, 1525020.3750,
         1524767.3750, 1521165.3750, 1520759.2500, 1520293.7500, 1519700.8750],
        [1494972.0000, 1488605.5000, 1487246.1250, 1483076.3750, 1482732.6250,
         1476908.3750, 1474657.8750, 1473926.7500, 1470520.6250, 1470515.0000],
        [1515619.3750, 1512054.7500, 1506417.0000, 1506376.8750, 1504985.3750,
         1503149.3750, 1497247.7500, 1495151.7500, 1493018.6250, 1490250.3750],
        [1473276.0000, 1465653.8750, 1457048.1250, 1451376.0000, 1447828.6250,
         1446230.6250, 1445244.7500, 1444183.8750, 1442448.1250, 1441898.0000],
        [1531513.3750, 1528077.6250, 1524988.3750, 1524773.1250, 1522324.8750,
         1521001.5000, 1520538.8750, 1519002.5000, 1517910.5000, 1517718.0000],
        [1546163.8750, 1545970.7500, 1533770.1250, 1532518.5000, 1531287.0000,
         1530001.0000, 1529697.5000, 1529596.8750, 1529077.6250, 1529055.8750],
        [1476460.5000, 1466643.8750, 1465347.7500, 1453973.5000, 1451950.5000,
         1449848.7500, 1448052.3750, 1447424.1250, 1447168.7500, 1438785.3750],
        [1552046.6250, 1540130.1250, 1538935.0000, 1537566.2500, 1537465.0000,
         1536500.6250, 1535820.8750, 1533542.0000, 1531342.5000, 1530241.7500],
        [1551701.7500, 1548525.0000, 1548164.5000, 1546672.6250, 1546436.6250,
         1545415.0000, 1544031.6250, 1543994.8750, 1543731.3750, 1543494.3750],
        [1505983.3750, 1503383.0000, 1500841.7500, 1496237.1250, 1496227.1250,
         1495334.2500, 1493682.2500, 1491767.6250, 1490806.1250, 1490664.0000],
        [1545512.2500, 1543819.6250, 1543023.2500, 1541038.0000, 1539341.5000,
         1538484.5000, 1538277.5000, 1538258.5000, 1536233.8750, 1536091.8750],
        [1542864.5000, 1541202.6250, 1535195.5000, 1533691.2500, 1531509.0000,
         1529429.1250, 1526974.8750, 1526622.5000, 1526127.5000, 1526108.6250],
        [1544564.8750, 1543516.3750, 1539624.8750, 1535078.3750, 1535050.6250,
         1533311.0000, 1531828.8750, 1531700.3750, 1531682.8750, 1531611.2500],
        [1554793.2500, 1549448.1250, 1548270.8750, 1547149.1250, 1547006.0000,
         1546874.7500, 1546513.3750, 1546320.2500, 1545714.2500, 1545690.6250],
        [1555030.5000, 1554415.2500, 1551812.7500, 1549316.6250, 1549176.2500,
         1545572.7500, 1545493.1250, 1544121.6250, 1543656.2500, 1542695.2500],
        [1550746.1250, 1547782.2500, 1546407.1250, 1545077.5000, 1545026.0000,
         1544756.3750, 1542805.5000, 1542452.5000, 1542056.8750, 1542030.3750],
        [1549773.2500, 1543647.3750, 1543426.6250, 1543391.3750, 1540679.5000,
         1538716.2500, 1538544.6250, 1538358.2500, 1536626.5000, 1536478.6250],
        [1388348.2500, 1352686.7500, 1310051.5000, 1298866.5000, 1275196.6250,
         1232779.7500, 1195975.2500, 1180601.8750, 1174862.5000, 1137924.3750],
        [1515252.2500, 1515237.7500, 1513741.5000, 1513535.0000, 1512122.6250,
         1510113.7500, 1508885.7500, 1506878.2500, 1504830.5000, 1503953.8750],
        [1538327.5000, 1536521.0000, 1535784.1250, 1533476.1250, 1531735.3750,
         1531704.7500, 1530811.0000, 1530811.0000, 1530290.0000, 1529521.0000],
        [1525884.6250, 1521404.7500, 1509369.3750, 1508409.6250, 1508025.5000,
         1505261.0000, 1505226.5000, 1504638.1250, 1503331.5000, 1501130.8750],
        [1406598.3750, 1347053.2500, 1325199.5000, 1305747.0000, 1275562.6250,
         1274207.0000, 1249790.5000, 1241844.5000, 1229104.2500, 1225165.0000],
        [1507735.1250, 1505923.0000, 1505733.3750, 1504410.0000, 1502260.8750,
         1501519.0000, 1497754.6250, 1497000.7500, 1495474.0000, 1493765.0000],
        [1443254.5000, 1400457.2500, 1394563.8750, 1394478.7500, 1393615.8750,
         1392437.5000, 1390826.3750, 1390298.5000, 1385454.2500, 1383066.1250],
        [1503770.2500, 1497897.6250, 1496394.1250, 1491700.6250, 1489450.3750,
         1488476.3750, 1485723.5000, 1485549.2500, 1483911.0000, 1483500.6250],
        [1366959.3750, 1350203.0000, 1348273.0000, 1298574.2500, 1297639.5000,
         1290832.5000, 1259256.3750, 1252721.1250, 1248417.0000, 1239255.8750],
        [1541420.2500, 1536673.5000, 1536277.8750, 1534741.6250, 1534697.7500,
         1534454.8750, 1534301.1250, 1534215.0000, 1533685.2500, 1531443.2500],
        [1526741.8750, 1519999.3750, 1519444.3750, 1518316.0000, 1517632.6250,
         1517283.8750, 1517276.6250, 1516403.0000, 1515866.5000, 1514986.2500],
        [1515178.5000, 1513066.0000, 1513042.8750, 1512633.2500, 1510738.8750,
         1509474.5000, 1509337.6250, 1508721.7500, 1508428.2500, 1507782.5000],
        [1441781.1250, 1431770.5000, 1431433.2500, 1396914.5000, 1396086.1250,
         1393008.6250, 1382944.7500, 1381309.0000, 1380122.6250, 1374491.6250],
        [1325753.1250, 1302688.6250, 1278125.8750, 1276975.7500, 1267273.8750,
         1264952.0000, 1262267.1250, 1260447.1250, 1260057.6250, 1256578.7500],
        [1264113.8750, 1128372.5000, 1012089.0000,  990696.8125,  960941.7500,
          940044.1250,  931286.1250,  902301.2500,  896785.0625,  879399.4375],
        [1244797.0000, 1145433.7500, 1136926.5000, 1135158.3750, 1123823.3750,
         1063773.1250, 1054689.7500, 1048826.0000, 1039558.0000,  978427.6250],
        [1430734.3750, 1408174.1250, 1406399.8750, 1402733.7500, 1402077.0000,
         1396830.6250, 1396757.3750, 1395170.5000, 1394954.8750, 1394429.5000],
        [1463191.7500, 1455292.7500, 1451424.5000, 1448207.0000, 1436152.0000,
         1435389.2500, 1427918.2500, 1422187.1250, 1421061.7500, 1421061.7500],
        [1443553.2500, 1442171.6250, 1439972.7500, 1432274.2500, 1431922.0000,
         1424367.0000, 1423817.0000, 1422666.0000, 1421309.7500, 1419988.8750],
        [1410702.6250, 1397668.8750, 1387761.7500, 1386284.2500, 1366926.8750,
         1359956.0000, 1357767.3750, 1343257.5000, 1341602.0000, 1335394.5000],
        [1470520.6250, 1462603.0000, 1453349.6250, 1442489.3750, 1422860.0000,
         1411527.3750, 1398828.8750, 1387842.5000, 1378829.3750, 1371391.1250],
        [1382952.7500, 1378851.7500, 1334710.7500, 1303619.3750, 1302379.2500,
         1301758.3750, 1262728.2500, 1262302.0000, 1260215.1250, 1252470.2500],
        [1439276.7500, 1426582.8750, 1423176.2500, 1414757.8750, 1411247.5000,
         1401356.5000, 1398278.0000, 1398207.3750, 1396939.7500, 1395709.3750],
        [1469439.7500, 1468833.0000, 1464481.6250, 1463988.7500, 1463863.1250,
         1457823.7500, 1453312.2500, 1451482.5000, 1450007.7500, 1449599.7500],
        [1376356.8750, 1365871.2500, 1361319.8750, 1337506.3750, 1334862.1250,
         1324804.0000, 1306648.8750, 1298452.8750, 1298142.1250, 1294844.5000],
        [1457406.6250, 1429275.1250, 1416685.8750, 1411078.0000, 1394911.0000,
         1344231.3750, 1340359.0000, 1335379.1250, 1330666.6250, 1315000.8750],
        [1463898.0000, 1439873.8750, 1435645.2500, 1413626.2500, 1413323.0000,
         1402624.0000, 1399743.0000, 1398340.6250, 1394457.3750, 1378553.2500],
        [1505288.3750, 1505114.6250, 1471003.1250, 1460850.7500, 1429757.7500,
         1418335.1250, 1416962.8750, 1415061.3750, 1409692.5000, 1408527.3750],
        [1369592.7500, 1369557.5000, 1367460.1250, 1343931.3750, 1342605.5000,
         1333739.8750, 1325736.7500, 1323926.1250, 1321990.7500, 1318265.5000],
        [1417949.6250, 1414473.1250, 1394755.3750, 1380387.1250, 1379730.5000,
         1377470.3750, 1376223.0000, 1374529.6250, 1370500.8750, 1369211.3750],
        [1437409.7500, 1412943.0000, 1394933.6250, 1375549.8750, 1372772.8750,
         1371898.7500, 1352052.1250, 1351652.5000, 1345575.5000, 1323835.2500],
        [1451859.1250, 1431732.1250, 1427688.0000, 1414092.8750, 1413362.1250,
         1409254.2500, 1406609.1250, 1392784.1250, 1382031.1250, 1377304.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1522783.7500,       0.0000],
         [1514187.6250,       0.0000],
         [1511932.2500,       0.0000],
         ...,
         [1507203.1250,       0.0000],
         [1507011.8750,       0.0000],
         [1506009.1250,       0.0000]],

        [[1529229.2500,       0.0000],
         [1525916.6250,       0.0000],
         [1524095.7500,       0.0000],
         ...,
         [1520022.6250,       0.0000],
         [1519422.6250,       0.0000],
         [1519128.5000,       0.0000]],

        [[1294080.3750,       0.0000],
         [1284667.5000,       0.0000],
         [1280745.6250,       0.0000],
         ...,
         [1144196.8750,       0.0000],
         [1143674.2500,       0.0000],
         [1131307.6250,       0.0000]],

        ...,

        [[1417949.6250,       0.0000],
         [1414473.1250,       0.0000],
         [      0.0000, 1394755.3750],
         ...,
         [1374529.6250,       0.0000],
         [1370500.8750,       0.0000],
         [1369211.3750,       0.0000]],

        [[1437409.7500,       0.0000],
         [1412943.0000,       0.0000],
         [1394933.6250,       0.0000],
         ...,
         [      0.0000, 1351652.5000],
         [1345575.5000,       0.0000],
         [      0.0000, 1323835.2500]],

        [[      0.0000, 1451859.1250],
         [      0.0000, 1431732.1250],
         [      0.0000, 1427688.0000],
         ...,
         [      0.0000, 1392784.1250],
         [      0.0000, 1382031.1250],
         [1377304.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15105104.0000,        0.0000],
        [15227580.0000,        0.0000],
        [ 9590284.0000,  2382158.2500],
        [14409086.0000,        0.0000],
        [10467214.0000,  2652065.5000],
        [11138370.0000,  1239676.7500],
        [ 5623564.0000,  5375532.0000],
        [10799866.0000,  1193571.0000],
        [13840741.0000,  1536565.1250],
        [10640377.0000,  2639283.5000],
        [15410310.0000,        0.0000],
        [14409233.0000,        0.0000],
        [14408731.0000,        0.0000],
        [13941412.0000,  1544899.2500],
        [15309727.0000,        0.0000],
        [15245662.0000,        0.0000],
        [14803161.0000,        0.0000],
        [10507123.0000,  4517148.0000],
        [14515188.0000,        0.0000],
        [13699772.0000,  1528077.6250],
        [15337140.0000,        0.0000],
        [11631842.0000,  2913812.5000],
        [15373590.0000,        0.0000],
        [15462168.0000,        0.0000],
        [10472514.0000,  4492413.0000],
        [15400082.0000,        0.0000],
        [15319726.0000,        0.0000],
        [15357971.0000,        0.0000],
        [15477780.0000,        0.0000],
        [15481290.0000,        0.0000],
        [15449140.0000,        0.0000],
        [15409642.0000,        0.0000],
        [ 3760110.5000,  8787182.0000],
        [12078687.0000,  3025864.0000],
        [13797247.0000,  1531735.3750],
        [ 9046940.0000,  6045741.5000],
        [ 7674113.5000,  5206158.5000],
        [ 9002171.0000,  6009405.0000],
        [ 9747654.0000,  4220799.0000],
        [13420650.0000,  1485723.5000],
        [ 9152420.0000,  3799712.5000],
        [15351910.0000,        0.0000],
        [15183950.0000,        0.0000],
        [13599683.0000,  1508721.7500],
        [ 4161168.2500,  9848693.0000],
        [ 6323153.0000,  6431966.5000],
        [ 5002488.5000,  4903541.0000],
        [       0.0000, 10971414.0000],
        [12625528.0000,  1402733.7500],
        [10039779.0000,  4342106.5000],
        [11426567.0000,  2875475.2500],
        [       0.0000, 13687322.0000],
        [       0.0000, 14200242.0000],
        [ 3818391.7500,  9223596.0000],
        [11251497.0000,  2854034.5000],
        [10227269.0000,  4365564.0000],
        [       0.0000, 13298809.0000],
        [       0.0000, 13774993.0000],
        [       0.0000, 14140085.0000],
        [ 2825490.2500, 11615103.0000],
        [ 8015192.5000,  5401614.0000],
        [12460476.0000,  1394755.3750],
        [ 9711083.0000,  4027540.0000],
        [ 1377304.8750, 12729413.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 151/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.63s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.8926117420196533
Epoch 152/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.57s/it]  7%|▋         | 2/29 [00:58<10:54, 24.25s/it] 10%|█         | 3/29 [00:59<05:53, 13.60s/it] 14%|█▍        | 4/29 [01:00<03:34,  8.59s/it] 17%|█▋        | 5/29 [01:01<02:19,  5.82s/it] 21%|██        | 6/29 [01:02<01:35,  4.16s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.10s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 3.8658344745635986
Epoch 153/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:02, 60.09s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:10, 14.23s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.85662579536438
Epoch 154/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:38, 59.22s/it]  7%|▋         | 2/29 [01:00<11:13, 24.93s/it] 10%|█         | 3/29 [01:01<06:03, 13.96s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.8440959453582764
Epoch 155/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:53, 57.61s/it]  7%|▋         | 2/29 [01:01<11:37, 25.84s/it] 10%|█         | 3/29 [01:02<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.12s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.8218674659729004
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0038, 0.0049, 0.0012,  ..., 0.0045, 0.0023, 0.0246],
        [0.0031, 0.0052, 0.0009,  ..., 0.0032, 0.0012, 0.0228],
        [0.0278, 0.0063, 0.0025,  ..., 0.0066, 0.0127, 0.0274],
        ...,
        [0.0047, 0.0094, 0.0038,  ..., 0.0037, 0.0023, 0.0260],
        [0.0027, 0.0105, 0.0015,  ..., 0.0042, 0.0027, 0.0202],
        [0.0118, 0.0066, 0.0010,  ..., 0.0027, 0.0044, 0.0225]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9968, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9973, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9856, 0.9855, 0.9851, 0.9808, 0.9797, 0.9769, 0.9766, 0.9766, 0.9765,
         0.9762],
        [0.9948, 0.9946, 0.9944, 0.9933, 0.9930, 0.9930, 0.9929, 0.9927, 0.9927,
         0.9924],
        [0.9874, 0.9872, 0.9871, 0.9870, 0.9866, 0.9865, 0.9864, 0.9856, 0.9854,
         0.9854],
        [0.9901, 0.9859, 0.9838, 0.9828, 0.9802, 0.9796, 0.9792, 0.9774, 0.9766,
         0.9766],
        [0.9792, 0.9742, 0.9738, 0.9734, 0.9718, 0.9716, 0.9712, 0.9703, 0.9696,
         0.9678],
        [0.9839, 0.9815, 0.9811, 0.9801, 0.9799, 0.9798, 0.9796, 0.9794, 0.9793,
         0.9774],
        [0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9927, 0.9890, 0.9885, 0.9879, 0.9879, 0.9874, 0.9861, 0.9856, 0.9853,
         0.9848],
        [0.9980, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9951, 0.9944, 0.9942, 0.9939, 0.9938, 0.9936, 0.9932, 0.9931, 0.9931,
         0.9928],
        [0.9947, 0.9941, 0.9937, 0.9935, 0.9934, 0.9932, 0.9932, 0.9932, 0.9929,
         0.9927],
        [0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9970,
         0.9970],
        [0.9974, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9968, 0.9968,
         0.9967],
        [0.9956, 0.9952, 0.9952, 0.9951, 0.9951, 0.9948, 0.9947, 0.9947, 0.9946,
         0.9945],
        [0.9964, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961, 0.9959, 0.9957, 0.9956,
         0.9956],
        [0.9949, 0.9945, 0.9941, 0.9939, 0.9938, 0.9938, 0.9937, 0.9936, 0.9935,
         0.9934],
        [0.9973, 0.9972, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9978, 0.9978, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9951, 0.9951, 0.9947, 0.9943, 0.9942, 0.9942, 0.9940, 0.9940, 0.9939,
         0.9936],
        [0.9980, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9970, 0.9968,
         0.9967],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9963, 0.9960, 0.9960, 0.9959, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9975, 0.9974, 0.9973, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9968],
        [0.9978, 0.9978, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9898, 0.9873, 0.9847, 0.9845, 0.9821, 0.9812, 0.9796, 0.9793, 0.9762,
         0.9750],
        [0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9975, 0.9975, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9970],
        [0.9969, 0.9967, 0.9965, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9902, 0.9871, 0.9863, 0.9844, 0.9835, 0.9834, 0.9829, 0.9817, 0.9817,
         0.9808],
        [0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959, 0.9958, 0.9957,
         0.9957],
        [0.9936, 0.9918, 0.9911, 0.9910, 0.9908, 0.9907, 0.9906, 0.9905, 0.9904,
         0.9904],
        [0.9960, 0.9960, 0.9959, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9884, 0.9875, 0.9868, 0.9854, 0.9851, 0.9831, 0.9826, 0.9826, 0.9825,
         0.9819],
        [0.9977, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9972, 0.9970, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9933, 0.9929, 0.9928, 0.9909, 0.9908, 0.9907, 0.9905, 0.9905, 0.9901,
         0.9899],
        [0.9879, 0.9872, 0.9856, 0.9853, 0.9850, 0.9845, 0.9843, 0.9841, 0.9839,
         0.9839],
        [0.9845, 0.9743, 0.9682, 0.9673, 0.9667, 0.9653, 0.9638, 0.9634, 0.9569,
         0.9560],
        [0.9813, 0.9757, 0.9751, 0.9750, 0.9723, 0.9718, 0.9699, 0.9690, 0.9668,
         0.9662],
        [0.9925, 0.9916, 0.9916, 0.9915, 0.9912, 0.9911, 0.9909, 0.9909, 0.9909,
         0.9909],
        [0.9945, 0.9944, 0.9938, 0.9938, 0.9932, 0.9931, 0.9931, 0.9928, 0.9928,
         0.9927],
        [0.9932, 0.9932, 0.9930, 0.9929, 0.9928, 0.9928, 0.9924, 0.9923, 0.9923,
         0.9921],
        [0.9910, 0.9908, 0.9904, 0.9897, 0.9894, 0.9891, 0.9882, 0.9881, 0.9880,
         0.9873],
        [0.9939, 0.9938, 0.9932, 0.9929, 0.9920, 0.9915, 0.9908, 0.9905, 0.9904,
         0.9899],
        [0.9907, 0.9906, 0.9882, 0.9871, 0.9863, 0.9859, 0.9845, 0.9843, 0.9841,
         0.9840],
        [0.9934, 0.9928, 0.9920, 0.9920, 0.9919, 0.9919, 0.9918, 0.9918, 0.9916,
         0.9915],
        [0.9949, 0.9947, 0.9946, 0.9944, 0.9941, 0.9941, 0.9940, 0.9939, 0.9938,
         0.9936],
        [0.9901, 0.9901, 0.9897, 0.9876, 0.9876, 0.9875, 0.9868, 0.9863, 0.9858,
         0.9857],
        [0.9938, 0.9924, 0.9920, 0.9917, 0.9911, 0.9882, 0.9880, 0.9874, 0.9866,
         0.9865],
        [0.9943, 0.9928, 0.9926, 0.9919, 0.9917, 0.9914, 0.9910, 0.9910, 0.9906,
         0.9895],
        [0.9961, 0.9957, 0.9942, 0.9940, 0.9924, 0.9923, 0.9919, 0.9919, 0.9919,
         0.9917],
        [0.9898, 0.9891, 0.9890, 0.9885, 0.9881, 0.9879, 0.9877, 0.9876, 0.9871,
         0.9870],
        [0.9912, 0.9908, 0.9902, 0.9896, 0.9893, 0.9892, 0.9890, 0.9890, 0.9889,
         0.9889],
        [0.9928, 0.9920, 0.9912, 0.9907, 0.9905, 0.9904, 0.9894, 0.9890, 0.9887,
         0.9878],
        [0.9939, 0.9927, 0.9923, 0.9921, 0.9917, 0.9915, 0.9913, 0.9910, 0.9905,
         0.9905]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 1],
        [1, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [0, 1, 1, 1, 0, 0, 0, 0, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1533710.2500, 1528217.5000, 1524518.6250, 1521436.6250, 1521268.3750,
         1520739.0000, 1520289.5000, 1519334.2500, 1519318.3750, 1519129.8750],
        [1538839.6250, 1533297.7500, 1532715.8750, 1532639.8750, 1532004.2500,
         1531982.3750, 1531958.8750, 1530622.6250, 1528701.5000, 1528501.7500],
        [1302102.3750, 1300739.5000, 1294000.1250, 1215984.5000, 1197825.5000,
         1150378.6250, 1146247.8750, 1145875.1250, 1143314.3750, 1138486.7500],
        [1485018.1250, 1482095.0000, 1477043.6250, 1454601.7500, 1448720.8750,
         1447135.6250, 1445941.0000, 1442389.0000, 1441265.6250, 1436230.0000],
        [1335944.7500, 1332515.5000, 1331827.0000, 1329668.2500, 1322082.8750,
         1319715.7500, 1317712.3750, 1302399.0000, 1299142.8750, 1299131.6250],
        [1389325.7500, 1307624.8750, 1270208.1250, 1251599.8750, 1206418.1250,
         1196182.7500, 1189282.8750, 1159142.3750, 1145202.1250, 1144882.2500],
        [1189332.7500, 1106227.1250, 1099892.1250, 1093938.8750, 1070362.3750,
         1066184.2500, 1060880.6250, 1047671.4375, 1037232.7500, 1009654.8125],
        [1271518.2500, 1229369.2500, 1221542.6250, 1204799.1250, 1201579.5000,
         1199405.2500, 1196347.0000, 1193120.3750, 1191259.1250, 1158293.7500],
        [1553140.8750, 1548421.6250, 1546115.1250, 1544899.2500, 1543997.8750,
         1543883.0000, 1539337.1250, 1539231.3750, 1537144.0000, 1536528.3750],
        [1441991.5000, 1367548.7500, 1357101.8750, 1347041.7500, 1345824.5000,
         1336764.2500, 1311701.7500, 1303355.7500, 1296619.0000, 1288204.5000],
        [1554602.0000, 1550045.2500, 1547990.5000, 1546893.8750, 1545204.3750,
         1543994.8750, 1543578.2500, 1543205.8750, 1542179.0000, 1542076.0000],
        [1493072.6250, 1477494.3750, 1473609.1250, 1465948.8750, 1464537.5000,
         1459562.6250, 1452487.8750, 1450081.0000, 1449110.6250, 1444070.8750],
        [1483804.8750, 1471953.1250, 1462836.0000, 1459047.6250, 1456967.5000,
         1453177.8750, 1452595.8750, 1451975.3750, 1445123.5000, 1442003.8750],
        [1559878.5000, 1558645.7500, 1558558.1250, 1555374.6250, 1554135.0000,
         1552939.3750, 1551735.8750, 1551462.1250, 1550618.8750, 1549615.1250],
        [1545407.6250, 1543802.0000, 1541834.8750, 1540977.7500, 1540554.6250,
         1540037.6250, 1539153.7500, 1537712.8750, 1533822.7500, 1533678.0000],
        [1541846.5000, 1538120.6250, 1535176.5000, 1535100.3750, 1534154.8750,
         1533950.0000, 1532341.7500, 1529312.5000, 1528603.8750, 1527100.1250],
        [1501864.0000, 1494758.1250, 1494752.5000, 1492336.7500, 1492211.5000,
         1486361.2500, 1484298.8750, 1484146.0000, 1481665.3750, 1479461.2500],
        [1520831.7500, 1518627.2500, 1517783.2500, 1516112.2500, 1514661.3750,
         1514576.1250, 1508911.7500, 1504641.0000, 1503817.5000, 1503783.1250],
        [1488108.6250, 1478956.3750, 1471825.3750, 1466154.3750, 1465366.0000,
         1463697.0000, 1461707.7500, 1460516.3750, 1459419.2500, 1456609.1250],
        [1540404.7500, 1537570.6250, 1536087.3750, 1530641.6250, 1530497.2500,
         1530014.2500, 1529715.1250, 1528940.6250, 1528681.1250, 1527052.0000],
        [1550950.1250, 1549783.6250, 1539730.6250, 1539046.5000, 1538644.3750,
         1537723.2500, 1535905.7500, 1535738.7500, 1535265.7500, 1535129.6250],
        [1492627.1250, 1491518.6250, 1483380.3750, 1474171.3750, 1473589.3750,
         1472767.5000, 1469532.1250, 1468994.2500, 1466095.6250, 1460867.3750],
        [1555601.6250, 1541240.8750, 1540130.1250, 1539645.5000, 1539533.8750,
         1538569.5000, 1537580.8750, 1533387.0000, 1529207.5000, 1527640.5000],
        [1558564.0000, 1554682.0000, 1553776.3750, 1553460.8750, 1552031.7500,
         1551783.1250, 1551419.1250, 1550339.5000, 1550339.5000, 1549525.0000],
        [1517032.2500, 1510871.5000, 1510419.1250, 1510355.7500, 1505733.3750,
         1505162.0000, 1503641.2500, 1501461.6250, 1501082.2500, 1500949.1250],
        [1550883.6250, 1550397.1250, 1549120.1250, 1546525.2500, 1544399.8750,
         1543603.2500, 1543481.1250, 1543320.6250, 1542030.3750, 1541780.3750],
        [1544492.6250, 1543005.7500, 1540086.0000, 1535880.8750, 1533464.5000,
         1533267.1250, 1532201.5000, 1531732.5000, 1531022.7500, 1529297.8750],
        [1551879.2500, 1550283.2500, 1541323.1250, 1540265.2500, 1539488.3750,
         1539071.3750, 1538104.5000, 1537946.1250, 1536874.2500, 1536393.6250],
        [1560342.7500, 1554923.6250, 1554250.6250, 1553326.0000, 1553176.3750,
         1551707.7500, 1550997.6250, 1550895.3750, 1550891.1250, 1550793.3750],
        [1561034.8750, 1560460.3750, 1557402.1250, 1557266.8750, 1555570.3750,
         1553862.3750, 1552197.6250, 1551858.6250, 1550428.1250, 1550142.8750],
        [1557068.0000, 1555700.8750, 1553194.1250, 1552074.7500, 1551834.8750,
         1551536.1250, 1550692.8750, 1549969.8750, 1549786.6250, 1549446.7500],
        [1557131.8750, 1551249.0000, 1551115.8750, 1550104.3750, 1546831.8750,
         1544859.5000, 1544466.1250, 1544192.1250, 1544155.3750, 1543886.0000],
        [1383996.3750, 1334172.3750, 1286415.7500, 1283249.6250, 1240027.8750,
         1224216.7500, 1196186.2500, 1191409.1250, 1139692.5000, 1119483.6250],
        [1521152.3750, 1520818.6250, 1520694.0000, 1519582.0000, 1519011.1250,
         1518941.6250, 1517463.3750, 1516511.5000, 1515894.0000, 1515701.7500],
        [1544797.6250, 1543292.7500, 1540544.2500, 1539974.3750, 1537050.1250,
         1536818.5000, 1536546.0000, 1536546.0000, 1535693.3750, 1533700.0000],
        [1530424.2500, 1527449.6250, 1522223.3750, 1518256.6250, 1517393.8750,
         1515791.3750, 1515508.1250, 1513526.3750, 1513458.5000, 1513308.5000],
        [1391471.1250, 1330061.3750, 1315625.5000, 1281228.2500, 1264769.8750,
         1262817.2500, 1252961.3750, 1232784.5000, 1231725.6250, 1216891.6250],
        [1515560.0000, 1514957.5000, 1513818.0000, 1512127.0000, 1512080.7500,
         1510923.2500, 1508311.7500, 1507847.2500, 1504379.8750, 1504176.1250],
        [1460325.6250, 1424122.5000, 1408579.7500, 1406267.1250, 1402681.6250,
         1400422.6250, 1398426.0000, 1397775.3750, 1395665.5000, 1395632.1250],
        [1512304.3750, 1511221.5000, 1508705.8750, 1504464.5000, 1502225.1250,
         1501719.5000, 1500967.7500, 1498239.0000, 1498199.0000, 1497609.0000],
        [1356514.5000, 1337738.6250, 1324845.6250, 1298201.5000, 1293084.8750,
         1257109.7500, 1248936.2500, 1248549.1250, 1245536.7500, 1235900.3750],
        [1547791.1250, 1543553.1250, 1543308.8750, 1542529.1250, 1542421.6250,
         1541845.1250, 1540575.2500, 1540529.6250, 1539301.8750, 1538226.2500],
        [1536979.8750, 1533623.8750, 1529270.1250, 1528619.8750, 1528150.5000,
         1527761.5000, 1527340.3750, 1525513.5000, 1525333.0000, 1525045.1250],
        [1525222.5000, 1522624.0000, 1521606.3750, 1520008.2500, 1519479.1250,
         1519164.6250, 1518798.1250, 1518792.3750, 1518764.8750, 1517841.0000],
        [1454418.7500, 1444991.1250, 1444639.8750, 1404406.8750, 1402455.5000,
         1401448.6250, 1397716.7500, 1396917.1250, 1388811.6250, 1385741.1250],
        [1346189.0000, 1333138.3750, 1301998.1250, 1297788.0000, 1291523.2500,
         1282936.2500, 1279311.2500, 1275427.6250, 1272014.2500, 1271620.1250],
        [1281691.3750, 1108495.5000, 1016558.0000, 1002833.7500,  994758.2500,
          975493.7500,  953524.5625,  949094.5625,  865047.6250,  853963.1250],
        [1225659.3750, 1130204.3750, 1121415.5000, 1119303.2500, 1077557.2500,
         1069750.0000, 1041766.1875, 1028399.6875,  995905.8750,  987015.1250],
        [1437102.7500, 1420090.5000, 1419417.6250, 1417302.0000, 1410270.7500,
         1409525.8750, 1406186.7500, 1405746.8750, 1405578.0000, 1404668.0000],
        [1479110.1250, 1477625.3750, 1465322.6250, 1465160.6250, 1452396.5000,
         1450720.0000, 1449554.1250, 1444744.5000, 1444223.7500, 1442386.2500],
        [1451550.3750, 1451419.0000, 1447515.2500, 1445290.2500, 1444624.6250,
         1443092.0000, 1434672.1250, 1434596.8750, 1432786.6250, 1429965.0000],
        [1406406.6250, 1403145.7500, 1395404.6250, 1380572.8750, 1375733.6250,
         1369373.2500, 1352136.0000, 1349518.2500, 1348339.8750, 1334069.3750],
        [1466576.6250, 1464674.3750, 1451679.1250, 1446975.5000, 1427600.8750,
         1418251.2500, 1403413.5000, 1397307.6250, 1395950.3750, 1384904.7500],
        [1400227.6250, 1399916.5000, 1351585.3750, 1330143.8750, 1315705.8750,
         1308278.6250, 1282159.6250, 1278514.8750, 1275599.1250, 1274175.5000],
        [1456046.6250, 1442922.8750, 1428027.1250, 1427626.8750, 1426121.7500,
         1424440.3750, 1423553.5000, 1423514.2500, 1419984.8750, 1418079.3750],
        [1487912.8750, 1484131.8750, 1480800.8750, 1477932.6250, 1471269.6250,
         1471160.2500, 1468995.6250, 1466608.8750, 1464946.8750, 1459551.5000],
        [1389361.3750, 1388552.1250, 1381793.8750, 1340930.5000, 1340327.0000,
         1337953.0000, 1326094.5000, 1316717.5000, 1307327.0000, 1304881.8750],
        [1464332.2500, 1434908.8750, 1426732.6250, 1421083.5000, 1409347.1250,
         1352205.6250, 1347566.0000, 1335794.3750, 1321070.7500, 1320020.3750],
        [1474184.0000, 1443679.8750, 1440380.6250, 1424588.5000, 1420809.8750,
         1415027.7500, 1407755.2500, 1406484.3750, 1398834.2500, 1377165.6250],
        [1512790.5000, 1504521.8750, 1473087.8750, 1469383.6250, 1436001.2500,
         1433671.0000, 1426403.3750, 1425658.0000, 1424710.7500, 1420406.0000],
        [1382654.6250, 1370425.0000, 1367586.6250, 1358127.2500, 1350295.7500,
         1347118.8750, 1343139.6250, 1339601.2500, 1331437.0000, 1328427.3750],
        [1410515.5000, 1403101.6250, 1391475.0000, 1379587.0000, 1372545.1250,
         1370950.5000, 1367464.0000, 1366876.0000, 1366323.3750, 1365691.5000],
        [1443674.3750, 1427594.1250, 1411022.7500, 1401426.0000, 1397823.3750,
         1395685.3750, 1375841.1250, 1368155.3750, 1362653.7500, 1344555.7500],
        [1466418.6250, 1441258.6250, 1434553.1250, 1429738.6250, 1421943.0000,
         1417034.5000, 1412963.2500, 1407800.8750, 1397410.1250, 1397102.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1533710.2500,       0.0000],
         [1528217.5000,       0.0000],
         [1524518.6250,       0.0000],
         ...,
         [1519334.2500,       0.0000],
         [1519318.3750,       0.0000],
         [1519129.8750,       0.0000]],

        [[1538839.6250,       0.0000],
         [1533297.7500,       0.0000],
         [1532715.8750,       0.0000],
         ...,
         [1530622.6250,       0.0000],
         [1528701.5000,       0.0000],
         [1528501.7500,       0.0000]],

        [[1302102.3750,       0.0000],
         [1300739.5000,       0.0000],
         [1294000.1250,       0.0000],
         ...,
         [      0.0000, 1145875.1250],
         [1143314.3750,       0.0000],
         [      0.0000, 1138486.7500]],

        ...,

        [[1410515.5000,       0.0000],
         [1403101.6250,       0.0000],
         [      0.0000, 1391475.0000],
         ...,
         [1366876.0000,       0.0000],
         [1366323.3750,       0.0000],
         [1365691.5000,       0.0000]],

        [[1443674.3750,       0.0000],
         [1427594.1250,       0.0000],
         [1411022.7500,       0.0000],
         ...,
         [1368155.3750,       0.0000],
         [      0.0000, 1362653.7500],
         [      0.0000, 1344555.7500]],

        [[      0.0000, 1466418.6250],
         [      0.0000, 1441258.6250],
         [      0.0000, 1434553.1250],
         ...,
         [      0.0000, 1407800.8750],
         [      0.0000, 1397410.1250],
         [      0.0000, 1397102.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15227963.0000,        0.0000],
        [15321266.0000,        0.0000],
        [ 8534608.0000,  3500346.2500],
        [14560441.0000,        0.0000],
        [ 9236198.0000,  3953941.7500],
        [ 9911444.0000,  2348425.2500],
        [ 5516564.0000,  5264813.5000],
        [10874113.0000,  1193120.3750],
        [13888700.0000,  1543997.8750],
        [10725250.0000,  2670904.5000],
        [15459771.0000,        0.0000],
        [14629975.0000,        0.0000],
        [14579486.0000,        0.0000],
        [15542963.0000,        0.0000],
        [15396980.0000,        0.0000],
        [15335707.0000,        0.0000],
        [14891857.0000,        0.0000],
        [10579645.0000,  4544100.0000],
        [14672360.0000,        0.0000],
        [13782034.0000,  1537570.6250],
        [15397917.0000,        0.0000],
        [11786745.0000,  2966798.5000],
        [15382538.0000,        0.0000],
        [15525920.0000,        0.0000],
        [ 9039823.0000,  6026886.0000],
        [15455542.0000,        0.0000],
        [15354452.0000,        0.0000],
        [15411630.0000,        0.0000],
        [15531304.0000,        0.0000],
        [15550224.0000,        0.0000],
        [15521306.0000,        0.0000],
        [15477992.0000,        0.0000],
        [ 3645927.2500,  8752923.0000],
        [12145370.0000,  3040400.5000],
        [13847912.0000,  1537050.1250],
        [ 9108568.0000,  6078773.0000],
        [ 7608317.0000,  5172019.5000],
        [ 9061840.0000,  6042341.0000],
        [ 9809784.0000,  4280113.5000],
        [13537416.0000,  1498239.0000],
        [ 9053743.0000,  3792674.5000],
        [15420082.0000,        0.0000],
        [15287638.0000,        0.0000],
        [13682292.0000,  1520008.2500],
        [ 5569186.5000,  8552361.0000],
        [ 6431196.5000,  6520750.0000],
        [ 5921953.0000,  4079507.0000],
        [       0.0000, 10796977.0000],
        [12729703.0000,  1406186.7500],
        [10175899.0000,  4395344.5000],
        [11519337.0000,  2896175.0000],
        [ 1334069.3750, 12380631.0000],
        [       0.0000, 14257333.0000],
        [ 2594220.7500, 10622086.0000],
        [11408149.0000,  2882168.5000],
        [11797707.0000,  2935604.5000],
        [       0.0000, 13433939.0000],
        [ 1321070.7500, 12511991.0000],
        [       0.0000, 14208910.0000],
        [ 1426403.3750, 13100232.0000],
        [ 6762810.0000,  6756003.0000],
        [12403055.0000,  1391475.0000],
        [ 9845382.0000,  4083050.5000],
        [       0.0000, 14226224.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 156/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:04, 60.17s/it]  7%|▋         | 2/29 [01:01<11:29, 25.53s/it] 10%|█         | 3/29 [01:02<06:11, 14.29s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.7942042350769043
Epoch 157/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:29, 58.90s/it]  7%|▋         | 2/29 [00:59<11:09, 24.80s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 3.792229652404785
Epoch 158/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:02, 57.95s/it]  7%|▋         | 2/29 [01:01<11:35, 25.77s/it] 10%|█         | 3/29 [01:02<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.14s/it] 21%|██        | 6/29 [01:04<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.771909713745117
Epoch 159/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:14, 58.38s/it]  7%|▋         | 2/29 [00:59<11:03, 24.58s/it] 10%|█         | 3/29 [01:00<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 3.7502238750457764
Epoch 160/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:26, 60.93s/it]  7%|▋         | 2/29 [01:01<11:32, 25.63s/it] 10%|█         | 3/29 [01:02<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 3.7213215827941895
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0046, 0.0057, 0.0013,  ..., 0.0048, 0.0025, 0.0231],
        [0.0036, 0.0060, 0.0011,  ..., 0.0034, 0.0015, 0.0221],
        [0.0309, 0.0058, 0.0023,  ..., 0.0063, 0.0134, 0.0270],
        ...,
        [0.0047, 0.0092, 0.0041,  ..., 0.0039, 0.0020, 0.0248],
        [0.0027, 0.0113, 0.0017,  ..., 0.0041, 0.0027, 0.0198],
        [0.0118, 0.0068, 0.0009,  ..., 0.0025, 0.0044, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9962, 0.9962, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9959],
        [0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9965,
         0.9964],
        [0.9858, 0.9843, 0.9833, 0.9808, 0.9785, 0.9778, 0.9759, 0.9751, 0.9749,
         0.9745],
        [0.9938, 0.9937, 0.9934, 0.9922, 0.9919, 0.9915, 0.9914, 0.9914, 0.9912,
         0.9911],
        [0.9869, 0.9867, 0.9865, 0.9864, 0.9855, 0.9854, 0.9850, 0.9847, 0.9845,
         0.9845],
        [0.9893, 0.9843, 0.9838, 0.9806, 0.9782, 0.9782, 0.9771, 0.9752, 0.9747,
         0.9747],
        [0.9788, 0.9744, 0.9740, 0.9732, 0.9726, 0.9708, 0.9692, 0.9688, 0.9687,
         0.9680],
        [0.9842, 0.9807, 0.9803, 0.9803, 0.9802, 0.9798, 0.9791, 0.9786, 0.9776,
         0.9771],
        [0.9977, 0.9976, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970,
         0.9969],
        [0.9911, 0.9876, 0.9865, 0.9863, 0.9863, 0.9862, 0.9842, 0.9837, 0.9834,
         0.9831],
        [0.9976, 0.9975, 0.9975, 0.9975, 0.9973, 0.9973, 0.9973, 0.9971, 0.9971,
         0.9971],
        [0.9942, 0.9930, 0.9929, 0.9925, 0.9923, 0.9922, 0.9916, 0.9915, 0.9913,
         0.9913],
        [0.9937, 0.9932, 0.9926, 0.9926, 0.9923, 0.9922, 0.9916, 0.9910, 0.9910,
         0.9908],
        [0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9974, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9970,
         0.9970],
        [0.9973, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9955, 0.9952, 0.9951, 0.9951, 0.9950, 0.9947, 0.9947, 0.9946, 0.9943,
         0.9942],
        [0.9962, 0.9961, 0.9960, 0.9959, 0.9959, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9951],
        [0.9945, 0.9942, 0.9941, 0.9938, 0.9938, 0.9938, 0.9937, 0.9936, 0.9936,
         0.9933],
        [0.9972, 0.9971, 0.9970, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9978, 0.9977, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969,
         0.9968],
        [0.9950, 0.9948, 0.9941, 0.9939, 0.9938, 0.9938, 0.9937, 0.9934, 0.9933,
         0.9931],
        [0.9980, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9969, 0.9969,
         0.9969],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9957, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9950],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9976, 0.9974, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9978, 0.9978, 0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9982, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9982, 0.9982, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9977,
         0.9976],
        [0.9981, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9976],
        [0.9981, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9902, 0.9874, 0.9848, 0.9842, 0.9826, 0.9812, 0.9802, 0.9798, 0.9759,
         0.9754],
        [0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9974, 0.9973, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9965, 0.9965, 0.9963, 0.9960, 0.9960, 0.9960, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9901, 0.9867, 0.9866, 0.9851, 0.9844, 0.9829, 0.9823, 0.9814, 0.9813,
         0.9808],
        [0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9924, 0.9913, 0.9909, 0.9902, 0.9899, 0.9899, 0.9898, 0.9898, 0.9896,
         0.9896],
        [0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954,
         0.9954],
        [0.9890, 0.9878, 0.9876, 0.9857, 0.9854, 0.9842, 0.9830, 0.9829, 0.9825,
         0.9823],
        [0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9969, 0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964,
         0.9964],
        [0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9936, 0.9932, 0.9930, 0.9911, 0.9909, 0.9908, 0.9907, 0.9907, 0.9900,
         0.9900],
        [0.9865, 0.9860, 0.9850, 0.9846, 0.9839, 0.9838, 0.9838, 0.9837, 0.9836,
         0.9827],
        [0.9846, 0.9744, 0.9665, 0.9661, 0.9639, 0.9625, 0.9621, 0.9599, 0.9583,
         0.9561],
        [0.9815, 0.9756, 0.9756, 0.9753, 0.9730, 0.9718, 0.9704, 0.9692, 0.9668,
         0.9667],
        [0.9922, 0.9915, 0.9912, 0.9912, 0.9910, 0.9910, 0.9909, 0.9908, 0.9906,
         0.9906],
        [0.9940, 0.9939, 0.9935, 0.9934, 0.9931, 0.9930, 0.9929, 0.9925, 0.9923,
         0.9923],
        [0.9932, 0.9932, 0.9931, 0.9929, 0.9929, 0.9927, 0.9922, 0.9922, 0.9921,
         0.9921],
        [0.9910, 0.9909, 0.9905, 0.9898, 0.9893, 0.9885, 0.9883, 0.9882, 0.9879,
         0.9873],
        [0.9938, 0.9936, 0.9933, 0.9925, 0.9918, 0.9918, 0.9907, 0.9905, 0.9901,
         0.9894],
        [0.9907, 0.9904, 0.9882, 0.9878, 0.9854, 0.9850, 0.9847, 0.9845, 0.9845,
         0.9839],
        [0.9930, 0.9928, 0.9919, 0.9918, 0.9918, 0.9915, 0.9915, 0.9915, 0.9914,
         0.9912],
        [0.9945, 0.9943, 0.9942, 0.9940, 0.9938, 0.9938, 0.9937, 0.9937, 0.9935,
         0.9934],
        [0.9896, 0.9894, 0.9890, 0.9873, 0.9872, 0.9871, 0.9863, 0.9855, 0.9854,
         0.9853],
        [0.9934, 0.9921, 0.9916, 0.9913, 0.9904, 0.9879, 0.9873, 0.9873, 0.9869,
         0.9864],
        [0.9941, 0.9928, 0.9924, 0.9917, 0.9909, 0.9908, 0.9907, 0.9906, 0.9901,
         0.9899],
        [0.9961, 0.9953, 0.9942, 0.9941, 0.9924, 0.9919, 0.9914, 0.9914, 0.9910,
         0.9909],
        [0.9896, 0.9887, 0.9884, 0.9883, 0.9879, 0.9878, 0.9878, 0.9875, 0.9874,
         0.9873],
        [0.9910, 0.9906, 0.9903, 0.9897, 0.9895, 0.9894, 0.9892, 0.9892, 0.9890,
         0.9890],
        [0.9926, 0.9921, 0.9907, 0.9907, 0.9906, 0.9899, 0.9889, 0.9888, 0.9887,
         0.9879],
        [0.9943, 0.9927, 0.9926, 0.9925, 0.9919, 0.9918, 0.9913, 0.9912, 0.9908,
         0.9907]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 1, 1, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 1, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [0, 1, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1525464.0000, 1515596.2500, 1514733.6250, 1513386.3750, 1511204.3750,
         1510148.2500, 1509974.0000, 1509065.7500, 1508659.8750, 1508216.7500],
        [1531346.8750, 1530904.5000, 1530813.8750, 1528764.1250, 1528468.1250,
         1527892.6250, 1525728.8750, 1523425.7500, 1522072.2500, 1520240.1250],
        [1306075.7500, 1278485.6250, 1259912.3750, 1216808.1250, 1177642.2500,
         1166035.3750, 1133822.1250, 1120805.0000, 1117842.8750, 1111520.8750],
        [1464023.6250, 1462956.0000, 1456554.8750, 1431942.5000, 1425966.7500,
         1418183.6250, 1415197.7500, 1414540.6250, 1412167.0000, 1409326.8750],
        [1328028.3750, 1322997.2500, 1319051.5000, 1318627.6250, 1301410.7500,
         1298324.1250, 1290745.1250, 1286431.6250, 1282674.5000, 1281818.5000],
        [1373329.3750, 1279278.3750, 1268836.3750, 1212946.3750, 1171380.7500,
         1171338.3750, 1153912.2500, 1122187.0000, 1115490.5000, 1115388.3750],
        [1181478.1250, 1110163.8750, 1103030.8750, 1091628.3750, 1082427.0000,
         1054579.2500, 1030214.6250, 1024365.8750, 1023985.0000, 1013122.3125],
        [1276061.5000, 1214517.1250, 1208283.2500, 1207902.0000, 1205765.8750,
         1198456.2500, 1186962.2500, 1179574.5000, 1162667.6250, 1153880.3750],
        [1548740.6250, 1545454.8750, 1539795.2500, 1538849.7500, 1538163.1250,
         1537796.5000, 1535837.0000, 1535782.7500, 1532936.6250, 1531755.8750],
        [1410038.1250, 1340030.5000, 1318906.8750, 1316510.3750, 1315529.0000,
         1313539.3750, 1276150.3750, 1267263.0000, 1261892.8750, 1256570.3750],
        [1545388.3750, 1545189.5000, 1543403.0000, 1543292.7500, 1540379.8750,
         1539974.3750, 1539589.6250, 1535785.7500, 1535552.8750, 1535100.3750],
        [1473634.3750, 1447850.7500, 1445662.5000, 1438586.3750, 1432958.8750,
         1431074.1250, 1418735.5000, 1417864.3750, 1412449.8750, 1412367.6250],
        [1462416.1250, 1451378.7500, 1440412.2500, 1439847.7500, 1432876.7500,
         1431375.8750, 1420173.1250, 1406756.7500, 1406734.0000, 1404123.0000],
        [1559319.2500, 1557810.6250, 1557745.2500, 1553600.1250, 1553429.6250,
         1553198.6250, 1551876.3750, 1551203.1250, 1550304.0000, 1548727.2500],
        [1542273.0000, 1542143.6250, 1541840.7500, 1539528.0000, 1538013.6250,
         1537639.6250, 1536591.3750, 1534905.6250, 1532958.5000, 1532903.0000],
        [1538996.6250, 1536003.8750, 1534087.5000, 1531855.1250, 1530065.1250,
         1527907.1250, 1527628.8750, 1527397.1250, 1526494.3750, 1526148.0000],
        [1499947.5000, 1494047.0000, 1491763.2500, 1491682.1250, 1489829.7500,
         1484675.5000, 1484194.1250, 1480455.0000, 1475050.3750, 1473388.5000],
        [1516757.3750, 1514303.1250, 1512197.6250, 1510290.8750, 1510005.6250,
         1504883.5000, 1504104.5000, 1503304.2500, 1499924.5000, 1491535.7500],
        [1480380.1250, 1473263.3750, 1471095.6250, 1465048.7500, 1464956.6250,
         1463856.1250, 1462478.8750, 1459983.0000, 1459728.2500, 1454044.2500],
        [1537126.3750, 1534295.3750, 1533881.3750, 1529414.5000, 1527738.1250,
         1526857.0000, 1526229.5000, 1525715.7500, 1524806.5000, 1524377.7500],
        [1550039.3750, 1547977.1250, 1539020.0000, 1537236.3750, 1536274.8750,
         1536087.3750, 1533746.7500, 1530215.5000, 1529941.1250, 1529069.0000],
        [1489571.1250, 1485754.6250, 1471509.6250, 1466857.8750, 1464822.5000,
         1464639.5000, 1461926.6250, 1455749.3750, 1453911.1250, 1450312.0000],
        [1555917.5000, 1541542.2500, 1541011.6250, 1540102.1250, 1539163.8750,
         1537685.0000, 1536173.8750, 1531958.8750, 1530971.6250, 1530580.3750],
        [1555747.0000, 1551596.7500, 1551117.2500, 1550481.3750, 1549897.5000,
         1547866.3750, 1547416.2500, 1547228.8750, 1546292.1250, 1545714.2500],
        [1505558.1250, 1499700.0000, 1499409.6250, 1497606.1250, 1497319.1250,
         1495385.5000, 1494181.0000, 1492770.8750, 1492733.8750, 1489052.6250],
        [1550191.5000, 1549476.1250, 1548304.8750, 1547379.2500, 1545341.3750,
         1544034.7500, 1543216.1250, 1542506.8750, 1542130.3750, 1541993.6250],
        [1545599.2500, 1541981.8750, 1540725.0000, 1537435.7500, 1534639.3750,
         1533977.8750, 1533357.7500, 1532436.7500, 1532138.6250, 1531682.8750],
        [1551151.3750, 1549910.7500, 1542152.5000, 1540786.7500, 1539738.0000,
         1537734.8750, 1536236.7500, 1535932.1250, 1535299.5000, 1534741.6250],
        [1559805.6250, 1554597.5000, 1554591.6250, 1554212.0000, 1552803.1250,
         1552088.1250, 1551430.8750, 1550793.3750, 1550423.7500, 1549439.3750],
        [1559444.2500, 1559344.6250, 1555253.0000, 1554130.6250, 1553509.7500,
         1552276.1250, 1551994.8750, 1550755.0000, 1548087.7500, 1547342.5000],
        [1556940.2500, 1554014.8750, 1553899.3750, 1551765.3750, 1551391.1250,
         1550351.2500, 1550243.2500, 1550045.2500, 1549891.6250, 1547110.8750],
        [1556895.7500, 1549095.1250, 1547978.5000, 1545285.2500, 1545101.1250,
         1544239.3750, 1543353.0000, 1542445.2500, 1541831.8750, 1541634.8750],
        [1391526.8750, 1336595.8750, 1288528.8750, 1277000.1250, 1247372.1250,
         1224083.6250, 1206277.7500, 1199641.0000, 1134713.5000, 1125811.1250],
        [1518734.5000, 1517871.5000, 1516537.3750, 1515482.0000, 1515275.3750,
         1514902.5000, 1514467.7500, 1511649.6250, 1511626.7500, 1508513.1250],
        [1541330.5000, 1540604.6250, 1539799.6250, 1536393.6250, 1536178.2500,
         1534301.1250, 1534054.0000, 1534054.0000, 1533868.1250, 1531497.3750],
        [1523312.5000, 1523247.0000, 1516935.1250, 1511785.2500, 1511775.1250,
         1511459.5000, 1508367.8750, 1507417.2500, 1506978.8750, 1505851.1250],
        [1390109.0000, 1323696.3750, 1322326.1250, 1292938.0000, 1280331.6250,
         1252792.8750, 1242391.7500, 1226419.3750, 1225894.3750, 1216065.6250],
        [1512150.0000, 1507618.6250, 1506697.2500, 1505140.5000, 1505097.3750,
         1500999.2500, 1500788.8750, 1500356.6250, 1500027.5000, 1499874.5000],
        [1436608.1250, 1412792.0000, 1404832.8750, 1390709.6250, 1386252.5000,
         1385150.3750, 1382373.8750, 1382362.0000, 1379880.5000, 1378811.1250],
        [1508783.6250, 1506418.5000, 1506243.2500, 1505869.8750, 1504767.2500,
         1503007.3750, 1502924.3750, 1500256.5000, 1498199.0000, 1497879.0000],
        [1366920.2500, 1344357.0000, 1341392.2500, 1305215.3750, 1299703.0000,
         1276563.0000, 1255533.0000, 1252807.2500, 1246699.0000, 1242619.2500],
        [1542734.8750, 1541280.6250, 1540807.2500, 1539732.1250, 1539669.0000,
         1538766.2500, 1538579.8750, 1538579.8750, 1536957.8750, 1536900.7500],
        [1531386.3750, 1528826.8750, 1528211.6250, 1524847.3750, 1524363.1250,
         1523970.6250, 1523528.8750, 1522764.8750, 1521166.7500, 1521072.5000],
        [1521666.0000, 1521618.1250, 1520277.7500, 1519998.0000, 1518928.6250,
         1517534.3750, 1516968.5000, 1515866.5000, 1515840.5000, 1515090.3750],
        [1459980.2500, 1452263.5000, 1447493.1250, 1409621.2500, 1404831.5000,
         1402946.3750, 1401403.2500, 1400997.0000, 1386445.5000, 1386359.6250],
        [1320490.0000, 1310775.1250, 1292368.5000, 1283417.2500, 1272377.1250,
         1270087.0000, 1269549.3750, 1267973.8750, 1266841.3750, 1250019.3750],
        [1284199.6250, 1109388.1250,  992238.9375,  986252.0000,  954958.8125,
          936720.5000,  930835.0000,  902621.3750,  881615.4375,  854156.1875],
        [1228411.6250, 1129828.3750, 1129183.1250, 1124046.3750, 1088084.1250,
         1070027.5000, 1047862.2500, 1030427.9375,  995878.3125,  994887.3125],
        [1431743.1250, 1417779.2500, 1411493.8750, 1410787.3750, 1407372.7500,
         1406285.8750, 1404944.1250, 1402791.2500, 1400028.7500, 1399717.6250],
        [1469654.2500, 1466810.3750, 1458115.7500, 1455859.1250, 1451081.1250,
         1447355.1250, 1446347.8750, 1437760.7500, 1433397.6250, 1433393.5000],
        [1452137.5000, 1451192.0000, 1450599.7500, 1446167.1250, 1445266.7500,
         1442332.6250, 1432091.3750, 1432035.3750, 1430332.0000, 1429102.0000],
        [1407509.6250, 1404444.3750, 1398114.0000, 1383192.7500, 1373592.6250,
         1358196.0000, 1354141.3750, 1351717.0000, 1346709.0000, 1334387.3750],
        [1464863.0000, 1459783.8750, 1454994.5000, 1438484.8750, 1422761.0000,
         1422565.6250, 1401585.0000, 1397523.3750, 1388275.3750, 1376238.7500],
        [1401705.2500, 1394764.6250, 1351874.2500, 1343673.8750, 1298563.0000,
         1292479.5000, 1285824.5000, 1283266.7500, 1281559.3750, 1271689.2500],
        [1447330.2500, 1444550.2500, 1425253.0000, 1424375.1250, 1424301.8750,
         1418297.1250, 1418098.3750, 1417872.5000, 1415563.6250, 1412274.7500],
        [1478613.6250, 1474452.6250, 1472974.0000, 1469668.1250, 1465188.5000,
         1464230.2500, 1463610.5000, 1463522.3750, 1459232.6250, 1456303.5000],
        [1378567.7500, 1376002.6250, 1367200.6250, 1335142.2500, 1332106.3750,
         1330236.5000, 1315482.5000, 1300750.7500, 1299001.5000, 1296586.8750],
        [1455712.0000, 1429782.2500, 1419987.5000, 1413052.1250, 1394312.5000,
         1345440.7500, 1334563.1250, 1334126.6250, 1326942.1250, 1316854.3750],
        [1471035.3750, 1443995.2500, 1434870.6250, 1421091.6250, 1405753.6250,
         1403748.0000, 1401332.3750, 1399660.2500, 1389486.0000, 1384688.1250],
        [1513623.1250, 1495814.7500, 1472821.0000, 1471498.3750, 1434717.2500,
         1424747.3750, 1415556.7500, 1415490.7500, 1407394.1250, 1404455.0000],
        [1378574.3750, 1361625.0000, 1356204.0000, 1353710.0000, 1346394.3750,
         1344801.8750, 1343937.7500, 1337770.3750, 1336181.7500, 1334871.1250],
        [1406358.3750, 1399524.1250, 1392250.3750, 1381056.1250, 1378163.0000,
         1374767.0000, 1371323.1250, 1370926.8750, 1367753.6250, 1366862.8750],
        [1439194.2500, 1429061.1250, 1401347.1250, 1400906.1250, 1399412.0000,
         1384916.6250, 1365991.1250, 1363803.1250, 1361640.5000, 1346087.6250],
        [1474802.8750, 1442402.7500, 1439643.1250, 1437991.1250, 1425395.7500,
         1422741.8750, 1413794.8750, 1410892.2500, 1402339.1250, 1400843.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1525464.0000,       0.0000],
         [1515596.2500,       0.0000],
         [1514733.6250,       0.0000],
         ...,
         [1509065.7500,       0.0000],
         [1508659.8750,       0.0000],
         [1508216.7500,       0.0000]],

        [[1531346.8750,       0.0000],
         [1530904.5000,       0.0000],
         [1530813.8750,       0.0000],
         ...,
         [1523425.7500,       0.0000],
         [1522072.2500,       0.0000],
         [1520240.1250,       0.0000]],

        [[1306075.7500,       0.0000],
         [1278485.6250,       0.0000],
         [1259912.3750,       0.0000],
         ...,
         [1120805.0000,       0.0000],
         [1117842.8750,       0.0000],
         [1111520.8750,       0.0000]],

        ...,

        [[1406358.3750,       0.0000],
         [1399524.1250,       0.0000],
         [      0.0000, 1392250.3750],
         ...,
         [1370926.8750,       0.0000],
         [1367753.6250,       0.0000],
         [1366862.8750,       0.0000]],

        [[1439194.2500,       0.0000],
         [1429061.1250,       0.0000],
         [1401347.1250,       0.0000],
         ...,
         [1363803.1250,       0.0000],
         [      0.0000, 1361640.5000],
         [      0.0000, 1346087.6250]],

        [[      0.0000, 1474802.8750],
         [      0.0000, 1442402.7500],
         [      0.0000, 1439643.1250],
         ...,
         [      0.0000, 1410892.2500],
         [      0.0000, 1402339.1250],
         [      0.0000, 1400843.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15126450.0000,        0.0000],
        [15269657.0000,        0.0000],
        [ 9538320.0000,  2350630.2500],
        [14310859.0000,        0.0000],
        [ 9100779.0000,  3929330.5000],
        [10812708.0000,  1171380.7500],
        [ 5400420.5000,  5314574.0000],
        [10840190.0000,  1153880.3750],
        [13846950.0000,  1538163.1250],
        [11736400.0000,  1340030.5000],
        [15403656.0000,        0.0000],
        [14331185.0000,        0.0000],
        [14296094.0000,        0.0000],
        [13986012.0000,  1551203.1250],
        [15378796.0000,        0.0000],
        [15306584.0000,        0.0000],
        [14865033.0000,        0.0000],
        [10537503.0000,  4529805.0000],
        [14654836.0000,        0.0000],
        [13756147.0000,  1534295.3750],
        [15369608.0000,        0.0000],
        [11707790.0000,  2957264.2500],
        [15385107.0000,        0.0000],
        [15493358.0000,        0.0000],
        [ 8980329.0000,  5983387.5000],
        [15454575.0000,        0.0000],
        [15363976.0000,        0.0000],
        [15403684.0000,        0.0000],
        [15530186.0000,        0.0000],
        [15532138.0000,        0.0000],
        [15515652.0000,        0.0000],
        [15457860.0000,        0.0000],
        [ 3661712.0000,  8769839.0000],
        [12115316.0000,  3029743.0000],
        [13825688.0000,  1536393.6250],
        [ 9067120.0000,  6060009.5000],
        [ 6397418.0000,  6375547.5000],
        [10519337.0000,  4519413.0000],
        [ 9705222.0000,  4234550.5000],
        [13536150.0000,  1498199.0000],
        [10383974.0000,  2547834.5000],
        [15394009.0000,        0.0000],
        [15250138.0000,        0.0000],
        [13666820.0000,  1516968.5000],
        [ 4188760.0000,  9963581.0000],
        [ 6351156.0000,  6452743.0000],
        [ 5778297.5000,  4054688.5000],
        [       0.0000, 10838636.0000],
        [12688000.0000,  1404944.1250],
        [10123768.0000,  4376007.0000],
        [11515390.0000,  2895866.5000],
        [       0.0000, 13712004.0000],
        [       0.0000, 14227076.0000],
        [ 2564168.7500, 10641232.0000],
        [11382290.0000,  2865627.5000],
        [10284360.0000,  4383436.5000],
        [ 1299001.5000, 12032076.0000],
        [ 1316854.3750, 12453919.0000],
        [       0.0000, 14155661.0000],
        [ 2820011.7500, 11636107.0000],
        [ 8084761.0000,  5409309.5000],
        [12416735.0000,  1392250.3750],
        [ 9818640.0000,  4073719.0000],
        [       0.0000, 14270848.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 161/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:50, 57.52s/it]  7%|▋         | 2/29 [01:02<11:52, 26.37s/it] 10%|█         | 3/29 [01:03<06:23, 14.75s/it] 14%|█▍        | 4/29 [01:03<03:52,  9.29s/it] 17%|█▋        | 5/29 [01:04<02:30,  6.28s/it] 21%|██        | 6/29 [01:05<01:42,  4.46s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.30s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.54s/it] 31%|███       | 9/29 [01:08<00:40,  2.04s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.6966428756713867
Epoch 162/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:52, 57.60s/it]  7%|▋         | 2/29 [00:58<10:59, 24.41s/it] 10%|█         | 3/29 [00:59<05:55, 13.68s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.06it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 3.666171073913574
Epoch 163/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.98s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 3.663525342941284
Epoch 164/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:15, 58.40s/it]  7%|▋         | 2/29 [00:59<11:03, 24.59s/it] 10%|█         | 3/29 [01:00<06:00, 13.86s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.75s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.621671199798584
Epoch 165/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:52, 57.60s/it]  7%|▋         | 2/29 [01:00<11:25, 25.41s/it] 10%|█         | 3/29 [01:01<06:09, 14.23s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.6190128326416016
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0048, 0.0057, 0.0014,  ..., 0.0051, 0.0027, 0.0225],
        [0.0035, 0.0064, 0.0011,  ..., 0.0033, 0.0013, 0.0219],
        [0.0305, 0.0065, 0.0022,  ..., 0.0055, 0.0133, 0.0264],
        ...,
        [0.0048, 0.0089, 0.0055,  ..., 0.0041, 0.0018, 0.0244],
        [0.0028, 0.0109, 0.0020,  ..., 0.0040, 0.0024, 0.0200],
        [0.0108, 0.0070, 0.0011,  ..., 0.0021, 0.0044, 0.0215]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9968, 0.9962, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9970, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9966, 0.9966,
         0.9966],
        [0.9862, 0.9838, 0.9837, 0.9806, 0.9789, 0.9781, 0.9761, 0.9754, 0.9750,
         0.9749],
        [0.9940, 0.9940, 0.9935, 0.9923, 0.9920, 0.9920, 0.9920, 0.9918, 0.9917,
         0.9915],
        [0.9885, 0.9885, 0.9875, 0.9871, 0.9866, 0.9865, 0.9861, 0.9859, 0.9858,
         0.9858],
        [0.9893, 0.9846, 0.9829, 0.9797, 0.9790, 0.9787, 0.9785, 0.9778, 0.9752,
         0.9747],
        [0.9777, 0.9736, 0.9736, 0.9712, 0.9710, 0.9699, 0.9688, 0.9687, 0.9680,
         0.9677],
        [0.9848, 0.9808, 0.9808, 0.9807, 0.9805, 0.9804, 0.9797, 0.9788, 0.9784,
         0.9770],
        [0.9976, 0.9976, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9970],
        [0.9921, 0.9882, 0.9874, 0.9871, 0.9864, 0.9860, 0.9851, 0.9848, 0.9847,
         0.9839],
        [0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9972, 0.9971,
         0.9971],
        [0.9944, 0.9935, 0.9930, 0.9929, 0.9922, 0.9921, 0.9921, 0.9921, 0.9908,
         0.9908],
        [0.9944, 0.9936, 0.9933, 0.9930, 0.9920, 0.9918, 0.9916, 0.9915, 0.9914,
         0.9912],
        [0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972,
         0.9971],
        [0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9957, 0.9953, 0.9952, 0.9951, 0.9950, 0.9948, 0.9948, 0.9946, 0.9944,
         0.9943],
        [0.9963, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9956,
         0.9955],
        [0.9944, 0.9942, 0.9941, 0.9940, 0.9938, 0.9936, 0.9935, 0.9934, 0.9934,
         0.9932],
        [0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9978, 0.9978, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9949, 0.9946, 0.9942, 0.9940, 0.9938, 0.9936, 0.9935, 0.9935, 0.9935,
         0.9932],
        [0.9980, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9970, 0.9969,
         0.9969],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9958, 0.9956, 0.9956, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953, 0.9953,
         0.9951],
        [0.9978, 0.9978, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9976, 0.9975, 0.9974, 0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9969],
        [0.9979, 0.9978, 0.9976, 0.9975, 0.9975, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9983, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9983, 0.9983, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9978],
        [0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9981, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9975],
        [0.9903, 0.9863, 0.9855, 0.9838, 0.9838, 0.9808, 0.9805, 0.9790, 0.9768,
         0.9752],
        [0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9975, 0.9975, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9967, 0.9967, 0.9963, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959,
         0.9959],
        [0.9892, 0.9860, 0.9854, 0.9849, 0.9839, 0.9839, 0.9827, 0.9821, 0.9808,
         0.9800],
        [0.9962, 0.9961, 0.9961, 0.9961, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9956],
        [0.9929, 0.9919, 0.9917, 0.9909, 0.9908, 0.9907, 0.9907, 0.9906, 0.9906,
         0.9904],
        [0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954,
         0.9953],
        [0.9887, 0.9874, 0.9872, 0.9864, 0.9853, 0.9832, 0.9829, 0.9826, 0.9823,
         0.9823],
        [0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9971, 0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9936, 0.9935, 0.9932, 0.9913, 0.9909, 0.9908, 0.9908, 0.9905, 0.9904,
         0.9901],
        [0.9871, 0.9869, 0.9860, 0.9855, 0.9854, 0.9853, 0.9853, 0.9852, 0.9849,
         0.9845],
        [0.9840, 0.9706, 0.9648, 0.9624, 0.9618, 0.9608, 0.9598, 0.9583, 0.9569,
         0.9545],
        [0.9820, 0.9761, 0.9761, 0.9752, 0.9726, 0.9708, 0.9701, 0.9691, 0.9670,
         0.9667],
        [0.9926, 0.9921, 0.9916, 0.9915, 0.9912, 0.9912, 0.9911, 0.9910, 0.9910,
         0.9905],
        [0.9940, 0.9939, 0.9938, 0.9936, 0.9932, 0.9930, 0.9927, 0.9927, 0.9927,
         0.9923],
        [0.9935, 0.9933, 0.9932, 0.9931, 0.9931, 0.9929, 0.9925, 0.9924, 0.9923,
         0.9923],
        [0.9909, 0.9906, 0.9903, 0.9898, 0.9894, 0.9884, 0.9883, 0.9880, 0.9877,
         0.9870],
        [0.9940, 0.9938, 0.9936, 0.9929, 0.9922, 0.9917, 0.9907, 0.9905, 0.9902,
         0.9898],
        [0.9909, 0.9901, 0.9885, 0.9876, 0.9862, 0.9851, 0.9850, 0.9844, 0.9844,
         0.9840],
        [0.9931, 0.9928, 0.9920, 0.9920, 0.9916, 0.9916, 0.9916, 0.9915, 0.9915,
         0.9914],
        [0.9944, 0.9944, 0.9941, 0.9941, 0.9939, 0.9938, 0.9937, 0.9936, 0.9936,
         0.9935],
        [0.9902, 0.9899, 0.9892, 0.9875, 0.9871, 0.9869, 0.9869, 0.9862, 0.9859,
         0.9858],
        [0.9935, 0.9924, 0.9917, 0.9914, 0.9906, 0.9880, 0.9876, 0.9874, 0.9861,
         0.9858],
        [0.9941, 0.9931, 0.9924, 0.9918, 0.9913, 0.9910, 0.9909, 0.9908, 0.9904,
         0.9902],
        [0.9962, 0.9951, 0.9944, 0.9943, 0.9928, 0.9920, 0.9913, 0.9913, 0.9911,
         0.9910],
        [0.9897, 0.9889, 0.9889, 0.9882, 0.9882, 0.9880, 0.9877, 0.9877, 0.9876,
         0.9874],
        [0.9906, 0.9899, 0.9897, 0.9897, 0.9896, 0.9894, 0.9893, 0.9891, 0.9891,
         0.9890],
        [0.9928, 0.9924, 0.9912, 0.9911, 0.9910, 0.9902, 0.9893, 0.9893, 0.9892,
         0.9881],
        [0.9946, 0.9929, 0.9927, 0.9926, 0.9923, 0.9920, 0.9917, 0.9913, 0.9909,
         0.9908]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 1],
        [1, 1, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 0, 0, 0, 1, 1, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 1, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1529462.7500, 1515998.0000, 1513511.8750, 1510746.1250, 1509799.8750,
         1509612.7500, 1509326.2500, 1508953.3750, 1508684.3750, 1507651.6250],
        [1532865.0000, 1532775.8750, 1532609.2500, 1531786.5000, 1529009.1250,
         1528797.7500, 1527859.0000, 1525517.8750, 1524760.1250, 1524203.2500],
        [1313807.5000, 1269383.3750, 1268237.6250, 1213799.3750, 1183384.0000,
         1169657.2500, 1137127.1250, 1126132.2500, 1119206.0000, 1118091.2500],
        [1469749.3750, 1468970.3750, 1458197.7500, 1433803.6250, 1427818.7500,
         1426627.7500, 1426529.8750, 1424163.2500, 1422060.8750, 1417852.2500],
        [1357407.3750, 1357099.2500, 1338951.1250, 1330553.6250, 1321593.7500,
         1319816.5000, 1312318.5000, 1308185.0000, 1306928.1250, 1306138.0000],
        [1374202.0000, 1284320.8750, 1253172.8750, 1197472.5000, 1185461.1250,
         1180639.1250, 1177116.7500, 1165444.0000, 1122252.2500, 1115104.3750],
        [1164550.7500, 1097471.7500, 1096812.6250, 1059940.1250, 1057894.2500,
         1040290.8750, 1025522.2500, 1023226.4375, 1013720.5000, 1008335.5000],
        [1288406.0000, 1216702.5000, 1216216.3750, 1215254.1250, 1211212.6250,
         1209052.1250, 1196722.6250, 1181420.7500, 1175026.1250, 1151485.0000],
        [1546414.5000, 1545518.1250, 1537314.0000, 1535762.2500, 1535599.6250,
         1535501.6250, 1534823.7500, 1534749.0000, 1534397.7500, 1532382.6250],
        [1430276.1250, 1351559.7500, 1336698.0000, 1330070.2500, 1318529.5000,
         1310205.2500, 1293944.6250, 1288551.0000, 1285554.7500, 1272395.2500],
        [1545891.1250, 1544019.8750, 1543484.0000, 1543263.2500, 1542393.7500,
         1540526.7500, 1540224.0000, 1537231.8750, 1536040.5000, 1535779.7500],
        [1477322.5000, 1458901.6250, 1447676.7500, 1445756.2500, 1430806.7500,
         1429215.1250, 1429033.8750, 1428881.2500, 1403105.6250, 1402796.5000],
        [1477512.7500, 1461339.7500, 1453988.7500, 1447933.5000, 1427297.3750,
         1422818.0000, 1419922.6250, 1417069.6250, 1415326.0000, 1410516.8750],
        [1560723.7500, 1559130.5000, 1558155.2500, 1556150.5000, 1555600.0000,
         1554444.7500, 1551974.0000, 1551092.1250, 1550794.8750, 1550611.5000],
        [1545970.7500, 1545708.3750, 1543345.6250, 1541798.0000, 1541198.2500,
         1541117.5000, 1540187.3750, 1540002.3750, 1536538.6250, 1535552.8750],
        [1539738.0000, 1536335.0000, 1533743.8750, 1532796.2500, 1532087.5000,
         1531713.5000, 1528073.2500, 1527786.2500, 1527088.5000, 1526615.2500],
        [1505431.8750, 1496696.6250, 1493461.5000, 1491521.5000, 1489373.7500,
         1486141.6250, 1485574.8750, 1481058.0000, 1476809.7500, 1475466.7500],
        [1518045.2500, 1514242.3750, 1512216.3750, 1510583.3750, 1510086.3750,
         1508494.5000, 1506124.0000, 1506036.5000, 1503619.7500, 1501288.5000],
        [1477249.2500, 1472249.3750, 1470649.6250, 1469843.3750, 1464910.5000,
         1461086.1250, 1459053.2500, 1455793.8750, 1455771.6250, 1452109.7500],
        [1536181.2500, 1533910.6250, 1533797.8750, 1533436.6250, 1532897.2500,
         1526960.2500, 1526851.0000, 1526487.1250, 1525765.1250, 1525371.0000],
        [1551534.5000, 1551263.7500, 1540501.7500, 1540404.7500, 1537539.8750,
         1537013.5000, 1534529.5000, 1533800.8750, 1533672.2500, 1533524.5000],
        [1488660.8750, 1482158.6250, 1472858.8750, 1468106.2500, 1464407.6250,
         1461511.1250, 1459345.3750, 1459239.6250, 1457416.3750, 1451259.7500],
        [1555325.6250, 1541861.3750, 1541568.7500, 1540947.0000, 1539909.7500,
         1539525.1250, 1537862.5000, 1532768.5000, 1530758.5000, 1530670.8750],
        [1556192.1250, 1552141.2500, 1552116.1250, 1551658.8750, 1551596.7500,
         1549994.8750, 1549396.3750, 1548866.1250, 1547885.6250, 1547218.5000],
        [1506270.5000, 1502511.6250, 1501793.8750, 1501377.1250, 1499501.2500,
         1499296.7500, 1497099.2500, 1497046.5000, 1495418.3750, 1492911.7500],
        [1551913.3750, 1550351.2500, 1550193.1250, 1549921.0000, 1547375.0000,
         1546678.5000, 1545874.8750, 1544399.8750, 1542842.3750, 1542771.7500],
        [1545998.6250, 1543192.6250, 1542278.8750, 1540616.3750, 1535775.3750,
         1535009.6250, 1534792.8750, 1533664.8750, 1533350.3750, 1531351.3750],
        [1552459.6250, 1550034.8750, 1546231.7500, 1544296.7500, 1543765.1250,
         1539902.5000, 1539724.7500, 1537506.1250, 1537058.8750, 1536773.2500],
        [1561480.1250, 1557140.7500, 1555791.5000, 1555705.3750, 1554738.3750,
         1554435.8750, 1553044.6250, 1551892.6250, 1551830.6250, 1550590.8750],
        [1562172.6250, 1562034.1250, 1557953.2500, 1557783.8750, 1556015.5000,
         1554966.7500, 1554553.0000, 1554302.5000, 1552421.1250, 1550305.3750],
        [1557825.5000, 1557185.3750, 1556123.7500, 1555739.5000, 1553366.0000,
         1553166.0000, 1553114.1250, 1553007.5000, 1552758.7500, 1549906.2500],
        [1558486.7500, 1552514.3750, 1551080.3750, 1548894.1250, 1548036.1250,
         1547897.3750, 1547603.7500, 1547236.2500, 1546391.0000, 1545039.2500],
        [1393512.2500, 1315353.2500, 1301537.5000, 1270544.8750, 1270358.2500,
         1216653.7500, 1211342.0000, 1185942.8750, 1148520.6250, 1122615.0000],
        [1521924.2500, 1521184.2500, 1519527.0000, 1519367.5000, 1518972.0000,
         1518911.2500, 1517825.1250, 1517487.8750, 1516822.3750, 1514431.6250],
        [1544413.1250, 1543922.7500, 1540472.3750, 1539770.2500, 1539680.7500,
         1538226.2500, 1537078.0000, 1536632.5000, 1536632.5000, 1536318.8750],
        [1527496.2500, 1527130.6250, 1518646.2500, 1514615.1250, 1513784.7500,
         1512288.5000, 1511543.0000, 1511096.2500, 1509828.6250, 1508887.2500],
        [1371981.1250, 1311043.8750, 1298532.1250, 1289830.8750, 1271324.2500,
         1270662.3750, 1249272.1250, 1238459.6250, 1216130.5000, 1202493.0000],
        [1515750.8750, 1514197.7500, 1513805.0000, 1513138.1250, 1507714.8750,
         1506195.8750, 1505575.5000, 1503951.0000, 1503512.1250, 1503003.2500],
        [1446136.7500, 1425394.3750, 1421826.3750, 1405583.3750, 1402418.0000,
         1402046.2500, 1400665.7500, 1399581.5000, 1398862.2500, 1395650.8750],
        [1508593.7500, 1508212.5000, 1507588.5000, 1505620.0000, 1504952.5000,
         1504378.3750, 1503219.7500, 1501428.7500, 1497997.5000, 1496552.5000],
        [1361986.0000, 1336130.7500, 1332777.3750, 1317875.8750, 1296967.7500,
         1258111.2500, 1253707.2500, 1248536.1250, 1243211.8750, 1241981.8750],
        [1545512.2500, 1545202.7500, 1544071.5000, 1543520.8750, 1543166.1250,
         1541545.1250, 1541046.8750, 1540257.8750, 1539146.3750, 1538616.5000],
        [1535012.6250, 1533210.0000, 1530940.8750, 1528694.1250, 1526931.1250,
         1526837.8750, 1526693.8750, 1524617.6250, 1523921.3750, 1523671.2500],
        [1524899.6250, 1524610.2500, 1521943.1250, 1521583.2500, 1521425.1250,
         1520495.3750, 1519757.3750, 1518727.2500, 1518612.8750, 1518392.7500],
        [1460538.6250, 1459035.1250, 1452356.2500, 1413780.0000, 1406017.7500,
         1403805.6250, 1403695.8750, 1396718.6250, 1396040.8750, 1389317.6250],
        [1330741.5000, 1328017.0000, 1309693.0000, 1301456.7500, 1298472.7500,
         1297428.0000, 1296888.6250, 1294440.7500, 1290364.7500, 1281971.3750],
        [1272510.6250, 1051908.3750,  968392.6250,  935495.6875,  927221.0625,
          913959.1250,  901042.3750,  882067.0625,  864230.5000,  835478.0625],
        [1236971.1250, 1137796.3750, 1136721.5000, 1122672.8750, 1081672.6250,
         1053760.8750, 1044466.1250, 1028726.3125,  999372.8125,  994790.5000],
        [1440542.7500, 1430302.0000, 1420151.3750, 1418167.3750, 1411677.0000,
         1411073.8750, 1410188.7500, 1407552.5000, 1406417.3750, 1397286.2500],
        [1468403.1250, 1467276.2500, 1464492.8750, 1460910.6250, 1452359.0000,
         1448057.8750, 1442367.0000, 1441157.0000, 1440930.2500, 1434263.1250],
        [1458282.6250, 1454110.8750, 1451268.0000, 1450147.3750, 1449142.2500,
         1445597.6250, 1437234.3750, 1435430.2500, 1434579.1250, 1433448.2500],
        [1404369.2500, 1399384.0000, 1393752.7500, 1383844.6250, 1375456.6250,
         1355340.3750, 1354748.5000, 1347564.7500, 1341664.7500, 1329854.6250],
        [1468905.8750, 1464945.3750, 1459902.2500, 1446714.7500, 1431715.7500,
         1422055.5000, 1400516.1250, 1397320.8750, 1391468.5000, 1384226.0000],
        [1404964.1250, 1389411.8750, 1357850.1250, 1340457.5000, 1314536.8750,
         1293238.8750, 1291655.0000, 1280236.3750, 1279823.8750, 1273822.0000],
        [1449230.7500, 1444240.3750, 1427400.8750, 1427127.2500, 1418984.5000,
         1418659.7500, 1418347.2500, 1417738.7500, 1416885.7500, 1415262.5000],
        [1477028.1250, 1476243.7500, 1470874.1250, 1470764.7500, 1466557.1250,
         1464494.1250, 1462234.8750, 1461289.6250, 1459796.5000, 1458841.7500],
        [1391776.2500, 1385479.3750, 1372249.3750, 1337930.0000, 1330042.3750,
         1327787.7500, 1326966.1250, 1314599.6250, 1308500.7500, 1307083.8750],
        [1457423.3750, 1434851.3750, 1421679.8750, 1414667.3750, 1398503.5000,
         1348679.3750, 1340774.5000, 1336907.0000, 1311795.5000, 1305570.1250],
        [1471690.6250, 1449474.0000, 1434933.5000, 1424318.1250, 1412423.0000,
         1406253.7500, 1405229.5000, 1402983.8750, 1395897.1250, 1391024.0000],
        [1515885.2500, 1491996.6250, 1476981.6250, 1475013.7500, 1444526.8750,
         1427166.7500, 1414142.7500, 1412389.2500, 1408386.3750, 1406511.2500],
        [1380987.6250, 1365797.0000, 1365278.7500, 1351309.7500, 1351308.3750,
         1348463.2500, 1341938.6250, 1341490.7500, 1340074.0000, 1337330.3750],
        [1398744.8750, 1384513.7500, 1381153.6250, 1380953.3750, 1378887.2500,
         1374542.7500, 1374312.1250, 1369997.6250, 1369488.2500, 1367059.8750],
        [1443144.3750, 1435474.2500, 1410491.2500, 1409611.8750, 1407584.7500,
         1390274.6250, 1374191.5000, 1373580.8750, 1371253.8750, 1349366.3750],
        [1481668.2500, 1445189.6250, 1442829.2500, 1439611.6250, 1433182.8750,
         1427287.8750, 1422207.5000, 1414123.8750, 1405974.7500, 1404109.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1529462.7500,       0.0000],
         [1515998.0000,       0.0000],
         [1513511.8750,       0.0000],
         ...,
         [1508953.3750,       0.0000],
         [1508684.3750,       0.0000],
         [1507651.6250,       0.0000]],

        [[1532865.0000,       0.0000],
         [1532775.8750,       0.0000],
         [1532609.2500,       0.0000],
         ...,
         [1525517.8750,       0.0000],
         [1524760.1250,       0.0000],
         [1524203.2500,       0.0000]],

        [[1313807.5000,       0.0000],
         [1269383.3750,       0.0000],
         [1268237.6250,       0.0000],
         ...,
         [1126132.2500,       0.0000],
         [1119206.0000,       0.0000],
         [      0.0000, 1118091.2500]],

        ...,

        [[1398744.8750,       0.0000],
         [1384513.7500,       0.0000],
         [      0.0000, 1381153.6250],
         ...,
         [1369997.6250,       0.0000],
         [1369488.2500,       0.0000],
         [1367059.8750,       0.0000]],

        [[1443144.3750,       0.0000],
         [1435474.2500,       0.0000],
         [1410491.2500,       0.0000],
         ...,
         [      0.0000, 1373580.8750],
         [      0.0000, 1371253.8750],
         [      0.0000, 1349366.3750]],

        [[      0.0000, 1481668.2500],
         [      0.0000, 1445189.6250],
         [      0.0000, 1442829.2500],
         ...,
         [      0.0000, 1414123.8750],
         [      0.0000, 1405974.7500],
         [      0.0000, 1404109.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15123748.0000,        0.0000],
        [15290184.0000,        0.0000],
        [ 9586935.0000,  2331890.5000],
        [14375773.0000,        0.0000],
        [ 7957964.0000,  5301027.0000],
        [10869724.0000,  1185461.1250],
        [ 5284792.0000,  5302973.0000],
        [10880077.0000,  1181420.7500],
        [13837714.0000,  1534749.0000],
        [10593829.0000,  2623955.0000],
        [15408855.0000,        0.0000],
        [14353496.0000,        0.0000],
        [14353725.0000,        0.0000],
        [15548678.0000,        0.0000],
        [15411420.0000,        0.0000],
        [15315978.0000,        0.0000],
        [14881536.0000,        0.0000],
        [10551981.0000,  4538756.0000],
        [14638716.0000,        0.0000],
        [13767861.0000,  1533797.8750],
        [15393786.0000,        0.0000],
        [11718398.0000,  2946566.2500],
        [15391198.0000,        0.0000],
        [15507067.0000,        0.0000],
        [ 9002338.0000,  5990889.0000],
        [15472321.0000,        0.0000],
        [15376031.0000,        0.0000],
        [15427753.0000,        0.0000],
        [15546650.0000,        0.0000],
        [15562508.0000,        0.0000],
        [15542193.0000,        0.0000],
        [15493180.0000,        0.0000],
        [ 3720416.5000,  8715964.0000],
        [12146358.0000,  3040095.5000],
        [13853376.0000,  1539770.2500],
        [ 9086868.0000,  6068449.0000],
        [ 6299978.0000,  6419752.0000],
        [10545703.0000,  4541141.0000],
        [11230203.0000,  2867963.0000],
        [13535325.0000,  1503219.7500],
        [10351106.0000,  2540179.5000],
        [15422087.0000,        0.0000],
        [15280531.0000,        0.0000],
        [13689952.0000,  1520495.3750],
        [ 2799736.7500, 11381570.0000],
        [ 6476218.0000,  6553257.0000],
        [ 4684473.0000,  4867833.0000],
        [       0.0000, 10836951.0000],
        [12723057.0000,  1430302.0000],
        [10126410.0000,  4393806.5000],
        [11544982.0000,  2904258.2500],
        [       0.0000, 13685980.0000],
        [       0.0000, 14267772.0000],
        [ 3846885.0000,  9379112.0000],
        [11386908.0000,  2866969.5000],
        [10276174.0000,  4391951.0000],
        [ 1314599.6250, 12087816.0000],
        [ 1305570.1250, 12465282.0000],
        [       0.0000, 14194227.0000],
        [ 4229040.0000, 10243960.0000],
        [ 6805310.5000,  6718668.0000],
        [12398500.0000,  1381153.6250],
        [ 9870773.0000,  4094201.0000],
        [       0.0000, 14316186.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 166/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:58, 59.95s/it]  7%|▋         | 2/29 [01:00<11:21, 25.23s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.607292413711548
Epoch 167/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:39, 61.40s/it]  7%|▋         | 2/29 [01:02<11:37, 25.82s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.588493824005127
Epoch 168/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:11, 60.42s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:10, 14.23s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.5765795707702637
Epoch 169/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:42, 57.25s/it]  7%|▋         | 2/29 [00:59<11:14, 24.98s/it] 10%|█         | 3/29 [01:00<06:03, 14.00s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.83s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.553215265274048
Epoch 170/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:41, 57.20s/it]  7%|▋         | 2/29 [01:01<11:38, 25.85s/it] 10%|█         | 3/29 [01:02<06:16, 14.47s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.12s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.5444509983062744
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0042, 0.0054, 0.0012,  ..., 0.0048, 0.0022, 0.0224],
        [0.0030, 0.0062, 0.0012,  ..., 0.0035, 0.0012, 0.0214],
        [0.0293, 0.0065, 0.0026,  ..., 0.0048, 0.0128, 0.0252],
        ...,
        [0.0045, 0.0086, 0.0071,  ..., 0.0040, 0.0019, 0.0249],
        [0.0022, 0.0107, 0.0024,  ..., 0.0038, 0.0021, 0.0199],
        [0.0098, 0.0071, 0.0015,  ..., 0.0020, 0.0041, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9967, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9858, 0.9843, 0.9831, 0.9805, 0.9801, 0.9769, 0.9767, 0.9764, 0.9757,
         0.9756],
        [0.9942, 0.9938, 0.9934, 0.9927, 0.9926, 0.9922, 0.9921, 0.9919, 0.9919,
         0.9916],
        [0.9882, 0.9876, 0.9871, 0.9870, 0.9869, 0.9867, 0.9866, 0.9865, 0.9863,
         0.9860],
        [0.9890, 0.9846, 0.9818, 0.9781, 0.9776, 0.9774, 0.9767, 0.9765, 0.9760,
         0.9721],
        [0.9776, 0.9729, 0.9721, 0.9718, 0.9676, 0.9675, 0.9673, 0.9671, 0.9666,
         0.9660],
        [0.9855, 0.9821, 0.9820, 0.9811, 0.9807, 0.9802, 0.9796, 0.9792, 0.9790,
         0.9778],
        [0.9977, 0.9977, 0.9974, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971,
         0.9971],
        [0.9930, 0.9882, 0.9866, 0.9866, 0.9860, 0.9860, 0.9858, 0.9857, 0.9846,
         0.9843],
        [0.9977, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9947, 0.9938, 0.9936, 0.9933, 0.9931, 0.9924, 0.9924, 0.9921, 0.9916,
         0.9909],
        [0.9947, 0.9938, 0.9933, 0.9933, 0.9926, 0.9924, 0.9922, 0.9920, 0.9916,
         0.9915],
        [0.9983, 0.9983, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9975, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9959, 0.9955, 0.9954, 0.9954, 0.9952, 0.9951, 0.9950, 0.9947, 0.9946,
         0.9946],
        [0.9965, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9960, 0.9959,
         0.9958],
        [0.9946, 0.9944, 0.9942, 0.9942, 0.9942, 0.9939, 0.9939, 0.9937, 0.9936,
         0.9935],
        [0.9975, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969,
         0.9969],
        [0.9980, 0.9979, 0.9975, 0.9974, 0.9974, 0.9974, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9952, 0.9947, 0.9942, 0.9941, 0.9940, 0.9939, 0.9939, 0.9937, 0.9937,
         0.9936],
        [0.9981, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9972, 0.9970,
         0.9969],
        [0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9958, 0.9958, 0.9958, 0.9958, 0.9957, 0.9955, 0.9954, 0.9954, 0.9954,
         0.9954],
        [0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9976, 0.9976, 0.9976, 0.9976, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9985, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9984, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980,
         0.9979],
        [0.9983, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9899, 0.9858, 0.9847, 0.9838, 0.9831, 0.9813, 0.9799, 0.9796, 0.9750,
         0.9739],
        [0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9969, 0.9968, 0.9966, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9892, 0.9856, 0.9856, 0.9837, 0.9835, 0.9830, 0.9824, 0.9816, 0.9807,
         0.9804],
        [0.9965, 0.9964, 0.9964, 0.9961, 0.9960, 0.9960, 0.9958, 0.9958, 0.9958,
         0.9958],
        [0.9933, 0.9925, 0.9915, 0.9912, 0.9912, 0.9911, 0.9910, 0.9909, 0.9908,
         0.9906],
        [0.9962, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9957, 0.9957,
         0.9956],
        [0.9893, 0.9873, 0.9872, 0.9861, 0.9858, 0.9834, 0.9831, 0.9828, 0.9826,
         0.9824],
        [0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9973, 0.9973, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9940, 0.9936, 0.9935, 0.9916, 0.9915, 0.9913, 0.9912, 0.9911, 0.9907,
         0.9906],
        [0.9872, 0.9871, 0.9865, 0.9860, 0.9855, 0.9853, 0.9852, 0.9852, 0.9847,
         0.9846],
        [0.9841, 0.9691, 0.9641, 0.9622, 0.9604, 0.9595, 0.9584, 0.9563, 0.9561,
         0.9552],
        [0.9814, 0.9750, 0.9749, 0.9748, 0.9717, 0.9694, 0.9685, 0.9665, 0.9661,
         0.9654],
        [0.9929, 0.9923, 0.9920, 0.9919, 0.9916, 0.9915, 0.9914, 0.9914, 0.9911,
         0.9908],
        [0.9943, 0.9942, 0.9940, 0.9940, 0.9932, 0.9930, 0.9930, 0.9930, 0.9928,
         0.9927],
        [0.9939, 0.9936, 0.9936, 0.9933, 0.9932, 0.9930, 0.9929, 0.9929, 0.9928,
         0.9928],
        [0.9912, 0.9911, 0.9905, 0.9902, 0.9899, 0.9895, 0.9887, 0.9887, 0.9882,
         0.9880],
        [0.9943, 0.9940, 0.9939, 0.9930, 0.9924, 0.9919, 0.9919, 0.9906, 0.9906,
         0.9903],
        [0.9908, 0.9899, 0.9887, 0.9875, 0.9863, 0.9859, 0.9858, 0.9846, 0.9842,
         0.9842],
        [0.9933, 0.9931, 0.9927, 0.9922, 0.9921, 0.9920, 0.9920, 0.9919, 0.9918,
         0.9918],
        [0.9948, 0.9947, 0.9944, 0.9944, 0.9941, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9936],
        [0.9910, 0.9904, 0.9897, 0.9879, 0.9876, 0.9874, 0.9871, 0.9870, 0.9868,
         0.9866],
        [0.9937, 0.9926, 0.9921, 0.9917, 0.9907, 0.9886, 0.9883, 0.9882, 0.9866,
         0.9864],
        [0.9946, 0.9935, 0.9926, 0.9925, 0.9923, 0.9918, 0.9912, 0.9910, 0.9910,
         0.9906],
        [0.9964, 0.9950, 0.9947, 0.9946, 0.9930, 0.9926, 0.9922, 0.9920, 0.9920,
         0.9919],
        [0.9897, 0.9890, 0.9888, 0.9883, 0.9882, 0.9881, 0.9877, 0.9877, 0.9876,
         0.9875],
        [0.9905, 0.9900, 0.9898, 0.9897, 0.9897, 0.9895, 0.9894, 0.9894, 0.9891,
         0.9891],
        [0.9932, 0.9927, 0.9917, 0.9915, 0.9912, 0.9906, 0.9899, 0.9898, 0.9894,
         0.9883],
        [0.9948, 0.9931, 0.9929, 0.9928, 0.9926, 0.9924, 0.9924, 0.9920, 0.9914,
         0.9911]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 1, 1, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 0, 1, 0, 0, 0, 1, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [0, 0, 0, 1, 1, 0, 1, 0, 1, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1533925.1250, 1525851.0000, 1519408.1250, 1517716.6250, 1517572.0000,
         1516385.6250, 1515304.2500, 1515117.8750, 1514246.7500, 1514177.5000],
        [1538287.8750, 1534529.5000, 1534343.6250, 1533332.8750, 1532930.7500,
         1529560.3750, 1529244.0000, 1528481.2500, 1527794.8750, 1526608.0000],
        [1306186.6250, 1279532.1250, 1257296.8750, 1210423.8750, 1203930.8750,
         1151065.5000, 1147203.6250, 1142523.0000, 1131017.5000, 1129858.6250],
        [1473547.2500, 1464976.1250, 1457205.1250, 1440970.1250, 1440173.3750,
         1431871.5000, 1428641.5000, 1425250.2500, 1425034.2500, 1419487.8750],
        [1352237.7500, 1340039.5000, 1330758.0000, 1329475.5000, 1327409.2500,
         1323810.0000, 1320929.6250, 1318711.8750, 1315594.1250, 1310057.7500],
        [1366855.1250, 1284683.3750, 1234558.7500, 1170906.1250, 1162734.1250,
         1159050.6250, 1147761.7500, 1144551.5000, 1135879.6250, 1073842.6250],
        [1161841.7500, 1085883.3750, 1073911.2500, 1070026.5000, 1007159.1250,
         1006495.6875, 1002823.1875, 1000574.4375,  993724.7500,  984817.8125],
        [1301702.6250, 1239438.0000, 1237557.5000, 1222371.1250, 1213862.8750,
         1206574.5000, 1196124.6250, 1188702.2500, 1184711.8750, 1164936.1250],
        [1548584.0000, 1548276.8750, 1541851.0000, 1538660.6250, 1538286.5000,
         1538019.3750, 1537160.1250, 1536052.2500, 1535358.0000, 1535246.7500],
        [1448218.1250, 1352301.0000, 1322366.5000, 1320964.8750, 1310605.1250,
         1310087.7500, 1306406.0000, 1304633.0000, 1283521.2500, 1278898.8750],
        [1548721.3750, 1544463.2500, 1543400.1250, 1542720.2500, 1542302.5000,
         1540118.2500, 1539376.7500, 1539163.8750, 1538073.6250, 1537726.1250],
        [1483657.7500, 1464235.8750, 1459558.3750, 1453984.6250, 1449941.3750,
         1435738.3750, 1435585.0000, 1428657.8750, 1419524.5000, 1404581.0000],
        [1483339.3750, 1465667.8750, 1454194.0000, 1453500.7500, 1440049.7500,
         1436572.5000, 1430988.1250, 1426844.1250, 1420045.7500, 1417581.8750],
        [1562843.1250, 1562125.0000, 1561508.3750, 1559163.1250, 1557419.8750,
         1556147.6250, 1555901.2500, 1555531.7500, 1554224.0000, 1553906.7500],
        [1549310.7500, 1547206.7500, 1545621.3750, 1545239.6250, 1544893.3750,
         1543591.5000, 1542773.1250, 1542359.8750, 1541531.8750, 1540836.7500],
        [1543235.2500, 1540544.2500, 1537765.6250, 1537097.0000, 1535292.1250,
         1535022.7500, 1531956.0000, 1531820.1250, 1531732.5000, 1531247.6250],
        [1509513.2500, 1501285.5000, 1499598.5000, 1498189.0000, 1493709.3750,
         1492410.7500, 1489173.3750, 1484194.1250, 1482096.3750, 1480959.1250],
        [1522493.2500, 1520865.1250, 1518345.0000, 1517240.5000, 1516683.5000,
         1516429.0000, 1512630.3750, 1510404.6250, 1509154.8750, 1506724.5000],
        [1480990.1250, 1476554.8750, 1473156.6250, 1473106.1250, 1472733.8750,
         1466374.0000, 1466109.6250, 1462661.5000, 1459607.1250, 1458270.1250],
        [1543584.1250, 1538166.1250, 1536348.2500, 1535738.7500, 1534711.0000,
         1533707.3750, 1533686.7500, 1532562.5000, 1531725.1250, 1531224.1250],
        [1554857.0000, 1552128.0000, 1543807.8750, 1542740.8750, 1542490.7500,
         1541715.7500, 1538223.2500, 1537261.2500, 1537163.1250, 1536956.3750],
        [1495030.5000, 1484559.2500, 1473190.3750, 1470760.5000, 1469846.2500,
         1467381.2500, 1465728.0000, 1462769.0000, 1461664.5000, 1460496.8750],
        [1556993.7500, 1544760.8750, 1543410.5000, 1542824.6250, 1541605.3750,
         1541534.8750, 1541445.1250, 1537397.6250, 1533262.6250, 1531855.1250],
        [1559075.5000, 1556129.8750, 1554195.7500, 1553868.2500, 1553745.2500,
         1553354.1250, 1552148.7500, 1551877.8750, 1551834.8750, 1548920.7500],
        [1507197.3750, 1507183.0000, 1507135.6250, 1506576.5000, 1504974.0000,
         1500678.6250, 1499546.8750, 1498683.3750, 1498296.2500, 1497789.0000],
        [1554732.3750, 1554579.7500, 1554338.0000, 1549950.6250, 1549564.8750,
         1549505.7500, 1547996.3750, 1547932.7500, 1547631.7500, 1545347.2500],
        [1547311.3750, 1547007.5000, 1545749.6250, 1545445.8750, 1538685.5000,
         1537627.7500, 1537513.5000, 1537504.6250, 1536071.2500, 1535631.8750],
        [1555045.3750, 1551759.5000, 1551055.2500, 1547850.1250, 1545922.0000,
         1543219.1250, 1542128.8750, 1540131.5000, 1540015.5000, 1539187.3750],
        [1566552.8750, 1559955.8750, 1559068.0000, 1558546.2500, 1558171.6250,
         1557528.3750, 1555785.5000, 1555514.0000, 1554083.1250, 1553917.2500],
        [1564979.0000, 1564573.0000, 1562114.5000, 1559747.6250, 1558745.3750,
         1558628.0000, 1557039.8750, 1556744.3750, 1554959.2500, 1553329.0000],
        [1561072.0000, 1558084.0000, 1558073.5000, 1557889.3750, 1557656.1250,
         1557316.0000, 1556719.1250, 1556567.6250, 1555806.3750, 1554235.7500],
        [1560399.2500, 1557497.1250, 1556352.3750, 1554993.5000, 1553043.0000,
         1551943.0000, 1551614.3750, 1549866.3750, 1549795.3750, 1549770.2500],
        [1385565.2500, 1306834.6250, 1285590.3750, 1270578.8750, 1257175.7500,
         1224600.8750, 1200878.2500, 1195871.5000, 1119349.1250, 1102416.7500],
        [1525513.5000, 1523462.1250, 1522882.5000, 1522791.0000, 1522349.6250,
         1522191.3750, 1521349.6250, 1520727.2500, 1520250.2500, 1519773.3750],
        [1547751.2500, 1546466.1250, 1544830.0000, 1542467.2500, 1540222.6250,
         1540222.6250, 1540205.0000, 1539989.1250, 1538896.8750, 1537064.7500],
        [1530656.2500, 1528952.2500, 1524808.1250, 1520295.2500, 1519835.6250,
         1517777.5000, 1516593.8750, 1516486.8750, 1516029.8750, 1514765.3750],
        [1371112.6250, 1303371.8750, 1302456.2500, 1267341.6250, 1264781.8750,
         1254440.3750, 1245159.1250, 1230610.2500, 1214885.6250, 1208889.6250],
        [1521666.0000, 1520666.3750, 1519505.2500, 1513513.3750, 1511985.6250,
         1510799.3750, 1507436.0000, 1507019.1250, 1506960.2500, 1506629.6250],
        [1455065.1250, 1436931.5000, 1416918.2500, 1411419.7500, 1410522.2500,
         1408250.7500, 1408199.6250, 1405658.3750, 1402856.7500, 1398598.1250],
        [1514950.2500, 1512174.5000, 1511159.6250, 1510525.7500, 1509907.8750,
         1509499.0000, 1509349.1250, 1504534.7500, 1504240.6250, 1502910.0000],
        [1372951.0000, 1334621.6250, 1332657.8750, 1311848.0000, 1306899.3750,
         1261776.0000, 1256359.5000, 1252526.5000, 1248876.6250, 1244417.1250],
        [1548042.1250, 1547777.8750, 1547212.6250, 1547001.6250, 1545734.8750,
         1545703.8750, 1544058.1250, 1543958.0000, 1543148.5000, 1543108.7500],
        [1540116.8750, 1539115.3750, 1534049.5000, 1533021.5000, 1531389.2500,
         1530520.5000, 1530405.2500, 1530288.3750, 1529496.2500, 1528563.0000],
        [1531304.5000, 1529273.0000, 1529121.3750, 1525571.6250, 1525244.3750,
         1524845.8750, 1524633.6250, 1523170.1250, 1522541.2500, 1521960.6250],
        [1469341.6250, 1460079.1250, 1458754.0000, 1418398.6250, 1416371.1250,
         1412847.2500, 1410609.6250, 1409844.3750, 1401071.7500, 1398580.7500],
        [1333588.5000, 1331273.3750, 1318911.8750, 1310386.3750, 1300670.1250,
         1296541.0000, 1295593.0000, 1295257.0000, 1285259.3750, 1283823.6250],
        [1275853.5000, 1028555.6250,  958600.3750,  932576.6250,  909377.2500,
          897055.4375,  883850.5625,  856989.9375,  854648.3125,  844398.1875],
        [1227588.3750, 1119544.5000, 1118056.0000, 1116256.6250, 1067831.6250,
         1032905.2500, 1020302.1875,  991854.8125,  985590.1250,  975929.1875],
        [1445046.3750, 1433401.6250, 1427489.2500, 1425920.5000, 1419060.2500,
         1416898.0000, 1415921.2500, 1415617.6250, 1409997.7500, 1402526.3750],
        [1475144.5000, 1472930.5000, 1468765.7500, 1468046.0000, 1452163.7500,
         1448005.3750, 1447917.0000, 1447645.0000, 1443590.3750, 1441350.8750],
        [1467361.6250, 1460732.3750, 1460619.5000, 1454661.5000, 1452170.7500,
         1448766.5000, 1446180.8750, 1445248.8750, 1443242.1250, 1443027.3750],
        [1410919.1250, 1410023.2500, 1397970.0000, 1391143.3750, 1385312.8750,
         1377760.7500, 1361693.8750, 1361229.0000, 1351268.3750, 1347523.5000],
        [1475039.0000, 1469699.0000, 1467533.7500, 1448748.5000, 1436257.3750,
         1425790.0000, 1425531.6250, 1399039.6250, 1398323.3750, 1393615.8750],
        [1402971.8750, 1385639.2500, 1362387.3750, 1338693.2500, 1315682.0000,
         1308686.6250, 1305859.1250, 1283964.5000, 1277006.2500, 1276927.1250],
        [1453590.8750, 1449367.5000, 1442258.3750, 1432416.3750, 1428569.2500,
         1427387.1250, 1426693.1250, 1425719.2500, 1423071.7500, 1422841.0000],
        [1484747.6250, 1483165.5000, 1477640.8750, 1477414.1250, 1471725.7500,
         1470638.3750, 1470042.5000, 1468617.3750, 1468410.1250, 1460572.0000],
        [1406903.0000, 1395706.7500, 1381812.3750, 1346768.1250, 1340265.6250,
         1336857.2500, 1331663.1250, 1329757.0000, 1325855.6250, 1321963.0000],
        [1463324.3750, 1439091.3750, 1429733.2500, 1421483.3750, 1400397.2500,
         1359510.0000, 1354499.1250, 1352515.1250, 1320618.5000, 1318377.3750],
        [1481080.6250, 1459118.6250, 1439937.0000, 1436965.6250, 1433025.7500,
         1424141.6250, 1411550.3750, 1408148.7500, 1406452.2500, 1399497.3750],
        [1520015.3750, 1489996.0000, 1484465.7500, 1481794.0000, 1448982.0000,
         1438963.7500, 1432400.0000, 1428475.2500, 1427195.2500, 1424690.2500],
        [1381790.0000, 1367268.5000, 1364219.3750, 1354031.5000, 1352388.7500,
         1349528.6250, 1342736.1250, 1341686.5000, 1340379.5000, 1338536.1250],
        [1397119.6250, 1388199.8750, 1383934.3750, 1381504.1250, 1381310.3750,
         1377592.5000, 1374862.6250, 1374645.0000, 1370205.3750, 1369766.3750],
        [1451914.5000, 1441816.8750, 1422145.1250, 1417000.6250, 1411324.2500,
         1398562.1250, 1385735.6250, 1383293.0000, 1375875.2500, 1354598.6250],
        [1485131.3750, 1449821.0000, 1446954.8750, 1443090.7500, 1440431.5000,
         1436453.2500, 1435906.8750, 1428310.5000, 1415381.3750, 1408769.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1533925.1250,       0.0000],
         [1525851.0000,       0.0000],
         [1519408.1250,       0.0000],
         ...,
         [1515117.8750,       0.0000],
         [1514246.7500,       0.0000],
         [1514177.5000,       0.0000]],

        [[1538287.8750,       0.0000],
         [1534529.5000,       0.0000],
         [1534343.6250,       0.0000],
         ...,
         [1528481.2500,       0.0000],
         [1527794.8750,       0.0000],
         [1526608.0000,       0.0000]],

        [[1306186.6250,       0.0000],
         [1279532.1250,       0.0000],
         [1257296.8750,       0.0000],
         ...,
         [1142523.0000,       0.0000],
         [      0.0000, 1131017.5000],
         [1129858.6250,       0.0000]],

        ...,

        [[1397119.6250,       0.0000],
         [1388199.8750,       0.0000],
         [      0.0000, 1383934.3750],
         ...,
         [1374645.0000,       0.0000],
         [1370205.3750,       0.0000],
         [1369766.3750,       0.0000]],

        [[1451914.5000,       0.0000],
         [1441816.8750,       0.0000],
         [1422145.1250,       0.0000],
         ...,
         [1383293.0000,       0.0000],
         [      0.0000, 1375875.2500],
         [      0.0000, 1354598.6250]],

        [[      0.0000, 1485131.3750],
         [      0.0000, 1449821.0000],
         [      0.0000, 1446954.8750],
         ...,
         [      0.0000, 1428310.5000],
         [      0.0000, 1415381.3750],
         [      0.0000, 1408769.2500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15189704.0000,        0.0000],
        [15315114.0000,        0.0000],
        [ 9617597.0000,  2341441.5000],
        [14407156.0000,        0.0000],
        [ 9277382.0000,  3991642.0000],
        [10736272.0000,  1144551.5000],
        [ 4219509.0000,  6167748.5000],
        [ 9794921.0000,  2361060.7500],
        [13862137.0000,  1535358.0000],
        [10602180.0000,  2635822.2500],
        [15416066.0000,        0.0000],
        [14435464.0000,        0.0000],
        [14428785.0000,        0.0000],
        [15578771.0000,        0.0000],
        [15443366.0000,        0.0000],
        [15355713.0000,        0.0000],
        [14931129.0000,        0.0000],
        [10593704.0000,  4557267.0000],
        [13229956.0000,  1459607.1250],
        [13815106.0000,  1536348.2500],
        [15427344.0000,        0.0000],
        [11759486.0000,  2951940.5000],
        [15415090.0000,        0.0000],
        [15535150.0000,        0.0000],
        [ 9014940.0000,  6013121.5000],
        [15501580.0000,        0.0000],
        [15408548.0000,        0.0000],
        [15456314.0000,        0.0000],
        [15579122.0000,        0.0000],
        [15590860.0000,        0.0000],
        [15573419.0000,        0.0000],
        [15535275.0000,        0.0000],
        [ 3662115.5000,  8686746.0000],
        [10652700.0000,  4568590.0000],
        [13878126.0000,  1539989.1250],
        [ 9119360.0000,  6086841.0000],
        [ 6263738.0000,  6399311.0000],
        [ 9065060.0000,  6061121.0000],
        [11262424.0000,  2891996.5000],
        [13579752.0000,  1509499.0000],
        [10359674.0000,  2563259.0000],
        [15455746.0000,        0.0000],
        [15326966.0000,        0.0000],
        [13732422.0000,  1525244.3750],
        [ 2813919.0000, 11441979.0000],
        [ 6481601.0000,  6569703.5000],
        [ 4575828.5000,  4866077.0000],
        [       0.0000, 10655858.0000],
        [12778477.0000,  1433401.6250],
        [10153603.0000,  4411956.0000],
        [11600660.0000,  2921352.0000],
        [       0.0000, 13794844.0000],
        [       0.0000, 14339578.0000],
        [ 3876652.7500,  9381165.0000],
        [11455482.0000,  2876432.0000],
        [10324719.0000,  4408255.5000],
        [       0.0000, 13517551.0000],
        [       0.0000, 13859550.0000],
        [       0.0000, 14299918.0000],
        [ 1432400.0000, 13144578.0000],
        [ 6804493.0000,  6728072.0000],
        [12415206.0000,  1383934.3750],
        [ 9926056.0000,  4116209.5000],
        [       0.0000, 14390251.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 171/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:45, 61.61s/it]  7%|▋         | 2/29 [01:02<11:39, 25.91s/it] 10%|█         | 3/29 [01:03<06:17, 14.50s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 3.537144899368286
Epoch 172/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:05, 58.04s/it]  7%|▋         | 2/29 [00:58<10:59, 24.44s/it] 10%|█         | 3/29 [00:59<05:56, 13.70s/it] 14%|█▍        | 4/29 [01:00<03:38,  8.73s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.92s/it] 21%|██        | 6/29 [01:02<01:37,  4.22s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.516359567642212
Epoch 173/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:46, 59.53s/it]  7%|▋         | 2/29 [01:00<11:16, 25.05s/it] 10%|█         | 3/29 [01:01<06:04, 14.03s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.86s/it] 17%|█▋        | 5/29 [01:03<02:23,  6.00s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.5031790733337402
Epoch 174/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.82s/it]  7%|▋         | 2/29 [01:01<11:30, 25.59s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4969184398651123
Epoch 175/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.64s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4841349124908447
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0041, 0.0055, 0.0012,  ..., 0.0050, 0.0023, 0.0221],
        [0.0030, 0.0066, 0.0012,  ..., 0.0041, 0.0013, 0.0205],
        [0.0306, 0.0070, 0.0026,  ..., 0.0050, 0.0137, 0.0246],
        ...,
        [0.0042, 0.0076, 0.0087,  ..., 0.0039, 0.0019, 0.0258],
        [0.0022, 0.0100, 0.0027,  ..., 0.0039, 0.0016, 0.0204],
        [0.0093, 0.0069, 0.0016,  ..., 0.0020, 0.0037, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9969, 0.9966, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9959],
        [0.9973, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9966, 0.9965,
         0.9965],
        [0.9856, 0.9833, 0.9806, 0.9805, 0.9798, 0.9781, 0.9771, 0.9760, 0.9755,
         0.9755],
        [0.9936, 0.9933, 0.9924, 0.9920, 0.9917, 0.9916, 0.9913, 0.9912, 0.9911,
         0.9910],
        [0.9881, 0.9873, 0.9869, 0.9867, 0.9865, 0.9862, 0.9858, 0.9855, 0.9854,
         0.9848],
        [0.9891, 0.9845, 0.9802, 0.9781, 0.9777, 0.9762, 0.9760, 0.9754, 0.9745,
         0.9710],
        [0.9780, 0.9741, 0.9737, 0.9729, 0.9712, 0.9685, 0.9679, 0.9673, 0.9669,
         0.9667],
        [0.9842, 0.9840, 0.9819, 0.9808, 0.9798, 0.9795, 0.9779, 0.9748, 0.9748,
         0.9737],
        [0.9977, 0.9976, 0.9973, 0.9973, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970,
         0.9969],
        [0.9928, 0.9870, 0.9855, 0.9852, 0.9851, 0.9850, 0.9841, 0.9836, 0.9831,
         0.9826],
        [0.9977, 0.9975, 0.9974, 0.9974, 0.9974, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9940, 0.9933, 0.9932, 0.9925, 0.9924, 0.9912, 0.9911, 0.9904, 0.9902,
         0.9898],
        [0.9941, 0.9933, 0.9926, 0.9922, 0.9922, 0.9921, 0.9910, 0.9905, 0.9904,
         0.9897],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9975, 0.9974, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9960, 0.9954, 0.9954, 0.9954, 0.9953, 0.9951, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9965, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9960, 0.9958, 0.9957,
         0.9957],
        [0.9943, 0.9943, 0.9940, 0.9940, 0.9938, 0.9938, 0.9936, 0.9935, 0.9935,
         0.9934],
        [0.9974, 0.9972, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9980, 0.9979, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9953, 0.9944, 0.9940, 0.9940, 0.9938, 0.9938, 0.9937, 0.9935, 0.9932,
         0.9931],
        [0.9982, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9971,
         0.9971],
        [0.9982, 0.9982, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9957, 0.9956, 0.9956, 0.9955, 0.9954, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9982, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9986, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9985, 0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9980,
         0.9980],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9983, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9900, 0.9852, 0.9851, 0.9837, 0.9831, 0.9816, 0.9794, 0.9790, 0.9751,
         0.9744],
        [0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9972,
         0.9972],
        [0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9962, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9893, 0.9864, 0.9854, 0.9846, 0.9844, 0.9829, 0.9822, 0.9815, 0.9811,
         0.9798],
        [0.9962, 0.9962, 0.9962, 0.9959, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9933, 0.9925, 0.9914, 0.9912, 0.9911, 0.9908, 0.9905, 0.9904, 0.9902,
         0.9901],
        [0.9961, 0.9960, 0.9960, 0.9959, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956,
         0.9956],
        [0.9895, 0.9874, 0.9873, 0.9865, 0.9856, 0.9838, 0.9834, 0.9833, 0.9832,
         0.9832],
        [0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9973, 0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9941, 0.9934, 0.9934, 0.9916, 0.9915, 0.9915, 0.9912, 0.9910, 0.9910,
         0.9905],
        [0.9859, 0.9858, 0.9857, 0.9856, 0.9848, 0.9844, 0.9843, 0.9842, 0.9837,
         0.9837],
        [0.9853, 0.9659, 0.9634, 0.9633, 0.9588, 0.9564, 0.9553, 0.9552, 0.9549,
         0.9532],
        [0.9818, 0.9750, 0.9749, 0.9736, 0.9722, 0.9691, 0.9669, 0.9665, 0.9662,
         0.9645],
        [0.9929, 0.9923, 0.9923, 0.9917, 0.9912, 0.9911, 0.9909, 0.9908, 0.9907,
         0.9905],
        [0.9946, 0.9942, 0.9939, 0.9937, 0.9930, 0.9930, 0.9929, 0.9928, 0.9928,
         0.9928],
        [0.9939, 0.9936, 0.9935, 0.9933, 0.9931, 0.9931, 0.9928, 0.9928, 0.9928,
         0.9927],
        [0.9911, 0.9910, 0.9903, 0.9902, 0.9897, 0.9896, 0.9887, 0.9884, 0.9880,
         0.9879],
        [0.9946, 0.9942, 0.9940, 0.9931, 0.9929, 0.9923, 0.9921, 0.9907, 0.9907,
         0.9906],
        [0.9910, 0.9899, 0.9898, 0.9887, 0.9864, 0.9863, 0.9858, 0.9850, 0.9849,
         0.9848],
        [0.9936, 0.9933, 0.9932, 0.9925, 0.9924, 0.9924, 0.9924, 0.9924, 0.9923,
         0.9923],
        [0.9948, 0.9948, 0.9945, 0.9945, 0.9941, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9937],
        [0.9914, 0.9909, 0.9900, 0.9884, 0.9882, 0.9876, 0.9876, 0.9875, 0.9871,
         0.9870],
        [0.9937, 0.9929, 0.9924, 0.9915, 0.9904, 0.9888, 0.9885, 0.9884, 0.9871,
         0.9863],
        [0.9948, 0.9940, 0.9929, 0.9927, 0.9925, 0.9921, 0.9912, 0.9911, 0.9910,
         0.9907],
        [0.9964, 0.9948, 0.9947, 0.9947, 0.9936, 0.9925, 0.9922, 0.9918, 0.9917,
         0.9917],
        [0.9900, 0.9896, 0.9895, 0.9887, 0.9882, 0.9881, 0.9880, 0.9880, 0.9876,
         0.9872],
        [0.9902, 0.9900, 0.9895, 0.9894, 0.9894, 0.9893, 0.9891, 0.9890, 0.9889,
         0.9889],
        [0.9933, 0.9930, 0.9920, 0.9919, 0.9915, 0.9911, 0.9897, 0.9897, 0.9895,
         0.9886],
        [0.9950, 0.9934, 0.9929, 0.9928, 0.9928, 0.9927, 0.9927, 0.9925, 0.9913,
         0.9912]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 1, 0, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [1, 1, 0, 1, 1, 0, 0, 0, 0, 1],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],
        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1530411.1250, 1525516.5000, 1516165.7500, 1515405.3750, 1514688.7500,
         1513686.6250, 1513540.7500, 1513517.7500, 1510939.1250, 1509987.0000],
        [1540415.1250, 1533275.8750, 1532144.5000, 1530465.1250, 1530056.3750,
         1529900.2500, 1528551.2500, 1524412.6250, 1523125.1250, 1523000.1250],
        [1302920.8750, 1260203.1250, 1212985.8750, 1210638.6250, 1199824.0000,
         1170190.6250, 1153584.3750, 1136296.6250, 1127714.2500, 1127393.7500],
        [1461213.0000, 1454332.6250, 1436340.8750, 1427524.6250, 1421993.1250,
         1419827.7500, 1414123.8750, 1411959.6250, 1409560.7500, 1407255.8750],
        [1349397.2500, 1335306.5000, 1327797.8750, 1322775.2500, 1320271.0000,
         1314802.7500, 1307062.6250, 1300984.0000, 1299233.2500, 1288650.5000],
        [1369711.5000, 1282467.7500, 1206109.7500, 1170370.2500, 1163634.8750,
         1139761.0000, 1135722.5000, 1126900.3750, 1111663.0000, 1057145.8750],
        [1167935.2500, 1105601.6250, 1099183.3750, 1087358.0000, 1060669.2500,
         1020958.2500, 1012054.2500, 1003635.5000,  997537.9375,  994892.0000],
        [1277040.3750, 1273032.6250, 1236442.7500, 1215847.6250, 1200016.2500,
         1194388.6250, 1167555.5000, 1116674.0000, 1116357.7500, 1098392.1250],
        [1547959.3750, 1545948.6250, 1539400.3750, 1538923.2500, 1535768.1250,
         1535598.1250, 1535050.6250, 1534978.8750, 1533925.1250, 1532011.5000],
        [1443576.6250, 1329395.6250, 1301343.8750, 1294582.7500, 1293985.3750,
         1291233.8750, 1274895.0000, 1265583.1250, 1256975.5000, 1247850.3750],
        [1547748.3750, 1543463.3750, 1542737.8750, 1541640.7500, 1541487.8750,
         1538656.1250, 1538283.3750, 1537861.0000, 1536425.7500, 1536411.2500],
        [1468642.6250, 1453215.2500, 1451882.6250, 1437523.6250, 1435864.3750,
         1411761.7500, 1409121.2500, 1394986.8750, 1390285.2500, 1382810.2500],
        [1470137.7500, 1453420.3750, 1440493.3750, 1431892.0000, 1431389.3750,
         1430286.8750, 1407814.3750, 1398016.7500, 1394891.0000, 1381103.5000],
        [1564221.0000, 1562870.0000, 1561728.7500, 1559267.2500, 1556221.7500,
         1556218.8750, 1556083.7500, 1555837.5000, 1554077.2500, 1553937.8750],
        [1550441.5000, 1549856.1250, 1548811.5000, 1548403.7500, 1547912.1250,
         1544318.8750, 1544290.8750, 1543529.7500, 1543292.7500, 1542499.6250],
        [1544831.5000, 1542896.8750, 1539487.0000, 1537383.0000, 1536732.0000,
         1535328.7500, 1534932.0000, 1534264.6250, 1534201.7500, 1532175.1250],
        [1511770.8750, 1499103.7500, 1498370.5000, 1498051.8750, 1497266.2500,
         1491153.1250, 1487570.8750, 1487053.1250, 1485615.8750, 1485552.1250],
        [1522439.6250, 1518226.1250, 1517233.2500, 1516578.0000, 1516475.2500,
         1513802.1250, 1511974.1250, 1507546.7500, 1505101.6250, 1504222.0000],
        [1474645.2500, 1474366.8750, 1469242.1250, 1468554.2500, 1465108.8750,
         1464270.8750, 1460005.2500, 1459374.7500, 1459031.0000, 1456307.6250],
        [1541382.0000, 1537286.1250, 1535488.3750, 1534866.2500, 1534141.6250,
         1533583.0000, 1532029.1250, 1531859.5000, 1531506.1250, 1531222.7500],
        [1554726.5000, 1551916.3750, 1545994.3750, 1545469.5000, 1543459.0000,
         1542504.0000, 1542183.3750, 1541898.0000, 1540074.2500, 1539955.2500],
        [1495419.7500, 1476450.7500, 1469875.6250, 1469491.6250, 1464714.8750,
         1463691.3750, 1463455.3750, 1457683.2500, 1452868.8750, 1449996.6250],
        [1559041.2500, 1544872.7500, 1544265.8750, 1543425.1250, 1543222.1250,
         1542929.2500, 1542233.3750, 1539442.8750, 1536129.8750, 1534813.5000],
        [1559761.0000, 1558656.2500, 1556212.8750, 1555212.8750, 1555204.0000,
         1553783.7500, 1553016.3750, 1552508.5000, 1552151.6250, 1551712.1250],
        [1505312.7500, 1502712.2500, 1502335.3750, 1501626.2500, 1499226.6250,
         1496506.8750, 1494654.1250, 1493132.5000, 1492503.2500, 1491157.2500],
        [1558497.1250, 1555597.1250, 1554336.6250, 1554324.7500, 1553274.1250,
         1551944.5000, 1550910.2500, 1550400.1250, 1550108.7500, 1549683.1250],
        [1550014.1250, 1549205.7500, 1548025.8750, 1547197.8750, 1541010.1250,
         1540094.8750, 1540043.5000, 1539909.7500, 1539541.2500, 1538745.6250],
        [1560113.6250, 1555779.6250, 1553263.7500, 1551732.8750, 1549890.0000,
         1548801.1250, 1548129.1250, 1546365.8750, 1544514.7500, 1543584.1250],
        [1569078.1250, 1562934.1250, 1561156.8750, 1560604.6250, 1560046.6250,
         1559717.8750, 1558038.0000, 1558023.1250, 1556245.5000, 1555896.8750],
        [1566258.5000, 1565741.7500, 1563939.0000, 1560673.1250, 1560122.5000,
         1559839.8750, 1558592.3750, 1558409.5000, 1555968.1250, 1554799.1250],
        [1563628.8750, 1561456.2500, 1561362.3750, 1560449.8750, 1559975.2500,
         1558840.5000, 1558387.2500, 1556932.8750, 1556760.6250, 1556686.3750],
        [1561240.2500, 1559778.8750, 1559694.1250, 1556689.3750, 1555545.1250,
         1554416.6250, 1554173.5000, 1554138.0000, 1552461.0000, 1552444.7500],
        [1386487.8750, 1295626.5000, 1293623.7500, 1267339.1250, 1257500.7500,
         1229788.8750, 1192378.7500, 1185815.0000, 1120721.7500, 1110440.2500],
        [1527926.1250, 1524643.7500, 1524325.3750, 1522918.8750, 1521535.3750,
         1521111.7500, 1520446.0000, 1520298.1250, 1519745.8750, 1517029.3750],
        [1548573.6250, 1546488.2500, 1545942.7500, 1543640.0000, 1542813.0000,
         1541602.5000, 1541602.5000, 1540704.3750, 1537877.1250, 1537488.5000],
        [1527120.5000, 1525234.2500, 1521683.3750, 1521423.6250, 1519651.5000,
         1516116.6250, 1514368.1250, 1513224.7500, 1512483.1250, 1511773.7500],
        [1372913.0000, 1317722.5000, 1298748.8750, 1284837.7500, 1281329.6250,
         1253513.5000, 1241288.0000, 1228581.6250, 1221016.1250, 1199912.1250],
        [1516703.8750, 1516414.5000, 1515859.2500, 1509241.2500, 1505755.0000,
         1505477.7500, 1504170.5000, 1502332.5000, 1501609.1250, 1499835.8750],
        [1453364.8750, 1438168.0000, 1415825.5000, 1411052.3750, 1408680.5000,
         1403306.2500, 1397093.1250, 1394655.6250, 1391216.3750, 1389066.0000],
        [1513109.2500, 1511949.6250, 1510900.2500, 1508708.7500, 1507772.5000,
         1504546.3750, 1503424.6250, 1503344.3750, 1502569.0000, 1502374.0000],
        [1377955.2500, 1337344.3750, 1335483.6250, 1319470.3750, 1302216.5000,
         1269602.5000, 1262563.2500, 1259897.8750, 1258434.0000, 1258338.1250],
        [1550753.5000, 1550191.5000, 1548532.2500, 1547934.2500, 1547529.8750,
         1546821.7500, 1546159.3750, 1545655.2500, 1544286.5000, 1543253.0000],
        [1539657.1250, 1539250.5000, 1535999.5000, 1533210.0000, 1532888.3750,
         1531492.8750, 1531342.5000, 1531211.1250, 1530888.3750, 1530107.5000],
        [1532898.6250, 1531722.2500, 1529222.0000, 1526948.7500, 1526412.8750,
         1525042.1250, 1523953.2500, 1523544.8750, 1523340.0000, 1523212.1250],
        [1469944.3750, 1457270.3750, 1456123.0000, 1419134.7500, 1416764.1250,
         1416483.2500, 1412037.7500, 1407619.6250, 1407226.2500, 1397542.1250],
        [1307697.3750, 1306398.5000, 1303823.2500, 1302096.1250, 1288508.0000,
         1280108.2500, 1277973.5000, 1276090.7500, 1268029.5000, 1267958.2500],
        [1297304.2500,  982943.0625,  948483.7500,  946849.7500,  888225.1250,
          858286.3125,  845071.6875,  843864.4375,  840689.1875,  819699.8125],
        [1234671.7500, 1120369.0000, 1118330.2500, 1098192.1250, 1076360.7500,
         1029552.6875,  996864.6250,  992156.6250,  987727.0000,  964132.5000],
        [1446523.0000, 1433716.1250, 1433024.5000, 1421513.2500, 1410551.8750,
         1409567.5000, 1405628.8750, 1403649.0000, 1400716.3750, 1397580.8750],
        [1480735.8750, 1472349.1250, 1467770.2500, 1463433.1250, 1447951.5000,
         1447792.7500, 1445162.0000, 1444678.3750, 1444644.0000, 1443798.2500],
        [1467703.0000, 1460508.1250, 1457709.6250, 1454753.0000, 1450357.6250,
         1449255.7500, 1444638.3750, 1443715.7500, 1442971.0000, 1442212.8750],
        [1409047.3750, 1408084.2500, 1393157.5000, 1391806.8750, 1380599.2500,
         1379121.3750, 1362032.7500, 1356564.8750, 1347735.6250, 1347139.3750],
        [1481754.3750, 1472469.8750, 1468208.5000, 1451057.6250, 1445694.1250,
         1434131.7500, 1429340.6250, 1400876.7500, 1400379.8750, 1398432.7500],
        [1406287.2500, 1386125.6250, 1383653.2500, 1360857.7500, 1317520.1250,
         1316408.6250, 1307068.8750, 1290863.2500, 1290530.8750, 1288399.7500],
        [1460141.7500, 1453678.2500, 1452325.7500, 1436746.5000, 1436257.3750,
         1435778.1250, 1434836.3750, 1434735.1250, 1434609.1250, 1432980.6250],
        [1485543.6250, 1485113.0000, 1480120.3750, 1479342.8750, 1471955.8750,
         1471777.7500, 1471478.7500, 1469350.0000, 1467938.2500, 1461624.1250],
        [1414624.2500, 1406228.2500, 1386655.7500, 1355938.8750, 1351483.6250,
         1341309.0000, 1341055.8750, 1338969.0000, 1330571.3750, 1329451.5000],
        [1463258.7500, 1445603.2500, 1435675.3750, 1418314.8750, 1396010.2500,
         1364061.8750, 1357780.2500, 1355617.0000, 1331378.6250, 1316082.2500],
        [1485343.8750, 1467938.2500, 1445770.0000, 1442219.8750, 1438619.2500,
         1430381.0000, 1411076.6250, 1409321.5000, 1407766.0000, 1400838.1250],
        [1519264.7500, 1485324.1250, 1483937.8750, 1483148.3750, 1460673.7500,
         1437024.6250, 1431048.2500, 1423162.6250, 1422397.3750, 1421971.5000],
        [1387833.2500, 1378477.1250, 1376614.1250, 1362127.6250, 1352493.2500,
         1350313.8750, 1348480.0000, 1348202.2500, 1340438.3750, 1333322.7500],
        [1390268.1250, 1388192.0000, 1378282.5000, 1375811.0000, 1375494.7500,
         1373298.0000, 1368666.8750, 1367578.8750, 1365351.6250, 1364840.0000],
        [1453431.3750, 1448783.0000, 1426802.0000, 1424710.7500, 1417842.8750,
         1409353.7500, 1380850.7500, 1380777.0000, 1377407.3750, 1359515.1250],
        [1489775.7500, 1455781.3750, 1445538.3750, 1444412.6250, 1443832.7500,
         1441672.5000, 1440836.7500, 1438442.3750, 1412542.8750, 1411113.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1530411.1250,       0.0000],
         [1525516.5000,       0.0000],
         [1516165.7500,       0.0000],
         ...,
         [1513517.7500,       0.0000],
         [1510939.1250,       0.0000],
         [1509987.0000,       0.0000]],

        [[1540415.1250,       0.0000],
         [1533275.8750,       0.0000],
         [1532144.5000,       0.0000],
         ...,
         [1524412.6250,       0.0000],
         [1523125.1250,       0.0000],
         [1523000.1250,       0.0000]],

        [[1302920.8750,       0.0000],
         [1260203.1250,       0.0000],
         [      0.0000, 1212985.8750],
         ...,
         [1136296.6250,       0.0000],
         [1127714.2500,       0.0000],
         [1127393.7500,       0.0000]],

        ...,

        [[1390268.1250,       0.0000],
         [1388192.0000,       0.0000],
         [      0.0000, 1378282.5000],
         ...,
         [1367578.8750,       0.0000],
         [1365351.6250,       0.0000],
         [1364840.0000,       0.0000]],

        [[1453431.3750,       0.0000],
         [1448783.0000,       0.0000],
         [1426802.0000,       0.0000],
         ...,
         [1380777.0000,       0.0000],
         [      0.0000, 1377407.3750],
         [      0.0000, 1359515.1250]],

        [[      0.0000, 1489775.7500],
         [      0.0000, 1455781.3750],
         [      0.0000, 1445538.3750],
         ...,
         [      0.0000, 1438442.3750],
         [      0.0000, 1412542.8750],
         [      0.0000, 1411113.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13649169.0000,  1514688.7500],
        [15295346.0000,        0.0000],
        [ 9535182.0000,  2366570.2500],
        [14264133.0000,        0.0000],
        [ 9210588.0000,  3955693.0000],
        [10651824.0000,  1111663.0000],
        [ 3250185.2500,  7299640.5000],
        [10695732.0000,  1200016.2500],
        [15379563.0000,        0.0000],
        [10422176.0000,  2577246.0000],
        [15404716.0000,        0.0000],
        [14236094.0000,        0.0000],
        [14239446.0000,        0.0000],
        [15580465.0000,        0.0000],
        [15463356.0000,        0.0000],
        [15372232.0000,        0.0000],
        [14941509.0000,        0.0000],
        [10581562.0000,  4552037.5000],
        [13191876.0000,  1459031.0000],
        [13808500.0000,  1534866.2500],
        [15448182.0000,        0.0000],
        [11717322.0000,  2946326.5000],
        [15430376.0000,        0.0000],
        [15548218.0000,        0.0000],
        [ 8989018.0000,  5990150.0000],
        [15529076.0000,        0.0000],
        [15433790.0000,        0.0000],
        [15502175.0000,        0.0000],
        [15601742.0000,        0.0000],
        [15604344.0000,        0.0000],
        [15594481.0000,        0.0000],
        [15560582.0000,        0.0000],
        [ 3673849.0000,  8665874.0000],
        [12171757.0000,  3048224.2500],
        [13886027.0000,  1540704.3750],
        [ 9106821.0000,  6076259.0000],
        [ 6243148.0000,  6456715.0000],
        [ 9039523.0000,  6037877.0000],
        [11210896.0000,  2891533.0000],
        [13566130.0000,  1502569.0000],
        [10420655.0000,  2560650.5000],
        [15471118.0000,        0.0000],
        [15336048.0000,        0.0000],
        [12212935.0000,  3053361.5000],
        [ 2809580.0000, 11450566.0000],
        [ 7672256.5000,  5206427.0000],
        [ 4370854.5000,  4900563.0000],
        [       0.0000, 10618358.0000],
        [11319879.0000,  2842592.0000],
        [10141797.0000,  4416518.0000],
        [11595607.0000,  2918217.7500],
        [       0.0000, 13775289.0000],
        [       0.0000, 14382346.0000],
        [ 3896450.7500,  9451264.0000],
        [11525430.0000,  2886659.0000],
        [11793423.0000,  2950821.5000],
        [ 1330571.3750, 12265716.0000],
        [       0.0000, 13883782.0000],
        [       0.0000, 14339274.0000],
        [ 2854211.0000, 11713742.0000],
        [ 6835856.0000,  6742446.5000],
        [12369501.0000,  1378282.5000],
        [ 9961701.0000,  4117773.2500],
        [       0.0000, 14423948.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 176/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:57, 59.92s/it]  7%|▋         | 2/29 [01:00<11:20, 25.21s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.482473373413086
Epoch 177/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:39, 59.28s/it]  7%|▋         | 2/29 [01:00<11:13, 24.95s/it] 10%|█         | 3/29 [01:01<06:03, 13.98s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.82s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.46795392036438
Epoch 178/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.13s/it]  7%|▋         | 2/29 [01:01<11:23, 25.30s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.4648733139038086
Epoch 179/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:17, 60.63s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4590630531311035
Epoch 180/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:59, 59.99s/it]  7%|▋         | 2/29 [01:01<11:29, 25.55s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.4475622177124023
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0053, 0.0012,  ..., 0.0053, 0.0020, 0.0216],
        [0.0030, 0.0071, 0.0010,  ..., 0.0045, 0.0015, 0.0201],
        [0.0270, 0.0072, 0.0025,  ..., 0.0050, 0.0123, 0.0278],
        ...,
        [0.0039, 0.0071, 0.0134,  ..., 0.0042, 0.0019, 0.0259],
        [0.0021, 0.0099, 0.0039,  ..., 0.0039, 0.0017, 0.0216],
        [0.0091, 0.0075, 0.0020,  ..., 0.0022, 0.0033, 0.0217]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9967, 0.9966, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9854, 0.9838, 0.9826, 0.9805, 0.9803, 0.9764, 0.9760, 0.9759, 0.9757,
         0.9755],
        [0.9945, 0.9942, 0.9932, 0.9927, 0.9926, 0.9922, 0.9922, 0.9921, 0.9919,
         0.9916],
        [0.9876, 0.9875, 0.9868, 0.9864, 0.9862, 0.9860, 0.9858, 0.9856, 0.9848,
         0.9847],
        [0.9891, 0.9841, 0.9809, 0.9775, 0.9768, 0.9758, 0.9755, 0.9741, 0.9729,
         0.9695],
        [0.9733, 0.9730, 0.9714, 0.9698, 0.9694, 0.9674, 0.9672, 0.9668, 0.9667,
         0.9661],
        [0.9854, 0.9842, 0.9813, 0.9809, 0.9800, 0.9795, 0.9791, 0.9759, 0.9752,
         0.9751],
        [0.9978, 0.9978, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9935, 0.9877, 0.9860, 0.9859, 0.9858, 0.9854, 0.9854, 0.9852, 0.9848,
         0.9843],
        [0.9977, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9949, 0.9941, 0.9940, 0.9937, 0.9932, 0.9930, 0.9922, 0.9921, 0.9920,
         0.9908],
        [0.9947, 0.9939, 0.9938, 0.9936, 0.9936, 0.9933, 0.9925, 0.9920, 0.9917,
         0.9909],
        [0.9984, 0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9975, 0.9974, 0.9972, 0.9972, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9961, 0.9958, 0.9957, 0.9956, 0.9954, 0.9953, 0.9952, 0.9952, 0.9951,
         0.9949],
        [0.9967, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9961, 0.9958,
         0.9957],
        [0.9947, 0.9946, 0.9944, 0.9942, 0.9939, 0.9939, 0.9938, 0.9938, 0.9938,
         0.9938],
        [0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9980, 0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9955, 0.9948, 0.9947, 0.9945, 0.9943, 0.9943, 0.9942, 0.9941, 0.9939,
         0.9937],
        [0.9982, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9971,
         0.9969],
        [0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9978,
         0.9978],
        [0.9962, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9954],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9977, 0.9977, 0.9975, 0.9975, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9982, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9974],
        [0.9987, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9980],
        [0.9985, 0.9985, 0.9985, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9895, 0.9847, 0.9840, 0.9834, 0.9828, 0.9817, 0.9792, 0.9780, 0.9750,
         0.9742],
        [0.9969, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9963],
        [0.9978, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9887, 0.9864, 0.9859, 0.9851, 0.9830, 0.9813, 0.9805, 0.9797, 0.9792,
         0.9788],
        [0.9964, 0.9964, 0.9962, 0.9962, 0.9961, 0.9958, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9940, 0.9931, 0.9911, 0.9910, 0.9910, 0.9909, 0.9907, 0.9906, 0.9904,
         0.9904],
        [0.9964, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9896, 0.9874, 0.9870, 0.9866, 0.9844, 0.9839, 0.9837, 0.9831, 0.9829,
         0.9824],
        [0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9969, 0.9969, 0.9969, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9935, 0.9931, 0.9923, 0.9915, 0.9913, 0.9908, 0.9908, 0.9904, 0.9902,
         0.9902],
        [0.9863, 0.9862, 0.9861, 0.9860, 0.9856, 0.9850, 0.9850, 0.9841, 0.9840,
         0.9838],
        [0.9858, 0.9649, 0.9641, 0.9628, 0.9592, 0.9572, 0.9531, 0.9494, 0.9491,
         0.9473],
        [0.9813, 0.9746, 0.9746, 0.9722, 0.9711, 0.9681, 0.9673, 0.9669, 0.9659,
         0.9639],
        [0.9930, 0.9919, 0.9919, 0.9919, 0.9915, 0.9915, 0.9912, 0.9912, 0.9909,
         0.9909],
        [0.9944, 0.9943, 0.9942, 0.9942, 0.9934, 0.9934, 0.9934, 0.9933, 0.9933,
         0.9930],
        [0.9940, 0.9934, 0.9934, 0.9931, 0.9931, 0.9929, 0.9928, 0.9927, 0.9927,
         0.9924],
        [0.9905, 0.9904, 0.9897, 0.9894, 0.9891, 0.9888, 0.9881, 0.9878, 0.9877,
         0.9872],
        [0.9947, 0.9945, 0.9937, 0.9933, 0.9932, 0.9916, 0.9913, 0.9910, 0.9908,
         0.9903],
        [0.9908, 0.9907, 0.9904, 0.9899, 0.9867, 0.9865, 0.9864, 0.9860, 0.9855,
         0.9850],
        [0.9936, 0.9935, 0.9935, 0.9929, 0.9926, 0.9926, 0.9925, 0.9924, 0.9924,
         0.9924],
        [0.9948, 0.9947, 0.9945, 0.9945, 0.9943, 0.9942, 0.9940, 0.9939, 0.9934,
         0.9934],
        [0.9915, 0.9914, 0.9901, 0.9889, 0.9885, 0.9878, 0.9876, 0.9873, 0.9872,
         0.9866],
        [0.9930, 0.9928, 0.9924, 0.9907, 0.9894, 0.9883, 0.9877, 0.9874, 0.9860,
         0.9858],
        [0.9947, 0.9940, 0.9926, 0.9926, 0.9923, 0.9919, 0.9915, 0.9908, 0.9905,
         0.9900],
        [0.9962, 0.9947, 0.9946, 0.9944, 0.9938, 0.9921, 0.9915, 0.9914, 0.9913,
         0.9912],
        [0.9900, 0.9899, 0.9895, 0.9894, 0.9883, 0.9881, 0.9879, 0.9879, 0.9878,
         0.9877],
        [0.9889, 0.9888, 0.9881, 0.9879, 0.9879, 0.9877, 0.9873, 0.9872, 0.9872,
         0.9872],
        [0.9931, 0.9929, 0.9920, 0.9920, 0.9915, 0.9912, 0.9890, 0.9889, 0.9886,
         0.9883],
        [0.9949, 0.9930, 0.9930, 0.9928, 0.9927, 0.9923, 0.9922, 0.9920, 0.9911,
         0.9908]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 0, 1, 0, 0, 1, 1, 1, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1533856.5000, 1527151.1250, 1524427.1250, 1520041.5000, 1518127.7500,
         1517990.2500, 1517451.8750, 1517363.5000, 1515908.5000, 1514385.5000],
        [1538509.3750, 1532309.6250, 1530849.0000, 1528484.2500, 1527154.0000,
         1524716.5000, 1524149.5000, 1523871.8750, 1522724.1250, 1522378.7500],
        [1298665.8750, 1269211.6250, 1248014.6250, 1210487.3750, 1207967.6250,
         1141850.8750, 1135878.5000, 1134289.3750, 1131326.0000, 1128041.1250],
        [1480299.6250, 1472674.8750, 1453083.5000, 1441433.2500, 1439460.6250,
         1431494.6250, 1430607.5000, 1430042.7500, 1425466.3750, 1418583.8750],
        [1340347.5000, 1338594.8750, 1324442.6250, 1316941.1250, 1313312.6250,
         1310725.1250, 1306647.6250, 1302286.0000, 1287193.8750, 1286585.0000],
        [1370123.1250, 1274608.1250, 1217349.0000, 1160538.3750, 1149158.2500,
         1133195.1250, 1127840.0000, 1104984.0000, 1085836.7500, 1035470.6250],
        [1092306.3750, 1088777.6250, 1063949.6250, 1039394.5000, 1033619.6875,
         1004186.0000, 1001868.2500,  995564.9375,  994364.6250,  986410.0625],
        [1299942.1250, 1276851.6250, 1224338.1250, 1218376.7500, 1202417.3750,
         1193576.7500, 1186556.0000, 1134015.7500, 1122338.8750, 1120961.1250],
        [1551519.7500, 1550216.7500, 1544775.5000, 1544005.2500, 1543242.6250,
         1543008.6250, 1542317.2500, 1540338.7500, 1540219.7500, 1537212.8750],
        [1457502.6250, 1342676.0000, 1310235.1250, 1309289.6250, 1306535.5000,
         1299938.5000, 1298517.2500, 1295026.1250, 1288539.8750, 1277922.3750],
        [1548049.3750, 1543188.1250, 1542989.5000, 1542608.5000, 1540944.0000,
         1538695.7500, 1537588.2500, 1537567.7500, 1536918.2500, 1536493.2500],
        [1487805.0000, 1471515.2500, 1469189.0000, 1463385.6250, 1452924.2500,
         1447019.7500, 1431860.5000, 1428896.2500, 1427362.7500, 1403052.1250],
        [1482807.5000, 1466413.1250, 1464210.6250, 1461285.5000, 1461041.6250,
         1454323.0000, 1437108.2500, 1428107.5000, 1420729.8750, 1404413.5000],
        [1564784.8750, 1563605.0000, 1562326.0000, 1560500.3750, 1557831.3750,
         1557057.6250, 1557024.8750, 1556545.3750, 1554842.2500, 1554498.2500],
        [1550514.0000, 1549613.7500, 1548987.1250, 1548901.6250, 1548167.6250,
         1544205.3750, 1542258.3750, 1542226.0000, 1542193.6250, 1541661.3750],
        [1543464.8750, 1542315.7500, 1537396.1250, 1537273.0000, 1533960.2500,
         1533716.1250, 1533052.1250, 1531967.6250, 1531791.0000, 1530532.2500],
        [1514288.7500, 1506295.0000, 1504742.8750, 1502829.7500, 1498795.0000,
         1496809.5000, 1495240.0000, 1493299.2500, 1492514.6250, 1488175.3750],
        [1527299.6250, 1522696.6250, 1521872.0000, 1520261.7500, 1520024.1250,
         1517453.2500, 1517074.1250, 1514283.0000, 1506704.3750, 1504232.1250],
        [1484522.5000, 1481890.1250, 1477502.8750, 1473609.1250, 1467509.8750,
         1465894.3750, 1464815.5000, 1463976.1250, 1463817.0000, 1463691.3750],
        [1540679.5000, 1536276.3750, 1536103.5000, 1534593.8750, 1533929.6250,
         1533669.2500, 1532144.5000, 1532018.7500, 1531805.5000, 1531329.2500],
        [1554682.0000, 1553652.0000, 1548656.3750, 1547279.1250, 1545210.1250,
         1544704.7500, 1543509.0000, 1542499.6250, 1541188.0000, 1540980.7500],
        [1500651.5000, 1485620.1250, 1483946.3750, 1480364.6250, 1475357.0000,
         1474475.0000, 1473569.8750, 1470855.8750, 1467424.5000, 1462085.6250],
        [1558693.2500, 1542968.8750, 1541136.6250, 1540813.2500, 1540803.0000,
         1540540.0000, 1539999.3750, 1538519.7500, 1534623.2500, 1530087.1250],
        [1559984.1250, 1558733.5000, 1558641.2500, 1558061.7500, 1556497.8750,
         1555625.2500, 1555385.0000, 1552584.0000, 1551402.8750, 1549854.6250],
        [1515002.2500, 1509832.8750, 1508011.1250, 1506504.6250, 1506055.1250,
         1504741.3750, 1502783.8750, 1500821.7500, 1499858.8750, 1498969.3750],
        [1555881.8750, 1554401.8750, 1554065.3750, 1552757.2500, 1552621.0000,
         1552615.1250, 1551917.7500, 1551583.3750, 1550577.5000, 1549931.3750],
        [1549152.7500, 1548425.8750, 1545127.6250, 1544718.0000, 1540312.2500,
         1539915.7500, 1539278.5000, 1538764.7500, 1538346.6250, 1537663.0000],
        [1558831.6250, 1556079.2500, 1552695.0000, 1550959.1250, 1549176.2500,
         1548502.6250, 1547503.3750, 1546233.2500, 1543891.8750, 1542991.0000],
        [1570524.2500, 1563652.6250, 1561931.3750, 1560766.8750, 1560485.6250,
         1559732.7500, 1559676.2500, 1556566.1250, 1556521.6250, 1556223.2500],
        [1566197.3750, 1565552.2500, 1565425.2500, 1560429.0000, 1559472.5000,
         1559063.5000, 1558791.5000, 1557907.2500, 1557391.7500, 1556831.8750],
        [1564352.2500, 1562557.0000, 1561713.8750, 1560429.0000, 1559993.1250,
         1559750.5000, 1558354.5000, 1558284.6250, 1557755.7500, 1557388.7500],
        [1559200.3750, 1558315.8750, 1558171.6250, 1556055.6250, 1555503.6250,
         1555175.7500, 1553909.7500, 1553410.3750, 1552757.2500, 1552304.2500],
        [1376811.1250, 1285515.6250, 1272874.6250, 1263220.8750, 1251823.1250,
         1232162.6250, 1188790.7500, 1168817.6250, 1119800.7500, 1106305.2500],
        [1531430.1250, 1527088.5000, 1525395.7500, 1524739.7500, 1524328.2500,
         1523919.8750, 1523335.6250, 1522377.1250, 1520994.2500, 1518463.6250],
        [1549795.3750, 1547385.2500, 1545252.8750, 1543835.8750, 1542530.5000,
         1541210.0000, 1541210.0000, 1540710.3750, 1539721.7500, 1538424.2500],
        [1531491.5000, 1529397.0000, 1526504.5000, 1524739.7500, 1524688.8750,
         1523530.3750, 1520480.7500, 1519664.6250, 1519086.5000, 1518659.1250],
        [1362269.2500, 1316815.5000, 1308623.0000, 1292648.3750, 1254725.1250,
         1225452.6250, 1211074.0000, 1197818.7500, 1188115.2500, 1183000.3750],
        [1520276.3750, 1519613.8750, 1516812.2500, 1516313.3750, 1514073.5000,
         1507141.2500, 1506757.6250, 1504434.3750, 1503136.5000, 1503054.7500],
        [1467855.6250, 1449750.5000, 1409931.8750, 1407394.1250, 1406884.1250,
         1404984.2500, 1401950.0000, 1399522.7500, 1395193.1250, 1394754.0000],
        [1519406.7500, 1507864.5000, 1505987.5000, 1505562.5000, 1504486.0000,
         1503277.0000, 1500940.5000, 1500535.5000, 1499659.8750, 1499529.7500],
        [1378507.2500, 1336320.6250, 1329744.3750, 1322017.1250, 1280394.0000,
         1272282.5000, 1267031.0000, 1256558.3750, 1252589.8750, 1244405.2500],
        [1548553.0000, 1547538.7500, 1547389.6250, 1546795.1250, 1545529.8750,
         1545161.5000, 1545114.3750, 1543707.7500, 1542139.2500, 1542012.7500],
        [1536434.7500, 1536269.0000, 1534292.3750, 1532799.1250, 1531323.5000,
         1531030.0000, 1529491.8750, 1529414.5000, 1529102.5000, 1528988.7500],
        [1531482.6250, 1530484.0000, 1530338.1250, 1526565.7500, 1526392.5000,
         1526190.1250, 1523528.8750, 1523372.0000, 1522457.0000, 1521532.5000],
        [1458965.6250, 1450937.2500, 1432980.6250, 1416715.6250, 1413921.6250,
         1403679.8750, 1403259.5000, 1395138.5000, 1391996.6250, 1390444.3750],
        [1316705.0000, 1313516.7500, 1312271.1250, 1310543.8750, 1302576.7500,
         1292539.7500, 1290804.1250, 1274808.6250, 1273202.5000, 1269061.3750],
        [1306609.0000,  969469.1875,  958393.8125,  940321.1875,  892857.1250,
          868793.6875,  818880.1875,  776759.6250,  772983.5000,  753467.5625],
        [1225722.5000, 1112953.0000, 1112583.6250, 1075197.3750, 1058347.2500,
         1013948.7500, 1002935.1875,  997043.3750,  982710.5625,  956116.1250],
        [1447645.0000, 1426217.0000, 1425879.6250, 1425692.1250, 1417026.2500,
         1416903.3750, 1411131.7500, 1411028.1250, 1405573.8750, 1405368.8750],
        [1478264.0000, 1474127.8750, 1473538.8750, 1473242.3750, 1457034.1250,
         1456042.5000, 1455709.2500, 1454970.8750, 1454361.8750, 1448376.8750],
        [1468938.1250, 1455621.8750, 1455383.0000, 1450937.2500, 1450637.1250,
         1445913.3750, 1442975.1250, 1441221.6250, 1440916.6250, 1436583.3750],
        [1397161.0000, 1395791.8750, 1381990.2500, 1375219.2500, 1370127.0000,
         1363006.0000, 1350376.8750, 1343694.2500, 1341978.3750, 1333021.5000],
        [1483945.0000, 1479404.8750, 1462494.1250, 1454927.8750, 1451273.6250,
         1419975.3750, 1413382.2500, 1407728.3750, 1403255.5000, 1393828.5000],
        [1402804.5000, 1401690.6250, 1394515.8750, 1384474.2500, 1323392.2500,
         1319574.7500, 1316978.7500, 1310628.7500, 1300712.2500, 1291979.1250],
        [1460081.8750, 1457529.0000, 1457374.7500, 1446169.8750, 1440500.1250,
         1440002.8750, 1438607.0000, 1436264.2500, 1435178.5000, 1434884.2500],
        [1486002.6250, 1483354.8750, 1479697.0000, 1479632.0000, 1474731.0000,
         1472072.5000, 1467952.2500, 1466295.5000, 1456750.7500, 1456614.6250],
        [1417091.1250, 1415297.6250, 1389877.0000, 1366569.6250, 1356923.3750,
         1343568.7500, 1341147.8750, 1334900.5000, 1332317.3750, 1321038.0000],
        [1448491.5000, 1444885.0000, 1436688.8750, 1401007.6250, 1375992.0000,
         1353861.1250, 1343133.1250, 1336851.0000, 1311001.3750, 1305974.8750],
        [1483073.5000, 1469271.6250, 1440512.5000, 1439662.3750, 1432949.2500,
         1425790.0000, 1416764.1250, 1404193.8750, 1397892.6250, 1386436.2500],
        [1516303.2500, 1484426.2500, 1481210.3750, 1477794.5000, 1465061.3750,
         1429136.1250, 1417461.6250, 1415863.2500, 1413620.8750, 1411479.0000],
        [1387355.6250, 1385674.8750, 1376981.8750, 1375100.0000, 1354185.2500,
         1350207.0000, 1346486.8750, 1345982.2500, 1344432.6250, 1342350.7500],
        [1365854.3750, 1363513.1250, 1350507.0000, 1347041.7500, 1346081.1250,
         1342848.8750, 1334211.8750, 1333601.2500, 1332730.3750, 1332006.0000],
        [1450418.5000, 1445994.7500, 1427512.3750, 1427139.5000, 1417594.0000,
         1410555.8750, 1367848.8750, 1365017.1250, 1359285.6250, 1354880.2500],
        [1487761.1250, 1448519.1250, 1448031.6250, 1444058.5000, 1442493.6250,
         1432969.7500, 1431180.7500, 1426747.5000, 1410148.2500, 1403820.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1533856.5000,       0.0000],
         [1527151.1250,       0.0000],
         [1524427.1250,       0.0000],
         ...,
         [1517363.5000,       0.0000],
         [1515908.5000,       0.0000],
         [1514385.5000,       0.0000]],

        [[1538509.3750,       0.0000],
         [1532309.6250,       0.0000],
         [1530849.0000,       0.0000],
         ...,
         [1523871.8750,       0.0000],
         [1522724.1250,       0.0000],
         [1522378.7500,       0.0000]],

        [[1298665.8750,       0.0000],
         [1269211.6250,       0.0000],
         [1248014.6250,       0.0000],
         ...,
         [1134289.3750,       0.0000],
         [1131326.0000,       0.0000],
         [1128041.1250,       0.0000]],

        ...,

        [[1365854.3750,       0.0000],
         [1363513.1250,       0.0000],
         [      0.0000, 1350507.0000],
         ...,
         [1333601.2500,       0.0000],
         [1332730.3750,       0.0000],
         [1332006.0000,       0.0000]],

        [[1450418.5000,       0.0000],
         [1445994.7500,       0.0000],
         [1427512.3750,       0.0000],
         ...,
         [1365017.1250,       0.0000],
         [      0.0000, 1359285.6250],
         [      0.0000, 1354880.2500]],

        [[      0.0000, 1487761.1250],
         [      0.0000, 1448519.1250],
         [      0.0000, 1448031.6250],
         ...,
         [      0.0000, 1426747.5000],
         [      0.0000, 1410148.2500],
         [      0.0000, 1403820.2500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13688713.0000,  1517990.2500],
        [15275146.0000,        0.0000],
        [10695245.0000,  1210487.3750],
        [14423147.0000,        0.0000],
        [ 9205324.0000,  3921752.5000],
        [10573267.0000,  1085836.7500],
        [ 3130112.0000,  7170330.0000],
        [10785798.0000,  1193576.7500],
        [15436857.0000,        0.0000],
        [10554967.0000,  2631216.0000],
        [15405043.0000,        0.0000],
        [14483010.0000,        0.0000],
        [14480440.0000,        0.0000],
        [15589017.0000,        0.0000],
        [15458730.0000,        0.0000],
        [15355468.0000,        0.0000],
        [14992990.0000,        0.0000],
        [10612314.0000,  4559587.0000],
        [13243412.0000,  1463817.0000],
        [13810406.0000,  1532144.5000],
        [15462363.0000,        0.0000],
        [11804784.0000,  2969566.5000],
        [15408185.0000,        0.0000],
        [15556770.0000,        0.0000],
        [ 9025449.0000,  6027132.5000],
        [15526352.0000,        0.0000],
        [15421705.0000,        0.0000],
        [15496864.0000,        0.0000],
        [15606081.0000,        0.0000],
        [15607063.0000,        0.0000],
        [15600580.0000,        0.0000],
        [15554804.0000,        0.0000],
        [ 4763445.0000,  7502677.5000],
        [12186315.0000,  3055758.5000],
        [13889367.0000,  1540710.3750],
        [12182342.0000,  3055901.5000],
        [ 6077186.0000,  6463356.5000],
        [12075188.0000,  3036426.0000],
        [11220615.0000,  2917606.0000],
        [13543973.0000,  1503277.0000],
        [10402897.0000,  2536952.5000],
        [15453942.0000,        0.0000],
        [15319146.0000,        0.0000],
        [12209385.0000,  3052958.2500],
        [ 1403679.8750, 12754360.0000],
        [ 7710960.0000,  5245069.5000],
        [ 4883742.0000,  4174793.2500],
        [       0.0000, 10537558.0000],
        [12766248.0000,  1426217.0000],
        [10199738.0000,  4425931.0000],
        [11578123.0000,  2911005.0000],
        [       0.0000, 13652366.0000],
        [       0.0000, 14370216.0000],
        [ 3912266.2500,  9534485.0000],
        [10109956.0000,  4336636.0000],
        [11768740.0000,  2954363.0000],
        [ 1321038.0000, 12297694.0000],
        [       0.0000, 13757886.0000],
        [       0.0000, 14296546.0000],
        [ 1413620.8750, 13098736.0000],
        [ 6844666.5000,  6764090.0000],
        [12097889.0000,  1350507.0000],
        [ 9944232.0000,  4082015.0000],
        [       0.0000, 14375730.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 67.1875
Top1 accuracy for validation set is 67.1875 size is torch.Size([64, 1])
Epoch 181/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.79s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4515721797943115
Epoch 182/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:04, 60.18s/it]  7%|▋         | 2/29 [01:01<11:30, 25.58s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4393928050994873
Epoch 183/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.79s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.4267942905426025
Epoch 184/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:32, 61.17s/it]  7%|▋         | 2/29 [01:02<11:34, 25.73s/it] 10%|█         | 3/29 [01:03<06:14, 14.40s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.01it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.4201955795288086
Epoch 185/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.71s/it]  7%|▋         | 2/29 [01:01<11:48, 26.24s/it] 10%|█         | 3/29 [01:02<06:21, 14.68s/it] 14%|█▍        | 4/29 [01:03<03:51,  9.25s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.25s/it] 21%|██        | 6/29 [01:05<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.408655881881714
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0058, 0.0012,  ..., 0.0054, 0.0018, 0.0205],
        [0.0032, 0.0074, 0.0009,  ..., 0.0045, 0.0016, 0.0199],
        [0.0273, 0.0077, 0.0025,  ..., 0.0049, 0.0125, 0.0290],
        ...,
        [0.0034, 0.0065, 0.0151,  ..., 0.0038, 0.0016, 0.0260],
        [0.0021, 0.0096, 0.0043,  ..., 0.0036, 0.0017, 0.0220],
        [0.0088, 0.0076, 0.0021,  ..., 0.0020, 0.0035, 0.0213]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9969, 0.9967, 0.9967, 0.9964, 0.9964, 0.9964, 0.9964, 0.9962, 0.9962,
         0.9961],
        [0.9973, 0.9970, 0.9968, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9850, 0.9826, 0.9817, 0.9810, 0.9806, 0.9761, 0.9759, 0.9756, 0.9753,
         0.9752],
        [0.9949, 0.9943, 0.9933, 0.9930, 0.9927, 0.9924, 0.9922, 0.9920, 0.9918,
         0.9918],
        [0.9878, 0.9875, 0.9874, 0.9872, 0.9870, 0.9865, 0.9864, 0.9862, 0.9851,
         0.9847],
        [0.9890, 0.9846, 0.9816, 0.9786, 0.9783, 0.9750, 0.9749, 0.9744, 0.9742,
         0.9707],
        [0.9746, 0.9728, 0.9715, 0.9701, 0.9692, 0.9686, 0.9664, 0.9663, 0.9659,
         0.9658],
        [0.9859, 0.9834, 0.9806, 0.9800, 0.9794, 0.9788, 0.9783, 0.9759, 0.9755,
         0.9747],
        [0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9933, 0.9874, 0.9864, 0.9863, 0.9855, 0.9853, 0.9847, 0.9846, 0.9845,
         0.9841],
        [0.9977, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9949, 0.9939, 0.9937, 0.9936, 0.9932, 0.9931, 0.9917, 0.9917, 0.9915,
         0.9913],
        [0.9945, 0.9940, 0.9934, 0.9931, 0.9930, 0.9929, 0.9927, 0.9908, 0.9908,
         0.9899],
        [0.9984, 0.9984, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9962, 0.9960, 0.9957, 0.9956, 0.9956, 0.9953, 0.9952, 0.9952, 0.9951,
         0.9951],
        [0.9968, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9960, 0.9956,
         0.9955],
        [0.9946, 0.9945, 0.9942, 0.9941, 0.9938, 0.9938, 0.9937, 0.9937, 0.9937,
         0.9936],
        [0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9980, 0.9978, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9954, 0.9948, 0.9947, 0.9946, 0.9941, 0.9941, 0.9940, 0.9940, 0.9939,
         0.9937],
        [0.9982, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972,
         0.9970],
        [0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9978,
         0.9978],
        [0.9962, 0.9960, 0.9958, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954,
         0.9953],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9978, 0.9978, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9982, 0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9975],
        [0.9987, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9984, 0.9984, 0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9984, 0.9984, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9896, 0.9843, 0.9839, 0.9826, 0.9819, 0.9818, 0.9792, 0.9779, 0.9752,
         0.9738],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9963],
        [0.9978, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9972],
        [0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9887, 0.9866, 0.9863, 0.9861, 0.9824, 0.9812, 0.9809, 0.9804, 0.9791,
         0.9790],
        [0.9963, 0.9963, 0.9961, 0.9961, 0.9961, 0.9958, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9932, 0.9928, 0.9913, 0.9911, 0.9909, 0.9906, 0.9904, 0.9904, 0.9904,
         0.9903],
        [0.9963, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9900, 0.9878, 0.9875, 0.9874, 0.9848, 0.9841, 0.9840, 0.9836, 0.9829,
         0.9828],
        [0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9971, 0.9971, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9969, 0.9968, 0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9935, 0.9931, 0.9924, 0.9916, 0.9913, 0.9909, 0.9907, 0.9907, 0.9907,
         0.9903],
        [0.9867, 0.9863, 0.9859, 0.9858, 0.9853, 0.9852, 0.9851, 0.9847, 0.9846,
         0.9843],
        [0.9867, 0.9672, 0.9669, 0.9649, 0.9585, 0.9580, 0.9538, 0.9510, 0.9487,
         0.9475],
        [0.9798, 0.9741, 0.9738, 0.9717, 0.9702, 0.9671, 0.9669, 0.9666, 0.9643,
         0.9642],
        [0.9930, 0.9921, 0.9921, 0.9919, 0.9917, 0.9914, 0.9913, 0.9912, 0.9910,
         0.9910],
        [0.9944, 0.9940, 0.9940, 0.9939, 0.9934, 0.9932, 0.9931, 0.9930, 0.9930,
         0.9928],
        [0.9939, 0.9934, 0.9933, 0.9933, 0.9931, 0.9929, 0.9926, 0.9926, 0.9925,
         0.9923],
        [0.9903, 0.9903, 0.9897, 0.9893, 0.9891, 0.9887, 0.9883, 0.9880, 0.9875,
         0.9874],
        [0.9949, 0.9949, 0.9936, 0.9935, 0.9933, 0.9915, 0.9914, 0.9911, 0.9904,
         0.9903],
        [0.9913, 0.9907, 0.9905, 0.9904, 0.9869, 0.9869, 0.9866, 0.9859, 0.9855,
         0.9853],
        [0.9938, 0.9937, 0.9936, 0.9934, 0.9933, 0.9930, 0.9929, 0.9925, 0.9925,
         0.9923],
        [0.9948, 0.9947, 0.9945, 0.9945, 0.9943, 0.9940, 0.9936, 0.9936, 0.9933,
         0.9931],
        [0.9917, 0.9916, 0.9903, 0.9892, 0.9886, 0.9877, 0.9874, 0.9874, 0.9873,
         0.9865],
        [0.9929, 0.9929, 0.9927, 0.9903, 0.9890, 0.9884, 0.9875, 0.9873, 0.9869,
         0.9863],
        [0.9947, 0.9943, 0.9931, 0.9927, 0.9921, 0.9918, 0.9918, 0.9907, 0.9903,
         0.9899],
        [0.9963, 0.9949, 0.9946, 0.9944, 0.9940, 0.9922, 0.9914, 0.9912, 0.9911,
         0.9908],
        [0.9904, 0.9902, 0.9899, 0.9891, 0.9884, 0.9884, 0.9884, 0.9883, 0.9881,
         0.9879],
        [0.9895, 0.9891, 0.9888, 0.9881, 0.9878, 0.9876, 0.9875, 0.9874, 0.9874,
         0.9873],
        [0.9934, 0.9933, 0.9928, 0.9923, 0.9918, 0.9917, 0.9897, 0.9896, 0.9892,
         0.9888],
        [0.9951, 0.9934, 0.9930, 0.9930, 0.9929, 0.9919, 0.9918, 0.9918, 0.9911,
         0.9910]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 1, 0, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 0, 1, 1, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1531931.2500, 1526474.0000, 1525887.5000, 1519580.6250, 1519370.3750,
         1519289.3750, 1519167.5000, 1515935.8750, 1515169.8750, 1513428.2500],
        [1538820.5000, 1532138.6250, 1529376.6250, 1525395.7500, 1523988.2500,
         1523547.7500, 1522046.1250, 1521033.2500, 1520753.3750, 1520408.2500],
        [1292109.6250, 1247748.0000, 1232826.7500, 1219537.0000, 1212547.5000,
         1138098.1250, 1133798.3750, 1128876.2500, 1124595.2500, 1122231.8750],
        [1486864.5000, 1475382.3750, 1453579.7500, 1448423.7500, 1441728.8750,
         1434876.0000, 1432279.8750, 1427375.0000, 1424397.0000, 1424000.2500],
        [1344174.8750, 1339103.1250, 1335845.3750, 1332102.6250, 1329260.0000,
         1320419.6250, 1318108.3750, 1313782.3750, 1292986.1250, 1287020.6250],
        [1368321.1250, 1284844.0000, 1230060.0000, 1177981.5000, 1173117.0000,
         1119363.0000, 1118115.8750, 1109985.0000, 1106729.3750, 1052368.8750],
        [1113261.8750, 1084868.0000, 1064502.7500, 1044605.5625, 1030995.0625,
         1022293.0625,  990104.5625,  989152.3125,  983515.0000,  981839.3750],
        [1307512.7500, 1261754.3750, 1212112.7500, 1203117.1250, 1193081.6250,
         1182149.8750, 1173410.1250, 1134163.8750, 1128189.6250, 1114679.1250],
        [1550843.6250, 1549857.5000, 1545867.5000, 1545521.1250, 1543933.0000,
         1543036.6250, 1542359.8750, 1541118.8750, 1540274.1250, 1539786.3750],
        [1454177.3750, 1336379.2500, 1317064.1250, 1315078.6250, 1300187.6250,
         1296912.1250, 1285480.0000, 1284601.3750, 1281605.8750, 1275487.3750],
        [1547717.2500, 1542654.1250, 1541973.1250, 1539864.2500, 1539751.1250,
         1538863.0000, 1538236.5000, 1538103.0000, 1537215.7500, 1536077.1250],
        [1487729.8750, 1466774.0000, 1461863.8750, 1460563.7500, 1452134.6250,
         1450899.8750, 1421918.6250, 1421717.8750, 1417959.1250, 1413344.6250],
        [1479744.8750, 1469788.7500, 1455878.6250, 1450215.1250, 1447211.6250,
         1446354.7500, 1442841.6250, 1402917.0000, 1402301.7500, 1384869.1250],
        [1564373.1250, 1563945.0000, 1559264.2500, 1558237.0000, 1556952.2500,
         1556860.1250, 1555708.3750, 1554868.8750, 1553832.7500, 1552854.8750],
        [1551629.2500, 1549504.3750, 1546716.8750, 1546658.0000, 1546292.1250,
         1541658.3750, 1541630.5000, 1541236.5000, 1539924.5000, 1539485.3750],
        [1539695.3750, 1537982.6250, 1534295.3750, 1533482.0000, 1532838.7500,
         1532685.2500, 1532525.8750, 1531444.7500, 1531116.1250, 1531104.5000],
        [1515216.0000, 1512142.8750, 1504430.1250, 1501947.1250, 1501795.2500,
         1496512.5000, 1495234.3750, 1493877.3750, 1492983.0000, 1491899.8750],
        [1528092.2500, 1520276.3750, 1519492.2500, 1518654.8750, 1517589.2500,
         1517537.2500, 1517501.0000, 1512288.5000, 1502822.6250, 1501299.8750],
        [1481876.0000, 1480246.0000, 1473731.3750, 1470785.7500, 1464041.7500,
         1463706.7500, 1463129.0000, 1462198.5000, 1461886.1250, 1461306.3750],
        [1540034.6250, 1537397.6250, 1537371.2500, 1535342.0000, 1534816.3750,
         1531403.8750, 1531252.0000, 1530195.1250, 1530183.3750, 1530087.1250],
        [1555843.3750, 1551484.2500, 1548036.1250, 1547559.3750, 1544482.3750,
         1544114.2500, 1543899.2500, 1542427.5000, 1540660.3750, 1540579.5000],
        [1498740.6250, 1485233.3750, 1484474.3750, 1481695.0000, 1471205.2500,
         1470909.1250, 1469193.1250, 1468477.3750, 1466993.6250, 1462823.3750],
        [1560512.3750, 1546324.6250, 1543915.3750, 1543576.7500, 1542920.3750,
         1541937.7500, 1540476.8750, 1540221.1250, 1537397.6250, 1532333.0000],
        [1560418.7500, 1559325.1250, 1558901.5000, 1557645.7500, 1557075.5000,
         1556894.2500, 1554687.8750, 1553626.6250, 1550243.2500, 1550034.8750],
        [1516093.5000, 1510898.7500, 1506481.7500, 1503515.0000, 1503360.1250,
         1502921.5000, 1501212.5000, 1500006.0000, 1499243.8750, 1496377.0000],
        [1556085.2500, 1554701.2500, 1554569.3750, 1554498.2500, 1553837.1250,
         1553645.8750, 1552586.8750, 1551567.1250, 1551559.6250, 1550865.8750],
        [1550200.5000, 1549715.6250, 1547267.1250, 1544474.8750, 1543581.2500,
         1541818.6250, 1541574.6250, 1540184.5000, 1539997.8750, 1537872.7500],
        [1560167.1250, 1555527.3750, 1555042.3750, 1551875.0000, 1551127.6250,
         1549798.3750, 1549118.6250, 1548248.7500, 1547540.1250, 1544718.0000],
        [1570659.1250, 1564437.2500, 1562832.7500, 1562349.8750, 1561748.1250,
         1560827.8750, 1560324.8750, 1559090.2500, 1558503.1250, 1557902.7500],
        [1565216.2500, 1565202.8750, 1564716.2500, 1560789.1250, 1560405.2500,
         1559973.7500, 1559100.7500, 1558922.3750, 1557678.3750, 1556664.1250],
        [1564237.3750, 1564176.1250, 1563785.3750, 1561090.0000, 1560085.2500,
         1559422.0000, 1559007.1250, 1558803.2500, 1558651.7500, 1558443.6250],
        [1559325.1250, 1558715.6250, 1558708.2500, 1556941.7500, 1556500.8750,
         1556153.5000, 1553909.7500, 1553794.2500, 1552671.3750, 1552387.0000],
        [1379214.7500, 1278933.1250, 1271866.3750, 1248278.8750, 1236003.0000,
         1233809.0000, 1189246.6250, 1167874.0000, 1122892.5000, 1100599.3750],
        [1531008.1250, 1527800.7500, 1526664.7500, 1525034.8750, 1523633.5000,
         1522923.2500, 1522878.1250, 1522425.1250, 1520038.6250, 1517699.2500],
        [1549863.3750, 1546491.2500, 1545294.2500, 1542635.0000, 1542536.3750,
         1541659.7500, 1541160.0000, 1541160.0000, 1540275.5000, 1536508.0000],
        [1529960.1250, 1527478.8750, 1526535.1250, 1525237.1250, 1523576.8750,
         1522581.8750, 1521825.5000, 1520334.2500, 1520198.1250, 1518759.1250],
        [1361374.2500, 1321949.1250, 1316118.7500, 1311751.7500, 1244654.5000,
         1223360.0000, 1217469.6250, 1210005.0000, 1187640.6250, 1185859.1250],
        [1518946.0000, 1517297.0000, 1513416.7500, 1512878.5000, 1512620.2500,
         1506583.7500, 1504913.6250, 1502914.2500, 1501222.6250, 1500323.7500],
        [1451406.5000, 1444569.5000, 1413205.7500, 1410214.2500, 1404410.8750,
         1399701.6250, 1394977.5000, 1394726.1250, 1394619.6250, 1394075.8750],
        [1517790.3750, 1507283.6250, 1504974.0000, 1502500.1250, 1501185.3750,
         1500674.2500, 1500536.8750, 1500076.2500, 1499030.7500, 1498885.0000],
        [1386370.1250, 1344633.8750, 1338947.3750, 1336667.3750, 1288713.2500,
         1274909.6250, 1273583.7500, 1266349.7500, 1253939.1250, 1251579.5000],
        [1549771.8750, 1546786.2500, 1546463.2500, 1546410.2500, 1545385.5000,
         1544889.0000, 1543382.5000, 1542924.7500, 1541917.1250, 1541686.2500],
        [1535996.6250, 1535866.1250, 1535406.3750, 1533208.6250, 1532901.5000,
         1531200.8750, 1530028.7500, 1529685.8750, 1528980.0000, 1528430.2500],
        [1531104.5000, 1527990.2500, 1527965.5000, 1525357.8750, 1525139.6250,
         1522515.0000, 1522243.6250, 1520591.0000, 1520098.0000, 1519795.1250],
        [1459323.2500, 1450541.6250, 1436386.1250, 1420156.8750, 1413479.3750,
         1406100.8750, 1402020.8750, 1401075.8750, 1401029.1250, 1393934.8750],
        [1323033.7500, 1315101.1250, 1307590.0000, 1306614.0000, 1296525.0000,
         1295947.7500, 1293741.0000, 1285246.0000, 1283772.2500, 1278552.6250],
        [1324017.1250, 1001682.0000,  997528.4375,  968914.5625,  884915.7500,
          878771.5625,  827450.3125,  794685.6875,  769297.6250,  755429.5625],
        [1198407.1250, 1104709.0000, 1101000.3750, 1068027.2500, 1045881.5000,
         1000107.0000,  998035.6250,  992820.0625,  961434.8750,  959592.8125],
        [1447527.6250, 1429941.8750, 1429408.7500, 1424983.7500, 1422314.6250,
         1415482.5000, 1413627.6250, 1411924.6250, 1406799.6250, 1406783.6250],
        [1477033.7500, 1468950.7500, 1468187.5000, 1467125.1250, 1457021.6250,
         1452201.1250, 1450395.0000, 1448935.0000, 1447603.6250, 1443019.2500],
        [1467427.3750, 1456839.6250, 1454368.7500, 1453889.0000, 1449980.0000,
         1445330.2500, 1439692.6250, 1438943.1250, 1437052.0000, 1433842.0000],
        [1393928.2500, 1393246.5000, 1380784.8750, 1374367.1250, 1369658.0000,
         1362331.6250, 1353988.8750, 1348773.2500, 1339368.6250, 1336914.6250],
        [1488479.1250, 1487346.7500, 1460400.7500, 1457523.3750, 1453772.5000,
         1417494.0000, 1415089.7500, 1410230.3750, 1395571.0000, 1394114.3750],
        [1413050.7500, 1402118.5000, 1397628.7500, 1395433.8750, 1327953.7500,
         1326719.5000, 1322115.6250, 1307823.3750, 1300291.8750, 1297520.7500],
        [1463641.1250, 1461620.0000, 1460388.2500, 1456980.0000, 1453762.7500,
         1448017.7500, 1445636.3750, 1437657.8750, 1436713.6250, 1434245.2500],
        [1484937.3750, 1482953.3750, 1479555.8750, 1479148.1250, 1474489.1250,
         1468603.3750, 1461253.3750, 1460672.3750, 1454987.5000, 1450341.0000],
        [1421384.3750, 1418592.1250, 1393099.0000, 1372067.3750, 1360722.7500,
         1341539.3750, 1336055.6250, 1335845.3750, 1334457.5000, 1318893.0000],
        [1445723.1250, 1445628.0000, 1441573.5000, 1393120.1250, 1366739.1250,
         1355748.8750, 1338037.1250, 1335692.5000, 1326309.5000, 1316273.1250],
        [1483693.1250, 1475048.8750, 1449819.6250, 1441693.1250, 1429474.1250,
         1422762.2500, 1422447.6250, 1401361.8750, 1392497.2500, 1385318.1250],
        [1517907.6250, 1487704.2500, 1482160.0000, 1476881.5000, 1469669.6250,
         1432021.6250, 1415153.2500, 1410312.3750, 1408872.6250, 1403094.8750],
        [1394504.0000, 1391930.2500, 1385920.7500, 1369975.5000, 1356614.0000,
         1355707.5000, 1355516.0000, 1353162.8750, 1351062.2500, 1346678.2500],
        [1378122.1250, 1368584.7500, 1362731.7500, 1351008.1250, 1344754.5000,
         1339757.1250, 1338552.7500, 1336060.7500, 1335892.5000, 1334064.2500],
        [1455921.6250, 1454528.2500, 1443579.3750, 1434553.1250, 1423196.6250,
         1421685.3750, 1380612.3750, 1378792.6250, 1371053.7500, 1363683.3750],
        [1492326.8750, 1457160.7500, 1448828.6250, 1447792.7500, 1446619.6250,
         1425274.6250, 1424398.2500, 1423981.2500, 1409068.8750, 1407419.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1531931.2500,       0.0000],
         [1526474.0000,       0.0000],
         [1525887.5000,       0.0000],
         ...,
         [1515935.8750,       0.0000],
         [1515169.8750,       0.0000],
         [1513428.2500,       0.0000]],

        [[1538820.5000,       0.0000],
         [1532138.6250,       0.0000],
         [1529376.6250,       0.0000],
         ...,
         [1521033.2500,       0.0000],
         [1520753.3750,       0.0000],
         [1520408.2500,       0.0000]],

        [[1292109.6250,       0.0000],
         [1247748.0000,       0.0000],
         [1232826.7500,       0.0000],
         ...,
         [1128876.2500,       0.0000],
         [1124595.2500,       0.0000],
         [1122231.8750,       0.0000]],

        ...,

        [[1378122.1250,       0.0000],
         [1368584.7500,       0.0000],
         [1362731.7500,       0.0000],
         ...,
         [1336060.7500,       0.0000],
         [1335892.5000,       0.0000],
         [1334064.2500,       0.0000]],

        [[1455921.6250,       0.0000],
         [1454528.2500,       0.0000],
         [1443579.3750,       0.0000],
         ...,
         [1378792.6250,       0.0000],
         [      0.0000, 1371053.7500],
         [      0.0000, 1363683.3750]],

        [[      0.0000, 1492326.8750],
         [      0.0000, 1457160.7500],
         [      0.0000, 1448828.6250],
         ...,
         [      0.0000, 1423981.2500],
         [      0.0000, 1409068.8750],
         [      0.0000, 1407419.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13686864.0000,  1519370.3750],
        [15257509.0000,        0.0000],
        [10639821.0000,  1212547.5000],
        [14448909.0000,        0.0000],
        [ 9255222.0000,  3957580.5000],
        [10630902.0000,  1109985.0000],
        [ 3126096.5000,  7179041.0000],
        [10728021.0000,  1182149.8750],
        [15442598.0000,        0.0000],
        [10525993.0000,  2620980.5000],
        [15400455.0000,        0.0000],
        [14454906.0000,        0.0000],
        [12997254.0000,  1384869.1250],
        [15576896.0000,        0.0000],
        [15444736.0000,        0.0000],
        [15337170.0000,        0.0000],
        [15006038.0000,        0.0000],
        [10600188.0000,  4555366.5000],
        [14682908.0000,        0.0000],
        [13807888.0000,  1530195.1250],
        [15459087.0000,        0.0000],
        [11790038.0000,  2969707.7500],
        [15429616.0000,        0.0000],
        [15558854.0000,        0.0000],
        [ 9023832.0000,  6016278.0000],
        [15533916.0000,        0.0000],
        [15436688.0000,        0.0000],
        [15513164.0000,        0.0000],
        [15618676.0000,        0.0000],
        [15608668.0000,        0.0000],
        [15607701.0000,        0.0000],
        [15559108.0000,        0.0000],
        [ 4738428.0000,  7490290.0000],
        [10662586.0000,  4577519.5000],
        [13885923.0000,  1541659.7500],
        [10663714.0000,  4572773.0000],
        [ 6083129.5000,  6497053.0000],
        [12060941.0000,  3030175.5000],
        [11205932.0000,  2895976.0000],
        [13532400.0000,  1500536.8750],
        [10475401.0000,  2540292.7500],
        [15449617.0000,        0.0000],
        [15321704.0000,        0.0000],
        [12196851.0000,  3045949.0000],
        [ 1401029.1250, 12783020.0000],
        [ 6459604.0000,  6526520.0000],
        [ 4910550.5000,  4292142.0000],
        [       0.0000, 10430015.0000],
        [11379680.0000,  2829114.2500],
        [10167363.0000,  4413109.5000],
        [11566637.0000,  2910728.5000],
        [       0.0000, 13653362.0000],
        [       0.0000, 14380022.0000],
        [ 2608115.2500, 10882542.0000],
        [ 8695692.0000,  5802971.0000],
        [10292963.0000,  4403978.0000],
        [       0.0000, 13632657.0000],
        [       0.0000, 13764844.0000],
        [       0.0000, 14304116.0000],
        [ 1403094.8750, 13100683.0000],
        [ 6852594.5000,  6808477.0000],
        [12138521.0000,  1351008.1250],
        [10012257.0000,  4115349.5000],
        [       0.0000, 14382871.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 186/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:36, 59.17s/it]  7%|▋         | 2/29 [01:00<11:12, 24.91s/it] 10%|█         | 3/29 [01:01<06:02, 13.95s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.402062177658081
Epoch 187/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:34, 61.23s/it]  7%|▋         | 2/29 [01:02<11:44, 26.08s/it] 10%|█         | 3/29 [01:03<06:19, 14.59s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.19s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.21s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 3.3998560905456543
Epoch 188/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.62s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.3997182846069336
Epoch 189/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:45, 57.33s/it]  7%|▋         | 2/29 [01:00<11:31, 25.59s/it] 10%|█         | 3/29 [01:01<06:12, 14.33s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.11s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.384780168533325
Epoch 190/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:56, 59.87s/it]  7%|▋         | 2/29 [01:00<11:20, 25.20s/it] 10%|█         | 3/29 [01:01<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.3820271492004395
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0042, 0.0062, 0.0016,  ..., 0.0057, 0.0019, 0.0203],
        [0.0031, 0.0076, 0.0011,  ..., 0.0046, 0.0015, 0.0195],
        [0.0277, 0.0076, 0.0030,  ..., 0.0044, 0.0127, 0.0287],
        ...,
        [0.0036, 0.0066, 0.0186,  ..., 0.0039, 0.0014, 0.0248],
        [0.0023, 0.0098, 0.0058,  ..., 0.0036, 0.0012, 0.0217],
        [0.0088, 0.0083, 0.0027,  ..., 0.0018, 0.0037, 0.0204]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9969, 0.9966, 0.9964, 0.9963, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959,
         0.9958],
        [0.9973, 0.9969, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9849, 0.9831, 0.9814, 0.9806, 0.9805, 0.9782, 0.9777, 0.9776, 0.9766,
         0.9761],
        [0.9946, 0.9939, 0.9929, 0.9928, 0.9919, 0.9919, 0.9919, 0.9916, 0.9914,
         0.9909],
        [0.9875, 0.9874, 0.9871, 0.9866, 0.9863, 0.9860, 0.9860, 0.9857, 0.9851,
         0.9848],
        [0.9892, 0.9842, 0.9827, 0.9779, 0.9775, 0.9752, 0.9752, 0.9751, 0.9744,
         0.9703],
        [0.9751, 0.9745, 0.9732, 0.9720, 0.9717, 0.9694, 0.9691, 0.9686, 0.9676,
         0.9671],
        [0.9873, 0.9840, 0.9818, 0.9813, 0.9804, 0.9791, 0.9781, 0.9766, 0.9763,
         0.9758],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9971],
        [0.9930, 0.9872, 0.9870, 0.9865, 0.9853, 0.9852, 0.9849, 0.9846, 0.9844,
         0.9834],
        [0.9975, 0.9974, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9945, 0.9937, 0.9935, 0.9931, 0.9929, 0.9924, 0.9912, 0.9911, 0.9908,
         0.9907],
        [0.9940, 0.9939, 0.9927, 0.9924, 0.9923, 0.9923, 0.9917, 0.9895, 0.9894,
         0.9886],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9979, 0.9976, 0.9976, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9970, 0.9970,
         0.9969],
        [0.9960, 0.9959, 0.9957, 0.9956, 0.9955, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9966, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9957, 0.9955,
         0.9953],
        [0.9945, 0.9944, 0.9943, 0.9941, 0.9941, 0.9939, 0.9938, 0.9937, 0.9935,
         0.9934],
        [0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9980, 0.9978, 0.9977, 0.9975, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9950, 0.9946, 0.9945, 0.9944, 0.9940, 0.9939, 0.9939, 0.9936, 0.9935,
         0.9934],
        [0.9982, 0.9976, 0.9974, 0.9973, 0.9973, 0.9973, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9979,
         0.9977],
        [0.9960, 0.9959, 0.9956, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9977, 0.9977, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9971],
        [0.9982, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9986, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9981],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9900, 0.9842, 0.9834, 0.9818, 0.9817, 0.9812, 0.9805, 0.9791, 0.9761,
         0.9749],
        [0.9968, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9962],
        [0.9977, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9971],
        [0.9968, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9888, 0.9860, 0.9860, 0.9854, 0.9822, 0.9821, 0.9810, 0.9807, 0.9790,
         0.9789],
        [0.9960, 0.9960, 0.9959, 0.9959, 0.9957, 0.9956, 0.9954, 0.9954, 0.9953,
         0.9952],
        [0.9927, 0.9924, 0.9906, 0.9904, 0.9903, 0.9900, 0.9900, 0.9899, 0.9898,
         0.9897],
        [0.9961, 0.9958, 0.9956, 0.9955, 0.9955, 0.9955, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9899, 0.9879, 0.9875, 0.9874, 0.9848, 0.9843, 0.9841, 0.9837, 0.9834,
         0.9823],
        [0.9977, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9972, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9933, 0.9927, 0.9918, 0.9915, 0.9910, 0.9909, 0.9907, 0.9906, 0.9904,
         0.9900],
        [0.9856, 0.9856, 0.9855, 0.9851, 0.9850, 0.9847, 0.9844, 0.9839, 0.9837,
         0.9835],
        [0.9871, 0.9708, 0.9669, 0.9668, 0.9586, 0.9547, 0.9539, 0.9523, 0.9503,
         0.9475],
        [0.9780, 0.9729, 0.9726, 0.9710, 0.9687, 0.9668, 0.9648, 0.9647, 0.9633,
         0.9617],
        [0.9927, 0.9924, 0.9921, 0.9915, 0.9912, 0.9909, 0.9909, 0.9908, 0.9908,
         0.9907],
        [0.9942, 0.9939, 0.9938, 0.9938, 0.9934, 0.9933, 0.9929, 0.9928, 0.9927,
         0.9926],
        [0.9938, 0.9931, 0.9931, 0.9930, 0.9928, 0.9925, 0.9924, 0.9924, 0.9923,
         0.9921],
        [0.9900, 0.9897, 0.9894, 0.9889, 0.9887, 0.9880, 0.9876, 0.9875, 0.9871,
         0.9866],
        [0.9951, 0.9949, 0.9935, 0.9931, 0.9930, 0.9912, 0.9912, 0.9910, 0.9902,
         0.9893],
        [0.9913, 0.9907, 0.9907, 0.9898, 0.9873, 0.9870, 0.9870, 0.9858, 0.9857,
         0.9853],
        [0.9939, 0.9937, 0.9936, 0.9935, 0.9934, 0.9932, 0.9927, 0.9925, 0.9923,
         0.9923],
        [0.9943, 0.9942, 0.9942, 0.9942, 0.9940, 0.9933, 0.9931, 0.9931, 0.9930,
         0.9928],
        [0.9918, 0.9913, 0.9901, 0.9891, 0.9882, 0.9874, 0.9872, 0.9869, 0.9865,
         0.9860],
        [0.9927, 0.9926, 0.9924, 0.9894, 0.9878, 0.9877, 0.9868, 0.9863, 0.9860,
         0.9859],
        [0.9943, 0.9940, 0.9927, 0.9920, 0.9915, 0.9914, 0.9911, 0.9903, 0.9898,
         0.9892],
        [0.9960, 0.9948, 0.9944, 0.9941, 0.9939, 0.9920, 0.9912, 0.9909, 0.9906,
         0.9906],
        [0.9901, 0.9899, 0.9898, 0.9887, 0.9885, 0.9882, 0.9882, 0.9882, 0.9881,
         0.9879],
        [0.9887, 0.9879, 0.9876, 0.9870, 0.9862, 0.9862, 0.9857, 0.9856, 0.9854,
         0.9853],
        [0.9932, 0.9931, 0.9931, 0.9921, 0.9918, 0.9917, 0.9898, 0.9897, 0.9892,
         0.9889],
        [0.9948, 0.9932, 0.9929, 0.9927, 0.9927, 0.9916, 0.9915, 0.9913, 0.9909,
         0.9907]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 1, 1, 1, 1, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 0, 1, 0, 1, 1, 0, 1],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1531295.7500, 1524453.2500, 1521149.3750, 1517967.1250, 1514179.0000,
         1513434.0000, 1512457.2500, 1510823.8750, 1508444.1250, 1507656.0000],
        [1538851.2500, 1530252.0000, 1525647.2500, 1524699.0000, 1521300.2500,
         1520453.2500, 1520274.8750, 1519414.0000, 1519072.0000, 1518433.2500],
        [1290324.1250, 1256912.0000, 1226819.5000, 1213177.8750, 1210721.7500,
         1171708.2500, 1163093.5000, 1162444.7500, 1145642.5000, 1137395.0000],
        [1481276.8750, 1467035.6250, 1446662.2500, 1444746.0000, 1425664.8750,
         1425437.7500, 1424959.3750, 1419765.5000, 1416021.3750, 1405917.1250],
        [1338937.0000, 1336675.0000, 1330156.6250, 1321335.2500, 1315347.0000,
         1310350.1250, 1310250.1250, 1304997.5000, 1293515.2500, 1287890.0000],
        [1371170.1250, 1276992.7500, 1249375.7500, 1167813.8750, 1160269.5000,
         1122600.1250, 1122439.5000, 1121453.0000, 1109477.0000, 1047463.6250],
        [1122013.5000, 1112416.0000, 1091982.5000, 1072165.5000, 1068491.7500,
         1032914.1250, 1028984.3750, 1021454.9375, 1006663.6875, 1000124.1875],
        [1335482.3750, 1273896.0000, 1234250.3750, 1224607.8750, 1210200.0000,
         1187521.6250, 1169577.0000, 1145356.2500, 1140638.5000, 1132299.6250],
        [1548656.3750, 1546829.0000, 1543810.8750, 1541005.6250, 1540603.1250,
         1540118.2500, 1539228.5000, 1539021.6250, 1537909.3750, 1534932.0000],
        [1448527.5000, 1332374.5000, 1329004.0000, 1319566.1250, 1296543.6250,
         1296185.1250, 1289207.2500, 1284654.0000, 1281154.8750, 1262746.3750],
        [1545062.8750, 1541004.2500, 1538466.8750, 1537594.1250, 1537566.2500,
         1536222.2500, 1535142.8750, 1534942.2500, 1534732.8750, 1534317.2500],
        [1479142.5000, 1462048.0000, 1458905.7500, 1449577.7500, 1445039.3750,
         1435011.5000, 1410703.8750, 1408390.3750, 1402949.1250, 1400556.1250],
        [1468004.1250, 1465804.8750, 1442463.2500, 1436653.2500, 1434152.2500,
         1432764.7500, 1421835.8750, 1377770.0000, 1375597.0000, 1360595.5000],
        [1564158.3750, 1562135.3750, 1559857.6250, 1557253.6250, 1557172.0000,
         1553940.8750, 1553435.6250, 1553296.3750, 1553216.2500, 1552991.2500],
        [1553729.0000, 1546913.1250, 1546513.3750, 1546278.8750, 1545668.5000,
         1542093.6250, 1541968.6250, 1541524.6250, 1539428.2500, 1539271.1250],
        [1540742.7500, 1538741.1250, 1537548.6250, 1536422.8750, 1535691.8750,
         1535195.5000, 1534926.1250, 1533445.5000, 1532967.3750, 1530418.3750],
        [1512344.6250, 1508504.6250, 1504553.3750, 1502722.2500, 1501602.0000,
         1496769.5000, 1493973.0000, 1493138.1250, 1492736.7500, 1491476.0000],
        [1523534.7500, 1518174.1250, 1515169.8750, 1514262.7500, 1513728.5000,
         1513328.7500, 1511482.3750, 1504669.6250, 1500627.0000, 1497000.7500],
        [1479705.3750, 1476374.6250, 1475758.0000, 1471815.6250, 1470468.6250,
         1466466.1250, 1465589.6250, 1462060.5000, 1458036.5000, 1457335.7500],
        [1535795.8750, 1534236.8750, 1533445.5000, 1532885.3750, 1531904.8750,
         1528477.0000, 1527879.5000, 1527036.0000, 1526758.0000, 1526449.2500],
        [1554444.7500, 1551728.3750, 1547547.6250, 1544793.1250, 1542327.5000,
         1541817.1250, 1539908.3750, 1538487.3750, 1537710.0000, 1537542.7500],
        [1489659.2500, 1481933.8750, 1480282.7500, 1476761.8750, 1469856.0000,
         1466902.6250, 1465841.1250, 1461502.8750, 1458602.5000, 1456988.3750],
        [1560068.8750, 1546056.2500, 1541706.8750, 1540366.6250, 1540018.5000,
         1539495.7500, 1536307.1250, 1534320.2500, 1533546.3750, 1532998.0000],
        [1560728.1250, 1559179.5000, 1558574.5000, 1558418.3750, 1557613.1250,
         1556805.1250, 1556604.7500, 1556532.0000, 1553539.2500, 1549366.8750],
        [1511903.5000, 1508920.3750, 1502058.8750, 1499444.0000, 1499292.3750,
         1496825.1250, 1496652.3750, 1494882.1250, 1493222.2500, 1491862.8750],
        [1557281.8750, 1556306.3750, 1555092.7500, 1553102.3750, 1552772.0000,
         1552536.6250, 1551903.0000, 1551386.6250, 1550485.7500, 1550299.5000],
        [1549229.5000, 1549114.2500, 1545795.3750, 1545727.5000, 1543063.1250,
         1541733.3750, 1541185.1250, 1540836.7500, 1540437.1250, 1536266.1250],
        [1559747.6250, 1553272.6250, 1552005.1250, 1551488.6250, 1550317.3750,
         1548812.8750, 1547118.1250, 1546675.6250, 1546572.3750, 1543079.2500],
        [1569630.3750, 1563496.1250, 1562983.2500, 1562759.7500, 1562515.2500,
         1560927.6250, 1560909.7500, 1559743.2500, 1559204.8750, 1558134.6250],
        [1565594.0000, 1565296.8750, 1563602.0000, 1561094.3750, 1559889.0000,
         1559247.8750, 1559164.6250, 1558464.5000, 1557567.0000, 1556849.6250],
        [1564762.5000, 1562512.3750, 1562108.5000, 1560284.7500, 1558947.6250,
         1558005.2500, 1557791.3750, 1557224.0000, 1556921.0000, 1556497.8750],
        [1560019.7500, 1558749.8750, 1557791.3750, 1557581.8750, 1556777.0000,
         1556373.1250, 1554504.1250, 1553929.0000, 1553286.0000, 1553044.6250],
        [1386628.1250, 1276285.5000, 1262836.6250, 1233110.1250, 1231766.7500,
         1222543.6250, 1211063.5000, 1186613.6250, 1136857.1250, 1117517.7500],
        [1528685.3750, 1524309.3750, 1523898.0000, 1523386.5000, 1522587.6250,
         1520852.1250, 1519450.1250, 1519015.5000, 1516868.6250, 1515633.7500],
        [1549569.2500, 1543965.3750, 1543921.2500, 1542477.6250, 1540535.5000,
         1540224.0000, 1540224.0000, 1539423.7500, 1538679.6250, 1535038.8750],
        [1528751.1250, 1525611.0000, 1523758.5000, 1522496.1250, 1520624.3750,
         1520060.3750, 1519371.8750, 1519001.0000, 1516954.0000, 1516777.5000],
        [1363093.1250, 1310585.0000, 1310253.8750, 1299602.6250, 1240350.7500,
         1239688.5000, 1219937.1250, 1215341.0000, 1184975.1250, 1183103.0000],
        [1512102.3750, 1511332.6250, 1509189.3750, 1508347.6250, 1504731.3750,
         1502511.6250, 1498743.5000, 1498366.1250, 1496417.0000, 1493582.5000],
        [1442658.6250, 1436601.2500, 1398554.1250, 1394711.5000, 1393056.3750,
         1388197.2500, 1388053.0000, 1385095.0000, 1384121.7500, 1381937.6250],
        [1514079.2500, 1506537.7500, 1503536.5000, 1500342.3750, 1500203.5000,
         1499714.3750, 1496909.3750, 1496770.8750, 1495806.2500, 1495769.2500],
        [1385146.5000, 1346051.6250, 1337673.5000, 1336731.1250, 1288073.0000,
         1279446.7500, 1274321.2500, 1267034.6250, 1261767.6250, 1243510.7500],
        [1548812.8750, 1544810.8750, 1543651.8750, 1543457.5000, 1543149.8750,
         1542371.6250, 1541384.8750, 1541089.5000, 1540895.5000, 1540628.0000],
        [1536720.3750, 1531919.5000, 1531487.1250, 1531455.0000, 1530167.2500,
         1530078.2500, 1529506.3750, 1527980.0000, 1527187.3750, 1526851.0000],
        [1527850.3750, 1525464.0000, 1525373.8750, 1523007.3750, 1521831.3750,
         1521280.0000, 1519512.3750, 1517288.2500, 1516372.6250, 1515431.5000],
        [1455263.6250, 1440935.7500, 1423170.7500, 1418074.0000, 1406353.0000,
         1404523.3750, 1400978.3750, 1400189.0000, 1395073.2500, 1386724.5000],
        [1303000.3750, 1302328.3750, 1301805.6250, 1293136.5000, 1292447.3750,
         1285279.0000, 1279760.3750, 1271460.1250, 1267544.6250, 1264948.3750],
        [1330480.1250, 1054778.3750,  996896.0000,  996122.4375,  885800.6875,
          837835.8750,  827848.1875,  809055.1875,  787164.0000,  756240.5000],
        [1169030.6250, 1087002.3750, 1081291.0000, 1057713.6250, 1023185.4375,
          995936.2500,  967865.3750,  966280.9375,  946888.6250,  925643.0625],
        [1441672.5000, 1435543.8750, 1428903.1250, 1417744.1250, 1411492.3750,
         1405417.1250, 1404384.0000, 1403658.3750, 1403133.7500, 1400251.7500],
        [1472297.1250, 1466256.3750, 1464945.3750, 1464914.6250, 1456289.6250,
         1453319.2500, 1445787.8750, 1443126.5000, 1442323.0000, 1440057.8750],
        [1465189.8750, 1450407.5000, 1449617.7500, 1447776.1250, 1443562.7500,
         1437718.2500, 1435993.1250, 1435990.3750, 1433716.1250, 1430033.2500],
        [1387306.6250, 1381953.3750, 1375307.2500, 1365497.6250, 1361482.1250,
         1348711.5000, 1340164.7500, 1338845.1250, 1331561.5000, 1320845.2500],
        [1491619.5000, 1488189.5000, 1458567.7500, 1449414.6250, 1447604.8750,
         1411998.6250, 1411184.2500, 1406438.8750, 1391274.7500, 1374143.0000],
        [1414196.6250, 1401009.0000, 1400795.2500, 1384078.2500, 1335558.7500,
         1329018.0000, 1328653.0000, 1305763.1250, 1304139.1250, 1297807.8750],
        [1465964.2500, 1462897.3750, 1460417.5000, 1459005.8750, 1455469.1250,
         1452277.2500, 1442351.8750, 1437063.0000, 1434361.6250, 1433537.0000],
        [1474347.1250, 1473952.1250, 1472444.6250, 1472081.0000, 1467815.1250,
         1454436.7500, 1449421.5000, 1449160.2500, 1448667.0000, 1442951.7500],
        [1424240.6250, 1412705.7500, 1390136.7500, 1369233.5000, 1351207.8750,
         1336918.3750, 1332026.3750, 1326809.2500, 1320025.3750, 1309775.5000],
        [1441524.0000, 1439194.2500, 1435585.0000, 1376362.1250, 1344232.6250,
         1342111.3750, 1325051.6250, 1316018.3750, 1310342.6250, 1309283.3750],
        [1475824.2500, 1467917.2500, 1441623.0000, 1427379.0000, 1417709.0000,
         1414310.0000, 1409500.2500, 1392725.7500, 1382467.3750, 1372177.3750],
        [1511540.1250, 1485107.3750, 1476701.3750, 1471233.1250, 1466076.0000,
         1428424.8750, 1411161.3750, 1404993.6250, 1399533.5000, 1399203.8750],
        [1388851.5000, 1384841.3750, 1384232.6250, 1361322.5000, 1357540.7500,
         1352075.3750, 1351464.3750, 1351233.6250, 1349495.0000, 1346937.6250],
        [1361756.1250, 1345393.2500, 1340968.8750, 1328978.6250, 1314872.8750,
         1313865.1250, 1304263.5000, 1303646.7500, 1299145.2500, 1296798.2500],
        [1451308.1250, 1449583.2500, 1449363.5000, 1428788.6250, 1424290.8750,
         1420465.6250, 1382805.0000, 1380923.1250, 1371883.0000, 1365763.2500],
        [1486433.6250, 1451965.7500, 1446578.1250, 1442757.7500, 1441221.6250,
         1418391.8750, 1416798.0000, 1413982.2500, 1405139.7500, 1401615.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1531295.7500,       0.0000],
         [1524453.2500,       0.0000],
         [1521149.3750,       0.0000],
         ...,
         [      0.0000, 1510823.8750],
         [1508444.1250,       0.0000],
         [1507656.0000,       0.0000]],

        [[1538851.2500,       0.0000],
         [1530252.0000,       0.0000],
         [1525647.2500,       0.0000],
         ...,
         [1519414.0000,       0.0000],
         [1519072.0000,       0.0000],
         [1518433.2500,       0.0000]],

        [[1290324.1250,       0.0000],
         [1256912.0000,       0.0000],
         [      0.0000, 1226819.5000],
         ...,
         [1162444.7500,       0.0000],
         [1145642.5000,       0.0000],
         [      0.0000, 1137395.0000]],

        ...,

        [[1361756.1250,       0.0000],
         [1345393.2500,       0.0000],
         [1340968.8750,       0.0000],
         ...,
         [1303646.7500,       0.0000],
         [1299145.2500,       0.0000],
         [1296798.2500,       0.0000]],

        [[1451308.1250,       0.0000],
         [1449583.2500,       0.0000],
         [1449363.5000,       0.0000],
         ...,
         [      0.0000, 1380923.1250],
         [      0.0000, 1371883.0000],
         [      0.0000, 1365763.2500]],

        [[      0.0000, 1486433.6250],
         [      0.0000, 1451965.7500],
         [      0.0000, 1446578.1250],
         ...,
         [      0.0000, 1413982.2500],
         [      0.0000, 1405139.7500],
         [      0.0000, 1401615.7500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13651035.0000,  1510823.8750],
        [15238397.0000,        0.0000],
        [ 9614025.0000,  2364214.5000],
        [14357488.0000,        0.0000],
        [ 9226409.0000,  3923044.0000],
        [10626455.0000,  1122600.1250],
        [ 2140657.2500,  8416553.0000],
        [10866308.0000,  1187521.6250],
        [15412115.0000,        0.0000],
        [10522935.0000,  2617028.5000],
        [15375052.0000,        0.0000],
        [14352324.0000,        0.0000],
        [12840043.0000,  1375597.0000],
        [15567457.0000,        0.0000],
        [15443390.0000,        0.0000],
        [15356100.0000,        0.0000],
        [14997820.0000,        0.0000],
        [10571064.0000,  4540915.0000],
        [13225574.0000,  1458036.5000],
        [13778420.0000,  1526449.2500],
        [15436306.0000,        0.0000],
        [11746115.0000,  2962216.5000],
        [15404885.0000,        0.0000],
        [15567362.0000,        0.0000],
        [ 9000235.0000,  5994829.0000],
        [15531167.0000,        0.0000],
        [15433388.0000,        0.0000],
        [15499089.0000,        0.0000],
        [15620305.0000,        0.0000],
        [15606769.0000,        0.0000],
        [15595055.0000,        0.0000],
        [15562057.0000,        0.0000],
        [ 3635686.0000,  8629537.0000],
        [10641762.0000,  4572924.0000],
        [13875380.0000,  1538679.6250],
        [12167151.0000,  3046254.5000],
        [ 6100292.5000,  6466637.5000],
        [12015644.0000,  3019680.2500],
        [ 8347667.0000,  5645319.5000],
        [15009669.0000,        0.0000],
        [10488173.0000,  2531583.7500],
        [15430252.0000,        0.0000],
        [15303353.0000,        0.0000],
        [12170749.0000,  3042662.0000],
        [ 1386724.5000, 12744561.0000],
        [ 6400533.0000,  6461178.0000],
        [ 4903944.5000,  4378277.0000],
        [       0.0000, 10220837.0000],
        [11343650.0000,  2808551.0000],
        [10145850.0000,  4403468.0000],
        [11538666.0000,  2891339.0000],
        [       0.0000, 13551675.0000],
        [       0.0000, 14330436.0000],
        [ 2603571.0000, 10897448.0000],
        [10132132.0000,  4371213.5000],
        [11663115.0000,  2942162.2500],
        [       0.0000, 13573079.0000],
        [ 1310342.6250, 12329362.0000],
        [       0.0000, 14201633.0000],
        [       0.0000, 14453976.0000],
        [ 6836585.5000,  6791409.0000],
        [10565837.0000,  2643851.5000],
        [10006605.0000,  4118569.5000],
        [       0.0000, 14324884.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 191/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:41, 57.18s/it]  7%|▋         | 2/29 [00:58<10:50, 24.09s/it] 10%|█         | 3/29 [00:59<05:51, 13.51s/it] 14%|█▍        | 4/29 [01:01<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:02<02:26,  6.12s/it] 21%|██        | 6/29 [01:03<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.50s/it] 31%|███       | 9/29 [01:05<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.36995005607605
Epoch 192/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:17, 60.63s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.358018398284912
Epoch 193/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.43s/it]  7%|▋         | 2/29 [01:00<11:15, 25.01s/it] 10%|█         | 3/29 [01:01<06:04, 14.01s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.84s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.3521857261657715
Epoch 194/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:26, 58.80s/it]  7%|▋         | 2/29 [00:59<11:12, 24.90s/it] 10%|█         | 3/29 [01:00<06:02, 13.95s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 3.3429243564605713
Epoch 195/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:02, 57.95s/it]  7%|▋         | 2/29 [00:58<10:58, 24.41s/it] 10%|█         | 3/29 [00:59<05:55, 13.68s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.64s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 3.3390121459960938
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0037, 0.0063, 0.0016,  ..., 0.0057, 0.0014, 0.0215],
        [0.0025, 0.0078, 0.0013,  ..., 0.0043, 0.0011, 0.0196],
        [0.0252, 0.0074, 0.0033,  ..., 0.0049, 0.0120, 0.0290],
        ...,
        [0.0032, 0.0067, 0.0199,  ..., 0.0038, 0.0012, 0.0239],
        [0.0023, 0.0100, 0.0062,  ..., 0.0031, 0.0010, 0.0217],
        [0.0082, 0.0084, 0.0033,  ..., 0.0015, 0.0035, 0.0202]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9971, 0.9969, 0.9965, 0.9965, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9961],
        [0.9976, 0.9973, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9843, 0.9842, 0.9829, 0.9817, 0.9807, 0.9804, 0.9793, 0.9779, 0.9775,
         0.9771],
        [0.9946, 0.9938, 0.9928, 0.9925, 0.9923, 0.9922, 0.9922, 0.9919, 0.9915,
         0.9914],
        [0.9883, 0.9877, 0.9860, 0.9857, 0.9855, 0.9855, 0.9855, 0.9852, 0.9848,
         0.9846],
        [0.9893, 0.9834, 0.9822, 0.9767, 0.9765, 0.9755, 0.9735, 0.9730, 0.9724,
         0.9678],
        [0.9744, 0.9742, 0.9741, 0.9727, 0.9689, 0.9685, 0.9679, 0.9669, 0.9664,
         0.9661],
        [0.9883, 0.9844, 0.9834, 0.9821, 0.9807, 0.9785, 0.9781, 0.9778, 0.9777,
         0.9767],
        [0.9979, 0.9978, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972,
         0.9971],
        [0.9932, 0.9876, 0.9871, 0.9871, 0.9857, 0.9852, 0.9850, 0.9846, 0.9841,
         0.9839],
        [0.9978, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9972],
        [0.9948, 0.9944, 0.9940, 0.9937, 0.9932, 0.9928, 0.9926, 0.9923, 0.9915,
         0.9913],
        [0.9943, 0.9941, 0.9932, 0.9929, 0.9928, 0.9923, 0.9921, 0.9904, 0.9900,
         0.9900],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9963, 0.9961, 0.9960, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954,
         0.9954],
        [0.9966, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961, 0.9957, 0.9957,
         0.9956],
        [0.9949, 0.9949, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9942, 0.9941,
         0.9939],
        [0.9976, 0.9974, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9980, 0.9980, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9954, 0.9953, 0.9950, 0.9949, 0.9949, 0.9949, 0.9943, 0.9943, 0.9943,
         0.9941],
        [0.9982, 0.9975, 0.9974, 0.9974, 0.9972, 0.9971, 0.9971, 0.9971, 0.9969,
         0.9969],
        [0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9980],
        [0.9963, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955,
         0.9955],
        [0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9971],
        [0.9982, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9986, 0.9986, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9981],
        [0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9980],
        [0.9903, 0.9836, 0.9835, 0.9814, 0.9812, 0.9808, 0.9804, 0.9798, 0.9744,
         0.9742],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9979, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9970, 0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9883, 0.9859, 0.9853, 0.9847, 0.9831, 0.9819, 0.9812, 0.9806, 0.9789,
         0.9780],
        [0.9962, 0.9961, 0.9959, 0.9959, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9928, 0.9918, 0.9912, 0.9907, 0.9905, 0.9902, 0.9900, 0.9900, 0.9895,
         0.9894],
        [0.9963, 0.9961, 0.9959, 0.9958, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9897, 0.9873, 0.9872, 0.9866, 0.9845, 0.9839, 0.9834, 0.9833, 0.9832,
         0.9826],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970,
         0.9970],
        [0.9969, 0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9964,
         0.9964],
        [0.9933, 0.9923, 0.9915, 0.9915, 0.9915, 0.9907, 0.9905, 0.9904, 0.9903,
         0.9899],
        [0.9862, 0.9860, 0.9853, 0.9851, 0.9844, 0.9843, 0.9840, 0.9840, 0.9837,
         0.9836],
        [0.9872, 0.9718, 0.9670, 0.9663, 0.9565, 0.9544, 0.9540, 0.9537, 0.9490,
         0.9471],
        [0.9775, 0.9736, 0.9711, 0.9688, 0.9687, 0.9674, 0.9646, 0.9641, 0.9640,
         0.9615],
        [0.9932, 0.9923, 0.9920, 0.9917, 0.9915, 0.9913, 0.9912, 0.9911, 0.9910,
         0.9909],
        [0.9944, 0.9943, 0.9940, 0.9940, 0.9939, 0.9936, 0.9936, 0.9933, 0.9933,
         0.9932],
        [0.9940, 0.9934, 0.9933, 0.9930, 0.9930, 0.9928, 0.9928, 0.9926, 0.9926,
         0.9924],
        [0.9896, 0.9894, 0.9892, 0.9888, 0.9883, 0.9878, 0.9875, 0.9873, 0.9870,
         0.9859],
        [0.9949, 0.9949, 0.9932, 0.9929, 0.9928, 0.9911, 0.9909, 0.9907, 0.9904,
         0.9897],
        [0.9916, 0.9909, 0.9908, 0.9896, 0.9875, 0.9871, 0.9871, 0.9860, 0.9856,
         0.9853],
        [0.9942, 0.9942, 0.9939, 0.9938, 0.9936, 0.9935, 0.9930, 0.9928, 0.9927,
         0.9927],
        [0.9948, 0.9945, 0.9944, 0.9944, 0.9942, 0.9939, 0.9937, 0.9936, 0.9933,
         0.9932],
        [0.9921, 0.9912, 0.9902, 0.9893, 0.9878, 0.9875, 0.9871, 0.9867, 0.9867,
         0.9861],
        [0.9931, 0.9927, 0.9922, 0.9899, 0.9881, 0.9880, 0.9867, 0.9866, 0.9864,
         0.9852],
        [0.9941, 0.9938, 0.9926, 0.9916, 0.9914, 0.9911, 0.9909, 0.9905, 0.9900,
         0.9891],
        [0.9961, 0.9948, 0.9944, 0.9941, 0.9938, 0.9920, 0.9914, 0.9911, 0.9908,
         0.9908],
        [0.9898, 0.9896, 0.9893, 0.9887, 0.9882, 0.9881, 0.9880, 0.9878, 0.9876,
         0.9876],
        [0.9884, 0.9875, 0.9871, 0.9868, 0.9857, 0.9855, 0.9854, 0.9851, 0.9850,
         0.9849],
        [0.9933, 0.9930, 0.9929, 0.9923, 0.9917, 0.9916, 0.9897, 0.9894, 0.9893,
         0.9885],
        [0.9945, 0.9934, 0.9929, 0.9928, 0.9921, 0.9915, 0.9913, 0.9911, 0.9908,
         0.9907]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 1, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1535198.3750, 1530422.7500, 1523274.7500, 1522444.0000, 1520276.3750,
         1518621.5000, 1516161.5000, 1515216.0000, 1515048.5000, 1513919.0000],
        [1545967.7500, 1538984.8750, 1530704.5000, 1526559.8750, 1525878.7500,
         1525381.1250, 1524870.5000, 1523755.6250, 1523297.8750, 1523087.3750],
        [1278905.0000, 1276908.8750, 1253979.7500, 1231305.1250, 1214795.2500,
         1210348.8750, 1190513.0000, 1166362.3750, 1160186.3750, 1154437.2500],
        [1482476.7500, 1464606.0000, 1444106.7500, 1438682.3750, 1433058.5000,
         1431485.0000, 1431246.2500, 1426104.1250, 1416685.8750, 1414729.5000],
        [1353959.2500, 1342928.1250, 1309874.1250, 1304383.0000, 1301168.8750,
         1301113.0000, 1301095.6250, 1294667.8750, 1287790.5000, 1283840.7500],
        [1373995.0000, 1263311.2500, 1240902.1250, 1146579.1250, 1143956.7500,
         1128384.3750, 1095319.0000, 1087522.8750, 1079154.3750, 1010709.6875],
        [1110361.8750, 1107614.2500, 1105860.0000, 1083782.1250, 1025901.7500,
         1021077.0000, 1012098.5625,  997640.6875,  990115.9375,  985384.2500],
        [1353467.5000, 1281515.3750, 1263301.5000, 1240063.3750, 1215042.0000,
         1177823.1250, 1170253.0000, 1164838.3750, 1163369.6250, 1147161.0000],
        [1553871.2500, 1550034.8750, 1546534.0000, 1544620.7500, 1542268.7500,
         1541595.2500, 1540470.8750, 1539984.6250, 1537104.3750, 1536345.2500],
        [1453064.2500, 1341023.8750, 1331504.3750, 1330044.8750, 1304995.1250,
         1295329.8750, 1292272.3750, 1284363.7500, 1275761.0000, 1271809.3750],
        [1550389.7500, 1547197.8750, 1543866.8750, 1543275.0000, 1542743.8750,
         1541884.7500, 1541533.3750, 1541211.5000, 1541210.0000, 1538594.5000],
        [1486488.8750, 1477452.1250, 1469296.8750, 1463529.5000, 1451640.3750,
         1443666.1250, 1439858.8750, 1433207.5000, 1417988.8750, 1413398.5000],
        [1475928.3750, 1470123.7500, 1452317.5000, 1445123.5000, 1444265.1250,
         1434575.0000, 1428689.1250, 1395734.6250, 1387644.0000, 1387640.0000],
        [1566464.7500, 1563290.3750, 1561289.3750, 1560441.0000, 1560356.1250,
         1559186.8750, 1558776.6250, 1555914.6250, 1555813.6250, 1554222.5000],
        [1558347.0000, 1552535.1250, 1551081.8750, 1551000.5000, 1548418.6250,
         1548030.2500, 1547597.8750, 1546600.3750, 1545636.0000, 1545518.1250],
        [1545227.7500, 1544548.7500, 1543981.6250, 1542089.2500, 1541617.2500,
         1541287.8750, 1540375.3750, 1539764.3750, 1539473.7500, 1538524.0000],
        [1518297.1250, 1514571.7500, 1510589.1250, 1506922.8750, 1504632.3750,
         1504008.2500, 1503487.7500, 1500431.0000, 1499017.8750, 1498932.2500],
        [1524547.7500, 1520952.1250, 1519222.6250, 1518217.5000, 1517573.3750,
         1514947.3750, 1513634.6250, 1505594.1250, 1504738.6250, 1502842.6250],
        [1488467.7500, 1488020.7500, 1486374.0000, 1485216.3750, 1484328.5000,
         1483188.0000, 1482902.3750, 1474102.5000, 1471445.0000, 1465886.0000],
        [1545366.3750, 1542464.3750, 1542142.1250, 1542012.7500, 1540188.7500,
         1538585.7500, 1537167.3750, 1536680.8750, 1536568.0000, 1536140.2500],
        [1556037.7500, 1554169.1250, 1551721.0000, 1547165.3750, 1547106.3750,
         1546923.5000, 1546469.1250, 1545456.2500, 1544142.1250, 1544127.5000],
        [1499605.6250, 1496982.1250, 1490998.1250, 1488530.2500, 1487636.1250,
         1487219.1250, 1476027.0000, 1475566.7500, 1475507.6250, 1470850.2500],
        [1560136.0000, 1544563.3750, 1541193.8750, 1540963.1250, 1537627.7500,
         1535885.2500, 1535623.0000, 1535125.2500, 1531183.2500, 1530447.5000],
        [1564210.5000, 1563338.1250, 1562429.0000, 1560953.0000, 1560344.1250,
         1560170.1250, 1559732.7500, 1559405.6250, 1556900.2500, 1556315.2500],
        [1518230.5000, 1507151.3750, 1506954.5000, 1505285.3750, 1504929.3750,
         1504678.2500, 1502540.2500, 1502230.7500, 1501460.2500, 1499791.5000],
        [1558298.0000, 1557578.8750, 1555847.8750, 1555164.0000, 1554441.7500,
         1553453.3750, 1553431.1250, 1553109.6250, 1550406.0000, 1550048.2500],
        [1549637.2500, 1546697.7500, 1544859.5000, 1544612.0000, 1543176.5000,
         1543173.5000, 1542609.8750, 1540716.2500, 1539917.1250, 1536169.3750],
        [1558764.6250, 1552949.7500, 1551504.8750, 1550891.1250, 1547214.1250,
         1547047.3750, 1546539.8750, 1546309.8750, 1542749.7500, 1542284.8750],
        [1569693.3750, 1565365.5000, 1565250.5000, 1565022.1250, 1564698.3750,
         1562135.3750, 1562081.7500, 1561667.6250, 1561090.0000, 1561019.8750],
        [1567711.0000, 1567633.3750, 1564549.2500, 1564015.1250, 1562338.0000,
         1562270.8750, 1561313.2500, 1561237.2500, 1559707.5000, 1559206.2500],
        [1565907.6250, 1563974.7500, 1563840.6250, 1561456.2500, 1561224.0000,
         1561051.2500, 1560947.0000, 1560414.1250, 1559175.1250, 1557893.8750],
        [1562151.7500, 1561597.6250, 1561538.1250, 1561308.7500, 1560655.2500,
         1559438.2500, 1558155.2500, 1557489.7500, 1557072.3750, 1555563.0000],
        [1392624.7500, 1265712.2500, 1264675.7500, 1227680.8750, 1222621.7500,
         1217149.2500, 1210280.7500, 1199555.1250, 1110932.7500, 1106258.7500],
        [1529917.8750, 1529152.0000, 1527579.2500, 1526864.1250, 1525481.5000,
         1524675.7500, 1524399.5000, 1523996.8750, 1522388.7500, 1522133.2500],
        [1552128.0000, 1547073.8750, 1545942.7500, 1545640.5000, 1545485.7500,
         1543245.5000, 1543245.5000, 1541480.5000, 1540798.5000, 1539597.0000],
        [1533935.5000, 1531513.3750, 1531122.1250, 1527154.0000, 1525823.3750,
         1525446.6250, 1524225.1250, 1524054.8750, 1523616.1250, 1523036.5000],
        [1354185.2500, 1308835.2500, 1296913.2500, 1285491.1250, 1257728.5000,
         1235674.1250, 1223598.1250, 1213595.5000, 1183412.1250, 1169262.5000],
        [1515788.5000, 1513558.1250, 1509414.0000, 1508950.5000, 1502392.6250,
         1501327.0000, 1500727.2500, 1498301.8750, 1497690.5000, 1496248.5000],
        [1443452.7500, 1424229.8750, 1410810.1250, 1400556.1250, 1396954.5000,
         1391787.0000, 1386963.8750, 1386347.7500, 1376535.5000, 1376280.7500],
        [1517583.5000, 1514667.1250, 1509638.5000, 1506675.7500, 1502859.8750,
         1501857.0000, 1501635.0000, 1500257.8750, 1499838.7500, 1498643.3750],
        [1380995.6250, 1334074.3750, 1333691.5000, 1320769.6250, 1283004.8750,
         1271460.1250, 1262729.5000, 1260492.7500, 1258967.0000, 1248770.7500],
        [1549903.3750, 1548722.7500, 1547861.8750, 1547583.0000, 1545335.5000,
         1544304.1250, 1542808.5000, 1542486.3750, 1542098.1250, 1541755.5000],
        [1541448.1250, 1539020.0000, 1538364.1250, 1537107.3750, 1537086.8750,
         1536713.0000, 1534416.7500, 1534374.5000, 1533935.5000, 1533916.3750],
        [1530994.8750, 1529904.7500, 1528647.5000, 1528466.7500, 1526725.8750,
         1524765.8750, 1524352.8750, 1523544.8750, 1520898.5000, 1520699.7500],
        [1454009.6250, 1434044.3750, 1417688.7500, 1417158.8750, 1416762.8750,
         1400498.7500, 1398123.3750, 1395776.0000, 1393576.0000, 1384870.5000],
        [1314747.5000, 1310611.3750, 1296802.0000, 1293211.7500, 1279839.6250,
         1279180.7500, 1273995.6250, 1273775.7500, 1267112.0000, 1266326.7500],
        [1333733.5000, 1070121.3750,  999008.8125,  989089.0625,  859153.5625,
          833789.8125,  828984.1875,  825692.4375,  771814.4375,  752109.1875],
        [1160181.0000, 1098234.0000, 1059734.0000, 1025454.6875, 1023154.2500,
         1004449.3750,  965259.5625,  957782.5625,  956771.0625,  923362.1875],
        [1451504.7500, 1433031.2500, 1428221.8750, 1420488.6250, 1417946.8750,
         1413591.2500, 1411602.8750, 1409969.5000, 1406599.8750, 1405025.8750],
        [1476507.0000, 1475801.7500, 1469361.2500, 1468805.0000, 1466417.3750,
         1460183.5000, 1459506.8750, 1453742.0000, 1453351.1250, 1452979.7500],
        [1469351.5000, 1455531.5000, 1455059.6250, 1449015.1250, 1448799.6250,
         1444134.2500, 1443226.8750, 1440801.1250, 1439647.3750, 1436201.2500],
        [1379817.3750, 1375317.7500, 1371769.1250, 1363878.5000, 1354783.2500,
         1345258.5000, 1339387.8750, 1335498.8750, 1328607.2500, 1308974.8750],
        [1487963.8750, 1487365.2500, 1452845.2500, 1446165.7500, 1443966.2500,
         1409868.6250, 1405741.5000, 1401090.5000, 1395899.7500, 1381282.7500],
        [1419546.1250, 1405651.7500, 1403974.3750, 1379342.3750, 1339203.8750,
         1331010.5000, 1330321.5000, 1309919.1250, 1303569.6250, 1296758.7500],
        [1473935.1250, 1472222.6250, 1467402.2500, 1463706.7500, 1460626.5000,
         1458548.2500, 1447211.6250, 1443370.1250, 1442654.5000, 1440827.1250],
        [1485855.3750, 1480309.5000, 1476880.2500, 1476801.3750, 1473949.2500,
         1466182.3750, 1463068.8750, 1460300.5000, 1455149.7500, 1452728.8750],
        [1430226.8750, 1411182.8750, 1390742.8750, 1372615.7500, 1344903.2500,
         1338859.1250, 1331644.1250, 1324073.8750, 1323950.1250, 1312179.6250],
        [1449637.1250, 1441701.3750, 1432260.6250, 1384333.0000, 1349549.1250,
         1348555.8750, 1322584.6250, 1322065.1250, 1318290.6250, 1295873.5000],
        [1471450.6250, 1465459.6250, 1439054.3750, 1419478.3750, 1414964.2500,
         1409499.0000, 1406181.3750, 1396953.2500, 1387200.7500, 1368677.5000],
        [1514025.8750, 1486600.8750, 1476349.3750, 1470423.8750, 1464896.5000,
         1428300.8750, 1415301.7500, 1408262.8750, 1403410.7500, 1403103.0000],
        [1382662.6250, 1379333.2500, 1373751.2500, 1361283.3750, 1352662.2500,
         1349332.8750, 1347745.8750, 1345217.5000, 1340722.1250, 1340470.2500],
        [1355535.5000, 1337836.7500, 1331913.2500, 1324457.8750, 1304478.6250,
         1301049.7500, 1298917.2500, 1293240.1250, 1291462.8750, 1289093.0000],
        [1454011.0000, 1447754.1250, 1445330.2500, 1433307.3750, 1420406.0000,
         1418446.0000, 1381389.3750, 1374605.6250, 1374055.1250, 1358525.0000],
        [1479327.2500, 1456495.1250, 1445492.8750, 1443200.7500, 1429489.1250,
         1417207.3750, 1413479.3750, 1410199.5000, 1402384.5000, 1401524.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1535198.3750,       0.0000],
         [1530422.7500,       0.0000],
         [1523274.7500,       0.0000],
         ...,
         [      0.0000, 1515216.0000],
         [1515048.5000,       0.0000],
         [1513919.0000,       0.0000]],

        [[1545967.7500,       0.0000],
         [1538984.8750,       0.0000],
         [1530704.5000,       0.0000],
         ...,
         [1523755.6250,       0.0000],
         [1523297.8750,       0.0000],
         [1523087.3750,       0.0000]],

        [[1278905.0000,       0.0000],
         [1276908.8750,       0.0000],
         [1253979.7500,       0.0000],
         ...,
         [1166362.3750,       0.0000],
         [1160186.3750,       0.0000],
         [1154437.2500,       0.0000]],

        ...,

        [[1355535.5000,       0.0000],
         [1337836.7500,       0.0000],
         [1331913.2500,       0.0000],
         ...,
         [1293240.1250,       0.0000],
         [1291462.8750,       0.0000],
         [      0.0000, 1289093.0000]],

        [[1454011.0000,       0.0000],
         [1447754.1250,       0.0000],
         [1445330.2500,       0.0000],
         ...,
         [      0.0000, 1374605.6250],
         [      0.0000, 1374055.1250],
         [1358525.0000,       0.0000]],

        [[      0.0000, 1479327.2500],
         [      0.0000, 1456495.1250],
         [      0.0000, 1445492.8750],
         ...,
         [      0.0000, 1410199.5000],
         [      0.0000, 1402384.5000],
         [      0.0000, 1401524.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13695366.0000,  1515216.0000],
        [15288488.0000,        0.0000],
        [ 9736880.0000,  2400862.0000],
        [14383182.0000,        0.0000],
        [ 9190766.0000,  3890055.0000],
        [10490680.0000,  1079154.3750],
        [ 3081360.2500,  7358476.0000],
        [11006582.0000,  1170253.0000],
        [13896486.0000,  1536345.2500],
        [10534150.0000,  2646019.0000],
        [15431906.0000,        0.0000],
        [14496528.0000,        0.0000],
        [14322040.0000,        0.0000],
        [15595756.0000,        0.0000],
        [15494766.0000,        0.0000],
        [15416890.0000,        0.0000],
        [15060891.0000,        0.0000],
        [10595471.0000,  4546799.5000],
        [14809931.0000,        0.0000],
        [15397316.0000,        0.0000],
        [15483318.0000,        0.0000],
        [11852335.0000,  2996587.7500],
        [15392748.0000,        0.0000],
        [15603798.0000,        0.0000],
        [ 9039345.0000,  6013906.0000],
        [15541778.0000,        0.0000],
        [15431570.0000,        0.0000],
        [15486256.0000,        0.0000],
        [15638025.0000,        0.0000],
        [15629982.0000,        0.0000],
        [15615884.0000,        0.0000],
        [15594970.0000,        0.0000],
        [ 3581215.2500,  8636277.0000],
        [10675407.0000,  4581181.5000],
        [13903839.0000,  1540798.5000],
        [12215190.0000,  3054738.2500],
        [ 6114008.0000,  6414687.0000],
        [12021890.0000,  3022508.5000],
        [ 8342317.5000,  5651601.0000],
        [15053658.0000,        0.0000],
        [11671952.0000,  1283004.8750],
        [15452860.0000,        0.0000],
        [15366383.0000,        0.0000],
        [12203654.0000,  3055347.7500],
        [ 1384870.5000, 12727639.0000],
        [ 3864226.7500,  8991376.0000],
        [ 4871543.5000,  4391953.0000],
        [  923362.1875,  9251021.0000],
        [14197983.0000,        0.0000],
        [10221982.0000,  4414673.0000],
        [11583953.0000,  2897814.7500],
        [       0.0000, 13503294.0000],
        [       0.0000, 14312190.0000],
        [ 2600328.5000, 10918970.0000],
        [10181956.0000,  4388549.0000],
        [10287746.0000,  4403479.5000],
        [ 1312179.6250, 12268198.0000],
        [ 1318290.6250, 12346560.0000],
        [       0.0000, 14178920.0000],
        [       0.0000, 14470676.0000],
        [ 6790099.5000,  6783082.0000],
        [ 9209956.0000,  3918029.5000],
        [11359169.0000,  2748660.7500],
        [       0.0000, 14298800.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 196/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:25, 56.63s/it]  7%|▋         | 2/29 [01:00<11:32, 25.64s/it] 10%|█         | 3/29 [01:01<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.3336126804351807
Epoch 197/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:24, 58.75s/it]  7%|▋         | 2/29 [00:59<11:07, 24.73s/it] 10%|█         | 3/29 [01:01<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.08s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.327799081802368
Epoch 198/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.65s/it]  7%|▋         | 2/29 [01:01<11:28, 25.52s/it] 10%|█         | 3/29 [01:02<06:11, 14.29s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.307194948196411
Epoch 199/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:55<26:04, 55.86s/it]  7%|▋         | 2/29 [00:56<10:36, 23.58s/it] 10%|█         | 3/29 [01:01<06:29, 14.99s/it] 14%|█▍        | 4/29 [01:02<03:56,  9.44s/it] 17%|█▋        | 5/29 [01:03<02:32,  6.37s/it] 21%|██        | 6/29 [01:04<01:43,  4.52s/it] 24%|██▍       | 7/29 [01:05<01:13,  3.34s/it] 28%|██▊       | 8/29 [01:06<00:54,  2.57s/it] 31%|███       | 9/29 [01:07<00:41,  2.06s/it] 34%|███▍      | 10/29 [01:08<00:32,  1.71s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.47s/it] 41%|████▏     | 12/29 [01:09<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.309573173522949
Epoch 200/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:21, 60.77s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.3089935779571533
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0037, 0.0071, 0.0016,  ..., 0.0059, 0.0013, 0.0213],
        [0.0022, 0.0083, 0.0016,  ..., 0.0041, 0.0009, 0.0192],
        [0.0260, 0.0073, 0.0033,  ..., 0.0053, 0.0121, 0.0286],
        ...,
        [0.0031, 0.0068, 0.0221,  ..., 0.0037, 0.0011, 0.0238],
        [0.0027, 0.0101, 0.0083,  ..., 0.0033, 0.0009, 0.0218],
        [0.0084, 0.0083, 0.0036,  ..., 0.0012, 0.0034, 0.0204]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9972, 0.9970, 0.9964, 0.9964, 0.9963, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9976, 0.9972, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9845, 0.9836, 0.9809, 0.9805, 0.9804, 0.9793, 0.9790, 0.9765, 0.9763,
         0.9758],
        [0.9942, 0.9937, 0.9927, 0.9924, 0.9923, 0.9921, 0.9921, 0.9920, 0.9919,
         0.9915],
        [0.9885, 0.9879, 0.9867, 0.9864, 0.9860, 0.9856, 0.9856, 0.9855, 0.9854,
         0.9854],
        [0.9891, 0.9831, 0.9821, 0.9773, 0.9768, 0.9758, 0.9754, 0.9754, 0.9727,
         0.9667],
        [0.9742, 0.9740, 0.9738, 0.9721, 0.9703, 0.9681, 0.9672, 0.9666, 0.9663,
         0.9660],
        [0.9884, 0.9845, 0.9831, 0.9820, 0.9811, 0.9789, 0.9774, 0.9769, 0.9767,
         0.9766],
        [0.9978, 0.9976, 0.9974, 0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970,
         0.9970],
        [0.9935, 0.9880, 0.9879, 0.9878, 0.9866, 0.9863, 0.9858, 0.9851, 0.9842,
         0.9840],
        [0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9948, 0.9943, 0.9942, 0.9940, 0.9931, 0.9926, 0.9926, 0.9923, 0.9914,
         0.9913],
        [0.9942, 0.9934, 0.9930, 0.9928, 0.9923, 0.9923, 0.9917, 0.9909, 0.9901,
         0.9895],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9981, 0.9981,
         0.9980],
        [0.9981, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9963, 0.9960, 0.9960, 0.9958, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952,
         0.9952],
        [0.9964, 0.9964, 0.9962, 0.9962, 0.9962, 0.9961, 0.9960, 0.9956, 0.9956,
         0.9954],
        [0.9950, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9946, 0.9943, 0.9939,
         0.9939],
        [0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9952, 0.9952, 0.9951, 0.9950, 0.9950, 0.9948, 0.9944, 0.9942, 0.9940,
         0.9940],
        [0.9982, 0.9976, 0.9974, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969,
         0.9968],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981,
         0.9980],
        [0.9960, 0.9958, 0.9956, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954,
         0.9951],
        [0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9973, 0.9973,
         0.9972],
        [0.9982, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9902, 0.9836, 0.9832, 0.9823, 0.9813, 0.9813, 0.9811, 0.9796, 0.9751,
         0.9734],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9978, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9972, 0.9969, 0.9969, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9883, 0.9867, 0.9857, 0.9851, 0.9816, 0.9812, 0.9805, 0.9789, 0.9788,
         0.9786],
        [0.9963, 0.9961, 0.9958, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9929, 0.9917, 0.9909, 0.9907, 0.9905, 0.9901, 0.9901, 0.9901, 0.9900,
         0.9900],
        [0.9963, 0.9962, 0.9960, 0.9960, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9894, 0.9872, 0.9868, 0.9865, 0.9846, 0.9841, 0.9832, 0.9828, 0.9828,
         0.9826],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9970, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9964],
        [0.9934, 0.9923, 0.9914, 0.9911, 0.9910, 0.9905, 0.9903, 0.9902, 0.9901,
         0.9897],
        [0.9862, 0.9859, 0.9857, 0.9852, 0.9841, 0.9841, 0.9839, 0.9839, 0.9836,
         0.9835],
        [0.9877, 0.9763, 0.9690, 0.9656, 0.9591, 0.9580, 0.9555, 0.9525, 0.9496,
         0.9487],
        [0.9778, 0.9741, 0.9713, 0.9700, 0.9696, 0.9678, 0.9671, 0.9650, 0.9644,
         0.9614],
        [0.9933, 0.9923, 0.9919, 0.9916, 0.9911, 0.9910, 0.9910, 0.9909, 0.9908,
         0.9908],
        [0.9944, 0.9944, 0.9941, 0.9940, 0.9939, 0.9937, 0.9936, 0.9933, 0.9933,
         0.9933],
        [0.9944, 0.9938, 0.9934, 0.9933, 0.9931, 0.9931, 0.9928, 0.9928, 0.9927,
         0.9926],
        [0.9894, 0.9894, 0.9892, 0.9888, 0.9883, 0.9878, 0.9872, 0.9872, 0.9868,
         0.9856],
        [0.9948, 0.9948, 0.9929, 0.9929, 0.9925, 0.9913, 0.9910, 0.9904, 0.9899,
         0.9891],
        [0.9918, 0.9912, 0.9904, 0.9892, 0.9881, 0.9872, 0.9868, 0.9859, 0.9858,
         0.9857],
        [0.9940, 0.9940, 0.9939, 0.9938, 0.9937, 0.9934, 0.9929, 0.9929, 0.9927,
         0.9926],
        [0.9947, 0.9946, 0.9945, 0.9944, 0.9942, 0.9937, 0.9935, 0.9935, 0.9934,
         0.9932],
        [0.9923, 0.9911, 0.9904, 0.9897, 0.9878, 0.9875, 0.9871, 0.9866, 0.9864,
         0.9862],
        [0.9929, 0.9928, 0.9922, 0.9895, 0.9879, 0.9873, 0.9866, 0.9864, 0.9860,
         0.9850],
        [0.9939, 0.9936, 0.9926, 0.9919, 0.9915, 0.9906, 0.9904, 0.9904, 0.9903,
         0.9890],
        [0.9963, 0.9950, 0.9943, 0.9940, 0.9937, 0.9918, 0.9914, 0.9908, 0.9904,
         0.9902],
        [0.9902, 0.9900, 0.9893, 0.9885, 0.9884, 0.9881, 0.9880, 0.9879, 0.9877,
         0.9877],
        [0.9883, 0.9870, 0.9866, 0.9860, 0.9852, 0.9850, 0.9846, 0.9845, 0.9843,
         0.9842],
        [0.9933, 0.9930, 0.9929, 0.9923, 0.9916, 0.9915, 0.9894, 0.9894, 0.9891,
         0.9884],
        [0.9944, 0.9933, 0.9930, 0.9928, 0.9920, 0.9915, 0.9913, 0.9909, 0.9908,
         0.9908]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 1, 1, 0, 1, 0, 0, 1, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1537537.0000, 1533268.5000, 1520802.6250, 1519731.2500, 1518392.7500,
         1513409.5000, 1513398.0000, 1513187.2500, 1512298.6250, 1512287.1250],
        [1546970.6250, 1538648.7500, 1532056.7500, 1526485.6250, 1526040.2500,
         1524313.7500, 1524188.6250, 1523895.1250, 1523313.8750, 1523215.0000],
        [1282130.2500, 1266245.8750, 1218994.0000, 1212058.5000, 1209398.1250,
         1191077.3750, 1184948.0000, 1143528.1250, 1140032.7500, 1133039.5000],
        [1473668.1250, 1462676.8750, 1442519.7500, 1434940.2500, 1434460.1250,
         1430008.6250, 1429442.8750, 1427424.0000, 1425886.5000, 1417710.2500],
        [1357360.7500, 1346239.1250, 1323629.5000, 1317071.6250, 1310947.6250,
         1302328.3750, 1301984.3750, 1300609.3750, 1298974.2500, 1298403.3750],
        [1370193.6250, 1257884.5000, 1239660.1250, 1156337.0000, 1149389.5000,
         1131820.2500, 1126829.3750, 1125378.5000, 1083209.6250,  994095.3125],
        [1106285.1250, 1104161.2500, 1100613.0000, 1074018.7500, 1046997.1875,
         1015245.2500, 1001538.6875,  993557.9375,  989028.7500,  984921.0625],
        [1355654.3750, 1281857.6250, 1256767.0000, 1237202.3750, 1221920.0000,
         1184508.5000, 1158410.8750, 1150928.3750, 1147557.1250, 1145962.5000],
        [1551203.1250, 1547023.7500, 1542792.2500, 1540109.5000, 1538786.7500,
         1537023.7500, 1536233.8750, 1534270.5000, 1533005.3750, 1532742.2500],
        [1458706.8750, 1348003.0000, 1346882.5000, 1343685.2500, 1321524.3750,
         1315222.7500, 1306889.3750, 1292682.8750, 1276865.0000, 1273633.6250],
        [1551954.8750, 1549399.3750, 1545680.2500, 1545165.8750, 1543974.2500,
         1543504.7500, 1542977.7500, 1542592.2500, 1542293.6250, 1542234.7500],
        [1486382.5000, 1474918.1250, 1472808.2500, 1469040.3750, 1450808.6250,
         1440215.7500, 1439363.1250, 1433468.6250, 1415214.0000, 1413447.0000],
        [1473263.3750, 1456592.3750, 1449002.7500, 1442951.7500, 1433117.3750,
         1432987.5000, 1421040.2500, 1404792.7500, 1390152.7500, 1376494.7500],
        [1566264.5000, 1563660.1250, 1562876.0000, 1562025.1250, 1561816.6250,
         1561152.5000, 1560537.7500, 1557402.1250, 1556407.3750, 1554372.2500],
        [1558494.2500, 1553480.1250, 1552412.2500, 1550993.1250, 1550450.2500,
         1549219.1250, 1549089.1250, 1548594.2500, 1547958.0000, 1546578.2500],
        [1547606.6250, 1547007.5000, 1545469.5000, 1544271.7500, 1542446.6250,
         1542176.0000, 1541749.6250, 1541545.1250, 1541380.6250, 1540302.0000],
        [1518078.5000, 1511982.7500, 1511893.3750, 1508094.5000, 1499958.8750,
         1497987.6250, 1495382.6250, 1494815.2500, 1493998.5000, 1493830.5000],
        [1520766.5000, 1520247.3750, 1516724.0000, 1516040.0000, 1515060.0000,
         1512947.7500, 1512429.7500, 1503811.7500, 1502021.6250, 1497600.5000],
        [1490234.7500, 1489048.5000, 1488226.5000, 1487841.8750, 1485264.5000,
         1485069.0000, 1480473.3750, 1474250.1250, 1466843.8750, 1466030.0000],
        [1545783.5000, 1545301.5000, 1543927.1250, 1543372.2500, 1542699.6250,
         1540005.2500, 1538609.2500, 1538152.8750, 1538111.7500, 1537426.8750],
        [1558168.7500, 1554317.3750, 1552992.7500, 1552758.7500, 1549832.3750,
         1549449.7500, 1548975.3750, 1546702.2500, 1545251.3750, 1545003.8750],
        [1494644.1250, 1493928.7500, 1491066.3750, 1490096.7500, 1490047.1250,
         1485825.5000, 1477319.7500, 1473942.2500, 1469644.3750, 1469376.6250],
        [1558641.2500, 1545429.7500, 1541558.3750, 1540467.8750, 1536887.5000,
         1536294.0000, 1535522.0000, 1533351.8750, 1531281.2500, 1528296.2500],
        [1565792.6250, 1563828.6250, 1562114.5000, 1561201.5000, 1561009.6250,
         1560982.7500, 1560637.3750, 1559967.7500, 1557131.8750, 1555281.1250],
        [1512295.7500, 1507174.3750, 1502654.8750, 1502292.3750, 1500532.6250,
         1499172.3750, 1498942.1250, 1498433.3750, 1498136.1250, 1492257.0000],
        [1559410.0000, 1558225.2500, 1556802.2500, 1555908.6250, 1554714.6250,
         1553456.3750, 1553235.5000, 1551181.0000, 1551027.0000, 1550808.1250],
        [1549705.2500, 1547481.2500, 1545640.5000, 1544277.6250, 1543357.3750,
         1543298.6250, 1543085.1250, 1539577.8750, 1539030.3750, 1536837.6250],
        [1558935.7500, 1554040.2500, 1551965.2500, 1550017.2500, 1548505.7500,
         1545953.1250, 1545450.3750, 1545005.2500, 1544399.8750, 1543862.3750],
        [1568185.1250, 1566621.5000, 1566157.0000, 1566103.2500, 1565740.3750,
         1563272.5000, 1562464.7500, 1561897.0000, 1561873.2500, 1561704.8750],
        [1568882.1250, 1567129.6250, 1565464.1250, 1565141.6250, 1563897.2500,
         1563005.6250, 1562260.5000, 1561970.0000, 1561428.0000, 1560603.2500],
        [1565995.7500, 1564062.7500, 1563989.7500, 1563220.2500, 1562160.7500,
         1561996.8750, 1561602.1250, 1560457.3750, 1560228.1250, 1559588.3750],
        [1564586.3750, 1563479.6250, 1562803.0000, 1562117.5000, 1561505.3750,
         1559621.1250, 1559447.2500, 1557317.5000, 1556990.7500, 1556980.3750],
        [1392142.7500, 1266472.8750, 1258588.8750, 1241933.3750, 1225012.0000,
         1224376.6250, 1222298.8750, 1195739.1250, 1120587.1250, 1094726.8750],
        [1531145.3750, 1528720.3750, 1526999.6250, 1526741.8750, 1525320.1250,
         1524463.5000, 1522931.8750, 1522391.6250, 1522198.6250, 1521062.3750],
        [1550697.3750, 1548019.8750, 1544223.1250, 1543810.8750, 1543329.5000,
         1542805.5000, 1542146.6250, 1542146.6250, 1541163.0000, 1539839.2500],
        [1536859.6250, 1531403.8750, 1531173.1250, 1524720.7500, 1524366.0000,
         1524273.1250, 1523553.6250, 1523126.5000, 1523003.0000, 1522791.0000],
        [1353943.7500, 1323599.2500, 1304624.2500, 1292748.2500, 1230177.2500,
         1223803.5000, 1211989.0000, 1183380.5000, 1181709.1250, 1179139.1250],
        [1516861.5000, 1514451.8750, 1508190.8750, 1501874.1250, 1501143.8750,
         1500808.8750, 1500262.1250, 1500160.6250, 1500144.8750, 1497889.0000],
        [1446456.8750, 1421560.6250, 1405196.0000, 1401670.6250, 1397219.6250,
         1389684.7500, 1389325.7500, 1388999.7500, 1386958.6250, 1386629.3750],
        [1517687.6250, 1514941.6250, 1510955.0000, 1510942.0000, 1510435.0000,
         1508160.7500, 1506356.6250, 1504952.5000, 1504599.3750, 1504557.7500],
        [1375013.3750, 1333397.7500, 1325276.6250, 1319629.0000, 1283933.8750,
         1275225.7500, 1258947.8750, 1251756.2500, 1251362.3750, 1247223.3750],
        [1553696.3750, 1550630.7500, 1549627.0000, 1549612.1250, 1547422.1250,
         1546410.2500, 1545599.2500, 1543313.2500, 1542985.0000, 1542483.5000],
        [1542055.3750, 1541220.3750, 1540823.5000, 1539736.5000, 1539213.8750,
         1538760.2500, 1538471.2500, 1536686.7500, 1536638.3750, 1536458.0000],
        [1532553.6250, 1528249.6250, 1528020.7500, 1527786.2500, 1526571.5000,
         1526325.5000, 1525480.0000, 1524684.5000, 1521419.2500, 1521097.1250],
        [1455632.8750, 1433206.2500, 1414575.6250, 1409502.8750, 1407790.1250,
         1398183.3750, 1394113.0000, 1390669.8750, 1389508.5000, 1380766.3750],
        [1314098.2500, 1309077.3750, 1304244.8750, 1295140.8750, 1275111.3750,
         1275053.1250, 1272166.0000, 1271297.6250, 1266805.1250, 1263992.0000],
        [1342307.2500, 1140513.5000, 1027779.9375,  978407.1250,  892416.1250,
          878289.0000,  846996.0000,  811785.7500,  779489.7500,  768482.9375],
        [1164932.8750, 1105246.3750, 1062419.6250, 1042053.4375, 1036159.1250,
         1010749.1875, 1000483.8125,  970456.1250,  962148.5000,  922596.4375],
        [1455281.7500, 1433507.0000, 1426359.8750, 1418561.0000, 1409263.7500,
         1407096.2500, 1406522.0000, 1404708.1250, 1403578.0000, 1403305.0000],
        [1478255.3750, 1477810.0000, 1470081.7500, 1468457.7500, 1467272.0000,
         1463149.8750, 1460339.5000, 1455072.1250, 1454220.3750, 1453340.0000],
        [1476404.2500, 1463704.0000, 1457224.5000, 1453631.0000, 1450141.8750,
         1449855.6250, 1443677.1250, 1443611.0000, 1442578.7500, 1440413.6250],
        [1375224.6250, 1375190.3750, 1371558.6250, 1363483.1250, 1353568.1250,
         1344037.7500, 1333558.0000, 1332401.1250, 1324471.7500, 1303340.8750],
        [1486272.0000, 1484788.6250, 1446589.2500, 1446332.6250, 1438095.3750,
         1413335.1250, 1406599.8750, 1395555.0000, 1384335.6250, 1370299.5000],
        [1423971.7500, 1411328.2500, 1395871.7500, 1370645.8750, 1350632.0000,
         1332704.8750, 1325578.6250, 1309052.3750, 1306089.5000, 1305180.5000],
        [1469753.6250, 1469459.3750, 1467570.1250, 1463641.1250, 1462388.1250,
         1456523.0000, 1446579.6250, 1446379.5000, 1441926.8750, 1438917.1250],
        [1484598.8750, 1481060.7500, 1479646.1250, 1477095.7500, 1474113.7500,
         1462048.0000, 1458857.0000, 1457477.5000, 1456809.2500, 1452634.7500],
        [1433675.0000, 1409969.5000, 1395219.7500, 1380447.7500, 1344540.3750,
         1337886.5000, 1330133.7500, 1321316.3750, 1318539.6250, 1313890.2500],
        [1446033.3750, 1443228.3750, 1430636.1250, 1376605.0000, 1346291.7500,
         1334803.6250, 1322029.8750, 1317178.5000, 1311033.8750, 1291099.6250],
        [1466146.0000, 1460917.6250, 1438751.0000, 1424437.6250, 1417287.1250,
         1400163.5000, 1395133.1250, 1394843.1250, 1392932.8750, 1367687.1250],
        [1517668.8750, 1489930.6250, 1474581.8750, 1468660.8750, 1461957.3750,
         1424285.5000, 1415266.6250, 1402359.1250, 1396024.8750, 1391911.7500],
        [1391379.5000, 1388215.8750, 1374456.2500, 1357582.1250, 1356343.7500,
         1350817.5000, 1348832.5000, 1346539.5000, 1342740.0000, 1341550.8750],
        [1353224.7500, 1329589.6250, 1322410.6250, 1310755.1250, 1294942.1250,
         1290761.1250, 1283708.6250, 1282646.3750, 1277917.5000, 1277465.5000],
        [1454585.1250, 1448598.0000, 1445687.3750, 1434525.7500, 1419808.7500,
         1417794.1250, 1376405.5000, 1376225.6250, 1370025.0000, 1356037.2500],
        [1476691.3750, 1454934.7500, 1448443.2500, 1443294.3750, 1427577.7500,
         1416930.3750, 1412297.6250, 1404765.8750, 1403932.8750, 1402408.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1537537.0000,       0.0000],
         [1533268.5000,       0.0000],
         [1520802.6250,       0.0000],
         ...,
         [1513187.2500,       0.0000],
         [1512298.6250,       0.0000],
         [1512287.1250,       0.0000]],

        [[1546970.6250,       0.0000],
         [1538648.7500,       0.0000],
         [1532056.7500,       0.0000],
         ...,
         [1523895.1250,       0.0000],
         [1523313.8750,       0.0000],
         [1523215.0000,       0.0000]],

        [[1282130.2500,       0.0000],
         [1266245.8750,       0.0000],
         [1218994.0000,       0.0000],
         ...,
         [1143528.1250,       0.0000],
         [1140032.7500,       0.0000],
         [1133039.5000,       0.0000]],

        ...,

        [[1353224.7500,       0.0000],
         [1329589.6250,       0.0000],
         [      0.0000, 1322410.6250],
         ...,
         [1282646.3750,       0.0000],
         [1277917.5000,       0.0000],
         [1277465.5000,       0.0000]],

        [[1454585.1250,       0.0000],
         [1448598.0000,       0.0000],
         [1445687.3750,       0.0000],
         ...,
         [1376225.6250,       0.0000],
         [      0.0000, 1370025.0000],
         [1356037.2500,       0.0000]],

        [[      0.0000, 1476691.3750],
         [      0.0000, 1454934.7500],
         [      0.0000, 1448443.2500],
         ...,
         [      0.0000, 1404765.8750],
         [      0.0000, 1403932.8750],
         [      0.0000, 1402408.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15194312.0000,        0.0000],
        [15289129.0000,        0.0000],
        [ 9605428.0000,  2376025.5000],
        [14378738.0000,        0.0000],
        [ 9230981.0000,  3926567.5000],
        [10507968.0000,  1126829.3750],
        [ 3140187.2500,  7276180.0000],
        [ 9842283.0000,  2298485.5000],
        [12325916.0000,  3067276.0000],
        [10625188.0000,  2658908.0000],
        [15449778.0000,        0.0000],
        [14495667.0000,        0.0000],
        [14280396.0000,        0.0000],
        [15606515.0000,        0.0000],
        [15507270.0000,        0.0000],
        [15433956.0000,        0.0000],
        [15026023.0000,        0.0000],
        [10577212.0000,  4540437.5000],
        [14813282.0000,        0.0000],
        [15413389.0000,        0.0000],
        [15503453.0000,        0.0000],
        [11847319.0000,  2988573.0000],
        [15387730.0000,        0.0000],
        [15607947.0000,        0.0000],
        [10508510.0000,  4503380.5000],
        [15544768.0000,        0.0000],
        [15432292.0000,        0.0000],
        [15488136.0000,        0.0000],
        [15644020.0000,        0.0000],
        [15639782.0000,        0.0000],
        [15623302.0000,        0.0000],
        [15604849.0000,        0.0000],
        [ 4706799.0000,  7535079.5000],
        [10671890.0000,  4580086.0000],
        [13894372.0000,  1543810.8750],
        [12210543.0000,  3054726.7500],
        [ 6026818.0000,  6458296.0000],
        [12019146.0000,  3022642.7500],
        [ 8369041.5000,  5644661.0000],
        [15093588.0000,        0.0000],
        [10399317.0000,  2522449.0000],
        [15471780.0000,        0.0000],
        [15390064.0000,        0.0000],
        [12204950.0000,  3057238.0000],
        [ 1380766.3750, 12693183.0000],
        [ 5114587.5000,  7732399.0000],
        [ 4977460.0000,  4489008.0000],
        [  922596.4375,  9354649.0000],
        [14168183.0000,        0.0000],
        [10232390.0000,  4415609.0000],
        [11617469.0000,  2903773.0000],
        [       0.0000, 13476834.0000],
        [       0.0000, 14272202.0000],
        [ 2611270.0000, 10919786.0000],
        [10179435.0000,  4383703.0000],
        [11733132.0000,  2951209.5000],
        [ 1321316.3750, 12264302.0000],
        [ 1322029.8750, 12296910.0000],
        [       0.0000, 14158299.0000],
        [       0.0000, 14442648.0000],
        [ 8172862.0000,  5425596.0000],
        [ 9115307.0000,  3908114.0000],
        [11353262.0000,  2746430.5000],
        [       0.0000, 14291277.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 201/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:44, 59.44s/it]  7%|▋         | 2/29 [01:00<11:15, 25.02s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.2986032962799072
Epoch 202/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:53, 57.61s/it]  7%|▋         | 2/29 [00:58<10:55, 24.27s/it] 10%|█         | 3/29 [01:02<06:29, 15.00s/it] 14%|█▍        | 4/29 [01:03<03:56,  9.44s/it] 17%|█▋        | 5/29 [01:04<02:32,  6.37s/it] 21%|██        | 6/29 [01:05<01:43,  4.52s/it] 24%|██▍       | 7/29 [01:06<01:13,  3.34s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.57s/it] 31%|███       | 9/29 [01:08<00:41,  2.05s/it] 34%|███▍      | 10/29 [01:08<00:32,  1.71s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.47s/it] 41%|████▏     | 12/29 [01:10<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.19s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.11s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.279118537902832
Epoch 203/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:42, 61.50s/it]  7%|▋         | 2/29 [01:02<11:38, 25.87s/it] 10%|█         | 3/29 [01:03<06:16, 14.48s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.12s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 3.287609338760376
Epoch 204/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:31, 58.98s/it]  7%|▋         | 2/29 [00:59<11:10, 24.83s/it] 10%|█         | 3/29 [01:00<06:01, 13.91s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.78s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.95s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 3.269352674484253
Epoch 205/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:37, 59.21s/it]  7%|▋         | 2/29 [01:00<11:12, 24.92s/it] 10%|█         | 3/29 [01:01<06:03, 13.96s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.2579145431518555
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0036, 0.0082, 0.0017,  ..., 0.0057, 0.0013, 0.0203],
        [0.0023, 0.0087, 0.0017,  ..., 0.0043, 0.0009, 0.0189],
        [0.0271, 0.0076, 0.0031,  ..., 0.0055, 0.0134, 0.0281],
        ...,
        [0.0033, 0.0066, 0.0233,  ..., 0.0031, 0.0012, 0.0240],
        [0.0031, 0.0106, 0.0107,  ..., 0.0037, 0.0009, 0.0212],
        [0.0083, 0.0085, 0.0041,  ..., 0.0013, 0.0038, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9972, 0.9971, 0.9965, 0.9964, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959,
         0.9958],
        [0.9976, 0.9972, 0.9971, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9841, 0.9817, 0.9792, 0.9784, 0.9782, 0.9780, 0.9779, 0.9756, 0.9755,
         0.9751],
        [0.9937, 0.9935, 0.9927, 0.9924, 0.9924, 0.9922, 0.9918, 0.9917, 0.9910,
         0.9910],
        [0.9889, 0.9876, 0.9869, 0.9864, 0.9861, 0.9859, 0.9856, 0.9855, 0.9853,
         0.9852],
        [0.9892, 0.9836, 0.9819, 0.9774, 0.9763, 0.9762, 0.9753, 0.9752, 0.9728,
         0.9695],
        [0.9750, 0.9749, 0.9744, 0.9723, 0.9713, 0.9688, 0.9680, 0.9672, 0.9665,
         0.9664],
        [0.9880, 0.9830, 0.9825, 0.9816, 0.9798, 0.9771, 0.9762, 0.9761, 0.9753,
         0.9752],
        [0.9979, 0.9976, 0.9976, 0.9974, 0.9974, 0.9973, 0.9972, 0.9971, 0.9971,
         0.9971],
        [0.9933, 0.9878, 0.9877, 0.9875, 0.9862, 0.9853, 0.9849, 0.9847, 0.9834,
         0.9830],
        [0.9979, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9949, 0.9945, 0.9939, 0.9938, 0.9928, 0.9927, 0.9918, 0.9918, 0.9912,
         0.9912],
        [0.9938, 0.9927, 0.9925, 0.9924, 0.9924, 0.9922, 0.9910, 0.9907, 0.9904,
         0.9890],
        [0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9981,
         0.9981],
        [0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9977,
         0.9977],
        [0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9964, 0.9961, 0.9960, 0.9960, 0.9955, 0.9955, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9964, 0.9964, 0.9961, 0.9961, 0.9961, 0.9961, 0.9958, 0.9955, 0.9953,
         0.9952],
        [0.9950, 0.9950, 0.9949, 0.9948, 0.9945, 0.9945, 0.9943, 0.9942, 0.9940,
         0.9939],
        [0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9952, 0.9951, 0.9951, 0.9948, 0.9947, 0.9947, 0.9944, 0.9942, 0.9940,
         0.9938],
        [0.9982, 0.9978, 0.9975, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9968,
         0.9968],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9981],
        [0.9960, 0.9958, 0.9957, 0.9956, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974,
         0.9972],
        [0.9983, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9987, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9902, 0.9832, 0.9826, 0.9819, 0.9813, 0.9813, 0.9801, 0.9796, 0.9743,
         0.9725],
        [0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9978, 0.9977, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9972, 0.9969, 0.9969, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9884, 0.9862, 0.9853, 0.9837, 0.9830, 0.9821, 0.9809, 0.9798, 0.9797,
         0.9794],
        [0.9963, 0.9962, 0.9958, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9932, 0.9926, 0.9916, 0.9915, 0.9906, 0.9904, 0.9902, 0.9900, 0.9900,
         0.9899],
        [0.9964, 0.9963, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9886, 0.9868, 0.9862, 0.9853, 0.9845, 0.9841, 0.9830, 0.9830, 0.9824,
         0.9823],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9971],
        [0.9971, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9932, 0.9921, 0.9913, 0.9907, 0.9905, 0.9904, 0.9901, 0.9900, 0.9897,
         0.9896],
        [0.9868, 0.9859, 0.9853, 0.9851, 0.9842, 0.9842, 0.9842, 0.9839, 0.9838,
         0.9835],
        [0.9880, 0.9788, 0.9709, 0.9650, 0.9633, 0.9607, 0.9557, 0.9554, 0.9522,
         0.9492],
        [0.9780, 0.9745, 0.9718, 0.9716, 0.9694, 0.9669, 0.9656, 0.9651, 0.9648,
         0.9610],
        [0.9932, 0.9920, 0.9920, 0.9913, 0.9911, 0.9906, 0.9905, 0.9904, 0.9903,
         0.9902],
        [0.9945, 0.9943, 0.9941, 0.9940, 0.9940, 0.9938, 0.9937, 0.9933, 0.9932,
         0.9931],
        [0.9943, 0.9938, 0.9932, 0.9932, 0.9930, 0.9929, 0.9926, 0.9926, 0.9926,
         0.9926],
        [0.9896, 0.9892, 0.9890, 0.9887, 0.9885, 0.9876, 0.9869, 0.9868, 0.9867,
         0.9856],
        [0.9947, 0.9947, 0.9930, 0.9927, 0.9922, 0.9912, 0.9908, 0.9902, 0.9894,
         0.9893],
        [0.9917, 0.9909, 0.9902, 0.9887, 0.9875, 0.9874, 0.9867, 0.9858, 0.9858,
         0.9854],
        [0.9941, 0.9941, 0.9940, 0.9939, 0.9939, 0.9935, 0.9931, 0.9930, 0.9928,
         0.9928],
        [0.9948, 0.9946, 0.9944, 0.9943, 0.9940, 0.9933, 0.9932, 0.9931, 0.9930,
         0.9930],
        [0.9922, 0.9910, 0.9902, 0.9896, 0.9878, 0.9866, 0.9865, 0.9864, 0.9864,
         0.9861],
        [0.9927, 0.9925, 0.9924, 0.9885, 0.9875, 0.9864, 0.9861, 0.9857, 0.9853,
         0.9851],
        [0.9937, 0.9933, 0.9927, 0.9920, 0.9914, 0.9905, 0.9904, 0.9897, 0.9894,
         0.9892],
        [0.9963, 0.9950, 0.9942, 0.9936, 0.9931, 0.9921, 0.9909, 0.9909, 0.9902,
         0.9900],
        [0.9903, 0.9900, 0.9896, 0.9884, 0.9884, 0.9880, 0.9879, 0.9878, 0.9877,
         0.9875],
        [0.9887, 0.9875, 0.9867, 0.9854, 0.9850, 0.9849, 0.9849, 0.9848, 0.9841,
         0.9837],
        [0.9927, 0.9927, 0.9926, 0.9922, 0.9911, 0.9910, 0.9888, 0.9886, 0.9883,
         0.9874],
        [0.9942, 0.9932, 0.9931, 0.9928, 0.9916, 0.9915, 0.9912, 0.9909, 0.9908,
         0.9906]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1537506.1250, 1534510.5000, 1521642.7500, 1519509.5000, 1515837.6250,
         1513592.8750, 1512636.1250, 1512460.1250, 1510015.7500, 1508085.8750],
        [1546966.2500, 1537864.0000, 1534771.0000, 1525868.5000, 1525841.0000,
         1525251.6250, 1525104.6250, 1524430.0000, 1523344.5000, 1523258.7500],
        [1275571.2500, 1232544.6250, 1188277.2500, 1175881.3750, 1171325.0000,
         1167973.0000, 1167793.7500, 1129085.1250, 1127276.5000, 1120592.3750],
        [1463406.6250, 1458697.0000, 1442779.6250, 1436667.0000, 1434793.8750,
         1431766.2500, 1424012.5000, 1422146.5000, 1408210.3750, 1406497.7500],
        [1365500.1250, 1341273.2500, 1326741.0000, 1317716.2500, 1312823.0000,
         1307561.3750, 1302563.1250, 1301794.5000, 1298015.8750, 1295640.0000],
        [1370921.7500, 1266911.5000, 1234897.8750, 1158277.2500, 1140333.8750,
         1139386.0000, 1125042.6250, 1123475.1250, 1084919.6250, 1035721.4375],
        [1120278.2500, 1118521.1250, 1109678.0000, 1076718.1250, 1061610.3750,
         1024464.5625, 1013718.6250, 1001206.3750,  992312.7500,  990539.0000],
        [1348019.6250, 1254990.7500, 1246737.0000, 1229777.2500, 1198321.3750,
         1154451.6250, 1138448.7500, 1137589.1250, 1124743.3750, 1122935.2500],
        [1552818.0000, 1547333.6250, 1546334.8750, 1541877.5000, 1540930.7500,
         1538741.1250, 1537866.8750, 1536261.7500, 1534447.6250, 1534393.5000],
        [1453549.2500, 1344167.2500, 1342483.8750, 1337773.0000, 1313347.7500,
         1297400.7500, 1289885.0000, 1286549.5000, 1262395.8750, 1255175.0000],
        [1553201.5000, 1550652.8750, 1546180.1250, 1546178.6250, 1545207.2500,
         1544903.6250, 1544676.8750, 1544542.7500, 1543968.3750, 1542459.8750],
        [1487846.1250, 1480047.0000, 1466320.7500, 1464314.0000, 1443713.0000,
         1442755.0000, 1423039.1250, 1422695.8750, 1411749.6250, 1411703.7500],
        [1465626.0000, 1441871.8750, 1437659.2500, 1436590.2500, 1435381.1250,
         1431876.8750, 1406732.5000, 1401204.1250, 1396038.2500, 1368229.7500],
        [1566676.7500, 1565758.1250, 1563761.6250, 1563041.3750, 1562652.5000,
         1561840.5000, 1561684.1250, 1561267.1250, 1557359.0000, 1557180.8750],
        [1559584.0000, 1555546.6250, 1554787.2500, 1553306.6250, 1552696.5000,
         1552569.2500, 1552101.3750, 1549850.1250, 1549232.5000, 1548606.1250],
        [1549446.7500, 1548544.1250, 1547627.2500, 1547293.7500, 1544833.0000,
         1544376.2500, 1544089.1250, 1543830.0000, 1543756.3750, 1543210.2500],
        [1520528.6250, 1512777.5000, 1511512.7500, 1511259.1250, 1500697.2500,
         1500180.6250, 1498423.3750, 1497887.6250, 1496345.6250, 1495642.2500],
        [1519996.5000, 1519725.5000, 1514628.1250, 1514379.6250, 1514275.7500,
         1512980.8750, 1507714.8750, 1500651.5000, 1496808.0000, 1494853.6250],
        [1490823.1250, 1489038.5000, 1488629.6250, 1484979.8750, 1480086.5000,
         1478386.6250, 1474487.7500, 1474074.3750, 1468331.6250, 1466074.7500],
        [1543741.6250, 1543531.1250, 1542795.3750, 1540803.0000, 1540119.7500,
         1537234.8750, 1536944.6250, 1536805.5000, 1536529.8750, 1535443.0000],
        [1558232.5000, 1555399.7500, 1554149.8750, 1553568.8750, 1550585.0000,
         1549235.3750, 1547315.8750, 1546831.8750, 1546470.6250, 1545588.8750],
        [1494786.6250, 1491675.1250, 1491410.5000, 1486789.5000, 1483963.3750,
         1483643.6250, 1476511.2500, 1474008.3750, 1469443.8750, 1463814.2500],
        [1559645.0000, 1549964.0000, 1544981.7500, 1539131.6250, 1537129.2500,
         1534664.1250, 1534550.0000, 1533517.1250, 1529573.5000, 1528660.6250],
        [1566977.1250, 1565204.2500, 1562992.2500, 1562664.3750, 1562344.0000,
         1562288.8750, 1562122.0000, 1561816.6250, 1559322.2500, 1557467.5000],
        [1510844.1250, 1507825.6250, 1504117.3750, 1503109.2500, 1497029.2500,
         1495021.8750, 1493720.7500, 1492242.8750, 1491497.2500, 1491360.7500],
        [1562744.7500, 1559706.0000, 1558403.5000, 1555925.0000, 1555684.6250,
         1555564.3750, 1555511.1250, 1554410.7500, 1552757.2500, 1551951.8750],
        [1551493.1250, 1550023.1250, 1548805.5000, 1547107.8750, 1546214.1250,
         1545935.3750, 1544326.2500, 1541834.8750, 1541740.6250, 1538199.8750],
        [1562028.1250, 1556030.2500, 1555150.6250, 1554687.8750, 1553619.3750,
         1550642.6250, 1549859.0000, 1549040.3750, 1546953.0000, 1545813.0000],
        [1567868.0000, 1567013.0000, 1566800.7500, 1566654.3750, 1565594.0000,
         1565435.6250, 1564429.7500, 1563690.0000, 1563536.3750, 1563406.6250],
        [1570187.5000, 1567794.8750, 1567350.8750, 1565694.0000, 1564822.2500,
         1563895.8750, 1563323.2500, 1563084.6250, 1562978.7500, 1562052.0000],
        [1569108.1250, 1564999.7500, 1564546.2500, 1564462.6250, 1563560.2500,
         1562893.8750, 1562685.2500, 1562002.8750, 1561834.5000, 1561259.7500],
        [1567808.2500, 1565213.2500, 1565029.6250, 1564698.3750, 1563075.7500,
         1562260.5000, 1561018.5000, 1560213.2500, 1559459.0000, 1558674.0000],
        [1391071.7500, 1259027.0000, 1248992.1250, 1235105.1250, 1225402.2500,
         1224423.3750, 1203905.6250, 1195461.0000, 1108945.8750, 1080745.6250],
        [1530762.7500, 1530217.0000, 1526714.1250, 1526670.5000, 1525471.3750,
         1521976.5000, 1521793.6250, 1520746.1250, 1520432.8750, 1519209.6250],
        [1549789.5000, 1548318.1250, 1544081.7500, 1543989.0000, 1541433.5000,
         1540121.2500, 1540121.2500, 1540086.0000, 1539770.2500, 1538552.0000],
        [1537016.5000, 1531122.1250, 1530349.7500, 1525632.7500, 1524701.8750,
         1524331.1250, 1523893.6250, 1523315.3750, 1523191.8750, 1522672.0000],
        [1356748.6250, 1313685.8750, 1297457.6250, 1267808.2500, 1255309.1250,
         1240011.2500, 1218081.7500, 1199298.8750, 1196896.0000, 1192865.5000],
        [1517434.3750, 1515427.2500, 1506754.6250, 1503364.3750, 1502025.8750,
         1501414.3750, 1499850.1250, 1499326.7500, 1499138.1250, 1497293.3750],
        [1451950.5000, 1440349.1250, 1419274.1250, 1416811.5000, 1400102.1250,
         1395965.0000, 1390465.6250, 1388160.2500, 1387055.2500, 1385586.3750],
        [1519347.3750, 1517884.6250, 1513214.6250, 1511648.2500, 1510986.7500,
         1509198.1250, 1509028.2500, 1508705.8750, 1507789.6250, 1506582.2500],
        [1359368.6250, 1324514.6250, 1313554.5000, 1296960.3750, 1281707.2500,
         1274239.8750, 1255803.7500, 1255134.3750, 1244512.1250, 1243534.3750],
        [1554699.8750, 1552239.0000, 1551263.7500, 1551086.2500, 1549436.3750,
         1546214.1250, 1546205.1250, 1545061.3750, 1544771.0000, 1543868.2500],
        [1542349.5000, 1540172.6250, 1540000.8750, 1539989.1250, 1539671.8750,
         1538905.6250, 1538675.2500, 1538333.3750, 1537381.5000, 1536159.2500],
        [1536170.8750, 1528717.5000, 1528245.2500, 1528006.2500, 1526354.6250,
         1525971.8750, 1525225.3750, 1524739.7500, 1522949.2500, 1521751.6250],
        [1452760.7500, 1429182.5000, 1412588.6250, 1400681.7500, 1396320.3750,
         1394340.5000, 1389360.1250, 1386987.7500, 1381236.6250, 1379817.3750],
        [1324929.1250, 1307526.5000, 1297798.0000, 1294108.7500, 1277365.5000,
         1276963.6250, 1276707.8750, 1271113.3750, 1269223.6250, 1264456.2500],
        [1348540.5000, 1181550.3750, 1055375.0000,  970964.3750,  946940.0625,
          912491.6250,  849692.5625,  846135.3125,  808409.6250,  774174.9375],
        [1167983.1250, 1112187.8750, 1069114.6250, 1066824.0000, 1033079.6250,
          997753.8750,  979525.5625,  972488.8750,  967796.1875,  917011.3750],
        [1452188.7500, 1428080.2500, 1427915.5000, 1413856.8750, 1409528.5000,
         1399342.6250, 1396375.1250, 1395819.8750, 1393572.1250, 1390863.5000],
        [1478789.8750, 1474517.3750, 1470074.7500, 1469574.3750, 1468198.6250,
         1465679.1250, 1461794.1250, 1454183.0000, 1451964.3750, 1451052.1250],
        [1474919.5000, 1465620.3750, 1453026.7500, 1451478.5000, 1448062.0000,
         1446291.2500, 1440775.0000, 1440676.1250, 1439661.1250, 1439197.0000],
        [1378654.5000, 1370554.3750, 1368382.3750, 1362095.1250, 1358760.7500,
         1340618.5000, 1326537.3750, 1325509.1250, 1323628.2500, 1302571.7500],
        [1483547.3750, 1483131.5000, 1447518.0000, 1441957.1250, 1431670.7500,
         1412119.8750, 1403167.1250, 1391747.1250, 1375612.8750, 1373079.2500],
        [1420712.2500, 1404467.1250, 1390692.3750, 1362176.8750, 1338354.8750,
         1337246.2500, 1322704.6250, 1306550.5000, 1306255.1250, 1299657.1250],
        [1471572.7500, 1470210.7500, 1469039.0000, 1466353.0000, 1465932.1250,
         1458468.8750, 1449703.5000, 1447854.8750, 1444482.7500, 1444482.7500],
        [1485087.5000, 1481344.7500, 1476939.3750, 1475791.8750, 1468503.8750,
         1454305.0000, 1452122.2500, 1450783.7500, 1448667.0000, 1448267.7500],
        [1430656.6250, 1407399.5000, 1391361.0000, 1378534.8750, 1343598.2500,
         1320750.7500, 1319314.3750, 1318332.1250, 1316879.5000, 1311380.2500],
        [1442391.7500, 1437593.3750, 1436058.7500, 1357195.0000, 1338217.1250,
         1317240.0000, 1311311.5000, 1305489.2500, 1297204.0000, 1292753.1250],
        [1461654.7500, 1454750.2500, 1441379.6250, 1426532.5000, 1414779.3750,
         1396789.2500, 1395736.0000, 1381759.7500, 1375055.5000, 1370780.5000],
        [1517143.5000, 1491025.1250, 1473387.1250, 1460875.8750, 1450596.8750,
         1430000.5000, 1405662.3750, 1404413.5000, 1390823.7500, 1387608.2500],
        [1393476.3750, 1386412.6250, 1379176.6250, 1355456.7500, 1355405.0000,
         1347589.1250, 1346195.3750, 1344292.8750, 1343038.3750, 1339221.8750],
        [1361653.5000, 1338441.7500, 1323827.7500, 1299142.8750, 1290735.2500,
         1290054.6250, 1288928.2500, 1287321.5000, 1274788.0000, 1267570.1250],
        [1442632.5000, 1440930.2500, 1439692.6250, 1431188.8750, 1409111.8750,
         1408049.2500, 1363185.3750, 1360148.0000, 1353596.5000, 1336857.2500],
        [1473470.0000, 1452260.7500, 1449591.5000, 1443302.6250, 1419044.0000,
         1416450.7500, 1411605.5000, 1404751.1250, 1402389.8750, 1399584.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1537506.1250,       0.0000],
         [1534510.5000,       0.0000],
         [1521642.7500,       0.0000],
         ...,
         [1512460.1250,       0.0000],
         [1510015.7500,       0.0000],
         [1508085.8750,       0.0000]],

        [[1546966.2500,       0.0000],
         [1537864.0000,       0.0000],
         [1534771.0000,       0.0000],
         ...,
         [1524430.0000,       0.0000],
         [1523344.5000,       0.0000],
         [1523258.7500,       0.0000]],

        [[1275571.2500,       0.0000],
         [1232544.6250,       0.0000],
         [1188277.2500,       0.0000],
         ...,
         [1129085.1250,       0.0000],
         [1127276.5000,       0.0000],
         [      0.0000, 1120592.3750]],

        ...,

        [[1361653.5000,       0.0000],
         [1338441.7500,       0.0000],
         [      0.0000, 1323827.7500],
         ...,
         [1287321.5000,       0.0000],
         [1274788.0000,       0.0000],
         [1267570.1250,       0.0000]],

        [[1442632.5000,       0.0000],
         [1440930.2500,       0.0000],
         [1439692.6250,       0.0000],
         ...,
         [      0.0000, 1360148.0000],
         [1353596.5000,       0.0000],
         [1336857.2500,       0.0000]],

        [[      0.0000, 1473470.0000],
         [      0.0000, 1452260.7500],
         [      0.0000, 1449591.5000],
         ...,
         [      0.0000, 1404751.1250],
         [      0.0000, 1402389.8750],
         [      0.0000, 1399584.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15185798.0000,        0.0000],
        [15292700.0000,        0.0000],
        [ 8296430.0000,  3459890.5000],
        [14328978.0000,        0.0000],
        [ 9259371.0000,  3910257.5000],
        [10539554.0000,  1140333.8750],
        [ 3170670.5000,  7338376.5000],
        [ 9694630.0000,  2261384.0000],
        [13876558.0000,  1534447.6250],
        [10541160.0000,  2641568.0000],
        [15461972.0000,        0.0000],
        [14454184.0000,        0.0000],
        [12852980.0000,  1368229.7500],
        [15621222.0000,        0.0000],
        [15528281.0000,        0.0000],
        [15457008.0000,        0.0000],
        [15045255.0000,        0.0000],
        [10559396.0000,  4536619.0000],
        [14794912.0000,        0.0000],
        [15393948.0000,        0.0000],
        [15507379.0000,        0.0000],
        [11832961.0000,  2983085.5000],
        [15391817.0000,        0.0000],
        [15623199.0000,        0.0000],
        [10487300.0000,  4499469.5000],
        [15562660.0000,        0.0000],
        [15455681.0000,        0.0000],
        [15523824.0000,        0.0000],
        [15654428.0000,        0.0000],
        [15651184.0000,        0.0000],
        [15637354.0000,        0.0000],
        [15627450.0000,        0.0000],
        [ 4674120.5000,  7498959.0000],
        [10667897.0000,  4576097.0000],
        [12343722.0000,  3082541.0000],
        [12210774.0000,  3055453.2500],
        [ 6109597.0000,  6428566.0000],
        [12019847.0000,  3022182.0000],
        [ 9795260.0000,  4280460.0000],
        [15114385.0000,        0.0000],
        [10312488.0000,  2536841.5000],
        [15484844.0000,        0.0000],
        [15391638.0000,        0.0000],
        [12205606.0000,  3062525.5000],
        [ 1379817.3750, 12643458.0000],
        [ 5111153.5000,  7749039.0000],
        [ 5137844.5000,  4556430.5000],
        [  917011.3750,  9366754.0000],
        [11270100.0000,  2837444.0000],
        [10229265.0000,  4416563.0000],
        [11598618.0000,  2901088.7500],
        [       0.0000, 13457312.0000],
        [       0.0000, 14243551.0000],
        [ 2606207.5000, 10882609.0000],
        [10199633.0000,  4388466.5000],
        [10233916.0000,  4407896.5000],
        [ 1318332.1250, 12219875.0000],
        [ 1317240.0000, 12218214.0000],
        [       0.0000, 14119218.0000],
        [ 1387608.2500, 13023928.0000],
        [ 9500226.0000,  4090038.2500],
        [ 9118972.0000,  3903491.2500],
        [11262060.0000,  2723333.5000],
        [       0.0000, 14272451.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 206/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.67s/it]  7%|▋         | 2/29 [01:01<11:29, 25.52s/it] 10%|█         | 3/29 [01:02<06:11, 14.29s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.271376848220825
Epoch 207/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:57, 57.75s/it]  7%|▋         | 2/29 [01:01<11:36, 25.79s/it] 10%|█         | 3/29 [01:02<06:15, 14.43s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.15s/it] 21%|██        | 6/29 [01:04<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.265190601348877
Epoch 208/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:44, 61.57s/it]  7%|▋         | 2/29 [01:02<11:39, 25.90s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 3.266314744949341
Epoch 209/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:46, 57.38s/it]  7%|▋         | 2/29 [01:01<11:50, 26.31s/it] 10%|█         | 3/29 [01:02<06:22, 14.72s/it] 14%|█▍        | 4/29 [01:03<03:51,  9.27s/it] 17%|█▋        | 5/29 [01:04<02:30,  6.26s/it] 21%|██        | 6/29 [01:05<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.54s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.07it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 3.255039691925049
Epoch 210/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:53, 59.78s/it]  7%|▋         | 2/29 [01:00<11:19, 25.16s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.234544515609741
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0084, 0.0018,  ..., 0.0060, 0.0010, 0.0206],
        [0.0022, 0.0091, 0.0017,  ..., 0.0045, 0.0009, 0.0188],
        [0.0264, 0.0082, 0.0030,  ..., 0.0058, 0.0137, 0.0270],
        ...,
        [0.0035, 0.0074, 0.0249,  ..., 0.0032, 0.0013, 0.0244],
        [0.0036, 0.0109, 0.0128,  ..., 0.0042, 0.0010, 0.0214],
        [0.0083, 0.0086, 0.0047,  ..., 0.0014, 0.0041, 0.0207]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9972, 0.9972, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961,
         0.9961],
        [0.9975, 0.9972, 0.9971, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9838, 0.9810, 0.9792, 0.9788, 0.9768, 0.9766, 0.9761, 0.9760, 0.9754,
         0.9750],
        [0.9945, 0.9939, 0.9931, 0.9929, 0.9928, 0.9927, 0.9924, 0.9923, 0.9920,
         0.9915],
        [0.9901, 0.9884, 0.9880, 0.9877, 0.9869, 0.9866, 0.9863, 0.9862, 0.9860,
         0.9858],
        [0.9893, 0.9839, 0.9818, 0.9779, 0.9758, 0.9754, 0.9751, 0.9751, 0.9742,
         0.9726],
        [0.9745, 0.9739, 0.9731, 0.9715, 0.9714, 0.9690, 0.9689, 0.9682, 0.9675,
         0.9668],
        [0.9882, 0.9834, 0.9824, 0.9806, 0.9806, 0.9759, 0.9757, 0.9753, 0.9753,
         0.9749],
        [0.9979, 0.9977, 0.9977, 0.9975, 0.9975, 0.9973, 0.9973, 0.9971, 0.9971,
         0.9971],
        [0.9936, 0.9887, 0.9884, 0.9883, 0.9872, 0.9856, 0.9855, 0.9847, 0.9845,
         0.9843],
        [0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9951, 0.9949, 0.9937, 0.9934, 0.9932, 0.9928, 0.9917, 0.9911, 0.9910,
         0.9910],
        [0.9936, 0.9932, 0.9928, 0.9926, 0.9922, 0.9920, 0.9911, 0.9908, 0.9905,
         0.9895],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9965, 0.9962, 0.9961, 0.9960, 0.9956, 0.9956, 0.9954, 0.9953, 0.9953,
         0.9952],
        [0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9957, 0.9956, 0.9953,
         0.9953],
        [0.9951, 0.9950, 0.9948, 0.9945, 0.9944, 0.9943, 0.9941, 0.9940, 0.9940,
         0.9936],
        [0.9974, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9970],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9952, 0.9952, 0.9951, 0.9949, 0.9948, 0.9947, 0.9944, 0.9944, 0.9942,
         0.9938],
        [0.9982, 0.9977, 0.9975, 0.9972, 0.9971, 0.9969, 0.9969, 0.9969, 0.9967,
         0.9967],
        [0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9981],
        [0.9962, 0.9959, 0.9957, 0.9956, 0.9952, 0.9952, 0.9952, 0.9951, 0.9950,
         0.9950],
        [0.9983, 0.9983, 0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9983, 0.9981, 0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977,
         0.9976],
        [0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9987, 0.9987, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9987, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9900, 0.9836, 0.9834, 0.9822, 0.9812, 0.9802, 0.9793, 0.9783, 0.9744,
         0.9734],
        [0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9977, 0.9976, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9972, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9890, 0.9863, 0.9853, 0.9835, 0.9830, 0.9824, 0.9821, 0.9812, 0.9806,
         0.9805],
        [0.9964, 0.9963, 0.9961, 0.9959, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9936, 0.9934, 0.9918, 0.9917, 0.9910, 0.9907, 0.9906, 0.9906, 0.9903,
         0.9903],
        [0.9964, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9957, 0.9956,
         0.9956],
        [0.9878, 0.9863, 0.9859, 0.9847, 0.9846, 0.9844, 0.9826, 0.9820, 0.9818,
         0.9813],
        [0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9971, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9964],
        [0.9926, 0.9913, 0.9908, 0.9901, 0.9900, 0.9900, 0.9899, 0.9898, 0.9896,
         0.9889],
        [0.9873, 0.9867, 0.9855, 0.9851, 0.9847, 0.9845, 0.9844, 0.9842, 0.9840,
         0.9840],
        [0.9878, 0.9796, 0.9710, 0.9658, 0.9650, 0.9577, 0.9539, 0.9535, 0.9507,
         0.9502],
        [0.9791, 0.9759, 0.9733, 0.9720, 0.9697, 0.9672, 0.9662, 0.9653, 0.9647,
         0.9636],
        [0.9933, 0.9929, 0.9913, 0.9909, 0.9906, 0.9901, 0.9901, 0.9900, 0.9899,
         0.9899],
        [0.9942, 0.9940, 0.9940, 0.9940, 0.9940, 0.9939, 0.9935, 0.9933, 0.9931,
         0.9929],
        [0.9940, 0.9937, 0.9927, 0.9926, 0.9926, 0.9925, 0.9924, 0.9923, 0.9923,
         0.9921],
        [0.9891, 0.9890, 0.9886, 0.9885, 0.9883, 0.9871, 0.9870, 0.9866, 0.9864,
         0.9847],
        [0.9945, 0.9944, 0.9930, 0.9927, 0.9921, 0.9915, 0.9908, 0.9903, 0.9895,
         0.9893],
        [0.9917, 0.9908, 0.9903, 0.9884, 0.9877, 0.9872, 0.9866, 0.9859, 0.9857,
         0.9854],
        [0.9942, 0.9942, 0.9941, 0.9940, 0.9939, 0.9937, 0.9930, 0.9930, 0.9930,
         0.9929],
        [0.9950, 0.9948, 0.9947, 0.9944, 0.9942, 0.9939, 0.9934, 0.9934, 0.9932,
         0.9932],
        [0.9928, 0.9911, 0.9905, 0.9899, 0.9874, 0.9873, 0.9868, 0.9866, 0.9866,
         0.9865],
        [0.9928, 0.9925, 0.9924, 0.9884, 0.9874, 0.9872, 0.9865, 0.9863, 0.9848,
         0.9845],
        [0.9936, 0.9933, 0.9929, 0.9920, 0.9917, 0.9906, 0.9905, 0.9897, 0.9894,
         0.9890],
        [0.9964, 0.9952, 0.9939, 0.9935, 0.9931, 0.9921, 0.9913, 0.9906, 0.9901,
         0.9900],
        [0.9905, 0.9897, 0.9889, 0.9884, 0.9881, 0.9880, 0.9877, 0.9877, 0.9876,
         0.9873],
        [0.9887, 0.9871, 0.9857, 0.9848, 0.9843, 0.9842, 0.9842, 0.9840, 0.9834,
         0.9826],
        [0.9924, 0.9924, 0.9922, 0.9921, 0.9910, 0.9908, 0.9884, 0.9880, 0.9877,
         0.9871],
        [0.9939, 0.9932, 0.9930, 0.9927, 0.9915, 0.9914, 0.9911, 0.9911, 0.9907,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1538660.6250, 1537044.3750, 1521877.8750, 1521105.8750, 1519319.7500,
         1518818.5000, 1517404.0000, 1515138.0000, 1512916.0000, 1512540.8750],
        [1544662.0000, 1536699.8750, 1535640.6250, 1529079.1250, 1528189.8750,
         1526040.2500, 1525913.7500, 1525627.0000, 1524988.3750, 1524850.2500],
        [1269387.0000, 1219802.1250, 1189096.8750, 1181731.7500, 1148207.3750,
         1145040.5000, 1136698.7500, 1135708.3750, 1126124.6250, 1119209.2500],
        [1479833.7500, 1467393.8750, 1450009.1250, 1445709.2500, 1443067.3750,
         1441091.0000, 1436664.2500, 1433952.6250, 1426561.1250, 1417572.3750],
        [1388997.1250, 1356341.1250, 1347601.8750, 1341483.1250, 1326689.1250,
         1321854.6250, 1315631.7500, 1313936.6250, 1310891.3750, 1307005.2500],
        [1373131.7500, 1270607.8750, 1233358.3750, 1166856.3750, 1133019.0000,
         1125850.8750, 1121011.3750, 1120827.5000, 1106753.7500, 1082497.1250],
        [1112146.6250, 1101917.5000, 1090035.6250, 1065450.3750, 1063781.1250,
         1027498.7500, 1026087.6875, 1015365.3125, 1005385.6875,  995281.0625],
        [1352481.6250, 1262816.1250, 1245223.2500, 1212945.3750, 1212235.2500,
         1134709.1250, 1131647.6250, 1124968.6250, 1124454.7500, 1118537.1250],
        [1553884.6250, 1549034.3750, 1547711.3750, 1544339.5000, 1543303.0000,
         1539713.0000, 1539705.6250, 1535601.1250, 1534718.3750, 1534627.5000],
        [1461449.8750, 1360922.6250, 1355527.7500, 1353659.7500, 1333082.5000,
         1301960.7500, 1300629.1250, 1286781.3750, 1281863.7500, 1278574.5000],
        [1551120.3750, 1550375.0000, 1546122.6250, 1545873.3750, 1545409.1250,
         1544326.2500, 1544176.1250, 1541293.8750, 1540368.0000, 1540227.0000],
        [1492106.2500, 1487806.3750, 1461784.5000, 1455846.6250, 1452223.2500,
         1444857.6250, 1422168.1250, 1409896.8750, 1407786.1250, 1406909.7500],
        [1460962.1250, 1451524.1250, 1442986.1250, 1439503.1250, 1432253.8750,
         1427826.8750, 1409587.7500, 1403429.5000, 1396581.6250, 1378304.8750],
        [1566750.0000, 1564558.1250, 1562524.2500, 1562193.5000, 1561515.8750,
         1560753.5000, 1559234.5000, 1558607.1250, 1558372.2500, 1557093.2500],
        [1558295.0000, 1556677.3750, 1556098.6250, 1554381.0000, 1553130.5000,
         1552955.6250, 1552447.7500, 1551479.7500, 1551197.2500, 1549630.0000],
        [1550064.5000, 1549853.0000, 1548805.5000, 1548604.6250, 1547611.0000,
         1546239.1250, 1546135.8750, 1546003.1250, 1545947.1250, 1545086.3750],
        [1522537.0000, 1514756.6250, 1513805.0000, 1511423.3750, 1501894.2500,
         1501839.7500, 1498559.1250, 1497273.5000, 1495779.2500, 1495215.8750],
        [1519015.5000, 1518872.1250, 1517663.1250, 1515281.1250, 1514896.7500,
         1513669.2500, 1504064.3750, 1503727.1250, 1496692.3750, 1495774.8750],
        [1491138.8750, 1490701.0000, 1486513.0000, 1480004.6250, 1476545.0000,
         1474674.7500, 1470234.6250, 1468962.0000, 1468756.0000, 1460074.8750],
        [1541799.5000, 1538992.2500, 1538249.7500, 1537641.0000, 1536122.5000,
         1535166.2500, 1535052.0000, 1534847.0000, 1534633.3750, 1533489.3750],
        [1557758.6250, 1554685.0000, 1554529.2500, 1553343.7500, 1552555.8750,
         1550521.2500, 1548529.2500, 1546994.2500, 1546979.5000, 1546467.7500],
        [1494081.2500, 1493603.8750, 1492846.2500, 1487291.3750, 1486763.8750,
         1482749.5000, 1477975.0000, 1476646.3750, 1473101.8750, 1465364.6250],
        [1560326.3750, 1549613.7500, 1545053.8750, 1537667.3750, 1536162.1250,
         1532027.5000, 1532023.2500, 1531991.1250, 1527277.7500, 1527247.2500],
        [1566854.6250, 1566012.0000, 1563854.0000, 1563537.8750, 1563057.7500,
         1562987.7500, 1562125.0000, 1561307.3750, 1558675.5000, 1557660.6250],
        [1515271.0000, 1510123.8750, 1505151.8750, 1502960.2500, 1494622.7500,
         1494178.1250, 1493368.8750, 1491187.2500, 1490685.3750, 1489108.1250],
        [1562914.7500, 1562844.7500, 1557804.6250, 1556970.0000, 1556888.2500,
         1554603.3750, 1553675.6250, 1553049.0000, 1551216.5000, 1551204.6250],
        [1549166.0000, 1548976.8750, 1547594.7500, 1546983.8750, 1544017.0000,
         1543581.2500, 1543478.1250, 1541192.3750, 1540570.7500, 1539531.0000],
        [1561581.2500, 1556416.2500, 1556238.1250, 1554581.1250, 1554559.0000,
         1551059.6250, 1551030.1250, 1550922.1250, 1548201.5000, 1545923.6250],
        [1567395.6250, 1567162.3750, 1566182.3750, 1565880.7500, 1565646.2500,
         1565453.6250, 1564301.5000, 1563986.8750, 1563843.6250, 1563189.0000],
        [1571310.8750, 1569967.2500, 1568096.8750, 1566054.0000, 1564629.7500,
         1564526.8750, 1563834.6250, 1563660.1250, 1563020.6250, 1562722.3750],
        [1569787.6250, 1565919.5000, 1565138.6250, 1563891.3750, 1563690.0000,
         1563274.0000, 1563007.1250, 1562443.7500, 1562125.0000, 1560939.5000],
        [1568080.3750, 1567337.3750, 1564520.7500, 1563901.7500, 1563822.7500,
         1561611.0000, 1561375.8750, 1560863.6250, 1560714.7500, 1559085.7500],
        [1386788.0000, 1265525.1250, 1261980.6250, 1241613.5000, 1222957.6250,
         1205875.1250, 1191254.6250, 1174575.7500, 1110307.8750, 1094741.5000],
        [1533344.5000, 1531872.7500, 1528424.5000, 1526685.1250, 1525434.8750,
         1522089.7500, 1522036.1250, 1520786.7500, 1520403.8750, 1519942.8750],
        [1549269.3750, 1545372.2500, 1541955.3750, 1541521.7500, 1540659.0000,
         1540039.0000, 1539093.3750, 1537773.0000, 1537773.0000, 1537689.3750],
        [1536821.5000, 1531278.2500, 1527773.1250, 1527091.3750, 1526027.1250,
         1524779.0000, 1524640.8750, 1522869.5000, 1522666.1250, 1522160.8750],
        [1366664.8750, 1316207.8750, 1296992.5000, 1264876.0000, 1254816.0000,
         1244730.3750, 1239807.8750, 1223686.7500, 1212129.0000, 1211555.7500],
        [1520956.5000, 1517826.6250, 1513448.5000, 1509930.8750, 1505740.5000,
         1504750.0000, 1501892.7500, 1501222.6250, 1501010.6250, 1500031.8750],
        [1460608.3750, 1457064.7500, 1423162.6250, 1421398.0000, 1406302.0000,
         1402159.8750, 1400067.3750, 1399047.6250, 1393063.1250, 1392920.8750],
        [1519457.3750, 1513640.5000, 1511701.6250, 1509386.7500, 1509205.2500,
         1508542.0000, 1506642.6250, 1504783.1250, 1502990.2500, 1502099.0000],
        [1344930.1250, 1316435.1250, 1309203.5000, 1285621.0000, 1283488.2500,
         1280726.1250, 1248098.0000, 1236913.3750, 1233706.6250, 1225820.7500],
        [1553880.1250, 1551510.8750, 1550540.5000, 1549265.0000, 1549013.7500,
         1547904.7500, 1547237.6250, 1544157.0000, 1543796.1250, 1543725.5000],
        [1543285.3750, 1541386.5000, 1539924.5000, 1539754.1250, 1539582.3750,
         1539271.1250, 1539168.3750, 1539048.0000, 1537658.6250, 1537113.1250],
        [1535027.1250, 1527502.0000, 1527194.7500, 1524915.6250, 1524763.0000,
         1524677.1250, 1524498.3750, 1523786.1250, 1522008.3750, 1520525.7500],
        [1439069.3750, 1412564.3750, 1403957.0000, 1390256.1250, 1387584.3750,
         1387382.1250, 1384364.6250, 1383546.2500, 1378548.0000, 1366219.2500],
        [1335529.5000, 1322684.3750, 1300243.5000, 1293982.8750, 1286543.3750,
         1283255.7500, 1280588.1250, 1277878.5000, 1274050.2500, 1273932.5000],
        [1343960.8750, 1195083.6250, 1057854.8750,  982404.1250,  971331.1250,
          874593.6875,  828628.5625,  823957.1250,  791133.9375,  785601.8125],
        [1187086.8750, 1134378.1250, 1092544.8750, 1073474.0000, 1037407.8750,
         1002031.6875,  987643.1875,  975048.1875,  966952.0000,  951501.5625],
        [1453988.7500, 1445091.8750, 1412308.5000, 1405366.1250, 1399386.6250,
         1389650.2500, 1389407.7500, 1387253.6250, 1385301.0000, 1385200.6250],
        [1472127.1250, 1469750.8750, 1469135.6250, 1469085.2500, 1469011.0000,
         1467337.8750, 1457559.5000, 1454533.8750, 1450406.0000, 1446906.5000],
        [1469717.2500, 1463126.2500, 1442408.2500, 1440509.7500, 1439173.7500,
         1436928.7500, 1435804.1250, 1433578.0000, 1433252.6250, 1430523.0000],
        [1370002.8750, 1366907.3750, 1360390.6250, 1357147.1250, 1354302.7500,
         1330664.1250, 1329028.0000, 1321567.2500, 1316964.8750, 1285917.7500],
        [1479040.8750, 1478127.2500, 1447101.1250, 1441793.5000, 1428709.6250,
         1417767.0000, 1402287.0000, 1393787.2500, 1376656.1250, 1372947.0000],
        [1421341.0000, 1403002.5000, 1394063.8750, 1355503.1250, 1342769.3750,
         1333666.1250, 1320655.0000, 1308314.7500, 1305246.5000, 1299891.3750],
        [1473631.6250, 1472868.6250, 1469945.7500, 1469738.2500, 1466948.7500,
         1461882.1250, 1447719.5000, 1447028.0000, 1447028.0000, 1445669.3750],
        [1489782.8750, 1484705.1250, 1483843.1250, 1476726.7500, 1472537.2500,
         1466193.5000, 1456303.5000, 1455891.1250, 1452166.5000, 1451540.7500],
        [1444351.8750, 1409898.2500, 1398028.7500, 1384961.5000, 1337322.7500,
         1334409.1250, 1325027.6250, 1321097.1250, 1320573.2500, 1319081.6250],
        [1443264.1250, 1436871.1250, 1434699.5000, 1355689.3750, 1336375.5000,
         1332624.8750, 1320497.6250, 1315477.3750, 1287740.2500, 1281652.2500],
        [1459818.6250, 1453922.2500, 1445490.1250, 1427828.3750, 1420920.8750,
         1399787.1250, 1397530.1250, 1380991.6250, 1374706.6250, 1368450.2500],
        [1520340.1250, 1493267.8750, 1467710.1250, 1458602.5000, 1450549.8750,
         1428698.7500, 1412427.0000, 1399606.7500, 1389866.3750, 1387256.2500],
        [1397883.3750, 1381676.6250, 1365463.7500, 1356667.0000, 1349433.2500,
         1347337.2500, 1342409.6250, 1342268.7500, 1339937.2500, 1335702.7500],
        [1361599.0000, 1331739.2500, 1305540.2500, 1287940.3750, 1278162.5000,
         1277255.8750, 1276148.0000, 1274080.7500, 1262910.1250, 1247369.7500],
        [1436494.3750, 1434653.0000, 1431351.2500, 1429684.1250, 1406978.1250,
         1402702.8750, 1356794.0000, 1349052.3750, 1341746.7500, 1330099.5000],
        [1466424.2500, 1452310.5000, 1447954.2500, 1441991.5000, 1416948.0000,
         1414964.2500, 1409423.6250, 1409115.8750, 1401502.1250, 1392429.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1538660.6250,       0.0000],
         [1537044.3750,       0.0000],
         [1521877.8750,       0.0000],
         ...,
         [1515138.0000,       0.0000],
         [1512916.0000,       0.0000],
         [1512540.8750,       0.0000]],

        [[1544662.0000,       0.0000],
         [1536699.8750,       0.0000],
         [1535640.6250,       0.0000],
         ...,
         [1525627.0000,       0.0000],
         [1524988.3750,       0.0000],
         [1524850.2500,       0.0000]],

        [[1269387.0000,       0.0000],
         [1219802.1250,       0.0000],
         [1189096.8750,       0.0000],
         ...,
         [1135708.3750,       0.0000],
         [1126124.6250,       0.0000],
         [1119209.2500,       0.0000]],

        ...,

        [[1361599.0000,       0.0000],
         [1331739.2500,       0.0000],
         [      0.0000, 1305540.2500],
         ...,
         [      0.0000, 1274080.7500],
         [1262910.1250,       0.0000],
         [1247369.7500,       0.0000]],

        [[1436494.3750,       0.0000],
         [1434653.0000,       0.0000],
         [1431351.2500,       0.0000],
         ...,
         [      0.0000, 1349052.3750],
         [1341746.7500,       0.0000],
         [1330099.5000,       0.0000]],

        [[      0.0000, 1466424.2500],
         [      0.0000, 1452310.5000],
         [      0.0000, 1447954.2500],
         ...,
         [      0.0000, 1409115.8750],
         [      0.0000, 1401502.1250],
         [      0.0000, 1392429.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15214826.0000,        0.0000],
        [15301690.0000,        0.0000],
        [ 9344234.0000,  2326772.2500],
        [14441856.0000,        0.0000],
        [10701572.0000,  2628860.0000],
        [10600895.0000,  1133019.0000],
        [ 3194866.5000,  7308083.5000],
        [ 9669834.0000,  2250184.7500],
        [13888010.0000,  1534627.5000],
        [10666748.0000,  2647704.0000],
        [15449292.0000,        0.0000],
        [14441386.0000,        0.0000],
        [12864654.0000,  1378304.8750],
        [15611602.0000,        0.0000],
        [15536293.0000,        0.0000],
        [15474350.0000,        0.0000],
        [15053084.0000,        0.0000],
        [10563033.0000,  4536624.0000],
        [14767604.0000,        0.0000],
        [15365994.0000,        0.0000],
        [15512364.0000,        0.0000],
        [11843974.0000,  2986450.0000],
        [15379390.0000,        0.0000],
        [15626072.0000,        0.0000],
        [10487860.0000,  4498797.5000],
        [15561171.0000,        0.0000],
        [15445092.0000,        0.0000],
        [15530513.0000,        0.0000],
        [15653042.0000,        0.0000],
        [15657824.0000,        0.0000],
        [15640217.0000,        0.0000],
        [15631314.0000,        0.0000],
        [ 4708643.5000,  7446976.0000],
        [10670320.0000,  4580701.0000],
        [13870487.0000,  1540659.0000],
        [12207738.0000,  3058369.5000],
        [ 6183184.5000,  6448282.0000],
        [12045536.0000,  3031275.0000],
        [11238122.0000,  2917673.0000],
        [15088448.0000,        0.0000],
        [10231223.0000,  2533719.0000],
        [15481031.0000,        0.0000],
        [15396192.0000,        0.0000],
        [12196086.0000,  3058813.2500],
        [ 1383546.2500, 12549946.0000],
        [ 5125221.5000,  7803467.5000],
        [ 5075246.0000,  4579303.5000],
        [       0.0000, 10408068.0000],
        [ 9803950.0000,  4249005.0000],
        [10220369.0000,  4405484.5000],
        [11543440.0000,  2881582.0000],
        [       0.0000, 13392892.0000],
        [       0.0000, 14238217.0000],
        [ 1305246.5000, 12179208.0000],
        [10211371.0000,  4391089.0000],
        [ 8818900.0000,  5870790.0000],
        [ 1325027.6250, 12269724.0000],
        [ 1332624.8750, 12212267.0000],
        [       0.0000, 14129446.0000],
        [ 1389866.3750, 13018459.0000],
        [ 9496711.0000,  4062068.0000],
        [ 9045869.0000,  3856876.7500],
        [11213710.0000,  2705846.5000],
        [       0.0000, 14253064.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 211/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:48, 61.74s/it]  7%|▋         | 2/29 [01:02<11:41, 25.96s/it] 10%|█         | 3/29 [01:03<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.16s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 3.2358193397521973
Epoch 212/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:31, 56.84s/it]  7%|▋         | 2/29 [01:00<11:32, 25.64s/it] 10%|█         | 3/29 [01:01<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.234412670135498
Epoch 213/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<29:00, 62.15s/it]  7%|▋         | 2/29 [01:03<11:45, 26.13s/it] 10%|█         | 3/29 [01:03<06:20, 14.62s/it] 14%|█▍        | 4/29 [01:04<03:50,  9.21s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.22s/it] 21%|██        | 6/29 [01:06<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.53s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.04s/it]
Epoch loss is 3.2328038215637207
Epoch 214/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:42, 59.36s/it]  7%|▋         | 2/29 [01:00<11:25, 25.38s/it] 10%|█         | 3/29 [01:01<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:02<03:44,  8.96s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.2116146087646484
Epoch 215/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.49s/it]  7%|▋         | 2/29 [01:00<11:16, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.03s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.2168900966644287
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0094, 0.0019,  ..., 0.0059, 0.0009, 0.0203],
        [0.0023, 0.0098, 0.0020,  ..., 0.0045, 0.0009, 0.0186],
        [0.0276, 0.0091, 0.0028,  ..., 0.0057, 0.0141, 0.0266],
        ...,
        [0.0040, 0.0078, 0.0262,  ..., 0.0034, 0.0012, 0.0243],
        [0.0045, 0.0110, 0.0154,  ..., 0.0043, 0.0011, 0.0209],
        [0.0080, 0.0085, 0.0052,  ..., 0.0013, 0.0042, 0.0204]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9973, 0.9970, 0.9964, 0.9963, 0.9963, 0.9963, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9974, 0.9971, 0.9970, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9841, 0.9796, 0.9793, 0.9788, 0.9760, 0.9760, 0.9751, 0.9750, 0.9746,
         0.9746],
        [0.9943, 0.9935, 0.9929, 0.9929, 0.9923, 0.9923, 0.9922, 0.9921, 0.9918,
         0.9913],
        [0.9903, 0.9883, 0.9882, 0.9881, 0.9875, 0.9867, 0.9866, 0.9866, 0.9864,
         0.9862],
        [0.9890, 0.9843, 0.9819, 0.9774, 0.9765, 0.9758, 0.9754, 0.9737, 0.9731,
         0.9726],
        [0.9752, 0.9741, 0.9733, 0.9727, 0.9723, 0.9699, 0.9688, 0.9688, 0.9677,
         0.9675],
        [0.9880, 0.9840, 0.9808, 0.9801, 0.9800, 0.9769, 0.9759, 0.9751, 0.9751,
         0.9748],
        [0.9978, 0.9976, 0.9976, 0.9974, 0.9973, 0.9973, 0.9970, 0.9969, 0.9969,
         0.9969],
        [0.9936, 0.9880, 0.9876, 0.9876, 0.9874, 0.9858, 0.9851, 0.9849, 0.9848,
         0.9848],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9949, 0.9946, 0.9933, 0.9929, 0.9928, 0.9922, 0.9913, 0.9908, 0.9908,
         0.9907],
        [0.9931, 0.9926, 0.9920, 0.9918, 0.9918, 0.9910, 0.9907, 0.9902, 0.9893,
         0.9889],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9963, 0.9959, 0.9959, 0.9957, 0.9955, 0.9952, 0.9951, 0.9951, 0.9951,
         0.9950],
        [0.9963, 0.9963, 0.9963, 0.9962, 0.9960, 0.9959, 0.9958, 0.9956, 0.9953,
         0.9953],
        [0.9949, 0.9948, 0.9945, 0.9941, 0.9941, 0.9940, 0.9938, 0.9937, 0.9936,
         0.9935],
        [0.9973, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976,
         0.9975],
        [0.9952, 0.9948, 0.9947, 0.9946, 0.9945, 0.9945, 0.9944, 0.9942, 0.9939,
         0.9938],
        [0.9983, 0.9978, 0.9975, 0.9972, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968,
         0.9968],
        [0.9985, 0.9985, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9961, 0.9958, 0.9957, 0.9956, 0.9951, 0.9950, 0.9950, 0.9947, 0.9947,
         0.9946],
        [0.9984, 0.9984, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979,
         0.9978],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9976,
         0.9976],
        [0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9986, 0.9986, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9901, 0.9846, 0.9822, 0.9816, 0.9804, 0.9803, 0.9794, 0.9784, 0.9734,
         0.9732],
        [0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9977, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9971, 0.9968, 0.9968, 0.9967, 0.9967, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9893, 0.9861, 0.9852, 0.9840, 0.9831, 0.9828, 0.9826, 0.9819, 0.9806,
         0.9804],
        [0.9963, 0.9961, 0.9960, 0.9960, 0.9957, 0.9956, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9934, 0.9933, 0.9922, 0.9920, 0.9914, 0.9911, 0.9907, 0.9906, 0.9904,
         0.9903],
        [0.9963, 0.9961, 0.9960, 0.9959, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9877, 0.9867, 0.9862, 0.9853, 0.9850, 0.9847, 0.9834, 0.9822, 0.9820,
         0.9815],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9970, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9924, 0.9910, 0.9908, 0.9902, 0.9901, 0.9899, 0.9897, 0.9894, 0.9893,
         0.9888],
        [0.9871, 0.9857, 0.9852, 0.9844, 0.9842, 0.9842, 0.9840, 0.9840, 0.9834,
         0.9834],
        [0.9887, 0.9801, 0.9736, 0.9668, 0.9665, 0.9615, 0.9559, 0.9531, 0.9522,
         0.9518],
        [0.9784, 0.9753, 0.9735, 0.9721, 0.9689, 0.9674, 0.9659, 0.9645, 0.9642,
         0.9619],
        [0.9932, 0.9924, 0.9911, 0.9909, 0.9904, 0.9900, 0.9900, 0.9897, 0.9896,
         0.9896],
        [0.9942, 0.9940, 0.9940, 0.9939, 0.9939, 0.9938, 0.9934, 0.9933, 0.9929,
         0.9926],
        [0.9936, 0.9934, 0.9924, 0.9923, 0.9922, 0.9921, 0.9919, 0.9918, 0.9918,
         0.9918],
        [0.9889, 0.9889, 0.9883, 0.9881, 0.9880, 0.9870, 0.9867, 0.9865, 0.9858,
         0.9841],
        [0.9948, 0.9945, 0.9934, 0.9928, 0.9922, 0.9919, 0.9909, 0.9906, 0.9891,
         0.9888],
        [0.9919, 0.9907, 0.9905, 0.9883, 0.9881, 0.9869, 0.9865, 0.9863, 0.9857,
         0.9855],
        [0.9944, 0.9942, 0.9941, 0.9941, 0.9939, 0.9936, 0.9930, 0.9930, 0.9930,
         0.9929],
        [0.9951, 0.9950, 0.9948, 0.9945, 0.9944, 0.9942, 0.9935, 0.9934, 0.9933,
         0.9932],
        [0.9937, 0.9910, 0.9909, 0.9903, 0.9886, 0.9875, 0.9873, 0.9870, 0.9870,
         0.9869],
        [0.9930, 0.9924, 0.9923, 0.9883, 0.9875, 0.9872, 0.9865, 0.9864, 0.9847,
         0.9846],
        [0.9935, 0.9933, 0.9930, 0.9922, 0.9918, 0.9906, 0.9905, 0.9897, 0.9894,
         0.9889],
        [0.9964, 0.9952, 0.9940, 0.9935, 0.9933, 0.9924, 0.9915, 0.9908, 0.9903,
         0.9899],
        [0.9906, 0.9894, 0.9892, 0.9888, 0.9882, 0.9881, 0.9877, 0.9876, 0.9875,
         0.9871],
        [0.9889, 0.9869, 0.9856, 0.9849, 0.9842, 0.9839, 0.9835, 0.9832, 0.9832,
         0.9820],
        [0.9926, 0.9919, 0.9919, 0.9915, 0.9904, 0.9903, 0.9879, 0.9875, 0.9864,
         0.9862],
        [0.9938, 0.9931, 0.9930, 0.9927, 0.9914, 0.9913, 0.9911, 0.9908, 0.9906,
         0.9902]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 0, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 0, 1, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1539341.5000, 1534159.2500, 1519969.0000, 1518788.1250, 1518392.7500,
         1518046.6250, 1513607.2500, 1511703.0000, 1510870.0000, 1509781.1250],
        [1541160.0000, 1535705.1250, 1533407.5000, 1528834.1250, 1526644.2500,
         1525968.8750, 1525670.6250, 1524712.1250, 1524552.2500, 1524088.3750],
        [1274957.0000, 1196226.1250, 1189844.3750, 1181757.7500, 1135412.7500,
         1135299.0000, 1121477.6250, 1118934.0000, 1113873.5000, 1113511.3750],
        [1475573.6250, 1458393.8750, 1446643.0000, 1445173.1250, 1433949.8750,
         1433081.7500, 1430737.1250, 1430247.3750, 1424384.7500, 1413650.6250],
        [1392640.7500, 1353732.1250, 1352899.5000, 1349824.6250, 1338175.0000,
         1323300.0000, 1322330.0000, 1321607.5000, 1317088.0000, 1314251.1250],
        [1367483.6250, 1279184.3750, 1235288.8750, 1158022.1250, 1143899.0000,
         1133239.5000, 1126644.6250, 1098753.6250, 1090379.8750, 1082444.5000],
        [1123223.3750, 1104839.6250, 1093132.7500, 1083776.0000, 1077719.7500,
         1041021.3750, 1024963.8750, 1024203.7500, 1009408.3125, 1005288.9375],
        [1348576.5000, 1272707.1250, 1215889.3750, 1203684.0000, 1201751.3750,
         1150006.7500, 1134839.0000, 1122091.6250, 1121041.3750, 1117055.3750],
        [1549857.5000, 1545653.7500, 1545531.5000, 1541157.1250, 1540659.0000,
         1538684.0000, 1533629.7500, 1531685.7500, 1531168.7500, 1530203.8750],
        [1459754.7500, 1348919.8750, 1340466.3750, 1339948.7500, 1337609.7500,
         1306407.1250, 1292845.6250, 1290121.2500, 1288667.7500, 1288016.5000],
        [1550262.5000, 1549208.7500, 1546861.5000, 1544678.2500, 1544252.6250,
         1543394.2500, 1542126.0000, 1540980.7500, 1539642.5000, 1539597.0000],
        [1487239.0000, 1480781.1250, 1454987.5000, 1446194.7500, 1444364.3750,
         1431599.7500, 1414104.8750, 1403279.6250, 1402603.8750, 1400788.6250],
        [1451000.8750, 1440156.7500, 1428354.0000, 1424209.5000, 1423100.1250,
         1407696.1250, 1401907.2500, 1391934.3750, 1372533.3750, 1365241.0000],
        [1566367.5000, 1563256.0000, 1562591.3750, 1561168.7500, 1559824.8750,
         1558778.0000, 1557421.5000, 1557325.0000, 1556941.7500, 1555665.3750],
        [1558451.1250, 1557011.5000, 1555908.6250, 1555275.2500, 1552920.1250,
         1552520.3750, 1552425.5000, 1552102.8750, 1551907.5000, 1550487.3750],
        [1551399.8750, 1550641.1250, 1550040.7500, 1549473.2500, 1548780.3750,
         1547652.5000, 1546927.8750, 1546737.6250, 1546243.5000, 1545331.0000],
        [1518537.5000, 1509481.6250, 1509310.3750, 1504246.3750, 1500157.7500,
         1493790.5000, 1492326.8750, 1492167.3750, 1491498.6250, 1490497.6250],
        [1518536.0000, 1518378.2500, 1517362.0000, 1515011.0000, 1512304.3750,
         1510243.3750, 1506608.1250, 1502944.5000, 1497156.2500, 1495660.7500],
        [1486827.6250, 1486609.3750, 1479527.6250, 1471450.6250, 1470571.1250,
         1469692.0000, 1465090.7500, 1462480.2500, 1461490.2500, 1457391.3750],
        [1540269.6250, 1540121.2500, 1538152.8750, 1535062.2500, 1533416.2500,
         1533315.2500, 1532813.8750, 1532745.1250, 1532572.6250, 1532167.8750],
        [1557584.7500, 1555346.5000, 1553475.6250, 1553352.6250, 1552936.3750,
         1552854.8750, 1547978.5000, 1547859.0000, 1545622.7500, 1545167.3750],
        [1494909.2500, 1485760.3750, 1484651.2500, 1482431.3750, 1480363.2500,
         1479646.1250, 1477409.7500, 1473690.6250, 1467690.5000, 1463663.5000],
        [1561159.8750, 1551623.3750, 1544776.8750, 1536883.0000, 1536373.1250,
         1532625.2500, 1532466.0000, 1531091.2500, 1529826.0000, 1529824.5000],
        [1566373.6250, 1566142.1250, 1562971.3750, 1562950.5000, 1562418.5000,
         1562347.0000, 1560677.6250, 1560192.3750, 1557350.1250, 1557280.2500],
        [1513107.8750, 1506981.7500, 1504638.1250, 1501804.0000, 1491187.2500,
         1491029.3750, 1490874.3750, 1484129.0000, 1483363.5000, 1482372.1250],
        [1564197.1250, 1563144.3750, 1558734.8750, 1558021.6250, 1557730.3750,
         1556545.3750, 1555610.5000, 1553210.3750, 1552101.3750, 1551758.0000],
        [1550549.5000, 1549689.0000, 1549556.1250, 1546864.3750, 1545232.2500,
         1543556.2500, 1542871.8750, 1542354.0000, 1541329.1250, 1540018.5000],
        [1562369.2500, 1558656.2500, 1556879.3750, 1556125.3750, 1554883.7500,
         1553536.2500, 1551462.1250, 1549896.0000, 1547041.3750, 1546317.1250],
        [1568701.1250, 1568358.6250, 1567691.6250, 1566523.0000, 1566012.0000,
         1565096.7500, 1564607.3750, 1564582.0000, 1563776.5000, 1563285.8750],
        [1571505.6250, 1570723.5000, 1569214.2500, 1567525.6250, 1565519.3750,
         1564690.8750, 1564276.2500, 1563827.2500, 1563202.5000, 1563059.3750],
        [1569468.8750, 1566142.1250, 1566110.6250, 1564735.6250, 1564304.5000,
         1563854.0000, 1563508.1250, 1563369.3750, 1562260.5000, 1560975.2500],
        [1568605.3750, 1568467.7500, 1564435.8750, 1564083.7500, 1563663.1250,
         1562242.6250, 1561670.6250, 1561539.5000, 1560680.6250, 1559900.8750],
        [1389756.3750, 1285051.1250, 1240262.0000, 1230531.6250, 1210255.3750,
         1208309.8750, 1192344.6250, 1175272.6250, 1094214.3750, 1091422.2500],
        [1530600.7500, 1530428.5000, 1526392.5000, 1525880.1250, 1524233.7500,
         1521293.0000, 1519645.7500, 1518536.0000, 1518381.1250, 1518345.0000],
        [1547585.8750, 1540575.2500, 1540375.3750, 1540068.3750, 1538689.8750,
         1537880.0000, 1537195.3750, 1536669.1250, 1536421.5000, 1536018.6250],
        [1534996.5000, 1529693.1250, 1528404.1250, 1527270.5000, 1526862.7500,
         1522430.8750, 1521481.6250, 1520750.5000, 1520022.6250, 1519974.7500],
        [1373042.6250, 1311639.1250, 1295633.8750, 1274034.5000, 1257452.7500,
         1251900.7500, 1248295.5000, 1236251.7500, 1212736.0000, 1210280.7500],
        [1517703.6250, 1514649.7500, 1512499.0000, 1511025.6250, 1503933.7500,
         1502217.8750, 1500096.1250, 1499215.2500, 1498948.0000, 1496551.1250],
        [1457298.2500, 1454224.5000, 1431971.1250, 1426670.0000, 1415323.3750,
         1409845.8750, 1400655.1250, 1399123.7500, 1395842.5000, 1393630.5000],
        [1517396.7500, 1512943.3750, 1511169.7500, 1508992.2500, 1508160.7500,
         1505355.7500, 1504229.2500, 1503090.6250, 1502140.5000, 1501776.6250],
        [1342225.2500, 1323108.2500, 1314068.1250, 1296572.0000, 1291775.8750,
         1286098.0000, 1262402.0000, 1241878.8750, 1238323.7500, 1228532.3750],
        [1555898.2500, 1551170.6250, 1551003.5000, 1550765.3750, 1549059.6250,
         1548188.2500, 1547891.5000, 1546715.5000, 1546514.8750, 1545670.0000],
        [1542112.7500, 1540099.2500, 1539150.6250, 1539119.8750, 1538390.5000,
         1538384.7500, 1538205.7500, 1537460.7500, 1537441.6250, 1536500.6250],
        [1532312.5000, 1527216.6250, 1525806.0000, 1525190.5000, 1523858.7500,
         1523485.3750, 1522439.6250, 1520739.0000, 1520604.0000, 1520214.0000],
        [1436312.1250, 1407502.8750, 1403176.5000, 1390408.6250, 1389422.3750,
         1385542.7500, 1382012.7500, 1374569.0000, 1373055.7500, 1363983.8750],
        [1331220.0000, 1304065.7500, 1295892.1250, 1280501.3750, 1277753.0000,
         1276936.8750, 1273863.2500, 1272560.3750, 1262237.0000, 1262218.8750],
        [1361158.8750, 1203779.2500, 1097879.0000,  995451.0000,  991706.3125,
          923139.4375,  852452.1250,  818810.6875,  807927.9375,  803873.0000],
        [1174641.7500, 1123706.5000, 1095534.2500, 1074468.5000, 1026199.1875,
         1004131.5000,  983064.9375,  963706.8750,  959386.0625,  928513.0000],
        [1451625.1250, 1436450.5000, 1409361.8750, 1404295.7500, 1394368.3750,
         1387055.2500, 1386936.2500, 1381762.2500, 1379741.0000, 1378567.7500],
        [1472579.3750, 1468670.5000, 1468484.2500, 1467554.7500, 1466112.3750,
         1464660.5000, 1455846.6250, 1454631.0000, 1446478.8750, 1440688.5000],
        [1459651.6250, 1456260.5000, 1434885.6250, 1433500.1250, 1431654.2500,
         1429272.5000, 1426340.7500, 1424397.0000, 1423560.3750, 1423330.8750],
        [1365515.7500, 1365325.6250, 1354899.6250, 1349307.1250, 1348186.8750,
         1328799.8750, 1322978.2500, 1319851.7500, 1306930.6250, 1274662.7500],
        [1485549.2500, 1479077.6250, 1455671.7500, 1443533.8750, 1431676.1250,
         1424627.8750, 1405851.3750, 1398402.0000, 1369246.6250, 1362961.7500],
        [1424577.6250, 1401685.2500, 1397069.1250, 1354709.7500, 1350521.1250,
         1327295.2500, 1320514.0000, 1315628.0000, 1305154.5000, 1300658.8750],
        [1476823.8750, 1473280.2500, 1470321.3750, 1469973.7500, 1466383.7500,
         1461350.8750, 1448528.8750, 1447388.2500, 1447388.2500, 1446375.5000],
        [1492235.7500, 1489001.6250, 1484975.5000, 1479747.7500, 1476391.5000,
         1473520.6250, 1457780.6250, 1456895.2500, 1454034.5000, 1451914.5000],
        [1462276.6250, 1406963.2500, 1405596.6250, 1392911.6250, 1359648.7500,
         1337827.8750, 1334844.3750, 1330017.0000, 1328791.1250, 1327656.0000],
        [1447961.1250, 1436606.6250, 1432947.8750, 1354594.6250, 1338472.3750,
         1332793.8750, 1318804.8750, 1318540.7500, 1285767.0000, 1284830.5000],
        [1457890.3750, 1454800.2500, 1448955.7500, 1430723.5000, 1423605.1250,
         1399900.6250, 1397790.1250, 1380608.3750, 1375225.8750, 1364941.5000],
        [1521178.5000, 1494192.3750, 1469177.6250, 1458374.2500, 1454662.7500,
         1435779.3750, 1416916.8750, 1402740.3750, 1392603.5000, 1386281.6250],
        [1399185.1250, 1376337.2500, 1370957.0000, 1364137.3750, 1352475.1250,
         1350299.6250, 1342349.5000, 1340995.7500, 1339354.6250, 1331713.8750],
        [1366045.8750, 1328012.0000, 1303587.0000, 1290534.6250, 1276559.3750,
         1270826.0000, 1264661.2500, 1258297.2500, 1257968.5000, 1236612.6250],
        [1440413.6250, 1425890.6250, 1425471.8750, 1417905.0000, 1394989.5000,
         1393759.3750, 1345699.8750, 1339239.7500, 1317311.6250, 1313476.7500],
        [1463882.6250, 1450448.8750, 1448368.6250, 1440933.0000, 1416076.6250,
         1414036.2500, 1408995.0000, 1403871.2500, 1399593.5000, 1391330.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1539341.5000,       0.0000],
         [1534159.2500,       0.0000],
         [1519969.0000,       0.0000],
         ...,
         [1511703.0000,       0.0000],
         [1510870.0000,       0.0000],
         [      0.0000, 1509781.1250]],

        [[1541160.0000,       0.0000],
         [1535705.1250,       0.0000],
         [1533407.5000,       0.0000],
         ...,
         [1524712.1250,       0.0000],
         [1524552.2500,       0.0000],
         [1524088.3750,       0.0000]],

        [[1274957.0000,       0.0000],
         [1196226.1250,       0.0000],
         [      0.0000, 1189844.3750],
         ...,
         [1118934.0000,       0.0000],
         [1113873.5000,       0.0000],
         [      0.0000, 1113511.3750]],

        ...,

        [[1366045.8750,       0.0000],
         [1328012.0000,       0.0000],
         [1303587.0000,       0.0000],
         ...,
         [1258297.2500,       0.0000],
         [1257968.5000,       0.0000],
         [      0.0000, 1236612.6250]],

        [[1440413.6250,       0.0000],
         [1425890.6250,       0.0000],
         [1425471.8750,       0.0000],
         ...,
         [      0.0000, 1339239.7500],
         [1317311.6250,       0.0000],
         [1313476.7500,       0.0000]],

        [[      0.0000, 1463882.6250],
         [      0.0000, 1450448.8750],
         [      0.0000, 1448368.6250],
         ...,
         [      0.0000, 1403871.2500],
         [      0.0000, 1399593.5000],
         [1391330.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13684877.0000,  1509781.1250],
        [15290743.0000,        0.0000],
        [ 8142525.0000,  3438768.5000],
        [14391834.0000,        0.0000],
        [10733422.0000,  2652426.0000],
        [10571441.0000,  1143899.0000],
        [ 3195056.2500,  7392522.0000],
        [ 9644510.0000,  2243133.0000],
        [15388230.0000,        0.0000],
        [11952809.0000,  1339948.7500],
        [15441005.0000,        0.0000],
        [14365944.0000,        0.0000],
        [11368359.0000,  2737774.5000],
        [15599341.0000,        0.0000],
        [15539010.0000,        0.0000],
        [15483227.0000,        0.0000],
        [15002015.0000,        0.0000],
        [10555224.0000,  4538981.0000],
        [14711131.0000,        0.0000],
        [15350638.0000,        0.0000],
        [15512178.0000,        0.0000],
        [11819804.0000,  2970411.5000],
        [15386649.0000,        0.0000],
        [15618703.0000,        0.0000],
        [ 8968807.0000,  5980680.0000],
        [15571054.0000,        0.0000],
        [15452022.0000,        0.0000],
        [15537168.0000,        0.0000],
        [15658635.0000,        0.0000],
        [15663545.0000,        0.0000],
        [15644729.0000,        0.0000],
        [15635289.0000,        0.0000],
        [ 4656430.0000,  7460990.0000],
        [10657610.0000,  4576126.5000],
        [13852790.0000,  1538689.8750],
        [12193790.0000,  3058097.2500],
        [ 4990063.5000,  7681204.0000],
        [12029692.0000,  3027148.7500],
        [11273063.0000,  2911522.7500],
        [15075256.0000,        0.0000],
        [10266010.0000,  2558974.0000],
        [15492878.0000,        0.0000],
        [15386866.0000,        0.0000],
        [12188950.0000,  3052916.5000],
        [ 1389422.3750, 12516564.0000],
        [ 3813853.2500,  9023395.0000],
        [ 5201654.0000,  4654523.5000],
        [       0.0000, 10333352.0000],
        [ 8380252.0000,  5629913.0000],
        [10206449.0000,  4399257.0000],
        [11477699.0000,  2865154.5000],
        [       0.0000, 13336458.0000],
        [       0.0000, 14256598.0000],
        [ 1305154.5000, 12192659.0000],
        [10212140.0000,  4395674.0000],
        [ 8836056.0000,  5880442.5000],
        [       0.0000, 13686532.0000],
        [ 1338472.3750, 12212848.0000],
        [       0.0000, 14134442.0000],
        [ 1392603.5000, 13039304.0000],
        [ 9493356.0000,  4074449.0000],
        [ 7790470.0000,  5062634.5000],
        [11129218.0000,  2684939.5000],
        [ 1391330.3750, 12846206.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 216/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:47, 57.41s/it]  7%|▋         | 2/29 [00:58<10:52, 24.18s/it] 10%|█         | 3/29 [00:59<06:00, 13.88s/it] 14%|█▍        | 4/29 [01:00<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.06s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.48s/it] 31%|███       | 9/29 [01:05<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.21774959564209
Epoch 217/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:44, 57.29s/it]  7%|▋         | 2/29 [01:00<11:22, 25.29s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.05s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.2107157707214355
Epoch 218/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.43s/it]  7%|▋         | 2/29 [00:58<10:53, 24.19s/it] 10%|█         | 3/29 [00:59<05:52, 13.57s/it] 14%|█▍        | 4/29 [01:00<03:34,  8.58s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:04<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.06it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 3.1907598972320557
Epoch 219/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:35, 59.12s/it]  7%|▋         | 2/29 [01:00<11:19, 25.18s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.2043869495391846
Epoch 220/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:11, 58.28s/it]  7%|▋         | 2/29 [00:59<11:02, 24.54s/it] 10%|█         | 3/29 [01:00<05:57, 13.76s/it] 14%|█▍        | 4/29 [01:02<03:50,  9.23s/it] 17%|█▋        | 5/29 [01:03<02:29,  6.24s/it] 21%|██        | 6/29 [01:04<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:05<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:06<00:53,  2.53s/it] 31%|███       | 9/29 [01:07<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:07<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.1835691928863525
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0100, 0.0020,  ..., 0.0063, 0.0008, 0.0198],
        [0.0024, 0.0103, 0.0021,  ..., 0.0045, 0.0009, 0.0182],
        [0.0281, 0.0091, 0.0027,  ..., 0.0059, 0.0143, 0.0261],
        ...,
        [0.0046, 0.0081, 0.0268,  ..., 0.0034, 0.0013, 0.0238],
        [0.0053, 0.0113, 0.0176,  ..., 0.0044, 0.0012, 0.0206],
        [0.0075, 0.0087, 0.0051,  ..., 0.0014, 0.0040, 0.0202]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9971, 0.9968, 0.9963, 0.9962, 0.9962, 0.9960, 0.9959, 0.9959, 0.9958,
         0.9957],
        [0.9973, 0.9970, 0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9843, 0.9782, 0.9782, 0.9772, 0.9755, 0.9751, 0.9744, 0.9743, 0.9738,
         0.9733],
        [0.9934, 0.9925, 0.9924, 0.9924, 0.9923, 0.9921, 0.9914, 0.9913, 0.9913,
         0.9911],
        [0.9899, 0.9883, 0.9877, 0.9876, 0.9865, 0.9865, 0.9859, 0.9859, 0.9858,
         0.9855],
        [0.9884, 0.9850, 0.9807, 0.9771, 0.9765, 0.9754, 0.9745, 0.9736, 0.9733,
         0.9732],
        [0.9760, 0.9749, 0.9734, 0.9718, 0.9717, 0.9701, 0.9689, 0.9685, 0.9669,
         0.9666],
        [0.9861, 0.9842, 0.9777, 0.9775, 0.9773, 0.9769, 0.9738, 0.9732, 0.9728,
         0.9721],
        [0.9977, 0.9976, 0.9975, 0.9973, 0.9973, 0.9972, 0.9970, 0.9970, 0.9969,
         0.9969],
        [0.9933, 0.9871, 0.9869, 0.9862, 0.9860, 0.9839, 0.9836, 0.9828, 0.9825,
         0.9821],
        [0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9947, 0.9944, 0.9931, 0.9926, 0.9924, 0.9920, 0.9912, 0.9911, 0.9902,
         0.9899],
        [0.9928, 0.9924, 0.9921, 0.9914, 0.9911, 0.9907, 0.9901, 0.9898, 0.9891,
         0.9888],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9964, 0.9959, 0.9959, 0.9957, 0.9954, 0.9952, 0.9952, 0.9952, 0.9952,
         0.9951],
        [0.9962, 0.9962, 0.9961, 0.9960, 0.9958, 0.9958, 0.9955, 0.9955, 0.9953,
         0.9952],
        [0.9949, 0.9947, 0.9943, 0.9942, 0.9940, 0.9939, 0.9938, 0.9934, 0.9934,
         0.9931],
        [0.9974, 0.9973, 0.9973, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970,
         0.9970],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9954, 0.9946, 0.9946, 0.9944, 0.9943, 0.9942, 0.9941, 0.9939, 0.9938,
         0.9935],
        [0.9983, 0.9978, 0.9975, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9985, 0.9984, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9958, 0.9957, 0.9955, 0.9954, 0.9950, 0.9950, 0.9949, 0.9947, 0.9946,
         0.9944],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9984, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9987, 0.9987, 0.9987, 0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9987, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9904, 0.9853, 0.9814, 0.9808, 0.9807, 0.9799, 0.9792, 0.9787, 0.9733,
         0.9726],
        [0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9976, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9901, 0.9854, 0.9846, 0.9846, 0.9845, 0.9840, 0.9836, 0.9823, 0.9807,
         0.9802],
        [0.9960, 0.9959, 0.9959, 0.9957, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9934, 0.9929, 0.9928, 0.9922, 0.9922, 0.9913, 0.9907, 0.9907, 0.9905,
         0.9904],
        [0.9961, 0.9961, 0.9959, 0.9958, 0.9958, 0.9957, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9874, 0.9861, 0.9859, 0.9850, 0.9849, 0.9840, 0.9839, 0.9822, 0.9821,
         0.9813],
        [0.9981, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9971],
        [0.9968, 0.9968, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9920, 0.9906, 0.9903, 0.9902, 0.9899, 0.9899, 0.9896, 0.9890, 0.9889,
         0.9886],
        [0.9874, 0.9847, 0.9847, 0.9847, 0.9839, 0.9839, 0.9837, 0.9836, 0.9836,
         0.9826],
        [0.9896, 0.9809, 0.9760, 0.9689, 0.9681, 0.9640, 0.9590, 0.9568, 0.9549,
         0.9544],
        [0.9780, 0.9758, 0.9735, 0.9711, 0.9686, 0.9670, 0.9651, 0.9650, 0.9642,
         0.9611],
        [0.9930, 0.9919, 0.9909, 0.9908, 0.9899, 0.9898, 0.9897, 0.9895, 0.9891,
         0.9891],
        [0.9943, 0.9941, 0.9940, 0.9938, 0.9938, 0.9938, 0.9935, 0.9935, 0.9929,
         0.9927],
        [0.9935, 0.9932, 0.9925, 0.9923, 0.9921, 0.9920, 0.9919, 0.9918, 0.9918,
         0.9918],
        [0.9887, 0.9886, 0.9879, 0.9877, 0.9875, 0.9870, 0.9865, 0.9861, 0.9851,
         0.9839],
        [0.9947, 0.9945, 0.9933, 0.9927, 0.9925, 0.9920, 0.9913, 0.9907, 0.9888,
         0.9884],
        [0.9918, 0.9908, 0.9908, 0.9884, 0.9873, 0.9867, 0.9866, 0.9861, 0.9860,
         0.9853],
        [0.9945, 0.9943, 0.9943, 0.9942, 0.9940, 0.9937, 0.9932, 0.9931, 0.9930,
         0.9930],
        [0.9953, 0.9950, 0.9948, 0.9945, 0.9945, 0.9942, 0.9936, 0.9935, 0.9934,
         0.9932],
        [0.9940, 0.9910, 0.9905, 0.9903, 0.9886, 0.9873, 0.9872, 0.9871, 0.9871,
         0.9870],
        [0.9932, 0.9923, 0.9921, 0.9877, 0.9873, 0.9868, 0.9863, 0.9858, 0.9849,
         0.9844],
        [0.9933, 0.9932, 0.9929, 0.9920, 0.9918, 0.9907, 0.9904, 0.9893, 0.9892,
         0.9886],
        [0.9964, 0.9950, 0.9939, 0.9935, 0.9932, 0.9925, 0.9912, 0.9906, 0.9902,
         0.9896],
        [0.9904, 0.9892, 0.9891, 0.9889, 0.9883, 0.9883, 0.9875, 0.9871, 0.9871,
         0.9870],
        [0.9892, 0.9870, 0.9867, 0.9847, 0.9843, 0.9835, 0.9834, 0.9832, 0.9825,
         0.9822],
        [0.9928, 0.9917, 0.9916, 0.9912, 0.9903, 0.9900, 0.9873, 0.9872, 0.9856,
         0.9855],
        [0.9937, 0.9935, 0.9931, 0.9928, 0.9915, 0.9911, 0.9910, 0.9906, 0.9905,
         0.9902]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 1, 1, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 1, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 1, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1535047.7500, 1529547.2500, 1518596.8750, 1515833.3750, 1514980.5000,
         1512135.6250, 1509513.2500, 1509035.3750, 1507913.3750, 1504661.1250],
        [1540848.5000, 1534118.3750, 1531492.8750, 1530403.7500, 1526661.7500,
         1526217.8750, 1524640.8750, 1523832.6250, 1523664.1250, 1523248.5000],
        [1278512.3750, 1172174.2500, 1171564.0000, 1155492.5000, 1128483.3750,
         1121635.8750, 1109795.5000, 1107798.0000, 1101177.8750, 1093376.6250],
        [1455757.8750, 1437656.5000, 1435360.6250, 1435227.7500, 1434520.2500,
         1430273.2500, 1416256.2500, 1414167.0000, 1412417.5000, 1409283.8750],
        [1384845.2500, 1354167.1250, 1342530.0000, 1339593.6250, 1320069.5000,
         1318968.3750, 1308706.6250, 1308254.8750, 1306254.0000, 1301749.7500],
        [1355779.8750, 1291041.7500, 1214845.1250, 1154064.1250, 1143327.3750,
         1126223.5000, 1111500.7500, 1096784.3750, 1093400.7500, 1091279.7500],
        [1135548.1250, 1118688.6250, 1094762.2500, 1068958.6250, 1067820.5000,
         1044685.2500, 1026587.8125, 1019973.3750,  997633.1250,  992771.8125],
        [1311679.1250, 1277197.3750, 1163306.3750, 1160329.1250, 1156493.5000,
         1150905.2500, 1099911.1250, 1091521.2500, 1085259.0000, 1073658.3750],
        [1548411.2500, 1545488.6250, 1543737.2500, 1540177.1250, 1539316.6250,
         1537714.2500, 1533774.6250, 1532220.5000, 1530897.1250, 1530396.3750],
        [1454532.3750, 1330085.6250, 1327803.0000, 1314170.8750, 1310116.3750,
         1270710.8750, 1266276.1250, 1251231.1250, 1247058.1250, 1239062.0000],
        [1549282.6250, 1548647.5000, 1546960.3750, 1543983.1250, 1542957.1250,
         1542112.7500, 1540676.5000, 1540325.5000, 1539448.6250, 1539406.1250],
        [1482574.2500, 1477194.3750, 1450711.7500, 1439805.1250, 1435008.7500,
         1426562.5000, 1411437.2500, 1408548.8750, 1390539.8750, 1386149.5000],
        [1444039.2500, 1435101.7500, 1428675.6250, 1414413.8750, 1408882.0000,
         1401669.2500, 1389309.7500, 1384207.6250, 1370089.1250, 1362879.8750],
        [1565967.2500, 1561422.0000, 1560528.7500, 1560197.0000, 1559793.7500,
         1559441.2500, 1557313.0000, 1556934.3750, 1556714.6250, 1555680.2500],
        [1557589.2500, 1556199.5000, 1555647.6250, 1555267.7500, 1553243.0000,
         1552388.6250, 1551801.0000, 1551752.1250, 1551064.1250, 1550873.2500],
        [1552022.8750, 1551080.3750, 1549650.6250, 1548139.5000, 1548080.5000,
         1547228.8750, 1546722.7500, 1546410.2500, 1544358.6250, 1544355.7500],
        [1520479.3750, 1509863.2500, 1509483.1250, 1505094.5000, 1498147.5000,
         1495043.2500, 1494595.6250, 1494430.3750, 1493951.6250, 1491972.5000],
        [1516486.8750, 1516106.5000, 1513780.3750, 1511122.1250, 1508073.0000,
         1507073.7500, 1500707.2500, 1500096.1250, 1495720.7500, 1493418.7500],
        [1488764.3750, 1484035.6250, 1475838.2500, 1472572.3750, 1468793.8750,
         1466150.1250, 1464367.1250, 1456191.1250, 1455916.0000, 1450720.0000],
        [1542587.8750, 1539824.6250, 1539754.1250, 1536028.8750, 1533628.2500,
         1533237.8750, 1533172.0000, 1533084.3750, 1532827.0000, 1532685.2500],
        [1554923.6250, 1554667.2500, 1552992.7500, 1551624.7500, 1551476.8750,
         1548886.7500, 1547662.6250, 1545714.2500, 1544631.1250, 1544413.1250],
        [1498680.5000, 1482191.1250, 1481519.8750, 1476504.1250, 1474968.6250,
         1474040.6250, 1471177.1250, 1466622.8750, 1465128.3750, 1458740.2500],
        [1562065.3750, 1551781.7500, 1544105.3750, 1535381.5000, 1533347.5000,
         1532869.3750, 1530168.7500, 1529462.7500, 1528959.5000, 1528796.2500],
        [1566221.1250, 1564722.2500, 1563487.1250, 1561569.3750, 1560421.6250,
         1559967.7500, 1559329.6250, 1558858.2500, 1556747.2500, 1556500.8750],
        [1507723.5000, 1505431.8750, 1501269.8750, 1497790.5000, 1490122.3750,
         1488959.0000, 1488920.6250, 1483370.5000, 1481235.8750, 1477679.0000],
        [1564310.5000, 1562058.0000, 1558764.6250, 1558648.7500, 1558121.1250,
         1556499.2500, 1556171.3750, 1553090.3750, 1552986.7500, 1552854.8750],
        [1550553.8750, 1550413.3750, 1549112.7500, 1546101.8750, 1546085.6250,
         1544290.8750, 1543509.0000, 1542696.7500, 1542339.2500, 1542145.1250],
        [1563078.7500, 1559835.3750, 1557849.2500, 1555414.7500, 1555374.6250,
         1552905.3750, 1551414.6250, 1550549.5000, 1549983.1250, 1549198.5000],
        [1570325.1250, 1568991.3750, 1568959.8750, 1567878.5000, 1566415.3750,
         1565629.8750, 1565349.1250, 1564391.0000, 1564237.3750, 1563945.0000],
        [1571634.6250, 1571589.6250, 1570087.0000, 1568370.5000, 1564843.1250,
         1564749.1250, 1564492.5000, 1563691.3750, 1563045.8750, 1563023.6250],
        [1570205.3750, 1567050.3750, 1566947.2500, 1565738.7500, 1565141.6250,
         1564413.3750, 1564395.5000, 1564158.3750, 1563628.8750, 1562198.0000],
        [1568882.1250, 1568068.5000, 1566222.7500, 1565743.2500, 1564491.0000,
         1564413.3750, 1561422.0000, 1561167.3750, 1560829.3750, 1559893.3750],
        [1395838.5000, 1298004.6250, 1227320.2500, 1215757.2500, 1214446.5000,
         1201703.1250, 1189619.7500, 1180412.7500, 1093302.7500, 1082720.1250],
        [1529777.7500, 1529168.0000, 1528730.6250, 1526306.6250, 1524443.1250,
         1521410.5000, 1519951.5000, 1518472.3750, 1517592.1250, 1516551.8750],
        [1545864.5000, 1541490.7500, 1541371.6250, 1540725.0000, 1538079.5000,
         1536721.8750, 1536663.2500, 1536663.2500, 1535137.0000, 1535035.8750],
        [1531085.5000, 1526609.3750, 1526279.0000, 1524818.2500, 1522645.7500,
         1521110.2500, 1519006.7500, 1518750.5000, 1518666.3750, 1517632.6250],
        [1389070.0000, 1299156.5000, 1284529.1250, 1284012.1250, 1282072.8750,
         1272866.1250, 1266043.0000, 1242991.3750, 1214656.1250, 1206085.5000],
        [1511380.1250, 1509969.7500, 1508737.5000, 1505502.1250, 1501354.2500,
         1499208.1250, 1496018.8750, 1495003.3750, 1493498.5000, 1492963.1250],
        [1456468.7500, 1445279.2500, 1443865.7500, 1431909.7500, 1431097.5000,
         1412735.5000, 1401806.8750, 1400874.1250, 1397975.3750, 1395233.0000],
        [1514027.3750, 1513161.2500, 1509225.5000, 1508134.7500, 1506345.2500,
         1505900.0000, 1501480.2500, 1500920.3750, 1498640.5000, 1498564.7500],
        [1336035.2500, 1312298.5000, 1308216.2500, 1291801.7500, 1290505.1250,
         1273910.6250, 1271799.6250, 1241753.2500, 1239150.7500, 1224332.2500],
        [1557381.3750, 1553166.0000, 1551925.2500, 1551377.7500, 1549318.1250,
         1548960.6250, 1548820.2500, 1547342.5000, 1546921.8750, 1546755.2500],
        [1542098.1250, 1540650.1250, 1540047.7500, 1539550.0000, 1539055.2500,
         1538940.8750, 1538704.6250, 1538493.2500, 1538333.3750, 1536235.3750],
        [1529572.0000, 1528319.5000, 1524981.1250, 1524668.5000, 1523300.7500,
         1521171.1250, 1519480.5000, 1519286.3750, 1519214.0000, 1518854.7500],
        [1427027.8750, 1398252.7500, 1394038.6250, 1391120.8750, 1386005.3750,
         1385316.8750, 1379047.7500, 1367363.6250, 1366491.5000, 1359206.6250],
        [1336736.1250, 1286891.7500, 1286321.3750, 1286149.6250, 1272089.6250,
         1271119.5000, 1267420.2500, 1266719.2500, 1265273.0000, 1248784.8750],
        [1379654.2500, 1218525.5000, 1136246.8750, 1025901.7500, 1013956.4375,
          956975.4375,  890685.0000,  863412.4375,  840380.6250,  834365.6875],
        [1169422.0000, 1132626.8750, 1096072.3750, 1059775.5000, 1022050.3125,
          999121.2500,  972386.8125,  970371.0625,  959332.0625,  917388.3750],
        [1447295.7500, 1424508.2500, 1406049.8750, 1403326.5000, 1385200.6250,
         1383955.3750, 1380890.1250, 1378124.7500, 1370282.5000, 1370243.3750],
        [1475122.0000, 1470961.0000, 1468579.5000, 1465245.8750, 1464099.0000,
         1463909.1250, 1458591.3750, 1458238.0000, 1445003.6250, 1441405.7500],
        [1459076.8750, 1452384.0000, 1438498.6250, 1432902.7500, 1429970.5000,
         1428382.6250, 1426377.5000, 1423883.5000, 1423307.8750, 1423029.6250],
        [1362004.1250, 1359571.0000, 1346302.0000, 1343179.3750, 1338630.6250,
         1328552.8750, 1320204.2500, 1311421.5000, 1292581.7500, 1271939.1250],
        [1483203.5000, 1480423.8750, 1454755.8750, 1440861.5000, 1437163.0000,
         1427841.8750, 1412658.6250, 1401734.7500, 1364026.8750, 1356383.7500],
        [1422880.3750, 1403175.1250, 1402904.8750, 1356281.6250, 1334316.2500,
         1322685.6250, 1322034.8750, 1312421.1250, 1310318.8750, 1297413.1250],
        [1478856.1250, 1476111.3750, 1475219.1250, 1472387.0000, 1468445.1250,
         1463469.5000, 1452842.5000, 1450002.1250, 1448738.8750, 1448468.1250],
        [1495856.2500, 1490217.7500, 1484960.0000, 1479935.3750, 1478950.6250,
         1473768.0000, 1460499.6250, 1458221.3750, 1456131.2500, 1452795.3750],
        [1469540.6250, 1408021.1250, 1398090.1250, 1393540.1250, 1359865.3750,
         1333999.3750, 1332810.3750, 1330320.2500, 1330065.2500, 1328440.1250],
        [1451895.1250, 1433751.6250, 1430546.1250, 1343033.2500, 1334420.5000,
         1324999.7500, 1315556.5000, 1306417.1250, 1289519.6250, 1280293.7500],
        [1454855.7500, 1452668.0000, 1445972.7500, 1426713.5000, 1423463.8750,
         1400907.5000, 1395222.3750, 1374004.0000, 1371952.3750, 1360565.7500],
        [1519128.5000, 1490176.5000, 1465944.6250, 1457516.5000, 1451604.3750,
         1438174.8750, 1410866.7500, 1399269.1250, 1391435.2500, 1379529.1250],
        [1396160.6250, 1372269.0000, 1369230.8750, 1365040.6250, 1353255.7500,
         1353085.3750, 1337746.2500, 1330708.5000, 1330572.7500, 1329982.8750],
        [1371994.2500, 1329362.7500, 1322934.1250, 1286098.0000, 1279105.1250,
         1263669.0000, 1262167.2500, 1258902.1250, 1247037.8750, 1240886.7500],
        [1443839.5000, 1421021.1250, 1418364.8750, 1410551.8750, 1393948.2500,
         1387001.0000, 1335034.0000, 1333535.1250, 1303517.5000, 1300784.2500],
        [1462895.8750, 1458858.5000, 1449427.1250, 1443611.0000, 1417702.1250,
         1409696.5000, 1406520.6250, 1399158.3750, 1397996.7500, 1391311.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1535047.7500,       0.0000],
         [1529547.2500,       0.0000],
         [1518596.8750,       0.0000],
         ...,
         [1509035.3750,       0.0000],
         [1507913.3750,       0.0000],
         [1504661.1250,       0.0000]],

        [[1540848.5000,       0.0000],
         [1534118.3750,       0.0000],
         [1531492.8750,       0.0000],
         ...,
         [1523832.6250,       0.0000],
         [1523664.1250,       0.0000],
         [1523248.5000,       0.0000]],

        [[1278512.3750,       0.0000],
         [1172174.2500,       0.0000],
         [      0.0000, 1171564.0000],
         ...,
         [      0.0000, 1107798.0000],
         [1101177.8750,       0.0000],
         [1093376.6250,       0.0000]],

        ...,

        [[1371994.2500,       0.0000],
         [1329362.7500,       0.0000],
         [1322934.1250,       0.0000],
         ...,
         [1258902.1250,       0.0000],
         [1247037.8750,       0.0000],
         [      0.0000, 1240886.7500]],

        [[1443839.5000,       0.0000],
         [1421021.1250,       0.0000],
         [1418364.8750,       0.0000],
         ...,
         [      0.0000, 1333535.1250],
         [      0.0000, 1303517.5000],
         [1300784.2500,       0.0000]],

        [[      0.0000, 1462895.8750],
         [      0.0000, 1458858.5000],
         [      0.0000, 1449427.1250],
         ...,
         [      0.0000, 1399158.3750],
         [1397996.7500,       0.0000],
         [1391311.8750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15157265.0000,        0.0000],
        [15285130.0000,        0.0000],
        [ 8032165.0000,  3407845.5000],
        [14280921.0000,        0.0000],
        [11965070.0000,  1320069.5000],
        [10524183.0000,  1154064.1250],
        [ 3134412.2500,  7433017.5000],
        [ 9396691.0000,  2173569.5000],
        [13851738.0000,  1530396.3750],
        [11680961.0000,  1330085.6250],
        [15433800.0000,        0.0000],
        [14308533.0000,        0.0000],
        [11306300.0000,  2732969.0000],
        [15593992.0000,        0.0000],
        [15535826.0000,        0.0000],
        [15478050.0000,        0.0000],
        [15013062.0000,        0.0000],
        [10536976.0000,  4525609.5000],
        [14683350.0000,        0.0000],
        [15356830.0000,        0.0000],
        [15496993.0000,        0.0000],
        [11785863.0000,  2963711.0000],
        [15376938.0000,        0.0000],
        [15607826.0000,        0.0000],
        [ 8953248.0000,  5969255.5000],
        [15573505.0000,        0.0000],
        [15457248.0000,        0.0000],
        [15545604.0000,        0.0000],
        [15666122.0000,        0.0000],
        [15665528.0000,        0.0000],
        [15653878.0000,        0.0000],
        [15641134.0000,        0.0000],
        [ 3500180.5000,  8598945.0000],
        [10654909.0000,  4577495.0000],
        [13846262.0000,  1541490.7500],
        [12173716.0000,  3052888.5000],
        [ 5053607.0000,  7687875.5000],
        [11994928.0000,  3018707.2500],
        [11316912.0000,  2900334.5000],
        [15056400.0000,        0.0000],
        [10226202.0000,  2563601.5000],
        [15501970.0000,        0.0000],
        [15392109.0000,        0.0000],
        [12179796.0000,  3049052.5000],
        [ 1385316.8750, 12468554.0000],
        [ 2532693.2500, 10254812.0000],
        [ 5411721.0000,  4748383.0000],
        [       0.0000, 10298546.0000],
        [ 8333206.0000,  5616671.0000],
        [10214568.0000,  4396587.5000],
        [10046558.0000,  4291256.0000],
        [       0.0000, 13274387.0000],
        [       0.0000, 14259054.0000],
        [       0.0000, 13484432.0000],
        [10234828.0000,  4399711.0000],
        [ 8843234.0000,  5888102.0000],
        [       0.0000, 13684692.0000],
        [ 2614714.2500, 10895719.0000],
        [       0.0000, 14106326.0000],
        [ 1391435.2500, 13012210.0000],
        [ 8135997.0000,  5402055.5000],
        [ 7809336.0000,  5052821.0000],
        [ 9775511.0000,  3972086.5000],
        [ 2789308.5000, 11447870.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 221/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<29:05, 62.34s/it]  7%|▋         | 2/29 [01:03<11:47, 26.21s/it] 10%|█         | 3/29 [01:04<06:21, 14.66s/it] 14%|█▍        | 4/29 [01:05<03:51,  9.24s/it] 17%|█▋        | 5/29 [01:06<02:29,  6.24s/it] 21%|██        | 6/29 [01:06<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.53s/it] 31%|███       | 9/29 [01:09<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:10<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:16<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:17<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:18<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.05s/it]
Epoch loss is 3.1854207515716553
Epoch 222/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:08, 60.30s/it]  7%|▋         | 2/29 [01:01<11:25, 25.37s/it] 10%|█         | 3/29 [01:02<06:09, 14.21s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.96s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.174584150314331
Epoch 223/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:23, 56.54s/it]  7%|▋         | 2/29 [00:57<10:44, 23.87s/it] 10%|█         | 3/29 [00:58<05:48, 13.41s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.48s/it] 17%|█▋        | 5/29 [01:00<02:22,  5.96s/it] 21%|██        | 6/29 [01:01<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:02<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:03<00:51,  2.45s/it] 31%|███       | 9/29 [01:04<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.87s/it]
Epoch loss is 3.1770427227020264
Epoch 224/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:28, 58.88s/it]  7%|▋         | 2/29 [00:59<11:09, 24.79s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 3.1634979248046875
Epoch 225/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:47, 57.41s/it]  7%|▋         | 2/29 [01:01<11:40, 25.95s/it] 10%|█         | 3/29 [01:02<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.1635546684265137
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0100, 0.0018,  ..., 0.0063, 0.0007, 0.0186],
        [0.0023, 0.0107, 0.0018,  ..., 0.0046, 0.0009, 0.0176],
        [0.0285, 0.0089, 0.0021,  ..., 0.0053, 0.0147, 0.0259],
        ...,
        [0.0047, 0.0082, 0.0259,  ..., 0.0034, 0.0012, 0.0231],
        [0.0057, 0.0123, 0.0185,  ..., 0.0048, 0.0014, 0.0200],
        [0.0085, 0.0093, 0.0049,  ..., 0.0016, 0.0040, 0.0201]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9971, 0.9969, 0.9964, 0.9963, 0.9963, 0.9962, 0.9959, 0.9959, 0.9958,
         0.9957],
        [0.9971, 0.9971, 0.9969, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9841, 0.9783, 0.9773, 0.9746, 0.9740, 0.9734, 0.9727, 0.9716, 0.9708,
         0.9707],
        [0.9942, 0.9934, 0.9934, 0.9930, 0.9929, 0.9928, 0.9926, 0.9920, 0.9919,
         0.9911],
        [0.9909, 0.9890, 0.9890, 0.9884, 0.9882, 0.9882, 0.9880, 0.9878, 0.9875,
         0.9873],
        [0.9889, 0.9854, 0.9819, 0.9797, 0.9784, 0.9781, 0.9771, 0.9757, 0.9745,
         0.9743],
        [0.9733, 0.9732, 0.9730, 0.9708, 0.9707, 0.9703, 0.9684, 0.9680, 0.9677,
         0.9666],
        [0.9872, 0.9838, 0.9787, 0.9779, 0.9774, 0.9740, 0.9738, 0.9735, 0.9721,
         0.9720],
        [0.9978, 0.9977, 0.9975, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9970],
        [0.9940, 0.9887, 0.9882, 0.9880, 0.9870, 0.9860, 0.9856, 0.9856, 0.9850,
         0.9844],
        [0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9972, 0.9972, 0.9971, 0.9970,
         0.9970],
        [0.9943, 0.9943, 0.9936, 0.9928, 0.9924, 0.9922, 0.9922, 0.9921, 0.9915,
         0.9908],
        [0.9939, 0.9936, 0.9933, 0.9933, 0.9927, 0.9919, 0.9917, 0.9916, 0.9898,
         0.9897],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9979],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9963, 0.9961, 0.9960, 0.9957, 0.9956, 0.9955, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9963, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9955, 0.9953, 0.9952,
         0.9952],
        [0.9949, 0.9943, 0.9941, 0.9940, 0.9940, 0.9937, 0.9935, 0.9931, 0.9930,
         0.9930],
        [0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9973,
         0.9972],
        [0.9954, 0.9950, 0.9942, 0.9942, 0.9941, 0.9941, 0.9939, 0.9938, 0.9938,
         0.9936],
        [0.9984, 0.9979, 0.9975, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969,
         0.9968],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9980],
        [0.9965, 0.9958, 0.9957, 0.9957, 0.9954, 0.9950, 0.9950, 0.9949, 0.9948,
         0.9948],
        [0.9984, 0.9984, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979,
         0.9978],
        [0.9978, 0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9984, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9987, 0.9987, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9986, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9908, 0.9865, 0.9824, 0.9809, 0.9807, 0.9797, 0.9796, 0.9787, 0.9730,
         0.9723],
        [0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9965, 0.9963, 0.9963,
         0.9963],
        [0.9976, 0.9973, 0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9896, 0.9860, 0.9850, 0.9848, 0.9842, 0.9840, 0.9840, 0.9820, 0.9806,
         0.9805],
        [0.9962, 0.9961, 0.9960, 0.9959, 0.9958, 0.9956, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9936, 0.9933, 0.9933, 0.9931, 0.9931, 0.9926, 0.9919, 0.9915, 0.9913,
         0.9913],
        [0.9960, 0.9960, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9871, 0.9870, 0.9856, 0.9852, 0.9850, 0.9844, 0.9830, 0.9820, 0.9810,
         0.9805],
        [0.9981, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9973, 0.9972, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9971],
        [0.9966, 0.9966, 0.9964, 0.9964, 0.9962, 0.9962, 0.9962, 0.9962, 0.9960,
         0.9960],
        [0.9920, 0.9907, 0.9906, 0.9901, 0.9899, 0.9899, 0.9897, 0.9889, 0.9888,
         0.9887],
        [0.9873, 0.9861, 0.9854, 0.9850, 0.9849, 0.9844, 0.9844, 0.9842, 0.9841,
         0.9837],
        [0.9892, 0.9825, 0.9747, 0.9687, 0.9680, 0.9625, 0.9571, 0.9564, 0.9542,
         0.9532],
        [0.9780, 0.9766, 0.9744, 0.9717, 0.9688, 0.9668, 0.9649, 0.9647, 0.9641,
         0.9613],
        [0.9937, 0.9921, 0.9908, 0.9901, 0.9899, 0.9896, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9937, 0.9934, 0.9933, 0.9933, 0.9931, 0.9930, 0.9926, 0.9925, 0.9923,
         0.9922],
        [0.9935, 0.9933, 0.9921, 0.9920, 0.9919, 0.9919, 0.9919, 0.9918, 0.9917,
         0.9917],
        [0.9882, 0.9879, 0.9875, 0.9873, 0.9872, 0.9868, 0.9863, 0.9859, 0.9841,
         0.9835],
        [0.9949, 0.9946, 0.9937, 0.9925, 0.9923, 0.9921, 0.9912, 0.9910, 0.9886,
         0.9886],
        [0.9919, 0.9912, 0.9905, 0.9886, 0.9873, 0.9873, 0.9869, 0.9868, 0.9860,
         0.9853],
        [0.9942, 0.9941, 0.9938, 0.9935, 0.9934, 0.9932, 0.9928, 0.9926, 0.9924,
         0.9924],
        [0.9951, 0.9943, 0.9943, 0.9942, 0.9939, 0.9935, 0.9935, 0.9929, 0.9929,
         0.9925],
        [0.9944, 0.9911, 0.9904, 0.9902, 0.9892, 0.9875, 0.9875, 0.9875, 0.9873,
         0.9872],
        [0.9932, 0.9923, 0.9923, 0.9879, 0.9876, 0.9869, 0.9864, 0.9855, 0.9853,
         0.9851],
        [0.9931, 0.9930, 0.9930, 0.9922, 0.9918, 0.9906, 0.9901, 0.9889, 0.9886,
         0.9885],
        [0.9963, 0.9951, 0.9937, 0.9937, 0.9931, 0.9926, 0.9914, 0.9906, 0.9901,
         0.9892],
        [0.9906, 0.9891, 0.9891, 0.9882, 0.9881, 0.9880, 0.9875, 0.9870, 0.9870,
         0.9868],
        [0.9897, 0.9879, 0.9869, 0.9846, 0.9844, 0.9842, 0.9842, 0.9834, 0.9832,
         0.9830],
        [0.9925, 0.9914, 0.9913, 0.9908, 0.9894, 0.9890, 0.9869, 0.9863, 0.9851,
         0.9848],
        [0.9934, 0.9931, 0.9928, 0.9925, 0.9914, 0.9909, 0.9908, 0.9905, 0.9903,
         0.9898]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 1, 1, 0, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1535274.6250, 1530508.8750, 1520189.3750, 1517747.0000, 1517145.0000,
         1515169.8750, 1509242.6250, 1508721.7500, 1507096.7500, 1505727.6250],
        [1536330.6250, 1536198.7500, 1530994.8750, 1526417.2500, 1525867.0000,
         1525817.6250, 1524934.6250, 1523408.2500, 1522452.6250, 1522287.1250],
        [1274971.6250, 1174436.7500, 1157641.1250, 1113095.1250, 1103601.2500,
         1094956.5000, 1083308.8750, 1066143.5000, 1054788.3750, 1052760.3750],
        [1473703.2500, 1456386.8750, 1456141.0000, 1448737.3750, 1445805.8750,
         1443701.8750, 1439797.0000, 1428231.3750, 1425655.3750, 1409434.3750],
        [1404495.2500, 1368086.2500, 1367584.0000, 1356303.6250, 1352845.5000,
         1351307.0000, 1347985.0000, 1344232.6250, 1338801.7500, 1333874.7500],
        [1365450.6250, 1299743.7500, 1235407.8750, 1196893.7500, 1174705.6250,
         1170966.3750, 1153947.3750, 1130934.3750, 1111137.2500, 1109141.6250],
        [1093026.3750, 1091900.1250, 1088836.6250, 1055109.3750, 1052618.8750,
         1046273.6250, 1018663.9375, 1012650.8750, 1008607.6875,  992448.1250],
        [1332546.0000, 1268795.2500, 1180725.7500, 1167532.0000, 1159083.8750,
         1104524.6250, 1100690.7500, 1095829.8750, 1074093.6250, 1073088.1250],
        [1551475.3750, 1548328.5000, 1544642.8750, 1540000.8750, 1539880.5000,
         1539288.6250, 1538628.2500, 1536823.0000, 1536814.2500, 1532407.5000],
        [1469504.2500, 1362523.8750, 1352448.1250, 1348351.3750, 1329549.1250,
         1310194.0000, 1303340.8750, 1302330.8750, 1291256.0000, 1280131.3750],
        [1546663.8750, 1546270.0000, 1544283.5000, 1542378.8750, 1541089.5000,
         1538656.1250, 1537406.5000, 1536381.8750, 1534018.8750, 1533714.5000],
        [1476195.8750, 1476021.2500, 1459866.1250, 1444626.1250, 1436065.7500,
         1431455.0000, 1430567.8750, 1429215.1250, 1417366.8750, 1403283.6250],
        [1466638.2500, 1460508.1250, 1454183.0000, 1453859.8750, 1441733.0000,
         1426180.2500, 1422274.0000, 1419728.8750, 1383182.2500, 1381731.8750],
        [1563988.2500, 1560758.0000, 1559914.2500, 1559479.8750, 1557812.1250,
         1556707.1250, 1556592.8750, 1554815.5000, 1554398.8750, 1553838.6250],
        [1555528.8750, 1555239.6250, 1553896.3750, 1551752.1250, 1551342.2500,
         1551257.8750, 1549059.6250, 1548160.2500, 1547768.8750, 1547506.2500],
        [1549859.0000, 1548547.1250, 1546863.0000, 1546340.8750, 1546284.8750,
         1545661.1250, 1545357.5000, 1544233.5000, 1543258.8750, 1543198.5000],
        [1518203.0000, 1512538.0000, 1510363.0000, 1504328.1250, 1502272.3750,
         1501023.5000, 1495706.3750, 1493713.6250, 1493212.2500, 1491403.3750],
        [1517126.2500, 1513044.3750, 1512277.0000, 1509275.8750, 1509198.1250,
         1506598.0000, 1501589.0000, 1495359.8750, 1495006.1250, 1494424.6250],
        [1486971.0000, 1476048.0000, 1471569.8750, 1468553.0000, 1468418.5000,
         1461770.5000, 1459366.2500, 1450977.3750, 1447651.8750, 1447224.0000],
        [1535772.5000, 1533490.7500, 1532658.8750, 1531554.2500, 1530695.6250,
         1527614.2500, 1527458.3750, 1527245.7500, 1526843.8750, 1525606.6250],
        [1552634.3750, 1548185.2500, 1547803.0000, 1545335.5000, 1545308.8750,
         1545112.8750, 1543423.7500, 1542352.5000, 1540763.2500, 1537356.5000],
        [1498034.7500, 1490426.6250, 1474119.3750, 1473503.7500, 1471425.5000,
         1470695.8750, 1466364.1250, 1465416.3750, 1464994.2500, 1460225.3750],
        [1563828.6250, 1552489.2500, 1544399.8750, 1534766.6250, 1534052.5000,
         1533640.0000, 1532118.1250, 1531237.3750, 1530508.8750, 1529462.7500],
        [1565296.8750, 1563619.8750, 1562525.7500, 1561295.5000, 1559981.1250,
         1559335.6250, 1557663.5000, 1557149.7500, 1556983.3750, 1554911.8750],
        [1522008.3750, 1506101.0000, 1505131.7500, 1504854.8750, 1497700.5000,
         1490583.0000, 1489930.6250, 1487057.5000, 1486388.1250, 1485822.7500],
        [1564965.5000, 1564565.6250, 1558054.2500, 1557913.1250, 1556747.2500,
         1556545.3750, 1555272.2500, 1552976.5000, 1552285.0000, 1551880.8750],
        [1551473.8750, 1550976.8750, 1549833.8750, 1546323.1250, 1546283.3750,
         1543124.8750, 1543057.2500, 1542298.1250, 1541074.8750, 1539830.5000],
        [1563800.3750, 1559323.7500, 1558006.7500, 1555637.1250, 1555073.5000,
         1554299.5000, 1553357.1250, 1551399.8750, 1550531.6250, 1550339.5000],
        [1568964.5000, 1568907.5000, 1567975.7500, 1567942.7500, 1565646.2500,
         1564841.6250, 1564556.6250, 1563758.6250, 1563561.7500, 1563005.6250],
        [1571378.2500, 1571002.2500, 1568005.6250, 1566440.7500, 1564258.2500,
         1563275.3750, 1562823.7500, 1562114.5000, 1561116.7500, 1559961.7500],
        [1569003.3750, 1565110.2500, 1564835.7500, 1564799.8750, 1564599.8750,
         1563615.5000, 1562962.5000, 1562706.0000, 1561046.7500, 1560786.2500],
        [1568192.6250, 1564959.6250, 1562624.1250, 1561843.5000, 1560615.1250,
         1560609.1250, 1559234.5000, 1558534.2500, 1557625.0000, 1557515.0000],
        [1402558.5000, 1320530.2500, 1244858.7500, 1217996.8750, 1214162.8750,
         1197994.6250, 1196343.7500, 1179686.8750, 1087475.2500, 1078081.5000],
        [1529179.7500, 1528837.0000, 1526851.0000, 1526647.2500, 1526030.1250,
         1524217.7500, 1522937.7500, 1518669.2500, 1518433.2500, 1518059.6250],
        [1547125.5000, 1539921.5000, 1539713.0000, 1539015.7500, 1538601.8750,
         1535869.1250, 1535869.1250, 1535721.2500, 1535580.6250, 1534836.8750],
        [1531087.0000, 1524294.8750, 1523906.7500, 1521671.7500, 1520506.8750,
         1520202.3750, 1519261.8750, 1519125.6250, 1517935.2500, 1517825.1250],
        [1379342.3750, 1309985.3750, 1292543.5000, 1288590.2500, 1277662.7500,
         1274124.3750, 1272713.2500, 1237102.0000, 1212634.1250, 1210430.8750],
        [1514928.6250, 1513100.6250, 1511325.3750, 1509547.8750, 1506743.2500,
         1503222.5000, 1499375.2500, 1497857.5000, 1497219.1250, 1496803.7500],
        [1459831.2500, 1454488.0000, 1454210.7500, 1449840.5000, 1449304.0000,
         1439245.0000, 1425602.3750, 1418045.6250, 1412934.8750, 1412903.8750],
        [1512503.3750, 1511492.5000, 1503659.8750, 1501755.2500, 1500685.7500,
         1499923.1250, 1498181.8750, 1496995.0000, 1496259.8750, 1496124.5000],
        [1331201.0000, 1328545.2500, 1302825.1250, 1295733.8750, 1291639.0000,
         1280927.6250, 1255188.2500, 1237165.8750, 1220335.1250, 1211377.7500],
        [1556748.7500, 1549523.6250, 1549519.1250, 1547904.7500, 1547620.0000,
         1546477.8750, 1545736.3750, 1545677.2500, 1545474.0000, 1545093.7500],
        [1538741.1250, 1537473.7500, 1537350.7500, 1536748.1250, 1536122.5000,
         1536097.6250, 1535391.7500, 1535179.3750, 1534989.1250, 1534642.2500],
        [1523726.5000, 1523360.5000, 1520093.7500, 1519264.7500, 1516418.8750,
         1516209.2500, 1515763.8750, 1514982.0000, 1512356.2500, 1511948.1250],
        [1428148.3750, 1400676.3750, 1398868.8750, 1388459.3750, 1385624.7500,
         1384746.2500, 1380712.3750, 1365991.1250, 1363093.1250, 1361112.1250],
        [1335627.5000, 1311635.3750, 1299170.1250, 1291938.3750, 1290435.0000,
         1280074.0000, 1280072.7500, 1277204.7500, 1275483.6250, 1267202.6250],
        [1372450.8750, 1245636.5000, 1114120.0000, 1023794.5625, 1012846.0000,
          937096.6875,  867368.0625,  858044.8125,  831851.0625,  820233.1250],
        [1169498.8750, 1145835.8750, 1109655.8750, 1068303.2500, 1024517.3125,
          996390.3750,  968739.0000,  966939.1875,  958468.7500,  920140.5000],
        [1463490.3750, 1428540.6250, 1402838.0000, 1388470.0000, 1385471.5000,
         1378577.0000, 1377303.5000, 1375944.7500, 1375577.3750, 1374358.0000],
        [1462919.6250, 1455780.0000, 1454658.7500, 1453430.1250, 1449309.6250,
         1448814.8750, 1440035.8750, 1438620.7500, 1432947.8750, 1430753.5000],
        [1459174.3750, 1454601.7500, 1430517.3750, 1428459.0000, 1426236.0000,
         1426071.5000, 1425992.5000, 1422575.1250, 1421547.0000, 1420460.2500],
        [1351334.1250, 1346868.2500, 1338731.5000, 1334680.2500, 1333462.6250,
         1324828.0000, 1316433.7500, 1308974.8750, 1275124.7500, 1265153.5000],
        [1488768.7500, 1480517.1250, 1462448.1250, 1438384.7500, 1434404.0000,
         1430033.2500, 1410948.7500, 1408132.5000, 1360598.2500, 1360128.6250],
        [1426007.5000, 1411267.6250, 1396808.0000, 1359386.8750, 1334714.6250,
         1333947.2500, 1326801.7500, 1324594.2500, 1309860.3750, 1297518.2500],
        [1473547.2500, 1472003.7500, 1464189.7500, 1457541.5000, 1457053.7500,
         1451555.8750, 1444413.8750, 1439223.1250, 1435902.6250, 1434728.2500],
        [1491599.7500, 1475442.8750, 1474902.6250, 1473692.1250, 1465757.3750,
         1458374.2500, 1457688.7500, 1445389.5000, 1444962.2500, 1437881.3750],
        [1477315.5000, 1409341.6250, 1395460.5000, 1391471.1250, 1371765.2500,
         1339410.8750, 1339066.0000, 1338349.7500, 1334959.0000, 1332058.1250],
        [1452064.1250, 1433148.7500, 1432604.8750, 1346304.5000, 1339753.2500,
         1326558.7500, 1316868.2500, 1301532.5000, 1296377.8750, 1293452.3750],
        [1450906.8750, 1448859.0000, 1447446.2500, 1431653.0000, 1422781.2500,
         1398466.0000, 1388663.3750, 1366307.8750, 1360271.2500, 1358455.0000],
        [1518036.6250, 1491999.5000, 1462265.3750, 1461614.3750, 1451110.2500,
         1439828.6250, 1415230.1250, 1400209.0000, 1389247.5000, 1370781.7500],
        [1398975.6250, 1369672.3750, 1368640.7500, 1351247.8750, 1349617.3750,
         1347318.0000, 1338813.2500, 1328296.8750, 1328141.1250, 1325263.8750],
        [1381581.7500, 1345330.3750, 1326367.7500, 1285031.5000, 1281037.6250,
         1277158.5000, 1276552.0000, 1261691.8750, 1258879.3750, 1255087.7500],
        [1438439.7500, 1415385.3750, 1414262.7500, 1402690.8750, 1376367.3750,
         1367394.8750, 1326458.8750, 1316401.1250, 1294296.2500, 1287675.1250],
        [1455960.5000, 1450085.1250, 1444368.3750, 1437012.3750, 1415706.6250,
         1404428.2500, 1403630.2500, 1397398.2500, 1392280.7500, 1383253.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1535274.6250,       0.0000],
         [1530508.8750,       0.0000],
         [1520189.3750,       0.0000],
         ...,
         [1508721.7500,       0.0000],
         [1507096.7500,       0.0000],
         [1505727.6250,       0.0000]],

        [[1536330.6250,       0.0000],
         [1536198.7500,       0.0000],
         [1530994.8750,       0.0000],
         ...,
         [1523408.2500,       0.0000],
         [1522452.6250,       0.0000],
         [1522287.1250,       0.0000]],

        [[1274971.6250,       0.0000],
         [      0.0000, 1174436.7500],
         [1157641.1250,       0.0000],
         ...,
         [      0.0000, 1066143.5000],
         [      0.0000, 1054788.3750],
         [      0.0000, 1052760.3750]],

        ...,

        [[1381581.7500,       0.0000],
         [1345330.3750,       0.0000],
         [1326367.7500,       0.0000],
         ...,
         [      0.0000, 1261691.8750],
         [1258879.3750,       0.0000],
         [1255087.7500,       0.0000]],

        [[1438439.7500,       0.0000],
         [1415385.3750,       0.0000],
         [1414262.7500,       0.0000],
         ...,
         [      0.0000, 1316401.1250],
         [      0.0000, 1294296.2500],
         [1287675.1250,       0.0000]],

        [[      0.0000, 1455960.5000],
         [      0.0000, 1450085.1250],
         [      0.0000, 1444368.3750],
         ...,
         [      0.0000, 1397398.2500],
         [      0.0000, 1392280.7500],
         [      0.0000, 1383253.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13657580.0000,  1509242.6250],
        [15274710.0000,        0.0000],
        [ 6827574.5000,  4348129.0000],
        [14427595.0000,        0.0000],
        [10875407.0000,  2690108.7500],
        [10751434.0000,  1196893.7500],
        [ 3151951.0000,  7308184.5000],
        [10456219.0000,  1100690.7500],
        [13875882.0000,  1532407.5000],
        [12001279.0000,  1348351.3750],
        [15400864.0000,        0.0000],
        [14404663.0000,        0.0000],
        [12928288.0000,  1381731.8750],
        [15578306.0000,        0.0000],
        [15511512.0000,        0.0000],
        [15459604.0000,        0.0000],
        [13529050.0000,  1493713.6250],
        [12035184.0000,  3018715.2500],
        [14638550.0000,        0.0000],
        [15298941.0000,        0.0000],
        [15448276.0000,        0.0000],
        [11790391.0000,  2944815.2500],
        [15386504.0000,        0.0000],
        [15598763.0000,        0.0000],
        [10467892.0000,  4507687.0000],
        [15571206.0000,        0.0000],
        [15454276.0000,        0.0000],
        [15551769.0000,        0.0000],
        [15659162.0000,        0.0000],
        [15650377.0000,        0.0000],
        [15639466.0000,        0.0000],
        [15611754.0000,        0.0000],
        [ 3503467.0000,  8636222.0000],
        [10659614.0000,  4580248.5000],
        [13842542.0000,  1539713.0000],
        [12167616.0000,  3048201.5000],
        [ 5056965.0000,  7698164.0000],
        [12028452.0000,  3021672.0000],
        [11462087.0000,  2914319.2500],
        [15017581.0000,        0.0000],
        [10204017.0000,  2550922.0000],
        [15479776.0000,        0.0000],
        [15362736.0000,        0.0000],
        [12138407.0000,  3035716.7500],
        [ 1388459.3750, 12468973.0000],
        [ 3822760.0000,  9086084.0000],
        [ 5338388.0000,  4745053.5000],
        [       0.0000, 10328490.0000],
        [ 8344089.0000,  5606482.0000],
        [10113366.0000,  4353904.5000],
        [11467067.0000,  2848567.5000],
        [       0.0000, 13195591.0000],
        [       0.0000, 14274364.0000],
        [       0.0000, 13520907.0000],
        [10145386.0000,  4384774.0000],
        [ 8756538.0000,  5869153.5000],
        [       0.0000, 13729197.0000],
        [ 2642682.5000, 10895982.0000],
        [       0.0000, 14073809.0000],
        [ 1389247.5000, 13011076.0000],
        [ 9461434.0000,  4044553.5000],
        [ 9128830.0000,  3819888.0000],
        [ 9702216.0000,  3937156.0000],
        [       0.0000, 14184124.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 226/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:40, 57.17s/it]  7%|▋         | 2/29 [01:01<11:37, 25.85s/it] 10%|█         | 3/29 [01:02<06:16, 14.47s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.12s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.1665682792663574
Epoch 227/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:55, 57.68s/it]  7%|▋         | 2/29 [01:01<11:42, 26.00s/it] 10%|█         | 3/29 [01:02<06:18, 14.55s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.19s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.153897523880005
Epoch 228/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:07, 58.14s/it]  7%|▋         | 2/29 [01:01<11:33, 25.69s/it] 10%|█         | 3/29 [01:02<06:13, 14.38s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.13s/it] 21%|██        | 6/29 [01:04<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.143444538116455
Epoch 229/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:58, 57.81s/it]  7%|▋         | 2/29 [00:58<10:57, 24.35s/it] 10%|█         | 3/29 [00:59<05:54, 13.65s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.63s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:36,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 3.1614127159118652
Epoch 230/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:44, 57.30s/it]  7%|▋         | 2/29 [00:58<10:52, 24.15s/it] 10%|█         | 3/29 [00:59<05:52, 13.55s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:01<02:24,  6.04s/it] 21%|██        | 6/29 [01:02<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.47s/it] 31%|███       | 9/29 [01:05<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 3.1326489448547363
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0111, 0.0017,  ..., 0.0059, 0.0008, 0.0179],
        [0.0025, 0.0109, 0.0019,  ..., 0.0043, 0.0008, 0.0171],
        [0.0295, 0.0086, 0.0021,  ..., 0.0054, 0.0154, 0.0243],
        ...,
        [0.0046, 0.0086, 0.0258,  ..., 0.0035, 0.0012, 0.0226],
        [0.0054, 0.0127, 0.0181,  ..., 0.0048, 0.0017, 0.0201],
        [0.0081, 0.0091, 0.0046,  ..., 0.0019, 0.0037, 0.0204]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9968, 0.9963, 0.9962, 0.9960, 0.9958, 0.9958, 0.9955, 0.9955,
         0.9955],
        [0.9974, 0.9971, 0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9841, 0.9765, 0.9754, 0.9736, 0.9736, 0.9729, 0.9715, 0.9715, 0.9709,
         0.9692],
        [0.9937, 0.9930, 0.9928, 0.9927, 0.9922, 0.9921, 0.9921, 0.9913, 0.9913,
         0.9908],
        [0.9903, 0.9882, 0.9878, 0.9878, 0.9874, 0.9872, 0.9872, 0.9871, 0.9868,
         0.9866],
        [0.9881, 0.9851, 0.9815, 0.9815, 0.9771, 0.9769, 0.9767, 0.9757, 0.9750,
         0.9739],
        [0.9759, 0.9740, 0.9737, 0.9702, 0.9694, 0.9685, 0.9683, 0.9679, 0.9665,
         0.9665],
        [0.9860, 0.9834, 0.9778, 0.9769, 0.9757, 0.9735, 0.9720, 0.9719, 0.9717,
         0.9714],
        [0.9977, 0.9976, 0.9974, 0.9972, 0.9971, 0.9971, 0.9971, 0.9970, 0.9968,
         0.9967],
        [0.9936, 0.9878, 0.9874, 0.9866, 0.9864, 0.9856, 0.9855, 0.9850, 0.9845,
         0.9838],
        [0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9938, 0.9936, 0.9930, 0.9919, 0.9917, 0.9909, 0.9906, 0.9905, 0.9905,
         0.9897],
        [0.9935, 0.9932, 0.9920, 0.9915, 0.9914, 0.9908, 0.9898, 0.9889, 0.9876,
         0.9876],
        [0.9984, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9981, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9963, 0.9960, 0.9959, 0.9954, 0.9952, 0.9951, 0.9951, 0.9950, 0.9950,
         0.9949],
        [0.9960, 0.9960, 0.9959, 0.9958, 0.9957, 0.9956, 0.9955, 0.9954, 0.9950,
         0.9950],
        [0.9950, 0.9942, 0.9939, 0.9936, 0.9935, 0.9935, 0.9934, 0.9930, 0.9930,
         0.9928],
        [0.9973, 0.9972, 0.9972, 0.9972, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9952, 0.9946, 0.9938, 0.9938, 0.9938, 0.9936, 0.9936, 0.9935, 0.9932,
         0.9928],
        [0.9985, 0.9979, 0.9976, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968,
         0.9967],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9980],
        [0.9962, 0.9957, 0.9957, 0.9957, 0.9951, 0.9951, 0.9949, 0.9948, 0.9946,
         0.9946],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9984, 0.9982, 0.9982, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9988, 0.9988, 0.9987, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9982],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9986, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9903, 0.9860, 0.9823, 0.9812, 0.9801, 0.9787, 0.9786, 0.9780, 0.9746,
         0.9710],
        [0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9963, 0.9962,
         0.9962],
        [0.9976, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9971, 0.9971, 0.9971,
         0.9970],
        [0.9969, 0.9965, 0.9965, 0.9964, 0.9964, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9892, 0.9860, 0.9846, 0.9843, 0.9839, 0.9829, 0.9829, 0.9820, 0.9810,
         0.9798],
        [0.9959, 0.9959, 0.9957, 0.9957, 0.9957, 0.9955, 0.9954, 0.9951, 0.9950,
         0.9950],
        [0.9936, 0.9935, 0.9932, 0.9931, 0.9930, 0.9921, 0.9914, 0.9912, 0.9911,
         0.9909],
        [0.9963, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955,
         0.9954],
        [0.9865, 0.9865, 0.9853, 0.9850, 0.9841, 0.9834, 0.9826, 0.9811, 0.9804,
         0.9801],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9975],
        [0.9973, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9968, 0.9967, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9961],
        [0.9918, 0.9905, 0.9903, 0.9902, 0.9900, 0.9897, 0.9895, 0.9888, 0.9885,
         0.9882],
        [0.9877, 0.9848, 0.9846, 0.9840, 0.9834, 0.9833, 0.9833, 0.9830, 0.9826,
         0.9824],
        [0.9891, 0.9830, 0.9721, 0.9682, 0.9681, 0.9605, 0.9572, 0.9550, 0.9528,
         0.9526],
        [0.9764, 0.9753, 0.9733, 0.9700, 0.9686, 0.9653, 0.9641, 0.9628, 0.9623,
         0.9603],
        [0.9931, 0.9917, 0.9911, 0.9902, 0.9901, 0.9895, 0.9892, 0.9891, 0.9891,
         0.9891],
        [0.9938, 0.9936, 0.9936, 0.9934, 0.9933, 0.9932, 0.9929, 0.9929, 0.9923,
         0.9922],
        [0.9934, 0.9932, 0.9927, 0.9923, 0.9922, 0.9921, 0.9920, 0.9920, 0.9918,
         0.9917],
        [0.9886, 0.9882, 0.9873, 0.9871, 0.9869, 0.9862, 0.9860, 0.9851, 0.9841,
         0.9831],
        [0.9948, 0.9945, 0.9935, 0.9925, 0.9923, 0.9921, 0.9912, 0.9911, 0.9890,
         0.9888],
        [0.9918, 0.9912, 0.9902, 0.9881, 0.9877, 0.9866, 0.9864, 0.9864, 0.9858,
         0.9854],
        [0.9943, 0.9941, 0.9940, 0.9936, 0.9936, 0.9934, 0.9931, 0.9926, 0.9925,
         0.9925],
        [0.9952, 0.9945, 0.9944, 0.9944, 0.9940, 0.9936, 0.9935, 0.9932, 0.9930,
         0.9929],
        [0.9944, 0.9911, 0.9903, 0.9903, 0.9890, 0.9873, 0.9873, 0.9873, 0.9871,
         0.9871],
        [0.9931, 0.9923, 0.9921, 0.9878, 0.9877, 0.9868, 0.9866, 0.9855, 0.9848,
         0.9848],
        [0.9931, 0.9929, 0.9929, 0.9918, 0.9914, 0.9900, 0.9900, 0.9887, 0.9884,
         0.9881],
        [0.9963, 0.9951, 0.9940, 0.9932, 0.9930, 0.9929, 0.9910, 0.9910, 0.9905,
         0.9892],
        [0.9900, 0.9891, 0.9888, 0.9880, 0.9878, 0.9876, 0.9873, 0.9866, 0.9864,
         0.9862],
        [0.9897, 0.9878, 0.9863, 0.9847, 0.9842, 0.9841, 0.9840, 0.9837, 0.9832,
         0.9831],
        [0.9925, 0.9916, 0.9913, 0.9908, 0.9896, 0.9889, 0.9866, 0.9863, 0.9852,
         0.9845],
        [0.9932, 0.9932, 0.9928, 0.9925, 0.9911, 0.9910, 0.9908, 0.9906, 0.9905,
         0.9901]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 1, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1532194.1250, 1527880.8750, 1517318.6250, 1516615.6250, 1510839.7500,
         1508091.6250, 1506088.1250, 1500620.0000, 1500219.2500, 1499954.6250],
        [1541371.6250, 1536003.8750, 1530386.2500, 1528280.2500, 1526310.8750,
         1524787.6250, 1524607.3750, 1524148.0000, 1523021.8750, 1522852.0000],
        [1275328.0000, 1144039.7500, 1126886.3750, 1097189.2500, 1096876.5000,
         1086585.7500, 1065286.7500, 1065272.5000, 1056405.1250, 1030520.3125],
        [1462339.3750, 1447776.1250, 1443938.7500, 1442525.1250, 1432546.1250,
         1429681.3750, 1429675.8750, 1414052.3750, 1413042.7500, 1402426.0000],
        [1394129.0000, 1352062.5000, 1345177.7500, 1343587.8750, 1336239.1250,
         1333516.0000, 1332439.3750, 1331626.2500, 1324591.7500, 1322147.1250],
        [1350785.2500, 1293370.8750, 1229034.0000, 1227917.5000, 1153384.1250,
         1150650.7500, 1147792.3750, 1130346.7500, 1119836.0000, 1101815.5000],
        [1133591.8750, 1104462.5000, 1098549.2500, 1045299.1875, 1033003.7500,
         1020831.6250, 1017661.8750, 1011705.8750,  991458.5625,  991271.3750],
        [1309505.6250, 1262800.5000, 1164987.2500, 1151131.5000, 1131395.0000,
         1096221.8750, 1072366.0000, 1070518.5000, 1068573.3750, 1063707.1250],
        [1548077.6250, 1545361.8750, 1542298.1250, 1536893.3750, 1535346.2500,
         1535281.8750, 1534835.3750, 1532577.0000, 1528221.8750, 1527189.0000],
        [1459866.1250, 1343435.5000, 1335752.3750, 1322282.0000, 1318166.1250,
         1303575.8750, 1301700.1250, 1291368.1250, 1281851.5000, 1270257.7500],
        [1548273.8750, 1548064.2500, 1546370.3750, 1543647.3750, 1542584.8750,
         1542137.7500, 1539818.7500, 1538064.8750, 1537840.5000, 1537544.1250],
        [1463861.6250, 1460157.1250, 1447813.3750, 1426468.6250, 1420610.6250,
         1404528.7500, 1399791.0000, 1398050.0000, 1397515.5000, 1380599.2500],
        [1457676.2500, 1453025.5000, 1427046.8750, 1416989.8750, 1415697.2500,
         1402705.5000, 1383706.0000, 1366216.6250, 1341103.1250, 1340727.2500],
        [1563970.3750, 1559766.8750, 1558665.1250, 1558396.1250, 1558170.2500,
         1557032.3750, 1556215.8750, 1556156.5000, 1554934.1250, 1554020.8750],
        [1557048.7500, 1556846.7500, 1556497.8750, 1553785.2500, 1552721.7500,
         1552012.5000, 1550784.6250, 1550610.1250, 1550398.5000, 1550060.0000],
        [1553044.6250, 1550701.7500, 1549310.7500, 1549194.0000, 1549095.1250,
         1548403.7500, 1548254.6250, 1547364.6250, 1546886.5000, 1546548.7500],
        [1517845.5000, 1510894.5000, 1508917.5000, 1498141.8750, 1494648.3750,
         1492810.7500, 1492593.0000, 1490942.6250, 1489399.3750, 1487878.8750],
        [1512010.2500, 1511060.2500, 1510149.7500, 1508025.5000, 1504572.1250,
         1503705.6250, 1501079.2500, 1499559.7500, 1490740.7500, 1490231.8750],
        [1489014.3750, 1473472.7500, 1467721.2500, 1460538.6250, 1459149.2500,
         1457802.8750, 1457160.7500, 1447836.8750, 1447709.8750, 1444072.3750],
        [1539240.3750, 1538455.1250, 1536732.0000, 1536699.8750, 1533210.0000,
         1532908.8750, 1531240.2500, 1530853.3750, 1530495.7500, 1530465.1250],
        [1550766.7500, 1549862.0000, 1549544.1250, 1548801.1250, 1545844.0000,
         1544529.5000, 1544517.7500, 1544464.7500, 1542501.0000, 1541245.3750],
        [1494805.2500, 1482233.6250, 1464611.6250, 1464173.0000, 1464090.6250,
         1461304.8750, 1460154.2500, 1458448.0000, 1452181.7500, 1443642.7500],
        [1565594.0000, 1553505.2500, 1545596.3750, 1534217.8750, 1533640.0000,
         1531885.8750, 1531802.6250, 1531509.0000, 1527955.2500, 1527676.8750],
        [1566509.5000, 1563633.2500, 1560997.6250, 1560640.3750, 1560379.8750,
         1560162.6250, 1559283.5000, 1558046.8750, 1557198.7500, 1555055.7500],
        [1515487.7500, 1504740.0000, 1504493.1250, 1503981.0000, 1492285.5000,
         1491710.6250, 1487958.2500, 1485564.8750, 1481269.7500, 1480707.7500],
        [1567205.7500, 1564561.1250, 1560070.5000, 1558633.8750, 1558507.6250,
         1557694.7500, 1556244.0000, 1555115.0000, 1554324.7500, 1554191.3750],
        [1552626.8750, 1552247.8750, 1551121.7500, 1547413.3750, 1545911.6250,
         1543408.8750, 1543051.3750, 1541768.7500, 1540805.8750, 1540786.7500],
        [1563788.5000, 1560807.1250, 1558757.3750, 1555962.0000, 1555840.3750,
         1554692.3750, 1553637.1250, 1553533.3750, 1553391.1250, 1552459.6250],
        [1569959.7500, 1569230.7500, 1568886.6250, 1566670.7500, 1565988.2500,
         1565494.0000, 1565443.1250, 1565290.8750, 1565129.6250, 1563691.3750],
        [1572438.1250, 1572052.8750, 1569884.8750, 1568001.1250, 1566340.7500,
         1564987.8750, 1563432.0000, 1563013.1250, 1562406.6250, 1560626.8750],
        [1569673.8750, 1566944.2500, 1566732.1250, 1566321.3750, 1565806.0000,
         1564762.5000, 1563633.2500, 1563209.8750, 1562515.2500, 1561879.2500],
        [1568016.1250, 1566461.6250, 1563329.1250, 1563189.0000, 1562822.3750,
         1562609.1250, 1560424.6250, 1559545.3750, 1559283.5000, 1558852.3750],
        [1394121.0000, 1310225.2500, 1242176.1250, 1223047.3750, 1204953.1250,
         1180308.1250, 1178659.1250, 1167960.7500, 1113809.8750, 1057808.5000],
        [1527773.1250, 1525900.6250, 1525864.1250, 1524098.6250, 1523690.2500,
         1521831.3750, 1521702.2500, 1517612.5000, 1516530.2500, 1516452.2500],
        [1545776.1250, 1539723.3750, 1539557.3750, 1538588.6250, 1537188.0000,
         1535352.1250, 1535268.6250, 1534844.1250, 1534418.3750, 1533964.7500],
        [1531560.1250, 1522786.7500, 1522271.1250, 1521052.2500, 1520060.3750,
         1514385.5000, 1513857.0000, 1513474.3750, 1513226.1250, 1512999.6250],
        [1372479.7500, 1310198.8750, 1284857.3750, 1278713.6250, 1271399.5000,
         1254363.7500, 1253217.1250, 1237563.5000, 1220492.2500, 1199563.1250],
        [1508491.6250, 1508314.6250, 1505391.7500, 1504724.2500, 1504204.8750,
         1501745.1250, 1497579.1250, 1492910.5000, 1491012.2500, 1490328.5000],
        [1459459.6250, 1457884.8750, 1452988.0000, 1449811.3750, 1447576.0000,
         1428667.2500, 1414457.0000, 1410492.6250, 1408676.5000, 1405513.6250],
        [1516944.0000, 1507692.0000, 1506586.6250, 1504513.2500, 1502835.3750,
         1502569.0000, 1502127.6250, 1501501.7500, 1501308.3750, 1498443.2500],
        [1320133.7500, 1319077.8750, 1296778.5000, 1290944.5000, 1274676.1250,
         1262227.3750, 1248102.7500, 1221596.1250, 1209935.7500, 1204823.3750],
        [1557325.0000, 1551781.7500, 1551735.8750, 1550233.0000, 1549850.1250,
         1549748.1250, 1548124.7500, 1547677.5000, 1545359.0000, 1544914.0000],
        [1540760.3750, 1540221.1250, 1539965.6250, 1539332.7500, 1538757.3750,
         1538462.3750, 1537850.7500, 1537066.2500, 1536831.7500, 1535942.5000],
        [1528274.3750, 1526787.1250, 1521841.5000, 1521158.1250, 1519983.5000,
         1517325.8750, 1516952.6250, 1516701.0000, 1516418.8750, 1514216.5000],
        [1423518.2500, 1396697.3750, 1393275.7500, 1392091.0000, 1387493.1250,
         1380376.7500, 1377847.5000, 1364588.8750, 1358342.2500, 1353028.6250],
        [1343023.0000, 1287490.8750, 1283895.8750, 1273818.2500, 1261938.5000,
         1260995.3750, 1260959.2500, 1254875.8750, 1247781.3750, 1244289.0000],
        [1369840.8750, 1255651.6250, 1074120.2500, 1015727.5625, 1014980.0000,
          909765.8125,  868536.8750,  841291.5000,  815960.7500,  812499.1250],
        [1142520.7500, 1124103.2500, 1092335.5000, 1042498.6875, 1022382.7500,
          974798.1250,  958406.6875,  940329.2500,  933763.7500,  907933.5000],
        [1450270.5000, 1420789.5000, 1409352.5000, 1390534.5000, 1389332.2500,
         1377399.5000, 1370538.6250, 1370289.1250, 1369814.7500, 1369395.5000],
        [1465414.8750, 1461235.2500, 1460218.3750, 1457337.1250, 1454758.6250,
         1452591.7500, 1446855.5000, 1444933.2500, 1433088.6250, 1431715.7500],
        [1456153.5000, 1452059.8750, 1441460.7500, 1433997.7500, 1430647.1250,
         1428512.1250, 1427897.7500, 1427768.3750, 1423128.7500, 1420580.7500],
        [1359956.0000, 1351720.7500, 1335325.6250, 1330451.0000, 1326906.7500,
         1314869.2500, 1309970.2500, 1292898.6250, 1274453.7500, 1256998.3750],
        [1484951.5000, 1479889.0000, 1457829.2500, 1436891.7500, 1433925.3750,
         1429040.7500, 1411889.6250, 1408810.8750, 1366670.0000, 1363210.1250],
        [1422640.2500, 1411255.5000, 1392198.5000, 1351015.8750, 1342871.8750,
         1320668.8750, 1318387.3750, 1317331.7500, 1307090.1250, 1299275.3750],
        [1475108.0000, 1471832.5000, 1468393.2500, 1461003.8750, 1460648.6250,
         1455330.2500, 1450530.5000, 1439985.1250, 1438216.0000, 1438091.2500],
        [1494594.2500, 1479299.1250, 1477362.0000, 1476522.5000, 1469130.1250,
         1460441.2500, 1457837.5000, 1452018.3750, 1447444.8750, 1445130.3750],
        [1476263.5000, 1409621.2500, 1393362.0000, 1392923.6250, 1367548.7500,
         1335320.5000, 1335245.3750, 1334737.5000, 1331192.0000, 1330263.1250],
        [1450751.7500, 1434317.8750, 1429925.5000, 1344218.5000, 1343329.1250,
         1325010.0000, 1320640.0000, 1300117.0000, 1288353.1250, 1288181.1250],
        [1449710.5000, 1446884.5000, 1446022.3750, 1423445.0000, 1415970.0000,
         1388231.6250, 1386690.1250, 1362500.5000, 1355816.0000, 1351037.7500],
        [1518960.5000, 1492927.5000, 1469253.3750, 1453121.0000, 1447974.8750,
         1445741.1250, 1407896.2500, 1406520.6250, 1396754.6250, 1370665.5000],
        [1386780.1250, 1370366.1250, 1364103.6250, 1347814.1250, 1344741.6250,
         1339722.5000, 1333948.5000, 1321799.1250, 1318102.0000, 1313917.7500],
        [1380428.0000, 1343598.2500, 1316581.8750, 1286494.2500, 1277711.6250,
         1276047.0000, 1273400.5000, 1267383.8750, 1259299.6250, 1256502.0000],
        [1437265.8750, 1418920.8750, 1414002.5000, 1402791.2500, 1378922.8750,
         1365001.3750, 1320616.0000, 1316118.7500, 1295960.1250, 1282963.2500],
        [1452740.0000, 1452291.2500, 1444666.0000, 1436809.5000, 1410155.0000,
         1407625.0000, 1402503.5000, 1399609.5000, 1397938.0000, 1388647.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1532194.1250,       0.0000],
         [1527880.8750,       0.0000],
         [1517318.6250,       0.0000],
         ...,
         [1500620.0000,       0.0000],
         [1500219.2500,       0.0000],
         [      0.0000, 1499954.6250]],

        [[1541371.6250,       0.0000],
         [1536003.8750,       0.0000],
         [1530386.2500,       0.0000],
         ...,
         [1524148.0000,       0.0000],
         [1523021.8750,       0.0000],
         [1522852.0000,       0.0000]],

        [[1275328.0000,       0.0000],
         [      0.0000, 1144039.7500],
         [1126886.3750,       0.0000],
         ...,
         [1065272.5000,       0.0000],
         [      0.0000, 1056405.1250],
         [      0.0000, 1030520.3125]],

        ...,

        [[1380428.0000,       0.0000],
         [1343598.2500,       0.0000],
         [1316581.8750,       0.0000],
         ...,
         [      0.0000, 1267383.8750],
         [1259299.6250,       0.0000],
         [1256502.0000,       0.0000]],

        [[1437265.8750,       0.0000],
         [1418920.8750,       0.0000],
         [1414002.5000,       0.0000],
         ...,
         [      0.0000, 1316118.7500],
         [      0.0000, 1295960.1250],
         [1282963.2500,       0.0000]],

        [[      0.0000, 1452740.0000],
         [      0.0000, 1452291.2500],
         [      0.0000, 1444666.0000],
         ...,
         [      0.0000, 1399609.5000],
         [      0.0000, 1397938.0000],
         [      0.0000, 1388647.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13619868.0000,  1499954.6250],
        [15281770.0000,        0.0000],
        [ 6748138.0000,  4296252.0000],
        [14318004.0000,        0.0000],
        [10737899.0000,  2677617.0000],
        [10675899.0000,  1229034.0000],
        [ 3187427.0000,  7260408.5000],
        [ 9255134.0000,  2136073.0000],
        [13837860.0000,  1528221.8750],
        [11910090.0000,  1318166.1250],
        [15424346.0000,        0.0000],
        [14199396.0000,        0.0000],
        [11323064.0000,  2681830.5000],
        [15577328.0000,        0.0000],
        [15530766.0000,        0.0000],
        [15488804.0000,        0.0000],
        [13493130.0000,  1490942.6250],
        [ 9025628.0000,  6005508.0000],
        [14604480.0000,        0.0000],
        [15340300.0000,        0.0000],
        [15462077.0000,        0.0000],
        [11716943.0000,  2928702.2500],
        [15383383.0000,        0.0000],
        [15601908.0000,        0.0000],
        [ 8961115.0000,  5987083.5000],
        [15586549.0000,        0.0000],
        [15459143.0000,        0.0000],
        [15562870.0000,        0.0000],
        [15665786.0000,        0.0000],
        [15663184.0000,        0.0000],
        [15651477.0000,        0.0000],
        [15624534.0000,        0.0000],
        [ 3443069.5000,  8630000.0000],
        [10647988.0000,  4573467.0000],
        [13834959.0000,  1539723.3750],
        [12143342.0000,  3042331.5000],
        [ 5004040.0000,  7678809.0000],
        [11990819.0000,  3013883.5000],
        [11434962.0000,  2900564.0000],
        [15044521.0000,        0.0000],
        [10109248.0000,  2539047.2500],
        [15496748.0000,        0.0000],
        [15385191.0000,        0.0000],
        [13671385.0000,  1528274.3750],
        [ 1380376.7500, 12446883.0000],
        [ 2492070.5000, 10226997.0000],
        [ 5263781.5000,  4714593.0000],
        [       0.0000, 10139072.0000],
        [ 9707575.0000,  4210141.5000],
        [10134818.0000,  4373331.0000],
        [11477562.0000,  2864645.0000],
        [ 1256998.3750, 11896552.0000],
        [       0.0000, 14273108.0000],
        [ 1299275.3750, 12183460.0000],
        [10173983.0000,  4385156.5000],
        [ 8785696.0000,  5874084.5000],
        [ 1335320.5000, 12371157.0000],
        [ 2631682.2500, 10893162.0000],
        [       0.0000, 14026308.0000],
        [ 1396754.6250, 13013060.0000],
        [ 9409197.0000,  4032098.0000],
        [ 9116305.0000,  3821142.5000],
        [ 9699868.0000,  3932694.7500],
        [       0.0000, 14192985.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 231/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:13, 58.33s/it]  7%|▋         | 2/29 [01:01<11:42, 26.03s/it] 10%|█         | 3/29 [01:02<06:18, 14.57s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.20s/it] 21%|██        | 6/29 [01:05<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.1423354148864746
Epoch 232/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:33, 61.19s/it]  7%|▋         | 2/29 [01:02<11:34, 25.74s/it] 10%|█         | 3/29 [01:03<06:14, 14.41s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.137000799179077
Epoch 233/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.97s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 3.1239066123962402
Epoch 234/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:11, 60.43s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.119161367416382
Epoch 235/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:24, 56.59s/it]  7%|▋         | 2/29 [00:58<11:00, 24.46s/it] 10%|█         | 3/29 [01:01<06:20, 14.63s/it] 14%|█▍        | 4/29 [01:02<03:50,  9.22s/it] 17%|█▋        | 5/29 [01:03<02:29,  6.22s/it] 21%|██        | 6/29 [01:04<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:05<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:06<00:53,  2.53s/it] 31%|███       | 9/29 [01:07<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:07<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:09<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.124616861343384
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0108, 0.0014,  ..., 0.0053, 0.0006, 0.0185],
        [0.0023, 0.0104, 0.0018,  ..., 0.0038, 0.0008, 0.0176],
        [0.0274, 0.0088, 0.0021,  ..., 0.0051, 0.0145, 0.0240],
        ...,
        [0.0050, 0.0086, 0.0263,  ..., 0.0036, 0.0014, 0.0227],
        [0.0053, 0.0124, 0.0180,  ..., 0.0045, 0.0020, 0.0209],
        [0.0081, 0.0089, 0.0046,  ..., 0.0020, 0.0039, 0.0207]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9971, 0.9969, 0.9963, 0.9963, 0.9961, 0.9960, 0.9959, 0.9956, 0.9956,
         0.9955],
        [0.9975, 0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967,
         0.9967],
        [0.9835, 0.9750, 0.9744, 0.9738, 0.9720, 0.9719, 0.9717, 0.9712, 0.9700,
         0.9698],
        [0.9934, 0.9928, 0.9927, 0.9927, 0.9926, 0.9926, 0.9919, 0.9915, 0.9910,
         0.9909],
        [0.9907, 0.9885, 0.9882, 0.9879, 0.9877, 0.9876, 0.9873, 0.9871, 0.9871,
         0.9870],
        [0.9880, 0.9851, 0.9828, 0.9825, 0.9794, 0.9772, 0.9767, 0.9760, 0.9759,
         0.9749],
        [0.9762, 0.9726, 0.9720, 0.9693, 0.9684, 0.9684, 0.9682, 0.9670, 0.9663,
         0.9649],
        [0.9869, 0.9829, 0.9787, 0.9775, 0.9751, 0.9749, 0.9730, 0.9729, 0.9721,
         0.9718],
        [0.9978, 0.9976, 0.9975, 0.9973, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970,
         0.9969],
        [0.9936, 0.9878, 0.9877, 0.9871, 0.9870, 0.9861, 0.9853, 0.9850, 0.9846,
         0.9838],
        [0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9945, 0.9944, 0.9938, 0.9929, 0.9923, 0.9919, 0.9917, 0.9912, 0.9910,
         0.9907],
        [0.9940, 0.9937, 0.9923, 0.9919, 0.9912, 0.9911, 0.9901, 0.9893, 0.9889,
         0.9884],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9966, 0.9963, 0.9960, 0.9956, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9952],
        [0.9961, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9953,
         0.9952],
        [0.9952, 0.9944, 0.9942, 0.9940, 0.9938, 0.9938, 0.9936, 0.9934, 0.9933,
         0.9933],
        [0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9954, 0.9948, 0.9942, 0.9942, 0.9942, 0.9940, 0.9940, 0.9939, 0.9934,
         0.9931],
        [0.9985, 0.9980, 0.9976, 0.9971, 0.9970, 0.9970, 0.9970, 0.9970, 0.9969,
         0.9968],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9962, 0.9959, 0.9958, 0.9957, 0.9953, 0.9953, 0.9951, 0.9950, 0.9949,
         0.9948],
        [0.9986, 0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9984, 0.9983, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9988, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9987, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9986, 0.9986, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9904, 0.9864, 0.9816, 0.9811, 0.9799, 0.9786, 0.9778, 0.9764, 0.9749,
         0.9715],
        [0.9968, 0.9968, 0.9968, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9962],
        [0.9977, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9971, 0.9967, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9895, 0.9864, 0.9844, 0.9842, 0.9838, 0.9830, 0.9829, 0.9823, 0.9799,
         0.9794],
        [0.9961, 0.9960, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9953, 0.9952,
         0.9951],
        [0.9940, 0.9938, 0.9937, 0.9934, 0.9924, 0.9923, 0.9917, 0.9913, 0.9911,
         0.9910],
        [0.9964, 0.9960, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9955],
        [0.9865, 0.9862, 0.9850, 0.9848, 0.9837, 0.9829, 0.9828, 0.9816, 0.9803,
         0.9796],
        [0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9919, 0.9904, 0.9902, 0.9902, 0.9901, 0.9894, 0.9894, 0.9887, 0.9885,
         0.9881],
        [0.9878, 0.9854, 0.9845, 0.9842, 0.9841, 0.9837, 0.9833, 0.9830, 0.9828,
         0.9825],
        [0.9889, 0.9835, 0.9710, 0.9689, 0.9676, 0.9595, 0.9563, 0.9554, 0.9520,
         0.9520],
        [0.9748, 0.9743, 0.9723, 0.9687, 0.9680, 0.9643, 0.9631, 0.9616, 0.9605,
         0.9603],
        [0.9932, 0.9918, 0.9912, 0.9904, 0.9902, 0.9901, 0.9894, 0.9893, 0.9892,
         0.9892],
        [0.9942, 0.9940, 0.9938, 0.9938, 0.9937, 0.9936, 0.9934, 0.9932, 0.9928,
         0.9927],
        [0.9940, 0.9933, 0.9932, 0.9928, 0.9926, 0.9924, 0.9923, 0.9923, 0.9922,
         0.9919],
        [0.9896, 0.9886, 0.9880, 0.9876, 0.9868, 0.9868, 0.9859, 0.9845, 0.9841,
         0.9835],
        [0.9947, 0.9946, 0.9935, 0.9927, 0.9925, 0.9920, 0.9914, 0.9913, 0.9899,
         0.9887],
        [0.9919, 0.9916, 0.9904, 0.9883, 0.9877, 0.9866, 0.9865, 0.9865, 0.9862,
         0.9858],
        [0.9943, 0.9942, 0.9939, 0.9939, 0.9936, 0.9933, 0.9932, 0.9926, 0.9926,
         0.9926],
        [0.9952, 0.9946, 0.9946, 0.9944, 0.9939, 0.9937, 0.9935, 0.9932, 0.9930,
         0.9929],
        [0.9946, 0.9912, 0.9905, 0.9903, 0.9893, 0.9881, 0.9875, 0.9875, 0.9874,
         0.9870],
        [0.9932, 0.9925, 0.9922, 0.9885, 0.9878, 0.9871, 0.9866, 0.9858, 0.9855,
         0.9851],
        [0.9931, 0.9931, 0.9927, 0.9916, 0.9914, 0.9901, 0.9897, 0.9890, 0.9886,
         0.9880],
        [0.9964, 0.9952, 0.9943, 0.9930, 0.9930, 0.9929, 0.9911, 0.9907, 0.9905,
         0.9892],
        [0.9898, 0.9897, 0.9891, 0.9886, 0.9875, 0.9874, 0.9871, 0.9865, 0.9863,
         0.9860],
        [0.9893, 0.9872, 0.9860, 0.9843, 0.9838, 0.9836, 0.9836, 0.9831, 0.9829,
         0.9825],
        [0.9925, 0.9917, 0.9915, 0.9909, 0.9899, 0.9890, 0.9867, 0.9864, 0.9854,
         0.9845],
        [0.9931, 0.9930, 0.9928, 0.9924, 0.9911, 0.9910, 0.9910, 0.9908, 0.9904,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 1, 0, 1, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1536311.5000, 1530285.5000, 1518038.0000, 1517874.3750, 1513546.5000,
         1512016.0000, 1508570.6250, 1503236.8750, 1502399.8750, 1500542.6250],
        [1545012.6250, 1536782.0000, 1533290.3750, 1531336.6250, 1529760.2500,
         1529281.8750, 1528808.0000, 1528073.2500, 1527620.1250, 1526993.7500],
        [1264405.6250, 1119187.8750, 1110509.1250, 1099885.8750, 1072565.3750,
         1071143.5000, 1067612.7500, 1060403.2500, 1042928.2500, 1040133.1875],
        [1455974.3750, 1444422.1250, 1442858.1250, 1441601.0000, 1439444.1250,
         1438829.2500, 1425179.5000, 1417268.2500, 1407416.8750, 1404460.3750],
        [1401099.8750, 1357829.5000, 1351509.3750, 1346389.2500, 1342563.2500,
         1341254.1250, 1334026.1250, 1331688.5000, 1331005.3750, 1329623.8750],
        [1347521.0000, 1292612.5000, 1252540.7500, 1246007.1250, 1192508.3750,
         1154732.3750, 1147595.3750, 1136083.2500, 1133917.2500, 1118669.3750],
        [1138853.7500, 1082715.0000, 1072892.7500, 1031817.3750, 1019678.6875,
         1018412.3750, 1016268.1875,  998834.5000,  988277.2500,  968883.1250],
        [1327056.1250, 1253511.1250, 1180132.5000, 1159783.7500, 1121799.6250,
         1117424.0000, 1087918.1250, 1086120.5000, 1074916.5000, 1069816.3750],
        [1551077.3750, 1547448.7500, 1544866.8750, 1539983.2500, 1539328.3750,
         1536628.1250, 1535784.1250, 1535678.7500, 1533230.5000, 1530262.2500],
        [1460960.8750, 1344605.6250, 1343361.1250, 1330737.6250, 1328517.3750,
         1311799.2500, 1296832.8750, 1290884.1250, 1283878.7500, 1269992.5000],
        [1551564.1250, 1551157.2500, 1547298.2500, 1547184.6250, 1545518.1250,
         1544805.0000, 1542327.5000, 1542289.2500, 1540916.0000, 1540631.0000],
        [1478932.2500, 1477293.0000, 1464668.7500, 1444970.5000, 1433230.7500,
         1424551.7500, 1422271.1250, 1410596.2500, 1407606.2500, 1401897.8750],
        [1469317.8750, 1462840.1250, 1432785.2500, 1424664.5000, 1410982.3750,
         1408609.3750, 1390217.6250, 1373347.7500, 1366168.3750, 1355333.8750],
        [1564422.3750, 1561043.7500, 1560170.1250, 1560042.2500, 1559560.2500,
         1558112.2500, 1557051.6250, 1556736.8750, 1556005.1250, 1555804.7500],
        [1559601.8750, 1557155.6250, 1556079.2500, 1554791.7500, 1553937.8750,
         1553920.1250, 1553103.7500, 1552918.7500, 1551672.2500, 1551436.8750],
        [1554723.5000, 1551740.1250, 1550970.8750, 1550769.7500, 1549822.0000,
         1549705.2500, 1549663.8750, 1548755.2500, 1547627.2500, 1547540.1250],
        [1524213.3750, 1517376.6250, 1512132.7500, 1503793.1250, 1499109.5000,
         1498456.2500, 1496317.0000, 1496290.0000, 1495327.0000, 1494537.2500],
        [1512729.8750, 1509339.1250, 1508588.0000, 1507802.6250, 1507305.2500,
         1504345.5000, 1503665.5000, 1501854.0000, 1497296.3750, 1494101.1250],
        [1494500.1250, 1476945.0000, 1472738.1250, 1468362.5000, 1465347.7500,
         1465305.8750, 1461391.3750, 1456093.8750, 1454642.0000, 1454528.2500],
        [1543410.5000, 1543063.1250, 1543014.5000, 1542142.1250, 1540482.6250,
         1539790.8750, 1539616.1250, 1538910.0000, 1538532.7500, 1538314.2500],
        [1552939.3750, 1550611.5000, 1550595.2500, 1549909.2500, 1548517.5000,
         1547724.6250, 1546171.2500, 1544774.0000, 1542387.8750, 1542128.8750],
        [1499198.0000, 1486650.5000, 1472811.1250, 1472503.6250, 1472222.6250,
         1469641.6250, 1468582.3750, 1465953.1250, 1456877.2500, 1450541.6250],
        [1567069.8750, 1554145.3750, 1546650.6250, 1535009.6250, 1534030.5000,
         1533011.2500, 1532816.7500, 1532663.2500, 1530170.2500, 1528542.6250],
        [1567216.2500, 1563937.6250, 1562622.6250, 1561871.7500, 1561630.3750,
         1560350.2500, 1559148.2500, 1558732.0000, 1557951.7500, 1557687.3750],
        [1515529.7500, 1508526.1250, 1508193.8750, 1505229.3750, 1496445.5000,
         1496195.7500, 1492739.6250, 1490366.8750, 1487700.0000, 1485720.6250],
        [1567549.6250, 1564699.8750, 1561207.6250, 1559503.6250, 1559347.6250,
         1558464.5000, 1557183.7500, 1556471.1250, 1555453.2500, 1554373.6250],
        [1552701.0000, 1551658.8750, 1551154.3750, 1546942.6250, 1545532.8750,
         1544483.8750, 1542913.0000, 1541260.0000, 1541240.8750, 1539889.2500],
        [1564280.6250, 1562390.2500, 1558118.2500, 1557152.6250, 1556809.6250,
         1556696.7500, 1556117.8750, 1555327.1250, 1554071.2500, 1553250.5000],
        [1570928.8750, 1569850.5000, 1569393.8750, 1567912.8750, 1567057.8750,
         1566763.5000, 1565861.2500, 1565423.7500, 1564437.2500, 1564335.7500],
        [1574106.6250, 1573189.6250, 1570621.7500, 1569368.5000, 1568312.2500,
         1566318.2500, 1565056.5000, 1564996.8750, 1564144.8750, 1562135.3750],
        [1571065.1250, 1568431.8750, 1567313.3750, 1567279.1250, 1566529.0000,
         1565519.3750, 1565370.0000, 1564158.3750, 1563567.6250, 1563107.0000],
        [1568588.8750, 1567745.5000, 1564562.6250, 1564325.3750, 1563687.0000,
         1563035.5000, 1562457.2500, 1560920.2500, 1560877.0000, 1560061.6250],
        [1396139.3750, 1316819.2500, 1229818.2500, 1222174.1250, 1200443.1250,
         1178219.6250, 1165826.3750, 1142451.1250, 1118545.6250, 1065246.1250],
        [1529134.5000, 1528531.0000, 1528488.6250, 1524892.3750, 1523085.7500,
         1520193.7500, 1519461.7500, 1519322.6250, 1517914.8750, 1516566.3750],
        [1548638.6250, 1543903.5000, 1542926.2500, 1542895.2500, 1540194.7500,
         1539206.5000, 1538475.6250, 1538337.6250, 1536146.0000, 1536146.0000],
        [1535429.7500, 1526315.3750, 1522856.3750, 1520840.3750, 1520008.2500,
         1517929.3750, 1517220.2500, 1516981.6250, 1515668.5000, 1515206.0000],
        [1378099.8750, 1317858.2500, 1280724.8750, 1276502.1250, 1269500.8750,
         1254515.7500, 1252855.0000, 1242411.8750, 1200964.2500, 1192109.2500],
        [1512683.7500, 1510828.2500, 1510579.0000, 1506938.6250, 1506369.6250,
         1505723.3750, 1504579.2500, 1496975.1250, 1493571.1250, 1491815.8750],
        [1469189.0000, 1464974.7500, 1463254.5000, 1455291.5000, 1435081.2500,
         1433222.6250, 1422142.3750, 1412615.5000, 1408581.1250, 1407866.6250],
        [1520406.8750, 1511816.8750, 1509470.1250, 1506692.8750, 1505905.6250,
         1504443.0000, 1504424.2500, 1502653.5000, 1502288.1250, 1500870.3750],
        [1319025.0000, 1313830.1250, 1292171.2500, 1288549.7500, 1267605.1250,
         1253721.5000, 1251360.0000, 1229590.7500, 1207657.7500, 1195082.5000],
        [1556771.1250, 1553998.6250, 1553472.6250, 1552353.0000, 1550771.2500,
         1550119.1250, 1550030.3750, 1549170.3750, 1546017.8750, 1545630.1250],
        [1544084.7500, 1543250.0000, 1542916.0000, 1541796.6250, 1541418.7500,
         1540416.5000, 1539586.7500, 1538019.3750, 1538007.7500, 1537956.3750],
        [1531529.5000, 1530498.6250, 1527130.6250, 1526980.7500, 1525162.8750,
         1521581.7500, 1520363.2500, 1519986.3750, 1519524.1250, 1518885.1250],
        [1424864.2500, 1395456.5000, 1392032.5000, 1391946.2500, 1388851.5000,
         1375085.5000, 1374915.1250, 1361784.7500, 1357465.6250, 1351036.5000],
        [1344572.3750, 1299664.5000, 1281978.6250, 1276931.8750, 1275414.2500,
         1267295.7500, 1260884.7500, 1255524.7500, 1251320.6250, 1246788.1250],
        [1366339.1250, 1264502.1250, 1057341.5000, 1025768.6875, 1007760.6250,
          896854.3750,  857224.5000,  846731.0625,  806394.5625,  805581.3125],
        [1116213.0000, 1108010.3750, 1076848.5000, 1023672.4375, 1013095.1875,
          960666.8750,  945022.0625,  925133.9375,  910540.0000,  908029.6250],
        [1451651.3750, 1422942.8750, 1411547.7500, 1395004.1250, 1391326.5000,
         1388508.3750, 1375448.8750, 1373715.8750, 1372184.0000, 1371586.0000],
        [1472301.3750, 1468256.0000, 1465558.8750, 1464362.8750, 1463064.7500,
         1460778.3750, 1456492.3750, 1452953.3750, 1443297.1250, 1442075.3750],
        [1468368.0000, 1455277.5000, 1451193.2500, 1444285.8750, 1439209.3750,
         1436538.1250, 1433374.2500, 1432662.2500, 1431702.1250, 1426437.2500],
        [1380277.8750, 1359161.3750, 1348445.3750, 1341000.8750, 1325634.2500,
         1325186.7500, 1308207.3750, 1282701.3750, 1274698.0000, 1263483.5000],
        [1483574.2500, 1482461.1250, 1459285.6250, 1441177.6250, 1438497.2500,
         1427624.1250, 1415849.8750, 1413798.8750, 1384958.8750, 1361889.8750],
        [1425730.1250, 1418362.0000, 1395399.3750, 1354129.6250, 1342265.0000,
         1321360.5000, 1319983.8750, 1319693.1250, 1313384.0000, 1306379.7500],
        [1476097.3750, 1472993.7500, 1467617.6250, 1466028.5000, 1460991.3750,
         1454793.2500, 1453039.2500, 1439685.7500, 1439202.6250, 1439202.6250],
        [1493930.1250, 1482042.6250, 1480607.3750, 1476490.1250, 1467584.1250,
         1463436.0000, 1457877.8750, 1452133.3750, 1448736.1250, 1445326.1250],
        [1480747.2500, 1412148.1250, 1397149.0000, 1393630.5000, 1372871.1250,
         1350905.0000, 1338838.6250, 1338476.2500, 1336036.5000, 1329598.6250],
        [1452228.8750, 1437249.3750, 1431582.0000, 1358609.2500, 1344186.5000,
         1331505.7500, 1322265.6250, 1305976.1250, 1300945.5000, 1293395.5000],
        [1450258.0000, 1450074.1250, 1442329.8750, 1418455.5000, 1414521.7500,
         1388414.3750, 1382318.5000, 1366796.5000, 1359044.6250, 1348557.2500],
        [1520973.8750, 1494987.6250, 1474223.3750, 1448538.5000, 1447327.5000,
         1446760.3750, 1408855.1250, 1400815.3750, 1396485.6250, 1371059.0000],
        [1384025.3750, 1381091.7500, 1368882.3750, 1359473.6250, 1338465.8750,
         1336166.5000, 1331524.7500, 1320024.2500, 1315978.1250, 1310237.6250],
        [1373478.7500, 1332380.8750, 1310893.8750, 1279560.2500, 1269830.1250,
         1265732.7500, 1265458.7500, 1256385.8750, 1252780.8750, 1246758.5000],
        [1438327.1250, 1420580.7500, 1416595.3750, 1404437.6250, 1384488.7500,
         1367070.2500, 1322599.8750, 1318043.0000, 1298467.7500, 1282511.7500],
        [1450382.5000, 1448114.5000, 1443063.2500, 1435036.1250, 1409499.0000,
         1407639.7500, 1407225.0000, 1403835.0000, 1394824.5000, 1382115.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1536311.5000,       0.0000],
         [1530285.5000,       0.0000],
         [1518038.0000,       0.0000],
         ...,
         [1503236.8750,       0.0000],
         [1502399.8750,       0.0000],
         [1500542.6250,       0.0000]],

        [[1545012.6250,       0.0000],
         [1536782.0000,       0.0000],
         [1533290.3750,       0.0000],
         ...,
         [1528073.2500,       0.0000],
         [1527620.1250,       0.0000],
         [1526993.7500,       0.0000]],

        [[1264405.6250,       0.0000],
         [1119187.8750,       0.0000],
         [      0.0000, 1110509.1250],
         ...,
         [      0.0000, 1060403.2500],
         [1042928.2500,       0.0000],
         [      0.0000, 1040133.1875]],

        ...,

        [[1373478.7500,       0.0000],
         [1332380.8750,       0.0000],
         [1310893.8750,       0.0000],
         ...,
         [      0.0000, 1256385.8750],
         [1252780.8750,       0.0000],
         [1246758.5000,       0.0000]],

        [[1438327.1250,       0.0000],
         [1420580.7500,       0.0000],
         [1416595.3750,       0.0000],
         ...,
         [      0.0000, 1318043.0000],
         [      0.0000, 1298467.7500],
         [1282511.7500,       0.0000]],

        [[      0.0000, 1450382.5000],
         [      0.0000, 1448114.5000],
         [      0.0000, 1443063.2500],
         ...,
         [      0.0000, 1403835.0000],
         [      0.0000, 1394824.5000],
         [      0.0000, 1382115.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15142821.0000,        0.0000],
        [15316960.0000,        0.0000],
        [ 6670117.0000,  4278658.5000],
        [14317455.0000,        0.0000],
        [10766596.0000,  2700392.7500],
        [10769647.0000,  1252540.7500],
        [ 3186939.5000,  7149693.5000],
        [10408662.0000,  1069816.3750],
        [13861058.0000,  1533230.5000],
        [11933053.0000,  1328517.3750],
        [15453691.0000,        0.0000],
        [14366019.0000,        0.0000],
        [12728099.0000,  1366168.3750],
        [15588949.0000,        0.0000],
        [15544618.0000,        0.0000],
        [15501318.0000,        0.0000],
        [13541263.0000,  1496290.0000],
        [ 9031482.0000,  6015546.0000],
        [14669854.0000,        0.0000],
        [15407276.0000,        0.0000],
        [15475759.0000,        0.0000],
        [11770255.0000,  2944726.2500],
        [15394111.0000,        0.0000],
        [15611149.0000,        0.0000],
        [ 8984039.0000,  6002608.5000],
        [15594255.0000,        0.0000],
        [15457776.0000,        0.0000],
        [15574215.0000,        0.0000],
        [15671966.0000,        0.0000],
        [15678252.0000,        0.0000],
        [15662342.0000,        0.0000],
        [15636262.0000,        0.0000],
        [ 3443909.0000,  8591774.0000],
        [12169968.0000,  3057623.0000],
        [13863976.0000,  1542895.2500],
        [12169686.0000,  3038769.7500],
        [ 4990967.0000,  7674575.0000],
        [12018657.0000,  3021407.2500],
        [11481846.0000,  2890372.7500],
        [15068972.0000,        0.0000],
        [10078684.0000,  2539909.7500],
        [15508334.0000,        0.0000],
        [15407453.0000,        0.0000],
        [12190589.0000,  3051053.5000],
        [ 2726122.0000, 11087316.0000],
        [ 2498108.7500, 10262267.0000],
        [ 5220546.5000,  4713951.5000],
        [       0.0000,  9987232.0000],
        [ 9739352.0000,  4214564.0000],
        [10193456.0000,  4395683.5000],
        [11541387.0000,  2877660.0000],
        [ 1263483.5000, 11945313.0000],
        [       0.0000, 14309118.0000],
        [ 1306379.7500, 12210308.0000],
        [11620561.0000,  2949091.0000],
        [10239865.0000,  4428298.0000],
        [ 1350905.0000, 12399497.0000],
        [ 2664585.5000, 10913359.0000],
        [       0.0000, 14020770.0000],
        [ 1396485.6250, 13013541.0000],
        [ 9386393.0000,  4059477.0000],
        [ 9061312.0000,  3791949.0000],
        [ 9714012.0000,  3939110.5000],
        [       0.0000, 14181735.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 236/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<28:56, 62.02s/it]  7%|▋         | 2/29 [01:02<11:44, 26.08s/it] 10%|█         | 3/29 [01:03<06:19, 14.59s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.19s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.21s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.03s/it]
Epoch loss is 3.114952325820923
Epoch 237/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:09, 60.35s/it]  7%|▋         | 2/29 [01:01<11:25, 25.39s/it] 10%|█         | 3/29 [01:02<06:09, 14.22s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 3.1238718032836914
Epoch 238/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:05, 60.21s/it]  7%|▋         | 2/29 [01:01<11:24, 25.33s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.1191930770874023
Epoch 239/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:38, 57.09s/it]  7%|▋         | 2/29 [00:58<10:49, 24.05s/it] 10%|█         | 3/29 [01:01<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:02<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:03<02:28,  6.18s/it] 21%|██        | 6/29 [01:03<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.51s/it] 31%|███       | 9/29 [01:06<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.119091749191284
Epoch 240/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:41, 57.21s/it]  7%|▋         | 2/29 [00:58<11:01, 24.49s/it] 10%|█         | 3/29 [01:00<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.1024010181427
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0027, 0.0100, 0.0011,  ..., 0.0053, 0.0004, 0.0188],
        [0.0021, 0.0101, 0.0014,  ..., 0.0038, 0.0008, 0.0184],
        [0.0247, 0.0093, 0.0021,  ..., 0.0058, 0.0126, 0.0227],
        ...,
        [0.0048, 0.0085, 0.0249,  ..., 0.0037, 0.0012, 0.0231],
        [0.0048, 0.0111, 0.0173,  ..., 0.0042, 0.0020, 0.0214],
        [0.0073, 0.0086, 0.0043,  ..., 0.0020, 0.0037, 0.0206]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9973, 0.9973, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9961, 0.9960,
         0.9960],
        [0.9976, 0.9974, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969,
         0.9969],
        [0.9830, 0.9758, 0.9755, 0.9728, 0.9727, 0.9713, 0.9704, 0.9701, 0.9696,
         0.9690],
        [0.9944, 0.9938, 0.9935, 0.9933, 0.9932, 0.9929, 0.9923, 0.9921, 0.9919,
         0.9917],
        [0.9910, 0.9889, 0.9880, 0.9880, 0.9879, 0.9879, 0.9873, 0.9872, 0.9872,
         0.9870],
        [0.9881, 0.9855, 0.9830, 0.9814, 0.9795, 0.9781, 0.9763, 0.9756, 0.9749,
         0.9741],
        [0.9724, 0.9720, 0.9713, 0.9695, 0.9682, 0.9681, 0.9663, 0.9653, 0.9645,
         0.9637],
        [0.9885, 0.9825, 0.9815, 0.9810, 0.9797, 0.9761, 0.9759, 0.9747, 0.9739,
         0.9739],
        [0.9981, 0.9978, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9972,
         0.9971],
        [0.9942, 0.9896, 0.9892, 0.9883, 0.9880, 0.9879, 0.9863, 0.9860, 0.9857,
         0.9854],
        [0.9981, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9953, 0.9952, 0.9944, 0.9941, 0.9932, 0.9929, 0.9928, 0.9921, 0.9916,
         0.9914],
        [0.9949, 0.9942, 0.9929, 0.9921, 0.9920, 0.9919, 0.9914, 0.9901, 0.9901,
         0.9890],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9969, 0.9966, 0.9964, 0.9961, 0.9959, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9964, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9958, 0.9956, 0.9955,
         0.9955],
        [0.9953, 0.9948, 0.9946, 0.9946, 0.9943, 0.9942, 0.9942, 0.9939, 0.9937,
         0.9936],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9956, 0.9953, 0.9950, 0.9949, 0.9947, 0.9945, 0.9944, 0.9943, 0.9942,
         0.9938],
        [0.9987, 0.9981, 0.9977, 0.9973, 0.9971, 0.9971, 0.9971, 0.9971, 0.9969,
         0.9969],
        [0.9987, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9964, 0.9962, 0.9961, 0.9960, 0.9957, 0.9955, 0.9951, 0.9951, 0.9950,
         0.9950],
        [0.9986, 0.9985, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9980],
        [0.9980, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9985, 0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9905, 0.9859, 0.9809, 0.9805, 0.9803, 0.9787, 0.9771, 0.9753, 0.9752,
         0.9715],
        [0.9971, 0.9971, 0.9969, 0.9969, 0.9968, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9973, 0.9970, 0.9968, 0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9898, 0.9866, 0.9848, 0.9841, 0.9833, 0.9833, 0.9826, 0.9822, 0.9800,
         0.9799],
        [0.9961, 0.9961, 0.9961, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9942, 0.9936, 0.9935, 0.9934, 0.9925, 0.9920, 0.9919, 0.9915, 0.9914,
         0.9913],
        [0.9965, 0.9963, 0.9961, 0.9961, 0.9961, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9866, 0.9852, 0.9840, 0.9835, 0.9822, 0.9821, 0.9821, 0.9800, 0.9789,
         0.9786],
        [0.9983, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9977],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9967, 0.9966, 0.9965,
         0.9965],
        [0.9920, 0.9908, 0.9905, 0.9902, 0.9901, 0.9894, 0.9894, 0.9890, 0.9887,
         0.9883],
        [0.9883, 0.9867, 0.9849, 0.9846, 0.9846, 0.9841, 0.9839, 0.9833, 0.9831,
         0.9829],
        [0.9892, 0.9842, 0.9706, 0.9705, 0.9659, 0.9604, 0.9570, 0.9558, 0.9542,
         0.9539],
        [0.9742, 0.9741, 0.9711, 0.9690, 0.9657, 0.9632, 0.9616, 0.9614, 0.9610,
         0.9585],
        [0.9931, 0.9924, 0.9916, 0.9909, 0.9906, 0.9906, 0.9902, 0.9898, 0.9897,
         0.9896],
        [0.9947, 0.9945, 0.9942, 0.9941, 0.9941, 0.9939, 0.9938, 0.9936, 0.9936,
         0.9934],
        [0.9944, 0.9935, 0.9932, 0.9930, 0.9930, 0.9930, 0.9928, 0.9926, 0.9925,
         0.9924],
        [0.9904, 0.9888, 0.9883, 0.9883, 0.9872, 0.9868, 0.9864, 0.9846, 0.9843,
         0.9841],
        [0.9947, 0.9946, 0.9936, 0.9929, 0.9923, 0.9921, 0.9915, 0.9915, 0.9896,
         0.9889],
        [0.9920, 0.9919, 0.9910, 0.9884, 0.9873, 0.9868, 0.9868, 0.9867, 0.9865,
         0.9862],
        [0.9945, 0.9945, 0.9944, 0.9941, 0.9941, 0.9939, 0.9936, 0.9932, 0.9932,
         0.9932],
        [0.9954, 0.9953, 0.9950, 0.9948, 0.9945, 0.9942, 0.9938, 0.9937, 0.9936,
         0.9935],
        [0.9946, 0.9913, 0.9906, 0.9905, 0.9893, 0.9887, 0.9877, 0.9875, 0.9875,
         0.9871],
        [0.9933, 0.9926, 0.9922, 0.9890, 0.9881, 0.9873, 0.9870, 0.9867, 0.9857,
         0.9853],
        [0.9932, 0.9931, 0.9929, 0.9914, 0.9913, 0.9903, 0.9894, 0.9891, 0.9885,
         0.9880],
        [0.9965, 0.9951, 0.9944, 0.9933, 0.9932, 0.9929, 0.9914, 0.9907, 0.9906,
         0.9893],
        [0.9904, 0.9897, 0.9890, 0.9887, 0.9874, 0.9873, 0.9869, 0.9869, 0.9864,
         0.9861],
        [0.9901, 0.9881, 0.9870, 0.9849, 0.9844, 0.9843, 0.9842, 0.9834, 0.9833,
         0.9829],
        [0.9928, 0.9921, 0.9917, 0.9909, 0.9902, 0.9895, 0.9867, 0.9864, 0.9859,
         0.9848],
        [0.9937, 0.9932, 0.9927, 0.9927, 0.9913, 0.9913, 0.9908, 0.9908, 0.9906,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 1, 0, 0, 1, 0, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1539321.0000, 1539109.6250, 1521156.7500, 1521101.5000, 1520385.0000,
         1518767.7500, 1515515.3750, 1513077.5000, 1511618.0000, 1510744.6250],
        [1546460.2500, 1542677.6250, 1534667.1250, 1534165.1250, 1532613.6250,
         1532090.5000, 1532058.2500, 1531960.3750, 1531945.7500, 1531323.5000],
        [1254932.1250, 1133025.5000, 1127868.0000, 1084813.1250, 1083346.1250,
         1062711.3750, 1047939.2500, 1043853.6875, 1035982.2500, 1027845.6875],
        [1478207.5000, 1463756.8750, 1458203.3750, 1454966.7500, 1452647.1250,
         1446019.6250, 1433424.8750, 1428847.2500, 1426403.3750, 1422090.7500],
        [1406748.7500, 1364702.1250, 1348746.2500, 1347530.0000, 1347067.3750,
         1346218.5000, 1335411.0000, 1332772.3750, 1331982.0000, 1329985.3750],
        [1349964.8750, 1300056.2500, 1256043.2500, 1227291.1250, 1193595.0000,
         1170695.1250, 1140428.5000, 1129979.2500, 1118473.0000, 1104981.8750],
        [1078756.2500, 1072102.1250, 1061950.5000, 1035128.0000, 1016165.5000,
         1014918.0000,  988917.4375,  974538.6875,  964375.3125,  952831.9375],
        [1358348.7500, 1247002.2500, 1228015.7500, 1219138.1250, 1196792.1250,
         1137616.2500, 1134201.7500, 1114139.2500, 1102572.3750, 1101690.5000],
        [1557923.6250, 1551213.5000, 1549195.5000, 1547295.1250, 1544293.8750,
         1541776.0000, 1540963.1250, 1540698.6250, 1538251.2500, 1535213.1250],
        [1473224.1250, 1380172.6250, 1371486.6250, 1353892.1250, 1348723.1250,
         1345644.7500, 1315526.3750, 1309400.7500, 1304883.0000, 1298352.5000],
        [1556543.8750, 1554693.8750, 1550743.1250, 1549909.2500, 1549281.2500,
         1549074.3750, 1546942.6250, 1546708.1250, 1545247.0000, 1544956.7500],
        [1495408.3750, 1494601.3750, 1476319.7500, 1471203.7500, 1452456.0000,
         1445295.7500, 1443620.6250, 1430401.5000, 1419548.7500, 1415820.1250],
        [1487458.8750, 1473198.8750, 1446516.1250, 1429587.3750, 1428362.1250,
         1425913.7500, 1415984.8750, 1389406.5000, 1388859.3750, 1366821.2500],
        [1566890.5000, 1563624.3750, 1561861.2500, 1561736.2500, 1560860.6250,
         1560494.5000, 1560426.0000, 1560359.1250, 1560257.8750, 1559145.3750],
        [1562576.3750, 1560598.7500, 1559466.5000, 1558864.3750, 1558558.1250,
         1556929.8750, 1556256.0000, 1556201.1250, 1555859.7500, 1555666.8750],
        [1558550.6250, 1555344.8750, 1555115.0000, 1554361.7500, 1554191.3750,
         1554173.5000, 1552314.6250, 1551130.6250, 1550333.5000, 1550150.1250],
        [1530726.3750, 1525504.7500, 1519141.6250, 1512836.6250, 1509627.0000,
         1505976.1250, 1504687.0000, 1502215.0000, 1501627.7500, 1501443.0000],
        [1519554.5000, 1511508.3750, 1508835.3750, 1508681.5000, 1508344.7500,
         1507056.5000, 1506638.3750, 1501965.7500, 1501357.1250, 1500662.8750],
        [1496732.3750, 1485213.5000, 1481247.2500, 1480980.2500, 1475600.5000,
         1473124.3750, 1472690.3750, 1467120.8750, 1462399.2500, 1460619.5000],
        [1549734.8750, 1548489.5000, 1548355.0000, 1547900.3750, 1547088.7500,
         1546383.6250, 1545615.5000, 1545378.1250, 1544887.5000, 1543051.3750],
        [1555674.2500, 1553840.0000, 1553688.8750, 1553549.6250, 1552860.8750,
         1551735.8750, 1549827.8750, 1547946.1250, 1547435.5000, 1546815.7500],
        [1503507.7500, 1497219.1250, 1489531.3750, 1487051.7500, 1484386.6250,
         1480271.3750, 1477783.2500, 1475131.8750, 1472572.3750, 1465523.8750],
        [1569819.0000, 1556738.3750, 1549265.0000, 1539077.2500, 1536379.0000,
         1535368.2500, 1534408.0000, 1534317.2500, 1531570.3750, 1530873.8750],
        [1570281.7500, 1566626.0000, 1565595.3750, 1565292.3750, 1564176.1250,
         1562376.7500, 1562361.7500, 1561596.2500, 1561378.7500, 1561255.2500],
        [1520731.6250, 1514970.3750, 1513985.5000, 1511563.2500, 1503983.8750,
         1500863.2500, 1491557.1250, 1491256.8750, 1491043.6250, 1489828.2500],
        [1568497.6250, 1566113.6250, 1562236.7500, 1562230.7500, 1560970.7500,
         1560189.5000, 1559010.0000, 1558935.7500, 1556643.3750, 1555196.6250],
        [1554685.0000, 1552695.0000, 1552132.5000, 1547901.8750, 1547541.7500,
         1545835.0000, 1545012.6250, 1544591.3750, 1542314.2500, 1542293.6250],
        [1566566.2500, 1565432.7500, 1563048.8750, 1560777.2500, 1559747.6250,
         1559616.7500, 1558741.0000, 1558150.8750, 1558115.2500, 1557112.5000],
        [1573035.0000, 1572327.2500, 1571535.6250, 1570424.0000, 1568906.1250,
         1568749.0000, 1568746.0000, 1567909.8750, 1567011.5000, 1566821.7500],
        [1576460.7500, 1574857.3750, 1572790.6250, 1571147.6250, 1570722.1250,
         1569094.6250, 1567069.8750, 1566148.0000, 1565800.1250, 1565774.6250],
        [1572661.6250, 1571469.7500, 1570281.7500, 1569428.3750, 1569037.8750,
         1568829.7500, 1568234.5000, 1567165.5000, 1567095.2500, 1566373.6250],
        [1571585.1250, 1570600.7500, 1569066.2500, 1568755.0000, 1567153.5000,
         1566502.0000, 1565806.0000, 1564865.6250, 1564722.2500, 1563737.6250],
        [1396412.3750, 1307915.6250, 1218196.7500, 1211279.6250, 1208402.0000,
         1181007.2500, 1153457.8750, 1123757.0000, 1123439.7500, 1065522.5000],
        [1535220.5000, 1535199.8750, 1531208.2500, 1530381.8750, 1528475.5000,
         1524838.5000, 1522799.7500, 1521946.0000, 1521607.8750, 1521139.2500],
        [1551558.2500, 1549132.0000, 1548727.2500, 1546615.1250, 1544489.7500,
         1543660.6250, 1542682.0000, 1542348.1250, 1541939.1250, 1541939.1250],
        [1539535.2500, 1533721.8750, 1529790.8750, 1528752.5000, 1527974.1250,
         1524335.5000, 1524011.3750, 1523491.1250, 1523098.8750, 1522872.3750],
        [1383101.7500, 1322350.1250, 1287439.3750, 1274284.8750, 1260974.8750,
         1259923.0000, 1248082.5000, 1240706.8750, 1202170.8750, 1200159.2500],
        [1514168.8750, 1513598.6250, 1513194.3750, 1509333.3750, 1507822.7500,
         1507046.3750, 1505149.0000, 1502378.3750, 1500476.7500, 1499827.3750],
        [1472725.3750, 1461462.5000, 1457800.1250, 1456663.2500, 1436987.6250,
         1428490.2500, 1425455.5000, 1417792.7500, 1415215.2500, 1412824.3750],
        [1523247.0000, 1517812.2500, 1514216.5000, 1513068.8750, 1512797.6250,
         1509881.8750, 1507039.2500, 1506780.5000, 1505612.7500, 1505568.2500],
        [1321399.6250, 1294558.0000, 1272722.8750, 1263612.5000, 1241054.7500,
         1239384.7500, 1239296.1250, 1203432.6250, 1183474.2500, 1178523.0000],
        [1561293.8750, 1556301.8750, 1556187.7500, 1555782.5000, 1553434.1250,
         1553151.2500, 1552154.6250, 1551984.5000, 1550868.8750, 1548945.8750],
        [1550292.1250, 1549595.8750, 1548984.2500, 1548699.2500, 1547686.3750,
         1546677.1250, 1544523.5000, 1544367.5000, 1543729.8750, 1543413.3750],
        [1536097.6250, 1533800.8750, 1533483.5000, 1531160.0000, 1530641.6250,
         1530279.7500, 1527687.1250, 1524489.6250, 1523331.3750, 1522131.7500],
        [1427997.1250, 1403935.5000, 1398003.3750, 1391728.6250, 1390215.0000,
         1375973.6250, 1375631.1250, 1366784.7500, 1361798.8750, 1353609.3750],
        [1353812.0000, 1323303.8750, 1290608.5000, 1285035.1250, 1283408.6250,
         1275323.0000, 1271948.8750, 1260423.1250, 1257949.2500, 1253747.8750],
        [1371558.6250, 1276700.5000, 1051150.1250, 1050594.0000,  983474.7500,
          908781.6250,  865533.6875,  851011.1875,  831389.5000,  828235.0625],
        [1106384.2500, 1104950.2500, 1059623.8750, 1027047.0625,  980121.6875,
          945819.1250,  924840.1250,  922255.1250,  916562.0000,  884477.8750],
        [1450743.5000, 1435669.8750, 1418594.8750, 1405844.7500, 1399253.1250,
         1398270.1250, 1390326.3750, 1383041.1250, 1380640.0000, 1379705.5000],
        [1483957.7500, 1479220.1250, 1472722.6250, 1471113.8750, 1470829.1250,
         1467349.0000, 1464469.1250, 1460783.8750, 1459898.0000, 1456992.5000],
        [1476252.1250, 1459413.6250, 1452181.7500, 1447766.5000, 1447192.1250,
         1447066.6250, 1443902.8750, 1440336.7500, 1437080.8750, 1435511.1250],
        [1395621.5000, 1363592.3750, 1353486.7500, 1353245.3750, 1333390.1250,
         1326209.6250, 1317787.8750, 1283370.7500, 1279023.3750, 1275051.8750],
        [1483097.5000, 1480476.1250, 1460413.3750, 1445425.3750, 1433446.7500,
         1429796.0000, 1417088.5000, 1417046.6250, 1380235.8750, 1365786.6250],
        [1427523.3750, 1424500.1250, 1406933.7500, 1355405.0000, 1335412.2500,
         1325099.6250, 1324566.3750, 1322953.0000, 1319172.2500, 1313732.3750],
        [1480270.0000, 1478655.8750, 1478331.6250, 1471821.1250, 1471025.5000,
         1466908.2500, 1460726.7500, 1452990.7500, 1451363.5000, 1451363.5000],
        [1497561.8750, 1495415.5000, 1490337.0000, 1485491.2500, 1478568.5000,
         1472927.6250, 1465475.1250, 1462872.2500, 1459584.7500, 1458452.2500],
        [1481863.2500, 1413793.5000, 1399166.5000, 1398096.6250, 1373261.2500,
         1362336.7500, 1342946.1250, 1339226.8750, 1338648.5000, 1330623.5000],
        [1453995.7500, 1440033.1250, 1431434.5000, 1368494.7500, 1350938.6250,
         1335605.8750, 1329820.3750, 1323551.2500, 1304823.2500, 1297160.7500],
        [1452666.5000, 1449324.8750, 1445108.2500, 1414395.0000, 1412480.8750,
         1393690.3750, 1374496.8750, 1369728.6250, 1357109.7500, 1348234.3750],
        [1522773.6250, 1492534.6250, 1476567.6250, 1453624.2500, 1451535.1250,
         1446878.8750, 1415289.5000, 1400594.8750, 1398678.1250, 1373580.8750],
        [1396030.1250, 1380426.7500, 1368439.8750, 1362036.7500, 1337037.1250,
         1334298.3750, 1327832.1250, 1326536.0000, 1318378.6250, 1312527.6250],
        [1388724.3750, 1349742.1250, 1328169.0000, 1289272.5000, 1281377.2500,
         1278085.7500, 1277610.3750, 1262650.0000, 1261491.0000, 1253655.8750],
        [1444390.5000, 1428606.0000, 1420377.6250, 1405161.1250, 1390489.5000,
         1377056.7500, 1323355.6250, 1317330.5000, 1308892.6250, 1288323.6250],
        [1461929.3750, 1452154.1250, 1442202.0000, 1441844.3750, 1413894.6250,
         1412379.7500, 1403306.2500, 1403294.3750, 1398966.2500, 1393820.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1539321.0000,       0.0000],
         [1539109.6250,       0.0000],
         [1521156.7500,       0.0000],
         ...,
         [1513077.5000,       0.0000],
         [1511618.0000,       0.0000],
         [1510744.6250,       0.0000]],

        [[1546460.2500,       0.0000],
         [1542677.6250,       0.0000],
         [1534667.1250,       0.0000],
         ...,
         [1531960.3750,       0.0000],
         [1531945.7500,       0.0000],
         [1531323.5000,       0.0000]],

        [[1254932.1250,       0.0000],
         [1133025.5000,       0.0000],
         [1127868.0000,       0.0000],
         ...,
         [      0.0000, 1043853.6875],
         [1035982.2500,       0.0000],
         [1027845.6875,       0.0000]],

        ...,

        [[1388724.3750,       0.0000],
         [1349742.1250,       0.0000],
         [1328169.0000,       0.0000],
         ...,
         [1262650.0000,       0.0000],
         [      0.0000, 1261491.0000],
         [1253655.8750,       0.0000]],

        [[1444390.5000,       0.0000],
         [1428606.0000,       0.0000],
         [1420377.6250,       0.0000],
         ...,
         [      0.0000, 1317330.5000],
         [      0.0000, 1308892.6250],
         [1288323.6250,       0.0000]],

        [[      0.0000, 1461929.3750],
         [      0.0000, 1452154.1250],
         [      0.0000, 1442202.0000],
         ...,
         [      0.0000, 1403294.3750],
         [      0.0000, 1398966.2500],
         [1393820.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15210797.0000,        0.0000],
        [15349964.0000,        0.0000],
        [ 7690304.0000,  3212013.0000],
        [14464567.0000,        0.0000],
        [10778931.0000,  2712232.0000],
        [10764217.0000,  1227291.1250],
        [ 3081769.0000,  7077915.0000],
        [10737828.0000,  1101690.5000],
        [12370912.0000,  3075911.7500],
        [12152583.0000,  1348723.1250],
        [15494100.0000,        0.0000],
        [14544675.0000,        0.0000],
        [12863250.0000,  1388859.3750],
        [15615656.0000,        0.0000],
        [15580978.0000,        0.0000],
        [15535666.0000,        0.0000],
        [13609098.0000,  1504687.0000],
        [ 9045090.0000,  6029516.0000],
        [13293329.0000,  1462399.2500],
        [15466884.0000,        0.0000],
        [15513375.0000,        0.0000],
        [11859062.0000,  2973918.0000],
        [15417816.0000,        0.0000],
        [15640940.0000,        0.0000],
        [ 9011130.0000,  6018653.5000],
        [15610026.0000,        0.0000],
        [15475002.0000,        0.0000],
        [15607309.0000,        0.0000],
        [15695466.0000,        0.0000],
        [15699866.0000,        0.0000],
        [15690578.0000,        0.0000],
        [15672794.0000,        0.0000],
        [ 3454931.7500,  8534458.0000],
        [10685270.0000,  4587547.0000],
        [13906475.0000,  1546615.1250],
        [13747792.0000,  1529790.8750],
        [ 4997616.0000,  7681578.0000],
        [12045633.0000,  3027363.2500],
        [11500263.0000,  2885153.5000],
        [15116024.0000,        0.0000],
        [ 8754269.0000,  3683190.2500],
        [15540105.0000,        0.0000],
        [15467970.0000,        0.0000],
        [12228142.0000,  3064961.0000],
        [ 2729583.0000, 11116094.0000],
        [ 2514171.0000, 10341389.0000],
        [ 5268425.5000,  4750003.0000],
        [       0.0000,  9872081.0000],
        [ 9812387.0000,  4229702.0000],
        [10272533.0000,  4414803.0000],
        [11591871.0000,  2894833.0000],
        [ 1283370.7500, 11997409.0000],
        [       0.0000, 14312812.0000],
        [ 1313732.3750, 12241566.0000],
        [11704532.0000,  2958926.0000],
        [10318157.0000,  4448528.0000],
        [ 2692960.2500, 11087002.0000],
        [ 2692046.0000, 10943812.0000],
        [       0.0000, 14017234.0000],
        [ 2774175.7500, 11657882.0000],
        [ 8066413.0000,  5397130.5000],
        [ 9149824.0000,  3820954.0000],
        [ 9754405.0000,  3949578.7500],
        [ 1393820.6250, 12829971.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 241/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:33, 61.20s/it]  7%|▋         | 2/29 [01:02<11:35, 25.74s/it] 10%|█         | 3/29 [01:03<06:14, 14.41s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.0978291034698486
Epoch 242/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.64s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.1082301139831543
Epoch 243/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:03, 58.00s/it]  7%|▋         | 2/29 [00:58<10:59, 24.42s/it] 10%|█         | 3/29 [00:59<05:55, 13.69s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 3.103135108947754
Epoch 244/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:26, 56.67s/it]  7%|▋         | 2/29 [00:58<10:55, 24.28s/it] 10%|█         | 3/29 [00:59<05:56, 13.72s/it] 14%|█▍        | 4/29 [01:01<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:02<02:26,  6.12s/it] 21%|██        | 6/29 [01:03<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.49s/it] 31%|███       | 9/29 [01:05<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.09818434715271
Epoch 245/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:16, 60.59s/it]  7%|▋         | 2/29 [01:01<11:28, 25.49s/it] 10%|█         | 3/29 [01:02<06:11, 14.27s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.0939557552337646
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0110, 0.0012,  ..., 0.0051, 0.0006, 0.0184],
        [0.0026, 0.0103, 0.0015,  ..., 0.0041, 0.0008, 0.0183],
        [0.0282, 0.0085, 0.0023,  ..., 0.0054, 0.0140, 0.0228],
        ...,
        [0.0056, 0.0087, 0.0254,  ..., 0.0041, 0.0013, 0.0227],
        [0.0059, 0.0114, 0.0196,  ..., 0.0044, 0.0025, 0.0215],
        [0.0083, 0.0081, 0.0046,  ..., 0.0021, 0.0040, 0.0206]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9968, 0.9960, 0.9959, 0.9959, 0.9957, 0.9957, 0.9955, 0.9954,
         0.9954],
        [0.9974, 0.9972, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9965, 0.9965,
         0.9965],
        [0.9824, 0.9725, 0.9720, 0.9717, 0.9701, 0.9696, 0.9694, 0.9687, 0.9680,
         0.9671],
        [0.9935, 0.9930, 0.9927, 0.9926, 0.9925, 0.9917, 0.9915, 0.9915, 0.9912,
         0.9911],
        [0.9901, 0.9877, 0.9874, 0.9869, 0.9867, 0.9866, 0.9865, 0.9863, 0.9862,
         0.9860],
        [0.9878, 0.9851, 0.9819, 0.9816, 0.9780, 0.9756, 0.9753, 0.9747, 0.9736,
         0.9735],
        [0.9741, 0.9741, 0.9709, 0.9700, 0.9686, 0.9686, 0.9678, 0.9667, 0.9664,
         0.9661],
        [0.9864, 0.9828, 0.9779, 0.9775, 0.9755, 0.9736, 0.9719, 0.9716, 0.9711,
         0.9702],
        [0.9980, 0.9975, 0.9975, 0.9975, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970,
         0.9969],
        [0.9937, 0.9882, 0.9877, 0.9874, 0.9870, 0.9864, 0.9846, 0.9844, 0.9840,
         0.9840],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9944, 0.9943, 0.9934, 0.9930, 0.9915, 0.9915, 0.9914, 0.9908, 0.9907,
         0.9900],
        [0.9940, 0.9933, 0.9915, 0.9910, 0.9908, 0.9902, 0.9901, 0.9884, 0.9882,
         0.9882],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9966, 0.9963, 0.9961, 0.9957, 0.9956, 0.9956, 0.9954, 0.9954, 0.9954,
         0.9952],
        [0.9960, 0.9957, 0.9957, 0.9956, 0.9956, 0.9956, 0.9955, 0.9953, 0.9952,
         0.9951],
        [0.9950, 0.9945, 0.9942, 0.9940, 0.9939, 0.9938, 0.9934, 0.9934, 0.9932,
         0.9932],
        [0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9954, 0.9946, 0.9946, 0.9943, 0.9940, 0.9939, 0.9938, 0.9935, 0.9933,
         0.9931],
        [0.9985, 0.9979, 0.9976, 0.9970, 0.9970, 0.9970, 0.9970, 0.9970, 0.9967,
         0.9967],
        [0.9986, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9959, 0.9959, 0.9957, 0.9955, 0.9953, 0.9953, 0.9950, 0.9950, 0.9949,
         0.9948],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9978,
         0.9978],
        [0.9978, 0.9978, 0.9978, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9984, 0.9984, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9988, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9902, 0.9864, 0.9813, 0.9807, 0.9801, 0.9792, 0.9764, 0.9751, 0.9746,
         0.9727],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9977, 0.9976, 0.9976, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972, 0.9972,
         0.9972],
        [0.9969, 0.9966, 0.9964, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9899, 0.9869, 0.9846, 0.9839, 0.9837, 0.9832, 0.9828, 0.9822, 0.9807,
         0.9797],
        [0.9958, 0.9958, 0.9957, 0.9956, 0.9954, 0.9954, 0.9952, 0.9951, 0.9951,
         0.9950],
        [0.9943, 0.9935, 0.9933, 0.9930, 0.9921, 0.9915, 0.9913, 0.9910, 0.9909,
         0.9909],
        [0.9962, 0.9958, 0.9958, 0.9956, 0.9956, 0.9953, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9864, 0.9861, 0.9845, 0.9840, 0.9834, 0.9832, 0.9823, 0.9822, 0.9793,
         0.9789],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9971],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9912, 0.9900, 0.9899, 0.9897, 0.9890, 0.9887, 0.9883, 0.9879, 0.9873,
         0.9872],
        [0.9877, 0.9847, 0.9842, 0.9840, 0.9837, 0.9829, 0.9817, 0.9817, 0.9817,
         0.9815],
        [0.9888, 0.9849, 0.9722, 0.9711, 0.9662, 0.9610, 0.9596, 0.9576, 0.9571,
         0.9558],
        [0.9751, 0.9747, 0.9721, 0.9696, 0.9685, 0.9644, 0.9630, 0.9618, 0.9611,
         0.9578],
        [0.9928, 0.9911, 0.9902, 0.9901, 0.9897, 0.9897, 0.9893, 0.9889, 0.9887,
         0.9886],
        [0.9943, 0.9941, 0.9938, 0.9937, 0.9935, 0.9935, 0.9935, 0.9931, 0.9931,
         0.9929],
        [0.9939, 0.9930, 0.9928, 0.9928, 0.9926, 0.9924, 0.9923, 0.9920, 0.9919,
         0.9919],
        [0.9902, 0.9882, 0.9881, 0.9880, 0.9869, 0.9863, 0.9853, 0.9842, 0.9839,
         0.9829],
        [0.9946, 0.9943, 0.9934, 0.9928, 0.9919, 0.9918, 0.9913, 0.9911, 0.9901,
         0.9889],
        [0.9917, 0.9917, 0.9906, 0.9885, 0.9872, 0.9869, 0.9865, 0.9862, 0.9861,
         0.9856],
        [0.9945, 0.9942, 0.9938, 0.9938, 0.9937, 0.9936, 0.9933, 0.9926, 0.9926,
         0.9926],
        [0.9953, 0.9946, 0.9945, 0.9945, 0.9939, 0.9937, 0.9935, 0.9933, 0.9927,
         0.9926],
        [0.9944, 0.9911, 0.9902, 0.9899, 0.9889, 0.9886, 0.9874, 0.9871, 0.9871,
         0.9870],
        [0.9930, 0.9922, 0.9921, 0.9894, 0.9872, 0.9869, 0.9868, 0.9865, 0.9856,
         0.9843],
        [0.9927, 0.9926, 0.9926, 0.9912, 0.9910, 0.9904, 0.9890, 0.9886, 0.9883,
         0.9872],
        [0.9964, 0.9950, 0.9940, 0.9929, 0.9928, 0.9924, 0.9913, 0.9901, 0.9897,
         0.9892],
        [0.9904, 0.9897, 0.9890, 0.9884, 0.9872, 0.9869, 0.9866, 0.9861, 0.9860,
         0.9860],
        [0.9902, 0.9886, 0.9865, 0.9851, 0.9843, 0.9841, 0.9839, 0.9836, 0.9831,
         0.9829],
        [0.9926, 0.9918, 0.9913, 0.9905, 0.9897, 0.9892, 0.9859, 0.9857, 0.9850,
         0.9837],
        [0.9930, 0.9930, 0.9926, 0.9922, 0.9914, 0.9907, 0.9905, 0.9904, 0.9904,
         0.9901]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 0, 0, 1, 0, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1532435.2500, 1529792.3750, 1511029.8750, 1510128.1250, 1509022.3750,
         1505813.8750, 1505450.5000, 1501427.2500, 1498887.8750, 1498539.1250],
        [1542146.6250, 1538606.2500, 1527749.7500, 1527554.6250, 1527257.3750,
         1525989.3750, 1525852.5000, 1523335.6250, 1522733.0000, 1522320.6250],
        [1245091.3750, 1079999.7500, 1072665.6250, 1068443.8750, 1044042.8750,
         1036861.9375, 1033233.3750, 1023976.1875, 1012625.7500,  999618.8125],
        [1457624.8750, 1447333.0000, 1440937.1250, 1439646.0000, 1437911.6250,
         1421834.5000, 1418107.8750, 1417692.6250, 1410734.8750, 1408804.1250],
        [1389955.1250, 1342978.2500, 1335942.2500, 1326753.6250, 1324207.7500,
         1321905.0000, 1319684.3750, 1315178.8750, 1313118.5000, 1311076.3750],
        [1344021.1250, 1293943.3750, 1234889.6250, 1230196.0000, 1169082.8750,
         1130006.1250, 1124135.3750, 1114279.3750, 1097640.2500, 1096541.7500],
        [1105991.8750, 1105445.6250, 1056696.3750, 1043062.5625, 1021805.6875,
         1021383.7500, 1010304.0000,  994508.7500,  989607.1250,  986714.9375],
        [1317577.8750, 1250891.1250, 1167427.3750, 1160470.8750, 1128195.0000,
         1098027.7500, 1071035.2500, 1066952.2500, 1059654.1250, 1045132.6875],
        [1554258.0000, 1545232.2500, 1544623.7500, 1543822.6250, 1539974.3750,
         1538563.7500, 1535878.0000, 1533771.6250, 1533015.5000, 1530574.5000],
        [1462450.8750, 1351320.0000, 1342066.6250, 1335886.1250, 1329715.1250,
         1316976.2500, 1285118.3750, 1281001.0000, 1274140.1250, 1273554.6250],
        [1552237.5000, 1549816.1250, 1548194.1250, 1546187.5000, 1543993.3750,
         1543123.3750, 1540808.8750, 1540703.0000, 1539840.7500, 1538883.6250],
        [1477603.0000, 1475590.6250, 1455682.7500, 1448184.8750, 1418006.3750,
         1416402.1250, 1414430.0000, 1402904.8750, 1401349.7500, 1386544.7500],
        [1468173.3750, 1454284.1250, 1417083.1250, 1406453.6250, 1403883.2500,
         1390948.2500, 1389533.7500, 1355256.3750, 1352899.5000, 1351309.7500],
        [1563195.0000, 1559524.5000, 1559310.3750, 1559289.5000, 1559111.1250,
         1558173.2500, 1557807.7500, 1556771.1250, 1556063.0000, 1556012.6250],
        [1558044.0000, 1555786.8750, 1555119.5000, 1554779.8750, 1554708.7500,
         1553410.3750, 1552641.7500, 1551649.8750, 1551642.6250, 1551314.1250],
        [1555212.8750, 1551132.1250, 1550965.0000, 1550069.0000, 1549426.0000,
         1548836.5000, 1548127.7500, 1548087.7500, 1548030.2500, 1546786.2500],
        [1524350.0000, 1517804.8750, 1514336.3750, 1504032.7500, 1502831.2500,
         1501771.0000, 1499256.7500, 1498397.6250, 1498079.0000, 1495020.5000],
        [1511482.3750, 1505515.1250, 1503972.5000, 1503674.1250, 1503601.1250,
         1502213.5000, 1499966.0000, 1495993.1250, 1493353.2500, 1492484.7500],
        [1489596.7500, 1478926.6250, 1473491.0000, 1468772.8750, 1466192.1250,
         1463736.0000, 1457010.6250, 1455476.0000, 1452180.3750, 1451464.5000],
        [1544793.1250, 1544230.5000, 1544230.5000, 1542109.7500, 1541896.6250,
         1541664.2500, 1541069.0000, 1541060.1250, 1541044.0000, 1539150.6250],
        [1554068.3750, 1552166.3750, 1551759.5000, 1551401.3750, 1549947.6250,
         1547673.0000, 1546097.5000, 1543320.6250, 1542914.3750, 1542159.8750],
        [1498769.2500, 1482447.0000, 1480768.3750, 1476070.5000, 1469671.0000,
         1467030.0000, 1464442.5000, 1457962.7500, 1453952.7500, 1450119.7500],
        [1566615.5000, 1553782.2500, 1546228.7500, 1533885.7500, 1532832.8750,
         1532828.5000, 1532828.5000, 1532629.6250, 1526926.8750, 1526628.2500],
        [1568038.5000, 1563603.5000, 1562721.0000, 1562485.5000, 1560650.7500,
         1559304.3750, 1558778.0000, 1558522.3750, 1558211.8750, 1557428.7500],
        [1510282.2500, 1510097.8750, 1504045.6250, 1501321.3750, 1496504.0000,
         1496160.0000, 1489896.5000, 1489098.2500, 1488599.8750, 1486493.0000],
        [1567286.5000, 1562923.6250, 1559575.0000, 1558592.3750, 1558011.2500,
         1557418.5000, 1556063.0000, 1555083.8750, 1551586.3750, 1551491.7500],
        [1551911.8750, 1550358.7500, 1550043.7500, 1544824.1250, 1544128.8750,
         1543173.5000, 1541074.8750, 1540848.5000, 1539657.1250, 1538417.0000],
        [1563982.2500, 1563469.3750, 1560613.5000, 1557691.7500, 1557359.0000,
         1556788.8750, 1556113.5000, 1555276.6250, 1554351.3750, 1554176.5000],
        [1571573.1250, 1569302.6250, 1568982.5000, 1568321.1250, 1567389.6250,
         1567267.0000, 1566434.8750, 1565895.6250, 1565038.6250, 1564474.6250],
        [1573713.2500, 1573134.1250, 1570548.2500, 1568759.5000, 1568363.0000,
         1566248.1250, 1565117.7500, 1562573.3750, 1562552.6250, 1562493.0000],
        [1569733.6250, 1569088.6250, 1567424.0000, 1566657.3750, 1566615.5000,
         1566542.3750, 1564731.2500, 1564159.7500, 1563806.2500, 1563602.0000],
        [1568600.8750, 1567347.8750, 1566696.2500, 1565832.8750, 1565159.5000,
         1564419.3750, 1563369.3750, 1562218.7500, 1561773.3750, 1561767.5000],
        [1391465.8750, 1318083.1250, 1225346.1250, 1213962.5000, 1204298.2500,
         1189706.0000, 1142021.8750, 1121578.1250, 1112626.1250, 1083015.5000],
        [1526495.7500, 1525707.0000, 1525071.2500, 1523497.0000, 1518404.2500,
         1516488.2500, 1515869.3750, 1514011.5000, 1513947.8750, 1513357.6250],
        [1547693.7500, 1546845.2500, 1546513.3750, 1542031.7500, 1540703.0000,
         1540172.6250, 1538576.8750, 1538547.5000, 1537957.7500, 1537957.7500],
        [1531904.8750, 1524435.7500, 1520721.5000, 1515727.7500, 1515545.6250,
         1513962.2500, 1513846.8750, 1513030.0000, 1512933.2500, 1512716.8750],
        [1385709.3750, 1327724.5000, 1284634.3750, 1271507.3750, 1268444.3750,
         1259374.1250, 1252199.1250, 1240360.2500, 1214199.8750, 1196609.5000],
        [1507431.7500, 1507391.3750, 1504741.3750, 1503804.7500, 1498754.8750,
         1498567.7500, 1495272.8750, 1491981.0000, 1491437.5000, 1489500.1250],
        [1474487.7500, 1458218.6250, 1453638.0000, 1448096.5000, 1430282.7500,
         1417830.6250, 1414235.7500, 1406283.2500, 1405952.0000, 1405850.1250],
        [1515259.5000, 1507367.0000, 1506157.0000, 1503287.0000, 1503070.5000,
         1497259.1250, 1497162.1250, 1496115.8750, 1496028.8750, 1495548.1250],
        [1317564.1250, 1311300.2500, 1282793.1250, 1273453.8750, 1262583.7500,
         1258450.8750, 1242689.1250, 1240350.7500, 1191035.3750, 1184689.2500],
        [1557841.8750, 1554259.5000, 1553918.6250, 1553534.8750, 1549457.0000,
         1548892.6250, 1548572.1250, 1546882.1250, 1546309.8750, 1545743.7500],
        [1544980.2500, 1543507.6250, 1543479.6250, 1541323.1250, 1541188.0000,
         1540626.6250, 1539415.0000, 1538462.3750, 1536877.2500, 1536308.6250],
        [1527429.2500, 1526888.8750, 1525000.0000, 1524549.2500, 1524082.6250,
         1522722.7500, 1520012.5000, 1518179.8750, 1516186.1250, 1516157.1250],
        [1411045.6250, 1386858.1250, 1384933.8750, 1381623.8750, 1367550.1250,
         1361100.3750, 1353868.8750, 1346868.2500, 1334309.7500, 1333776.7500],
        [1342277.7500, 1285964.3750, 1276228.2500, 1273424.6250, 1267329.5000,
         1253192.0000, 1232433.0000, 1231509.5000, 1231434.3750, 1228592.1250],
        [1363362.2500, 1289713.8750, 1076244.7500, 1059085.3750,  986784.5625,
          916436.1875,  898585.5000,  873747.5625,  866881.8125,  851567.2500],
        [1121013.5000, 1114674.7500, 1074896.8750, 1036646.3750, 1021055.6250,
          962725.8750,  943271.6875,  927810.1875,  918124.5000,  875338.0625],
        [1444610.8750, 1409415.6250, 1392023.2500, 1389116.3750, 1381841.3750,
         1380478.1250, 1373905.8750, 1364825.7500, 1361792.5000, 1360478.8750],
        [1475782.0000, 1471864.7500, 1465401.0000, 1463345.2500, 1458727.6250,
         1458371.5000, 1458322.8750, 1449496.1250, 1449193.5000, 1445033.8750],
        [1465818.8750, 1448610.3750, 1444560.0000, 1444517.2500, 1439452.3750,
         1434882.8750, 1433371.6250, 1427131.3750, 1425724.7500, 1425201.2500],
        [1391028.0000, 1351104.7500, 1350929.6250, 1347314.1250, 1326606.7500,
         1316128.7500, 1296528.7500, 1276155.2500, 1270998.1250, 1254324.2500],
        [1481829.3750, 1474593.2500, 1456524.3750, 1443404.5000, 1426440.0000,
         1424073.6250, 1413417.3750, 1408426.7500, 1389145.5000, 1365554.8750],
        [1421886.1250, 1421482.0000, 1398775.5000, 1357430.6250, 1332567.6250,
         1327295.2500, 1320331.3750, 1313118.5000, 1312142.1250, 1302722.0000],
        [1478445.8750, 1472298.5000, 1465321.2500, 1464315.5000, 1462032.6250,
         1459831.2500, 1453822.3750, 1440066.1250, 1439608.8750, 1439608.8750],
        [1495365.6250, 1482459.7500, 1479519.2500, 1479218.6250, 1465958.6250,
         1462282.2500, 1458695.6250, 1453869.6250, 1441724.7500, 1439275.2500],
        [1477924.2500, 1408972.1250, 1392168.0000, 1385471.5000, 1366561.8750,
         1360506.0000, 1336578.1250, 1331355.8750, 1331228.8750, 1329433.6250],
        [1448488.7500, 1430843.6250, 1429200.1250, 1374546.7500, 1332105.1250,
         1327130.7500, 1324913.8750, 1319231.3750, 1301900.0000, 1279114.8750],
        [1442195.0000, 1440551.0000, 1439867.0000, 1411131.7500, 1407145.8750,
         1394703.3750, 1368390.2500, 1359828.8750, 1353836.5000, 1333339.2500],
        [1520704.1250, 1490354.1250, 1469549.0000, 1445907.8750, 1442979.2500,
         1436343.7500, 1414051.0000, 1388462.0000, 1382079.8750, 1371676.2500],
        [1394691.5000, 1381023.2500, 1368456.8750, 1355866.5000, 1333418.1250,
         1326426.0000, 1321547.0000, 1312527.6250, 1311116.3750, 1309922.7500],
        [1391333.1250, 1359281.8750, 1318871.6250, 1292941.7500, 1278066.2500,
         1274785.6250, 1272357.6250, 1265327.2500, 1257809.0000, 1253807.6250],
        [1440628.0000, 1424003.0000, 1412953.7500, 1397139.7500, 1381037.7500,
         1370615.7500, 1307454.1250, 1305000.0000, 1292375.8750, 1267444.3750],
        [1447824.3750, 1447562.2500, 1440788.7500, 1432014.7500, 1415736.3750,
         1400907.5000, 1396283.1250, 1395435.2500, 1394686.1250, 1388296.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1532435.2500,       0.0000],
         [1529792.3750,       0.0000],
         [1511029.8750,       0.0000],
         ...,
         [1501427.2500,       0.0000],
         [1498887.8750,       0.0000],
         [1498539.1250,       0.0000]],

        [[1542146.6250,       0.0000],
         [1538606.2500,       0.0000],
         [1527749.7500,       0.0000],
         ...,
         [1523335.6250,       0.0000],
         [1522733.0000,       0.0000],
         [1522320.6250,       0.0000]],

        [[1245091.3750,       0.0000],
         [1079999.7500,       0.0000],
         [1072665.6250,       0.0000],
         ...,
         [1023976.1875,       0.0000],
         [1012625.7500,       0.0000],
         [      0.0000,  999618.8125]],

        ...,

        [[1391333.1250,       0.0000],
         [1359281.8750,       0.0000],
         [1318871.6250,       0.0000],
         ...,
         [      0.0000, 1265327.2500],
         [1257809.0000,       0.0000],
         [1253807.6250,       0.0000]],

        [[1440628.0000,       0.0000],
         [1424003.0000,       0.0000],
         [1412953.7500,       0.0000],
         ...,
         [      0.0000, 1305000.0000],
         [      0.0000, 1292375.8750],
         [1267444.3750,       0.0000]],

        [[      0.0000, 1447824.3750],
         [      0.0000, 1447562.2500],
         [      0.0000, 1440788.7500],
         ...,
         [      0.0000, 1395435.2500],
         [      0.0000, 1394686.1250],
         [      0.0000, 1388296.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15102528.0000,        0.0000],
        [15283545.0000,        0.0000],
        [ 6478401.5000,  4138158.0000],
        [14300626.0000,        0.0000],
        [10642953.0000,  2657847.2500],
        [10599846.0000,  1234889.6250],
        [ 3159358.5000,  7176162.0000],
        [10305710.0000,  1059654.1250],
        [12336124.0000,  3063590.0000],
        [11916343.0000,  1335886.1250],
        [15443788.0000,        0.0000],
        [12910155.0000,  1386544.7500],
        [12634569.0000,  1355256.3750],
        [15585258.0000,        0.0000],
        [15539098.0000,        0.0000],
        [15496674.0000,        0.0000],
        [13557482.0000,  1498397.6250],
        [ 9011461.0000,  6000794.5000],
        [14656847.0000,        0.0000],
        [15421250.0000,        0.0000],
        [15481509.0000,        0.0000],
        [11742717.0000,  2958517.5000],
        [15385186.0000,        0.0000],
        [15609745.0000,        0.0000],
        [ 8981075.0000,  5991423.5000],
        [15578032.0000,        0.0000],
        [15444438.0000,        0.0000],
        [15579824.0000,        0.0000],
        [15674681.0000,        0.0000],
        [15673503.0000,        0.0000],
        [15662360.0000,        0.0000],
        [15647186.0000,        0.0000],
        [ 3486684.0000,  8515419.0000],
        [12143646.0000,  3049204.0000],
        [13874968.0000,  1542031.7500],
        [12146562.0000,  3028262.5000],
        [ 6202960.5000,  6497803.0000],
        [11976751.0000,  3012132.7500],
        [11452543.0000,  2862332.2500],
        [15017255.0000,        0.0000],
        [10023666.0000,  2541244.0000],
        [15505413.0000,        0.0000],
        [15406168.0000,        0.0000],
        [12169696.0000,  3051512.0000],
        [ 2687645.5000, 10974290.0000],
        [ 1228592.1250, 11393793.0000],
        [ 5394003.0000,  4788406.0000],
        [       0.0000,  9995557.0000],
        [ 9650856.0000,  4207633.0000],
        [10199902.0000,  4395637.0000],
        [11509870.0000,  2879400.0000],
        [ 1276155.2500, 11904964.0000],
        [       0.0000, 14283410.0000],
        [ 1312142.1250, 12195609.0000],
        [11624606.0000,  2950744.5000],
        [10221504.0000,  4436866.5000],
        [ 2691735.0000, 11028466.0000],
        [ 2706652.0000, 10860823.0000],
        [       0.0000, 13950988.0000],
        [ 1388462.0000, 12973646.0000],
        [ 6730871.5000,  6684125.0000],
        [ 9148830.0000,  3815751.2500],
        [ 9693823.0000,  3904830.0000],
        [       0.0000, 14159536.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 246/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:43, 61.56s/it]  7%|▋         | 2/29 [01:02<11:38, 25.89s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 3.1021623611450195
Epoch 247/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:56, 59.87s/it]  7%|▋         | 2/29 [01:00<11:20, 25.20s/it] 10%|█         | 3/29 [01:01<06:06, 14.11s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.0795516967773438
Epoch 248/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.51s/it]  7%|▋         | 2/29 [00:59<11:05, 24.64s/it] 10%|█         | 3/29 [01:00<05:59, 13.81s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.73s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.22s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 3.0825562477111816
Epoch 249/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.51s/it]  7%|▋         | 2/29 [00:59<11:05, 24.63s/it] 10%|█         | 3/29 [01:00<05:58, 13.81s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.72s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:04<01:08,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.071831464767456
Epoch 250/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:59, 59.99s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.0891060829162598
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0115, 0.0013,  ..., 0.0046, 0.0006, 0.0187],
        [0.0028, 0.0104, 0.0014,  ..., 0.0041, 0.0008, 0.0183],
        [0.0295, 0.0091, 0.0026,  ..., 0.0049, 0.0139, 0.0229],
        ...,
        [0.0055, 0.0082, 0.0242,  ..., 0.0041, 0.0012, 0.0227],
        [0.0055, 0.0111, 0.0186,  ..., 0.0041, 0.0026, 0.0216],
        [0.0079, 0.0076, 0.0041,  ..., 0.0019, 0.0037, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9969, 0.9968, 0.9960, 0.9958, 0.9957, 0.9957, 0.9955, 0.9954, 0.9954,
         0.9952],
        [0.9974, 0.9973, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9965],
        [0.9813, 0.9715, 0.9709, 0.9708, 0.9690, 0.9681, 0.9667, 0.9666, 0.9656,
         0.9651],
        [0.9934, 0.9931, 0.9927, 0.9925, 0.9924, 0.9916, 0.9915, 0.9914, 0.9912,
         0.9910],
        [0.9899, 0.9875, 0.9871, 0.9869, 0.9868, 0.9866, 0.9866, 0.9865, 0.9861,
         0.9860],
        [0.9877, 0.9851, 0.9818, 0.9811, 0.9770, 0.9758, 0.9749, 0.9745, 0.9743,
         0.9731],
        [0.9744, 0.9738, 0.9706, 0.9696, 0.9688, 0.9679, 0.9677, 0.9674, 0.9662,
         0.9656],
        [0.9849, 0.9827, 0.9761, 0.9754, 0.9732, 0.9728, 0.9702, 0.9692, 0.9690,
         0.9690],
        [0.9980, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9971, 0.9971, 0.9971,
         0.9969],
        [0.9934, 0.9883, 0.9879, 0.9876, 0.9870, 0.9868, 0.9852, 0.9846, 0.9841,
         0.9838],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9944, 0.9943, 0.9934, 0.9930, 0.9914, 0.9913, 0.9913, 0.9911, 0.9910,
         0.9901],
        [0.9942, 0.9934, 0.9916, 0.9909, 0.9907, 0.9905, 0.9897, 0.9881, 0.9880,
         0.9880],
        [0.9984, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9979],
        [0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977,
         0.9976],
        [0.9965, 0.9962, 0.9962, 0.9960, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9954],
        [0.9960, 0.9957, 0.9956, 0.9956, 0.9955, 0.9953, 0.9952, 0.9952, 0.9952,
         0.9950],
        [0.9950, 0.9945, 0.9943, 0.9940, 0.9939, 0.9938, 0.9934, 0.9934, 0.9931,
         0.9931],
        [0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9955, 0.9950, 0.9947, 0.9946, 0.9941, 0.9938, 0.9938, 0.9935, 0.9934,
         0.9932],
        [0.9986, 0.9981, 0.9977, 0.9973, 0.9973, 0.9972, 0.9972, 0.9971, 0.9969,
         0.9969],
        [0.9986, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9959, 0.9959, 0.9956, 0.9954, 0.9954, 0.9953, 0.9948, 0.9947, 0.9947,
         0.9946],
        [0.9986, 0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9979,
         0.9979],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9984, 0.9984, 0.9983, 0.9981, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9988, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9902, 0.9867, 0.9814, 0.9804, 0.9793, 0.9778, 0.9758, 0.9754, 0.9750,
         0.9713],
        [0.9967, 0.9966, 0.9966, 0.9965, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9960],
        [0.9977, 0.9977, 0.9977, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9969, 0.9965, 0.9964, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9960],
        [0.9902, 0.9867, 0.9846, 0.9841, 0.9839, 0.9833, 0.9833, 0.9821, 0.9810,
         0.9799],
        [0.9958, 0.9957, 0.9957, 0.9957, 0.9953, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9948],
        [0.9943, 0.9933, 0.9927, 0.9924, 0.9920, 0.9913, 0.9910, 0.9910, 0.9908,
         0.9907],
        [0.9961, 0.9959, 0.9958, 0.9955, 0.9955, 0.9955, 0.9953, 0.9953, 0.9953,
         0.9952],
        [0.9866, 0.9863, 0.9852, 0.9843, 0.9840, 0.9832, 0.9831, 0.9823, 0.9797,
         0.9794],
        [0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9913, 0.9903, 0.9899, 0.9898, 0.9891, 0.9890, 0.9882, 0.9879, 0.9876,
         0.9872],
        [0.9874, 0.9848, 0.9841, 0.9841, 0.9838, 0.9830, 0.9821, 0.9821, 0.9813,
         0.9813],
        [0.9890, 0.9853, 0.9720, 0.9715, 0.9657, 0.9609, 0.9596, 0.9586, 0.9582,
         0.9569],
        [0.9760, 0.9750, 0.9726, 0.9711, 0.9693, 0.9656, 0.9639, 0.9616, 0.9615,
         0.9579],
        [0.9930, 0.9907, 0.9899, 0.9896, 0.9895, 0.9895, 0.9894, 0.9890, 0.9886,
         0.9884],
        [0.9944, 0.9941, 0.9940, 0.9937, 0.9936, 0.9935, 0.9935, 0.9931, 0.9930,
         0.9930],
        [0.9938, 0.9930, 0.9929, 0.9928, 0.9924, 0.9922, 0.9922, 0.9919, 0.9918,
         0.9918],
        [0.9907, 0.9891, 0.9890, 0.9885, 0.9877, 0.9866, 0.9854, 0.9845, 0.9844,
         0.9838],
        [0.9947, 0.9943, 0.9933, 0.9931, 0.9922, 0.9919, 0.9915, 0.9912, 0.9905,
         0.9892],
        [0.9919, 0.9918, 0.9907, 0.9887, 0.9874, 0.9871, 0.9868, 0.9865, 0.9864,
         0.9862],
        [0.9947, 0.9942, 0.9939, 0.9939, 0.9938, 0.9938, 0.9934, 0.9929, 0.9927,
         0.9926],
        [0.9953, 0.9947, 0.9946, 0.9945, 0.9938, 0.9937, 0.9936, 0.9932, 0.9928,
         0.9925],
        [0.9946, 0.9913, 0.9906, 0.9901, 0.9893, 0.9888, 0.9877, 0.9877, 0.9873,
         0.9872],
        [0.9933, 0.9924, 0.9922, 0.9896, 0.9878, 0.9872, 0.9871, 0.9869, 0.9861,
         0.9848],
        [0.9928, 0.9928, 0.9927, 0.9915, 0.9911, 0.9906, 0.9893, 0.9888, 0.9888,
         0.9876],
        [0.9965, 0.9952, 0.9942, 0.9929, 0.9927, 0.9924, 0.9916, 0.9902, 0.9896,
         0.9895],
        [0.9909, 0.9897, 0.9892, 0.9892, 0.9878, 0.9867, 0.9865, 0.9864, 0.9863,
         0.9862],
        [0.9911, 0.9896, 0.9870, 0.9858, 0.9850, 0.9848, 0.9841, 0.9841, 0.9841,
         0.9836],
        [0.9927, 0.9920, 0.9913, 0.9906, 0.9897, 0.9894, 0.9860, 0.9859, 0.9851,
         0.9840],
        [0.9934, 0.9933, 0.9929, 0.9925, 0.9919, 0.9910, 0.9907, 0.9907, 0.9906,
         0.9904]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 0, 0, 1, 1, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1531507.6250, 1528020.7500, 1511626.7500, 1506825.1250, 1505586.8750,
         1504811.7500, 1501453.1250, 1498454.8750, 1498394.7500, 1494121.1250],
        [1542242.2500, 1538993.7500, 1528204.3750, 1528188.3750, 1527183.1250,
         1526145.1250, 1525721.5000, 1524102.8750, 1524060.8750, 1523213.6250],
        [1225688.6250, 1065738.0000, 1056252.0000, 1054839.7500, 1028302.5625,
         1013970.9375,  994024.2500,  993018.0000,  978814.0000,  971912.1250],
        [1455669.0000, 1449082.8750, 1441503.3750, 1436702.6250, 1434952.6250,
         1420048.5000, 1416377.7500, 1416010.5000, 1410869.3750, 1407039.7500],
        [1386243.2500, 1338874.5000, 1330482.6250, 1327142.1250, 1325690.0000,
         1322269.3750, 1321922.7500, 1318991.0000, 1311257.7500, 1309611.8750],
        [1342918.0000, 1294240.7500, 1233945.3750, 1221317.7500, 1151680.5000,
         1132462.7500, 1117833.2500, 1110973.1250, 1109032.6250, 1090411.0000],
        [1110068.6250, 1100225.7500, 1051943.5000, 1037217.0000, 1024463.5625,
         1011725.1875, 1008565.4375, 1005163.3125,  987185.5000,  979032.5000],
        [1290223.3750, 1250144.5000, 1137795.3750, 1125490.1250, 1091164.2500,
         1085043.8750, 1045229.4375, 1030299.1875, 1028234.9375, 1028157.4375],
        [1555201.1250, 1547003.1250, 1545762.8750, 1543721.0000, 1541030.7500,
         1540932.2500, 1536437.6250, 1535573.2500, 1534371.3750, 1532040.7500],
        [1457316.2500, 1353340.8750, 1346560.1250, 1341022.6250, 1329280.3750,
         1325858.1250, 1295509.0000, 1284607.5000, 1275137.0000, 1268993.6250],
        [1551450.1250, 1550215.2500, 1548126.1250, 1546953.0000, 1546833.5000,
         1542726.1250, 1541210.0000, 1540396.0000, 1540257.8750, 1539153.7500],
        [1477555.0000, 1475421.7500, 1457335.7500, 1448831.3750, 1415621.6250,
         1414289.7500, 1413646.5000, 1410218.3750, 1408221.2500, 1390010.8750],
        [1473295.7500, 1455635.6250, 1419477.1250, 1404483.1250, 1401932.6250,
         1398107.3750, 1381779.3750, 1350169.6250, 1348832.5000, 1347526.1250],
        [1563391.7500, 1559244.8750, 1558848.0000, 1558458.5000, 1558445.1250,
         1557197.1250, 1556371.7500, 1555399.7500, 1554799.1250, 1553921.6250],
        [1558517.8750, 1556598.8750, 1556425.1250, 1555950.2500, 1555398.3750,
         1555214.3750, 1553363.0000, 1552927.6250, 1551985.8750, 1551842.3750],
        [1555877.6250, 1551749.1250, 1551678.1250, 1550715.0000, 1550400.1250,
         1550243.2500, 1550203.5000, 1549998.0000, 1548688.8750, 1547385.2500],
        [1522991.3750, 1516498.3750, 1515281.1250, 1510586.2500, 1506129.7500,
         1505149.0000, 1503826.2500, 1501723.6250, 1501364.2500, 1499242.3750],
        [1511768.0000, 1504368.3750, 1503813.2500, 1503788.8750, 1501138.1250,
         1495770.6250, 1494544.3750, 1493746.5000, 1493378.8750, 1490243.2500],
        [1490543.2500, 1478695.3750, 1474904.1250, 1469451.0000, 1466055.1250,
         1465005.5000, 1456604.8750, 1455920.2500, 1451064.6250, 1449258.5000],
        [1546037.1250, 1544058.1250, 1543466.3750, 1541748.1250, 1541471.6250,
         1541166.0000, 1541020.5000, 1540748.6250, 1540365.1250, 1540244.6250],
        [1552816.5000, 1551811.2500, 1550228.6250, 1548727.2500, 1547813.3750,
         1546680.1250, 1541925.8750, 1540866.1250, 1540701.5000, 1539767.3750],
        [1501052.1250, 1489976.0000, 1482687.2500, 1482092.1250, 1471411.3750,
         1465617.6250, 1465236.0000, 1458681.7500, 1457067.5000, 1452077.8750],
        [1568058.0000, 1556834.8750, 1548589.8750, 1538826.3750, 1538708.8750,
         1537708.5000, 1536828.8750, 1534610.0000, 1531323.5000, 1530777.5000],
        [1569185.8750, 1564491.0000, 1563728.7500, 1562585.3750, 1560914.2500,
         1560860.6250, 1559869.6250, 1559661.3750, 1559604.7500, 1559007.1250],
        [1509503.2500, 1508903.1250, 1503601.1250, 1498672.0000, 1497651.8750,
         1496118.7500, 1486586.6250, 1483923.7500, 1483080.5000, 1482523.3750],
        [1567886.0000, 1563769.1250, 1560869.6250, 1559484.3750, 1558859.8750,
         1557868.6250, 1557436.2500, 1556450.3750, 1552671.3750, 1552582.5000],
        [1553949.8750, 1552046.6250, 1551331.8750, 1547152.1250, 1546071.0000,
         1545739.2500, 1543541.3750, 1543432.5000, 1541980.5000, 1541069.0000],
        [1564799.8750, 1563830.2500, 1561092.8750, 1558428.7500, 1558274.2500,
         1557250.6250, 1556878.0000, 1556680.5000, 1555425.0000, 1555128.3750],
        [1572852.0000, 1571256.8750, 1569147.0000, 1569019.7500, 1567636.2500,
         1567589.8750, 1566862.1250, 1566709.6250, 1566470.6250, 1565809.0000],
        [1574153.1250, 1574115.5000, 1571030.6250, 1568874.7500, 1568672.6250,
         1566859.1250, 1565247.6250, 1565158.1250, 1563430.6250, 1562373.8750],
        [1569717.2500, 1569169.3750, 1567712.6250, 1567323.8750, 1567096.7500,
         1566859.1250, 1565528.2500, 1565498.3750, 1564543.2500, 1564212.0000],
        [1569887.8750, 1568704.1250, 1567630.3750, 1566812.8750, 1566766.5000,
         1566697.7500, 1565800.1250, 1563481.2500, 1563123.3750, 1563050.2500],
        [1390260.0000, 1323690.1250, 1226051.0000, 1209571.1250, 1191336.3750,
         1166216.6250, 1133157.3750, 1125806.8750, 1120172.3750, 1061805.7500],
        [1527011.2500, 1525181.8750, 1524485.2500, 1523129.3750, 1517406.8750,
         1515931.6250, 1515161.2500, 1513982.6250, 1513171.3750, 1512291.3750],
        [1548358.0000, 1548109.8750, 1547777.8750, 1542058.2500, 1541355.5000,
         1541240.8750, 1541240.8750, 1540559.0000, 1539310.7500, 1536573.8750],
        [1531146.8750, 1523173.0000, 1519718.2500, 1515090.3750, 1514737.8750,
         1513471.5000, 1512549.5000, 1512346.1250, 1511808.3750, 1511641.0000],
        [1391376.8750, 1323950.1250, 1284674.8750, 1275527.3750, 1271424.8750,
         1260366.5000, 1260221.1250, 1238793.8750, 1220388.6250, 1200095.2500],
        [1506994.7500, 1505674.5000, 1505463.5000, 1504029.8750, 1495746.3750,
         1495395.5000, 1493881.7500, 1492480.5000, 1491989.5000, 1485835.5000],
        [1474241.6250, 1454581.0000, 1441282.1250, 1436197.1250, 1428374.5000,
         1413922.8750, 1406721.8750, 1406581.0000, 1403183.2500, 1401623.7500],
        [1512865.5000, 1508572.1250, 1506651.2500, 1501443.0000, 1501201.1250,
         1500870.3750, 1496505.5000, 1495986.0000, 1495495.3750, 1494555.7500],
        [1320772.1250, 1316329.6250, 1295647.3750, 1278851.3750, 1273593.6250,
         1258426.8750, 1256183.3750, 1242404.7500, 1197865.5000, 1192374.2500],
        [1558253.3750, 1554013.5000, 1553889.0000, 1552923.1250, 1551826.1250,
         1550617.3750, 1549594.5000, 1547783.7500, 1547739.3750, 1547392.6250],
        [1546329.0000, 1544343.8750, 1544182.0000, 1542054.0000, 1541398.1250,
         1541183.6250, 1540281.3750, 1538729.5000, 1537381.5000, 1537050.1250],
        [1526261.5000, 1525734.6250, 1525295.2500, 1523845.6250, 1521919.8750,
         1521203.1250, 1519741.5000, 1519043.0000, 1517838.1250, 1517233.2500],
        [1413983.6250, 1392562.3750, 1384973.3750, 1382462.1250, 1370140.1250,
         1367902.2500, 1352222.3750, 1346208.2500, 1340113.6250, 1332964.1250],
        [1337399.2500, 1288058.2500, 1275484.7500, 1274252.0000, 1268963.5000,
         1255976.2500, 1239572.6250, 1238465.5000, 1225590.3750, 1224922.1250],
        [1366655.7500, 1296366.7500, 1072303.6250, 1064731.1250,  980004.9375,
          915257.0000,  899144.3750,  885652.8125,  880265.3750,  864533.8125],
        [1135522.1250, 1118939.2500, 1082408.3750, 1059097.5000, 1031978.8125,
          978536.7500,  955851.7500,  924617.9375,  923007.4375,  877431.6875],
        [1448070.2500, 1401002.3750, 1386142.7500, 1380241.1250, 1377822.5000,
         1377163.0000, 1375870.0000, 1367606.2500, 1359523.0000, 1355879.5000],
        [1477257.7500, 1471289.3750, 1468816.2500, 1462160.8750, 1460657.1250,
         1458245.0000, 1458147.6250, 1451093.6250, 1447678.1250, 1447678.1250],
        [1464818.2500, 1447425.5000, 1446136.7500, 1444475.8750, 1435853.3750,
         1430887.2500, 1430578.8750, 1425552.0000, 1424109.0000, 1423066.2500],
        [1402043.5000, 1369536.5000, 1366793.8750, 1358644.1250, 1342459.5000,
         1320929.6250, 1298517.2500, 1282734.5000, 1280630.8750, 1269941.6250],
        [1483587.0000, 1475499.1250, 1454884.8750, 1450883.2500, 1431859.1250,
         1426034.7500, 1418080.7500, 1411858.6250, 1397174.3750, 1370974.0000],
        [1425800.8750, 1423488.3750, 1401692.0000, 1361679.5000, 1336751.3750,
         1330221.2500, 1326021.2500, 1319042.6250, 1317089.2500, 1313429.1250],
        [1483421.5000, 1472298.5000, 1466165.6250, 1466122.2500, 1465153.6250,
         1464986.0000, 1457132.8750, 1446120.2500, 1441746.7500, 1440413.6250],
        [1495756.3750, 1483379.0000, 1480543.8750, 1478561.5000, 1464417.5000,
         1463036.8750, 1461502.8750, 1451452.1250, 1443173.2500, 1438257.2500],
        [1480515.6250, 1414211.5000, 1400103.5000, 1390009.5000, 1372610.6250,
         1363575.5000, 1343368.8750, 1342485.1250, 1333973.8750, 1332652.8750],
        [1453858.3750, 1435769.8750, 1432479.2500, 1378836.0000, 1344732.6250,
         1332635.0000, 1331912.0000, 1328014.5000, 1312858.0000, 1287403.6250],
        [1444695.0000, 1443918.0000, 1440927.5000, 1416999.3750, 1408763.8750,
         1400018.0000, 1372837.1250, 1363588.5000, 1362857.8750, 1339590.8750],
        [1522593.6250, 1494614.1250, 1472132.8750, 1445433.6250, 1442406.8750,
         1436457.3750, 1419735.6250, 1391236.2500, 1379404.2500, 1376590.5000],
        [1404255.5000, 1380971.8750, 1371005.3750, 1370866.7500, 1344644.2500,
         1323576.5000, 1320027.8750, 1318288.1250, 1315798.6250, 1314445.3750],
        [1408629.5000, 1378766.2500, 1329864.7500, 1306464.5000, 1291286.8750,
         1288646.7500, 1275870.5000, 1274959.3750, 1274853.6250, 1266889.6250],
        [1442107.1250, 1426821.0000, 1413033.2500, 1398474.1250, 1381006.1250,
         1374828.5000, 1309403.2500, 1309199.7500, 1294090.2500, 1273982.2500],
        [1456659.1250, 1454422.8750, 1446004.3750, 1436743.7500, 1425185.0000,
         1406884.1250, 1401575.7500, 1401352.5000, 1400031.3750, 1395717.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1531507.6250,       0.0000],
         [1528020.7500,       0.0000],
         [1511626.7500,       0.0000],
         ...,
         [1498454.8750,       0.0000],
         [1498394.7500,       0.0000],
         [      0.0000, 1494121.1250]],

        [[1542242.2500,       0.0000],
         [1538993.7500,       0.0000],
         [1528204.3750,       0.0000],
         ...,
         [1524102.8750,       0.0000],
         [1524060.8750,       0.0000],
         [1523213.6250,       0.0000]],

        [[1225688.6250,       0.0000],
         [      0.0000, 1065738.0000],
         [1056252.0000,       0.0000],
         ...,
         [ 993018.0000,       0.0000],
         [      0.0000,  978814.0000],
         [      0.0000,  971912.1250]],

        ...,

        [[1408629.5000,       0.0000],
         [1378766.2500,       0.0000],
         [1329864.7500,       0.0000],
         ...,
         [      0.0000, 1274959.3750],
         [1274853.6250,       0.0000],
         [1266889.6250,       0.0000]],

        [[1442107.1250,       0.0000],
         [1426821.0000,       0.0000],
         [1413033.2500,       0.0000],
         ...,
         [      0.0000, 1309199.7500],
         [      0.0000, 1294090.2500],
         [1273982.2500,       0.0000]],

        [[      0.0000, 1456659.1250],
         [      0.0000, 1454422.8750],
         [      0.0000, 1446004.3750],
         ...,
         [      0.0000, 1401352.5000],
         [      0.0000, 1400031.3750],
         [      0.0000, 1395717.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13586682.0000,  1494121.1250],
        [15288056.0000,        0.0000],
        [ 6352125.0000,  4030435.0000],
        [14288256.0000,        0.0000],
        [10643012.0000,  2649473.5000],
        [10583497.0000,  1221317.7500],
        [ 4123600.0000,  6191990.0000],
        [10083547.0000,  1028234.9375],
        [13880034.0000,  1532040.7500],
        [11931065.0000,  1346560.1250],
        [15447321.0000,        0.0000],
        [12921142.0000,  1390010.8750],
        [12631069.0000,  1350169.6250],
        [15576078.0000,        0.0000],
        [15548224.0000,        0.0000],
        [15506939.0000,        0.0000],
        [13583550.0000,  1499242.3750],
        [10492501.0000,  4500059.0000],
        [14657502.0000,        0.0000],
        [15420326.0000,        0.0000],
        [15461338.0000,        0.0000],
        [11753236.0000,  2972663.2500],
        [15422268.0000,        0.0000],
        [15619909.0000,        0.0000],
        [ 8970112.0000,  5980452.0000],
        [15587879.0000,        0.0000],
        [15466314.0000,        0.0000],
        [15587788.0000,        0.0000],
        [15683354.0000,        0.0000],
        [15679916.0000,        0.0000],
        [15667661.0000,        0.0000],
        [15661954.0000,        0.0000],
        [ 3419359.0000,  8528709.0000],
        [10626967.0000,  4560786.0000],
        [12347953.0000,  3078632.0000],
        [13650946.0000,  1514737.8750],
        [ 6227802.5000,  6499017.0000],
        [11966354.0000,  3011138.0000],
        [12825427.0000,  1441282.1250],
        [15014146.0000,        0.0000],
        [10078374.0000,  2554074.2500],
        [15514033.0000,        0.0000],
        [15412934.0000,        0.0000],
        [12169934.0000,  3048181.5000],
        [ 2685186.5000, 10998346.0000],
        [ 1225590.3750, 11403094.0000],
        [ 5424858.5000,  4800057.0000],
        [       0.0000, 10087392.0000],
        [ 9617286.0000,  4212035.5000],
        [10204673.0000,  4398351.0000],
        [11494590.0000,  2878312.7500],
        [ 1282734.5000, 12009496.0000],
        [       0.0000, 14320836.0000],
        [ 1317089.2500, 12238126.0000],
        [11647840.0000,  2955720.0000],
        [10220744.0000,  4439337.0000],
        [ 2706060.5000, 11067446.0000],
        [ 2723568.5000, 10914930.0000],
        [       0.0000, 13994196.0000],
        [ 1391236.2500, 12989370.0000],
        [ 6740087.0000,  6723793.0000],
        [ 9254114.0000,  3842117.0000],
        [ 9710252.0000,  3912693.2500],
        [       0.0000, 14224576.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 251/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<29:09, 62.48s/it]  7%|▋         | 2/29 [01:03<11:49, 26.27s/it] 10%|█         | 3/29 [01:04<06:22, 14.69s/it] 14%|█▍        | 4/29 [01:05<03:51,  9.26s/it] 17%|█▋        | 5/29 [01:06<02:29,  6.25s/it] 21%|██        | 6/29 [01:07<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.53s/it] 31%|███       | 9/29 [01:09<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:10<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:16<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:17<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:18<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:19<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.05s/it]
Epoch loss is 3.0887415409088135
Epoch 252/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:33, 59.04s/it]  7%|▋         | 2/29 [00:59<11:11, 24.86s/it] 10%|█         | 3/29 [01:00<06:02, 13.93s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 3.0632433891296387
Epoch 253/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:04, 60.15s/it]  7%|▋         | 2/29 [01:01<11:23, 25.31s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 3.063671827316284
Epoch 254/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:13, 56.20s/it]  7%|▋         | 2/29 [00:57<10:43, 23.82s/it] 10%|█         | 3/29 [00:59<05:56, 13.70s/it] 14%|█▍        | 4/29 [00:59<03:36,  8.65s/it] 17%|█▋        | 5/29 [01:00<02:20,  5.87s/it] 21%|██        | 6/29 [01:01<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:02<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.42s/it] 31%|███       | 9/29 [01:04<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.87s/it]
Epoch loss is 3.0541458129882812
Epoch 255/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:59, 57.85s/it]  7%|▋         | 2/29 [01:00<11:20, 25.21s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 3.0495495796203613
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0116, 0.0014,  ..., 0.0044, 0.0005, 0.0186],
        [0.0027, 0.0101, 0.0015,  ..., 0.0040, 0.0008, 0.0181],
        [0.0308, 0.0089, 0.0030,  ..., 0.0052, 0.0142, 0.0224],
        ...,
        [0.0058, 0.0079, 0.0232,  ..., 0.0042, 0.0012, 0.0227],
        [0.0055, 0.0106, 0.0188,  ..., 0.0038, 0.0029, 0.0208],
        [0.0074, 0.0070, 0.0040,  ..., 0.0017, 0.0035, 0.0202]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9969, 0.9967, 0.9960, 0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9951,
         0.9951],
        [0.9974, 0.9971, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9966],
        [0.9808, 0.9708, 0.9707, 0.9694, 0.9687, 0.9675, 0.9658, 0.9657, 0.9654,
         0.9634],
        [0.9934, 0.9931, 0.9925, 0.9924, 0.9922, 0.9919, 0.9917, 0.9915, 0.9911,
         0.9907],
        [0.9898, 0.9873, 0.9871, 0.9870, 0.9870, 0.9867, 0.9867, 0.9865, 0.9864,
         0.9860],
        [0.9876, 0.9855, 0.9814, 0.9806, 0.9762, 0.9761, 0.9750, 0.9744, 0.9741,
         0.9736],
        [0.9749, 0.9736, 0.9711, 0.9677, 0.9677, 0.9677, 0.9676, 0.9674, 0.9662,
         0.9650],
        [0.9850, 0.9829, 0.9746, 0.9746, 0.9735, 0.9712, 0.9705, 0.9682, 0.9682,
         0.9677],
        [0.9980, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9972, 0.9971, 0.9970,
         0.9970],
        [0.9935, 0.9884, 0.9879, 0.9877, 0.9869, 0.9866, 0.9860, 0.9855, 0.9836,
         0.9834],
        [0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9941, 0.9941, 0.9933, 0.9928, 0.9919, 0.9913, 0.9910, 0.9907, 0.9905,
         0.9899],
        [0.9942, 0.9931, 0.9917, 0.9908, 0.9905, 0.9904, 0.9892, 0.9882, 0.9876,
         0.9875],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9982, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9965, 0.9962, 0.9962, 0.9960, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9954],
        [0.9960, 0.9956, 0.9956, 0.9956, 0.9954, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9951],
        [0.9949, 0.9944, 0.9942, 0.9939, 0.9937, 0.9936, 0.9934, 0.9931, 0.9930,
         0.9929],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9973],
        [0.9957, 0.9950, 0.9946, 0.9946, 0.9939, 0.9938, 0.9937, 0.9933, 0.9933,
         0.9932],
        [0.9986, 0.9982, 0.9978, 0.9975, 0.9974, 0.9974, 0.9973, 0.9970, 0.9970,
         0.9970],
        [0.9987, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9958, 0.9956, 0.9955, 0.9954, 0.9952, 0.9950, 0.9946, 0.9945, 0.9945,
         0.9944],
        [0.9986, 0.9985, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9980,
         0.9980],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9984],
        [0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9900, 0.9863, 0.9809, 0.9800, 0.9791, 0.9777, 0.9749, 0.9748, 0.9745,
         0.9713],
        [0.9967, 0.9966, 0.9966, 0.9965, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9977, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9969, 0.9965, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959,
         0.9959],
        [0.9899, 0.9866, 0.9843, 0.9837, 0.9829, 0.9825, 0.9819, 0.9805, 0.9802,
         0.9794],
        [0.9958, 0.9957, 0.9956, 0.9956, 0.9952, 0.9951, 0.9951, 0.9949, 0.9949,
         0.9949],
        [0.9943, 0.9934, 0.9925, 0.9923, 0.9919, 0.9911, 0.9910, 0.9909, 0.9906,
         0.9905],
        [0.9961, 0.9960, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9953, 0.9953,
         0.9952],
        [0.9862, 0.9859, 0.9852, 0.9842, 0.9839, 0.9835, 0.9834, 0.9818, 0.9797,
         0.9792],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9963],
        [0.9914, 0.9906, 0.9900, 0.9899, 0.9894, 0.9894, 0.9882, 0.9879, 0.9878,
         0.9873],
        [0.9872, 0.9846, 0.9841, 0.9840, 0.9838, 0.9832, 0.9820, 0.9815, 0.9812,
         0.9812],
        [0.9891, 0.9860, 0.9731, 0.9728, 0.9651, 0.9621, 0.9619, 0.9612, 0.9599,
         0.9595],
        [0.9763, 0.9754, 0.9727, 0.9719, 0.9697, 0.9660, 0.9651, 0.9617, 0.9612,
         0.9582],
        [0.9928, 0.9900, 0.9899, 0.9896, 0.9893, 0.9892, 0.9890, 0.9888, 0.9885,
         0.9882],
        [0.9943, 0.9941, 0.9939, 0.9938, 0.9936, 0.9935, 0.9934, 0.9932, 0.9931,
         0.9929],
        [0.9937, 0.9933, 0.9930, 0.9929, 0.9926, 0.9922, 0.9921, 0.9920, 0.9919,
         0.9918],
        [0.9909, 0.9895, 0.9893, 0.9888, 0.9881, 0.9865, 0.9851, 0.9850, 0.9849,
         0.9837],
        [0.9946, 0.9943, 0.9931, 0.9930, 0.9922, 0.9919, 0.9915, 0.9912, 0.9910,
         0.9888],
        [0.9918, 0.9917, 0.9907, 0.9887, 0.9874, 0.9870, 0.9866, 0.9865, 0.9864,
         0.9863],
        [0.9948, 0.9943, 0.9942, 0.9942, 0.9940, 0.9940, 0.9938, 0.9934, 0.9932,
         0.9931],
        [0.9954, 0.9949, 0.9947, 0.9945, 0.9938, 0.9937, 0.9937, 0.9934, 0.9931,
         0.9928],
        [0.9946, 0.9915, 0.9908, 0.9902, 0.9892, 0.9890, 0.9880, 0.9876, 0.9873,
         0.9873],
        [0.9934, 0.9924, 0.9921, 0.9896, 0.9878, 0.9871, 0.9868, 0.9867, 0.9866,
         0.9850],
        [0.9930, 0.9927, 0.9926, 0.9912, 0.9908, 0.9907, 0.9894, 0.9888, 0.9888,
         0.9881],
        [0.9965, 0.9952, 0.9944, 0.9931, 0.9925, 0.9920, 0.9918, 0.9903, 0.9897,
         0.9890],
        [0.9899, 0.9891, 0.9887, 0.9878, 0.9872, 0.9872, 0.9869, 0.9866, 0.9865,
         0.9862],
        [0.9918, 0.9905, 0.9876, 0.9865, 0.9857, 0.9854, 0.9845, 0.9844, 0.9841,
         0.9841],
        [0.9930, 0.9921, 0.9913, 0.9905, 0.9898, 0.9898, 0.9863, 0.9855, 0.9853,
         0.9843],
        [0.9937, 0.9936, 0.9929, 0.9925, 0.9919, 0.9914, 0.9913, 0.9911, 0.9911,
         0.9906]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 0, 0, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1529996.6250, 1526485.6250, 1510460.8750, 1505104.5000, 1504161.7500,
         1501612.0000, 1501493.1250, 1498673.5000, 1492368.0000, 1492070.6250],
        [1543010.1250, 1536471.2500, 1530914.7500, 1529642.0000, 1529133.0000,
         1528306.3750, 1527781.7500, 1527215.2500, 1526270.1250, 1524515.7500],
        [1216697.8750, 1054812.5000, 1053485.6250, 1034343.4375, 1023858.0000,
         1006034.1250,  982251.4375,  980293.7500,  975510.4375,  949295.5000],
        [1455398.2500, 1450830.7500, 1438184.5000, 1435264.7500, 1432580.3750,
         1424928.1250, 1421166.1250, 1416988.5000, 1409558.1250, 1400318.5000],
        [1383682.2500, 1334203.0000, 1330407.7500, 1328661.7500, 1328531.3750,
         1323808.7500, 1323522.2500, 1320422.1250, 1317295.3750, 1310134.0000],
        [1340858.8750, 1300629.1250, 1227256.0000, 1213764.5000, 1138309.7500,
         1136984.0000, 1120299.6250, 1110335.3750, 1106046.7500, 1096988.3750],
        [1118531.7500, 1097874.8750, 1059258.1250, 1009186.8750, 1009072.3750,
         1008336.5000, 1006914.2500, 1004410.1250,  987426.5625,  970649.6250],
        [1291268.2500, 1253389.2500, 1114075.3750, 1113080.3750, 1095963.6250,
         1060608.5000, 1049840.7500, 1016208.1250, 1016075.3125, 1008858.8125],
        [1555003.8750, 1547287.8750, 1543967.0000, 1541296.7500, 1541126.2500,
         1540656.0000, 1537322.8750, 1536165.1250, 1534210.5000, 1533439.6250],
        [1457926.6250, 1356319.1250, 1345728.1250, 1342745.1250, 1327466.1250,
         1322377.8750, 1309885.3750, 1300311.7500, 1265748.3750, 1263311.2500],
        [1552256.8750, 1550828.8750, 1550537.5000, 1549627.0000, 1548257.6250,
         1542992.5000, 1542689.3750, 1542217.2500, 1541038.0000, 1540754.5000],
        [1470778.6250, 1470087.3750, 1454372.8750, 1444847.8750, 1425546.6250,
         1414283.0000, 1407258.5000, 1401329.7500, 1396681.3750, 1384348.8750],
        [1473706.1250, 1450725.5000, 1421998.6250, 1403649.0000, 1397552.7500,
         1396098.1250, 1372491.5000, 1352408.1250, 1341090.3750, 1338400.8750],
        [1564153.7500, 1561320.7500, 1561241.7500, 1560272.7500, 1559795.2500,
         1556684.8750, 1555081.0000, 1554726.5000, 1554053.5000, 1553158.5000],
        [1559889.0000, 1559267.2500, 1559071.0000, 1558958.0000, 1558801.8750,
         1557626.3750, 1556453.3750, 1555210.0000, 1554977.1250, 1554649.3750],
        [1557760.1250, 1554974.1250, 1554643.5000, 1553696.3750, 1552589.8750,
         1552505.5000, 1552014.1250, 1551574.5000, 1550567.1250, 1549098.0000],
        [1521561.5000, 1516371.1250, 1514966.1250, 1511507.0000, 1506981.7500,
         1505067.2500, 1503178.1250, 1500375.2500, 1499898.8750, 1499049.3750],
        [1511381.6250, 1503692.7500, 1503299.8750, 1503056.2500, 1498421.8750,
         1497284.8750, 1496502.5000, 1494166.6250, 1493653.7500, 1491409.0000],
        [1487399.3750, 1477030.8750, 1473264.8750, 1466241.0000, 1461759.3750,
         1461134.8750, 1456596.6250, 1449337.1250, 1449033.1250, 1445764.5000],
        [1547913.6250, 1546340.8750, 1546202.1250, 1543544.3750, 1543448.7500,
         1542763.0000, 1542273.0000, 1542020.1250, 1541726.0000, 1541354.1250],
        [1554269.8750, 1554016.5000, 1552732.0000, 1551621.8750, 1551439.8750,
         1547217.1250, 1544310.0000, 1543684.2500, 1542183.3750, 1540246.1250],
        [1503938.0000, 1490099.7500, 1481182.2500, 1481000.0000, 1467679.2500,
         1465002.6250, 1461599.1250, 1454932.0000, 1454389.6250, 1451540.7500],
        [1569455.3750, 1559761.0000, 1550803.8750, 1543457.5000, 1541451.1250,
         1541085.1250, 1539572.0000, 1533846.2500, 1533384.1250, 1532903.0000],
        [1570969.2500, 1566891.8750, 1566098.7500, 1565108.7500, 1562962.5000,
         1562949.0000, 1561696.0000, 1561215.0000, 1561064.6250, 1560762.5000],
        [1507663.1250, 1502432.7500, 1500980.6250, 1499344.0000, 1494617.0000,
         1490757.7500, 1482028.6250, 1479235.6250, 1478389.3750, 1478137.1250],
        [1568966.0000, 1565818.0000, 1561977.5000, 1561779.3750, 1560487.0000,
         1559582.5000, 1559567.6250, 1558766.2500, 1555702.5000, 1554487.7500],
        [1556242.6250, 1553000.0000, 1552949.7500, 1550094.1250, 1549263.3750,
         1548815.7500, 1546467.7500, 1545864.5000, 1543394.2500, 1542935.1250],
        [1567486.8750, 1566493.1250, 1564485.0000, 1562293.2500, 1562028.1250,
         1559307.3750, 1559026.3750, 1558963.8750, 1558790.0000, 1558593.7500],
        [1574818.3750, 1572825.1250, 1571451.7500, 1570069.1250, 1569109.6250,
         1569030.2500, 1568621.8750, 1568551.6250, 1568085.0000, 1568059.3750],
        [1575202.7500, 1574483.5000, 1572999.0000, 1570566.3750, 1569636.3750,
         1568436.3750, 1567881.5000, 1565847.8750, 1565586.5000, 1563628.8750],
        [1572019.8750, 1571011.1250, 1569754.6250, 1569271.2500, 1569117.0000,
         1568313.6250, 1567975.7500, 1567660.2500, 1565941.8750, 1565853.7500],
        [1571895.3750, 1571423.2500, 1569772.6250, 1569482.1250, 1569458.3750,
         1568969.0000, 1568722.0000, 1566497.5000, 1566106.2500, 1565731.3750],
        [1386345.1250, 1315718.3750, 1217574.2500, 1202212.1250, 1187179.6250,
         1163893.3750, 1118521.1250, 1115923.5000, 1111949.2500, 1061397.7500],
        [1527620.1250, 1525261.8750, 1525160.0000, 1522159.5000, 1517679.0000,
         1517259.3750, 1515902.7500, 1515685.7500, 1515571.7500, 1515373.6250],
        [1548926.6250, 1548225.1250, 1547522.5000, 1544164.2500, 1544164.2500,
         1543132.3750, 1541412.8750, 1539594.1250, 1538935.0000, 1537803.7500],
        [1530037.5000, 1522838.8750, 1516601.0000, 1515969.2500, 1515482.0000,
         1513418.1250, 1513161.2500, 1511357.0000, 1509389.6250, 1509166.5000],
        [1384660.5000, 1322448.5000, 1278072.2500, 1268360.8750, 1254123.2500,
         1246923.7500, 1235802.6250, 1211084.3750, 1205936.1250, 1191929.6250],
        [1506224.6250, 1504913.6250, 1503146.5000, 1502934.3750, 1493908.7500,
         1493081.2500, 1491517.1250, 1488909.3750, 1488175.3750, 1487312.6250],
        [1475597.6250, 1455607.8750, 1437009.6250, 1432861.7500, 1424656.3750,
         1408330.0000, 1408197.0000, 1404957.5000, 1398767.5000, 1397324.8750],
        [1512535.1250, 1510949.2500, 1506052.2500, 1505317.0000, 1504005.3750,
         1502147.6250, 1500494.0000, 1496766.6250, 1496743.7500, 1494980.6250],
        [1313734.8750, 1307842.0000, 1294430.8750, 1277404.5000, 1271389.7500,
         1264359.8750, 1261832.6250, 1233299.5000, 1197291.0000, 1189557.3750],
        [1560600.2500, 1557348.6250, 1556309.3750, 1555742.5000, 1554375.1250,
         1553471.2500, 1552122.0000, 1550589.3750, 1549742.2500, 1549248.7500],
        [1549513.2500, 1548257.6250, 1546560.6250, 1543797.5000, 1543329.5000,
         1542477.6250, 1542407.0000, 1541254.1250, 1540257.8750, 1540022.8750],
        [1528070.3750, 1526948.7500, 1524132.0000, 1523880.5000, 1523390.8750,
         1523148.3750, 1522621.1250, 1522117.2500, 1520343.1250, 1518962.0000],
        [1414797.0000, 1399835.1250, 1386567.2500, 1386140.1250, 1375315.1250,
         1374468.0000, 1352734.5000, 1345575.5000, 1345084.1250, 1335413.6250],
        [1333785.6250, 1284210.6250, 1275599.1250, 1273555.8750, 1270024.0000,
         1258358.5000, 1236856.7500, 1228056.7500, 1224126.7500, 1222539.0000],
        [1369456.8750, 1309641.8750, 1090412.0000, 1084449.0000,  971635.0625,
          931539.2500,  929102.9375,  919127.5625,  902635.1875,  896809.9375],
        [1140350.2500, 1125861.6250, 1083822.3750, 1070744.1250, 1037348.5625,
          984401.8125,  971554.4375,  925622.8125,  918900.5625,  880671.0000],
        [1443802.5000, 1386732.5000, 1384741.0000, 1379727.8750, 1374381.5000,
         1370583.1250, 1367470.6250, 1364309.1250, 1357432.0000, 1352393.8750],
        [1476005.8750, 1470241.6250, 1467617.6250, 1464511.0000, 1460457.8750,
         1458286.7500, 1456820.2500, 1452485.1250, 1449519.6250, 1446941.1250],
        [1462933.6250, 1453410.6250, 1447968.1250, 1445983.7500, 1439333.0000,
         1431861.8750, 1428784.5000, 1428148.3750, 1425335.8750, 1424214.8750],
        [1406133.0000, 1376650.8750, 1373474.8750, 1363202.2500, 1350104.0000,
         1320121.1250, 1293924.7500, 1291639.0000, 1289010.6250, 1267519.2500],
        [1482061.0000, 1474667.7500, 1450180.6250, 1448405.8750, 1432285.2500,
         1425879.6250, 1416910.1250, 1412208.8750, 1406712.5000, 1364464.0000],
        [1424327.6250, 1421384.3750, 1401423.3750, 1361382.1250, 1336963.1250,
         1329363.8750, 1321690.7500, 1319134.5000, 1317816.7500, 1315892.8750],
        [1485865.2500, 1475451.2500, 1472658.0000, 1472502.1250, 1469680.8750,
         1468960.6250, 1464456.5000, 1455534.2500, 1451668.1250, 1451115.7500],
        [1499210.8750, 1487975.2500, 1482667.6250, 1479747.7500, 1465711.2500,
         1463018.7500, 1462628.0000, 1456448.0000, 1449305.3750, 1443076.8750],
        [1481211.8750, 1417079.1250, 1402949.1250, 1392234.3750, 1371837.1250,
         1367036.3750, 1347823.0000, 1341307.8750, 1335125.7500, 1334026.1250],
        [1456182.6250, 1435719.2500, 1429453.7500, 1379741.0000, 1344222.3750,
         1331062.6250, 1324919.0000, 1324216.5000, 1322348.8750, 1291896.6250],
        [1447261.2500, 1441485.5000, 1440471.3750, 1411209.8750, 1404058.7500,
         1402042.2500, 1374816.7500, 1364521.2500, 1363796.6250, 1350697.6250],
        [1522749.0000, 1495093.1250, 1476777.3750, 1449594.2500, 1438398.5000,
         1427933.2500, 1422697.1250, 1392703.1250, 1382210.3750, 1368023.6250],
        [1386008.0000, 1370266.8750, 1361462.6250, 1344001.8750, 1333222.2500,
         1332978.1250, 1326347.5000, 1321088.3750, 1319006.2500, 1314732.5000],
        [1423503.3750, 1396845.2500, 1339663.7500, 1320096.0000, 1304179.0000,
         1299910.0000, 1282524.1250, 1281197.6250, 1275861.8750, 1274717.5000],
        [1447461.3750, 1430216.0000, 1412693.6250, 1397078.5000, 1384025.3750,
         1383692.8750, 1315491.2500, 1300876.0000, 1297847.5000, 1278453.8750],
        [1462127.5000, 1460516.3750, 1446961.7500, 1438678.3750, 1425219.0000,
         1414706.6250, 1413552.1250, 1410192.7500, 1408692.6250, 1398626.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1529996.6250,       0.0000],
         [1526485.6250,       0.0000],
         [1510460.8750,       0.0000],
         ...,
         [1498673.5000,       0.0000],
         [1492368.0000,       0.0000],
         [1492070.6250,       0.0000]],

        [[1543010.1250,       0.0000],
         [1536471.2500,       0.0000],
         [1530914.7500,       0.0000],
         ...,
         [1527215.2500,       0.0000],
         [1526270.1250,       0.0000],
         [1524515.7500,       0.0000]],

        [[1216697.8750,       0.0000],
         [      0.0000, 1054812.5000],
         [1053485.6250,       0.0000],
         ...,
         [      0.0000,  980293.7500],
         [ 975510.4375,       0.0000],
         [      0.0000,  949295.5000]],

        ...,

        [[1423503.3750,       0.0000],
         [1396845.2500,       0.0000],
         [1339663.7500,       0.0000],
         ...,
         [      0.0000, 1281197.6250],
         [      0.0000, 1275861.8750],
         [      0.0000, 1274717.5000]],

        [[1447461.3750,       0.0000],
         [1430216.0000,       0.0000],
         [1412693.6250,       0.0000],
         ...,
         [      0.0000, 1300876.0000],
         [      0.0000, 1297847.5000],
         [1278453.8750,       0.0000]],

        [[      0.0000, 1462127.5000],
         [      0.0000, 1460516.3750],
         [      0.0000, 1446961.7500],
         ...,
         [      0.0000, 1410192.7500],
         [1408692.6250,       0.0000],
         [1398626.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15062426.0000,        0.0000],
        [15303259.0000,        0.0000],
        [ 6286147.0000,  3990435.7500],
        [14285217.0000,        0.0000],
        [10646044.0000,  2654625.0000],
        [10564216.0000,  1227256.0000],
        [ 4103561.0000,  6168100.5000],
        [10003160.0000,  1016208.1250],
        [13877036.0000,  1533439.6250],
        [11946091.0000,  1345728.1250],
        [15461199.0000,        0.0000],
        [12885186.0000,  1384348.8750],
        [12609720.0000,  1338400.8750],
        [15580488.0000,        0.0000],
        [15574904.0000,        0.0000],
        [15529423.0000,        0.0000],
        [13579907.0000,  1499049.3750],
        [10493667.0000,  4499202.0000],
        [14627562.0000,        0.0000],
        [15437586.0000,        0.0000],
        [15481720.0000,        0.0000],
        [11740264.0000,  2971099.7500],
        [15445720.0000,        0.0000],
        [15639719.0000,        0.0000],
        [10425778.0000,  4487807.5000],
        [15607134.0000,        0.0000],
        [15489026.0000,        0.0000],
        [15617467.0000,        0.0000],
        [15700623.0000,        0.0000],
        [15694268.0000,        0.0000],
        [15686920.0000,        0.0000],
        [15688058.0000,        0.0000],
        [ 3412470.5000,  8468244.0000],
        [10632993.0000,  4564681.0000],
        [13890748.0000,  1543132.3750],
        [13641451.0000,  1515969.2500],
        [ 6154101.0000,  6445241.0000],
        [10463440.0000,  4496684.0000],
        [12806300.0000,  1437009.6250],
        [15029992.0000,        0.0000],
        [10054879.0000,  2556263.5000],
        [15539550.0000,        0.0000],
        [15437878.0000,        0.0000],
        [12182396.0000,  3051218.7500],
        [ 2688148.0000, 11027782.0000],
        [       0.0000, 12607112.0000],
        [ 5550850.0000,  4853960.0000],
        [       0.0000, 10139278.0000],
        [ 9571311.0000,  4210263.0000],
        [10206741.0000,  4396146.0000],
        [11509228.0000,  2878746.5000],
        [ 1289010.6250, 12042769.0000],
        [       0.0000, 14313776.0000],
        [ 2636951.2500, 10912428.0000],
        [11706576.0000,  2961316.5000],
        [10247812.0000,  4441977.0000],
        [ 2719660.0000, 11070970.0000],
        [ 2723963.5000, 10915800.0000],
        [       0.0000, 14000361.0000],
        [ 1392703.1250, 12983476.0000],
        [10679104.0000,  2730010.0000],
        [ 8062542.5000,  5135956.0000],
        [ 9733622.0000,  3914214.7500],
        [ 2807318.7500, 11471955.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 256/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:43, 61.57s/it]  7%|▋         | 2/29 [01:02<11:39, 25.89s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 3.0544018745422363
Epoch 257/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:06, 58.09s/it]  7%|▋         | 2/29 [01:00<11:23, 25.33s/it] 10%|█         | 3/29 [01:01<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.053027868270874
Epoch 258/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:14, 60.52s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.0574541091918945
Epoch 259/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:48, 59.58s/it]  7%|▋         | 2/29 [01:00<11:21, 25.24s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.0477731227874756
Epoch 260/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:31, 61.11s/it]  7%|▋         | 2/29 [01:02<11:34, 25.71s/it] 10%|█         | 3/29 [01:02<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.0327930450439453
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0113, 0.0014,  ..., 0.0042, 0.0004, 0.0186],
        [0.0025, 0.0100, 0.0014,  ..., 0.0040, 0.0007, 0.0183],
        [0.0294, 0.0086, 0.0031,  ..., 0.0055, 0.0136, 0.0225],
        ...,
        [0.0058, 0.0075, 0.0224,  ..., 0.0043, 0.0013, 0.0229],
        [0.0054, 0.0105, 0.0182,  ..., 0.0039, 0.0031, 0.0208],
        [0.0071, 0.0067, 0.0039,  ..., 0.0016, 0.0032, 0.0202]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9970, 0.9968, 0.9961, 0.9958, 0.9958, 0.9958, 0.9958, 0.9956, 0.9953,
         0.9952],
        [0.9975, 0.9972, 0.9970, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969,
         0.9968],
        [0.9813, 0.9722, 0.9717, 0.9712, 0.9696, 0.9678, 0.9671, 0.9664, 0.9660,
         0.9643],
        [0.9938, 0.9934, 0.9927, 0.9926, 0.9925, 0.9920, 0.9919, 0.9917, 0.9914,
         0.9909],
        [0.9901, 0.9879, 0.9874, 0.9872, 0.9872, 0.9871, 0.9870, 0.9870, 0.9867,
         0.9867],
        [0.9874, 0.9855, 0.9811, 0.9800, 0.9767, 0.9764, 0.9753, 0.9748, 0.9748,
         0.9730],
        [0.9752, 0.9737, 0.9707, 0.9700, 0.9680, 0.9674, 0.9672, 0.9671, 0.9669,
         0.9657],
        [0.9852, 0.9830, 0.9753, 0.9753, 0.9748, 0.9706, 0.9703, 0.9684, 0.9683,
         0.9679],
        [0.9980, 0.9978, 0.9976, 0.9974, 0.9974, 0.9974, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9936, 0.9884, 0.9882, 0.9879, 0.9873, 0.9864, 0.9862, 0.9862, 0.9842,
         0.9841],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9944, 0.9941, 0.9936, 0.9932, 0.9918, 0.9916, 0.9911, 0.9911, 0.9906,
         0.9902],
        [0.9943, 0.9929, 0.9919, 0.9907, 0.9905, 0.9905, 0.9898, 0.9885, 0.9884,
         0.9880],
        [0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9965, 0.9964, 0.9963, 0.9963, 0.9961, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9961, 0.9959, 0.9957, 0.9957, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9952],
        [0.9949, 0.9944, 0.9944, 0.9940, 0.9939, 0.9937, 0.9936, 0.9933, 0.9932,
         0.9930],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9958, 0.9951, 0.9950, 0.9945, 0.9941, 0.9939, 0.9937, 0.9936, 0.9935,
         0.9931],
        [0.9987, 0.9983, 0.9979, 0.9977, 0.9975, 0.9975, 0.9975, 0.9973, 0.9972,
         0.9972],
        [0.9987, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9959, 0.9956, 0.9955, 0.9955, 0.9954, 0.9951, 0.9947, 0.9946, 0.9946,
         0.9945],
        [0.9987, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9986, 0.9986, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9899, 0.9859, 0.9812, 0.9800, 0.9787, 0.9771, 0.9751, 0.9747, 0.9747,
         0.9710],
        [0.9969, 0.9967, 0.9967, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963,
         0.9962],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9969, 0.9967, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9960],
        [0.9896, 0.9866, 0.9845, 0.9829, 0.9822, 0.9813, 0.9811, 0.9803, 0.9794,
         0.9793],
        [0.9958, 0.9958, 0.9957, 0.9957, 0.9953, 0.9953, 0.9953, 0.9951, 0.9950,
         0.9950],
        [0.9944, 0.9934, 0.9925, 0.9923, 0.9915, 0.9914, 0.9910, 0.9909, 0.9907,
         0.9906],
        [0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958, 0.9954, 0.9954,
         0.9954],
        [0.9860, 0.9858, 0.9855, 0.9850, 0.9848, 0.9841, 0.9840, 0.9812, 0.9812,
         0.9808],
        [0.9983, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9916, 0.9909, 0.9903, 0.9902, 0.9898, 0.9896, 0.9883, 0.9882, 0.9881,
         0.9875],
        [0.9873, 0.9849, 0.9846, 0.9842, 0.9841, 0.9837, 0.9829, 0.9823, 0.9816,
         0.9815],
        [0.9890, 0.9869, 0.9746, 0.9729, 0.9642, 0.9630, 0.9628, 0.9624, 0.9610,
         0.9609],
        [0.9760, 0.9759, 0.9728, 0.9725, 0.9705, 0.9662, 0.9662, 0.9606, 0.9603,
         0.9579],
        [0.9931, 0.9902, 0.9899, 0.9898, 0.9898, 0.9895, 0.9894, 0.9891, 0.9890,
         0.9886],
        [0.9943, 0.9943, 0.9941, 0.9937, 0.9935, 0.9935, 0.9935, 0.9933, 0.9932,
         0.9931],
        [0.9938, 0.9933, 0.9932, 0.9930, 0.9928, 0.9926, 0.9923, 0.9921, 0.9921,
         0.9918],
        [0.9914, 0.9901, 0.9898, 0.9894, 0.9886, 0.9869, 0.9862, 0.9858, 0.9847,
         0.9839],
        [0.9948, 0.9942, 0.9934, 0.9930, 0.9925, 0.9920, 0.9918, 0.9917, 0.9916,
         0.9889],
        [0.9918, 0.9918, 0.9911, 0.9893, 0.9877, 0.9875, 0.9871, 0.9867, 0.9867,
         0.9866],
        [0.9951, 0.9945, 0.9945, 0.9945, 0.9943, 0.9940, 0.9940, 0.9939, 0.9935,
         0.9935],
        [0.9955, 0.9951, 0.9949, 0.9949, 0.9941, 0.9940, 0.9940, 0.9934, 0.9933,
         0.9933],
        [0.9947, 0.9915, 0.9909, 0.9906, 0.9895, 0.9895, 0.9886, 0.9879, 0.9879,
         0.9879],
        [0.9935, 0.9926, 0.9921, 0.9899, 0.9885, 0.9874, 0.9873, 0.9870, 0.9867,
         0.9855],
        [0.9931, 0.9928, 0.9927, 0.9917, 0.9909, 0.9901, 0.9901, 0.9893, 0.9890,
         0.9889],
        [0.9966, 0.9952, 0.9945, 0.9934, 0.9929, 0.9922, 0.9918, 0.9905, 0.9902,
         0.9897],
        [0.9904, 0.9892, 0.9885, 0.9879, 0.9876, 0.9876, 0.9870, 0.9868, 0.9867,
         0.9866],
        [0.9924, 0.9912, 0.9879, 0.9870, 0.9862, 0.9860, 0.9852, 0.9846, 0.9846,
         0.9845],
        [0.9931, 0.9921, 0.9915, 0.9906, 0.9902, 0.9898, 0.9862, 0.9855, 0.9852,
         0.9844],
        [0.9939, 0.9937, 0.9929, 0.9926, 0.9919, 0.9917, 0.9916, 0.9914, 0.9913,
         0.9909]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 0, 0, 1, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1532514.2500, 1529890.0000, 1514030.2500, 1507897.5000, 1506514.7500,
         1506392.6250, 1506326.5000, 1502719.5000, 1495526.7500, 1493860.3750],
        [1544523.5000, 1536696.8750, 1533710.2500, 1532805.0000, 1532734.8750,
         1531944.2500, 1531818.6250, 1530065.1250, 1529957.1250, 1527841.6250],
        [1225173.2500, 1075692.7500, 1067703.3750, 1061219.6250, 1037090.3125,
         1010089.1250, 1000723.3125,  990031.8125,  984510.7500,  960753.0000],
        [1465250.0000, 1456113.2500, 1441882.8750, 1439912.3750, 1438062.5000,
         1426672.7500, 1426421.0000, 1420588.8750, 1415184.2500, 1405864.8750],
        [1388798.5000, 1345533.1250, 1335985.5000, 1333556.7500, 1333270.6250,
         1331713.8750, 1329471.7500, 1329144.6250, 1322900.1250, 1322636.3750],
        [1336825.3750, 1301544.8750, 1221218.7500, 1203159.5000, 1147345.8750,
         1143046.1250, 1124275.7500, 1117232.2500, 1116585.6250, 1088734.0000],
        [1122555.1250, 1098665.6250, 1053012.3750, 1043165.0000, 1013794.9375,
         1004889.1875, 1002051.6875, 1000706.1250,  997304.9375,  980751.9375],
        [1295453.5000, 1255673.2500, 1124625.3750, 1124030.2500, 1117019.1250,
         1051399.8750, 1046995.1875, 1018647.4375, 1017189.3750, 1011599.6875],
        [1556205.5000, 1549792.5000, 1546317.1250, 1543016.0000, 1542926.2500,
         1542832.1250, 1538183.7500, 1537396.1250, 1536075.7500, 1534686.1250],
        [1461279.8750, 1356250.5000, 1351910.3750, 1347077.6250, 1334242.3750,
         1317850.6250, 1314539.3750, 1313365.2500, 1277436.2500, 1274484.1250],
        [1554296.5000, 1553613.5000, 1552157.6250, 1552085.1250, 1549359.5000,
         1547717.2500, 1546044.3750, 1545451.8750, 1543132.3750, 1542118.6250],
        [1477656.3750, 1471203.7500, 1460155.7500, 1452983.7500, 1422984.8750,
         1419669.3750, 1409817.5000, 1408646.8750, 1400058.0000, 1390286.6250],
        [1474479.2500, 1446888.6250, 1425667.6250, 1400826.0000, 1396863.8750,
         1396677.5000, 1383814.1250, 1357055.3750, 1356897.5000, 1347449.0000],
        [1563964.3750, 1561249.2500, 1561137.5000, 1560217.7500, 1560086.8750,
         1557292.2500, 1554794.6250, 1554513.0000, 1554484.8750, 1553380.8750],
        [1562345.3750, 1561282.0000, 1560723.7500, 1560656.7500, 1560451.2500,
         1558107.7500, 1557960.6250, 1557001.1250, 1556698.2500, 1556575.0000],
        [1559429.2500, 1556987.8750, 1556970.0000, 1554997.7500, 1553674.1250,
         1553491.8750, 1552271.6250, 1552011.1250, 1551793.5000, 1551540.3750],
        [1522711.2500, 1520425.7500, 1518095.8750, 1517871.5000, 1512611.6250,
         1506743.2500, 1505950.2500, 1505006.8750, 1501859.8750, 1500538.3750],
        [1513249.2500, 1509268.6250, 1505424.6250, 1505288.3750, 1500857.5000,
         1498579.1250, 1497244.8750, 1495653.6250, 1494064.0000, 1493458.6250],
        [1486866.0000, 1476473.1250, 1476378.8750, 1469525.2500, 1466787.8750,
         1462530.3750, 1460811.7500, 1454438.1250, 1452113.8750, 1448017.7500],
        [1550191.5000, 1548700.6250, 1548378.7500, 1545479.8750, 1545028.8750,
         1544280.6250, 1544011.1250, 1543952.1250, 1543406.0000, 1543295.6250],
        [1555462.1250, 1555374.6250, 1553660.7500, 1551006.3750, 1549254.6250,
         1548542.6250, 1545238.1250, 1543987.5000, 1543781.3750, 1542339.2500],
        [1506636.8750, 1491321.0000, 1489809.8750, 1478971.8750, 1470752.0000,
         1466424.2500, 1462609.8750, 1460708.6250, 1459335.7500, 1450877.7500],
        [1570743.0000, 1561977.5000, 1552723.1250, 1547822.1250, 1545045.1250,
         1544638.5000, 1544273.1250, 1538858.6250, 1537890.2500, 1537534.0000],
        [1571964.3750, 1569185.8750, 1566989.1250, 1566201.7500, 1564480.5000,
         1564440.2500, 1564183.6250, 1562938.6250, 1562898.2500, 1562658.3750],
        [1509758.0000, 1501835.3750, 1501742.2500, 1500848.8750, 1497764.7500,
         1491158.7500, 1483104.6250, 1481779.8750, 1481019.7500, 1479718.1250],
        [1570412.0000, 1566914.5000, 1563041.3750, 1562056.3750, 1561116.7500,
         1561110.7500, 1560216.2500, 1559622.7500, 1556836.2500, 1556048.1250],
        [1558344.0000, 1555481.3750, 1555072.0000, 1551778.7500, 1551337.7500,
         1550107.3750, 1548101.1250, 1547450.1250, 1545056.8750, 1544776.8750],
        [1568695.2500, 1568258.2500, 1566062.8750, 1563863.0000, 1562737.3750,
         1561259.7500, 1561158.5000, 1560528.7500, 1560234.1250, 1560086.8750],
        [1575779.7500, 1574813.7500, 1572271.7500, 1571206.0000, 1570818.0000,
         1570623.1250, 1570090.0000, 1569756.2500, 1569494.2500, 1569187.5000],
        [1575760.2500, 1575428.2500, 1573555.7500, 1570858.3750, 1569403.0000,
         1569034.8750, 1568753.5000, 1566732.1250, 1566428.8750, 1566113.6250],
        [1573212.1250, 1571947.8750, 1570894.3750, 1570476.3750, 1569890.8750,
         1569400.0000, 1568793.8750, 1568783.5000, 1567014.5000, 1566957.7500],
        [1572937.6250, 1572585.1250, 1570937.7500, 1570711.6250, 1570287.7500,
         1569994.2500, 1569715.7500, 1567676.7500, 1566636.5000, 1566617.1250],
        [1384882.2500, 1308767.8750, 1222548.2500, 1202280.8750, 1180072.8750,
         1154419.7500, 1121870.1250, 1115299.0000, 1114752.3750, 1057190.2500],
        [1530472.3750, 1527624.5000, 1527250.1250, 1522547.0000, 1520892.6250,
         1520119.7500, 1520057.3750, 1519505.2500, 1518071.3750, 1516809.3750],
        [1550108.7500, 1549102.3750, 1547515.1250, 1545569.7500, 1545569.7500,
         1543590.0000, 1542988.1250, 1541008.7500, 1540453.2500, 1540159.5000],
        [1530212.5000, 1526602.1250, 1520638.8750, 1518385.5000, 1517708.0000,
         1515035.5000, 1514456.2500, 1513965.1250, 1512584.1250, 1511642.5000],
        [1379109.5000, 1321131.2500, 1282590.1250, 1252749.8750, 1240246.6250,
         1224582.1250, 1221694.0000, 1207151.1250, 1192102.3750, 1190317.7500],
        [1508120.5000, 1506773.3750, 1505421.8750, 1504192.0000, 1496446.8750,
         1495993.1250, 1495910.5000, 1493185.2500, 1490824.6250, 1490274.5000],
        [1477114.0000, 1456698.0000, 1437108.2500, 1433766.7500, 1416503.5000,
         1414655.2500, 1406257.6250, 1405087.5000, 1400476.0000, 1398479.5000],
        [1514233.7500, 1510681.2500, 1510462.2500, 1508969.2500, 1508609.5000,
         1508441.2500, 1507032.1250, 1498800.6250, 1498076.1250, 1497790.5000],
        [1310256.3750, 1307034.0000, 1300733.3750, 1292035.7500, 1287436.8750,
         1275304.7500, 1273531.6250, 1223762.6250, 1222593.7500, 1217044.8750],
        [1560960.5000, 1557728.8750, 1557601.1250, 1554474.3750, 1553323.0000,
         1552674.2500, 1551351.1250, 1550726.8750, 1550487.3750, 1549907.8750],
        [1552403.3750, 1550935.3750, 1547395.5000, 1545397.2500, 1544460.2500,
         1544340.8750, 1543520.8750, 1543160.2500, 1542443.6250, 1541805.3750],
        [1530415.3750, 1529092.2500, 1527972.6250, 1526427.5000, 1524725.1250,
         1524418.3750, 1523264.5000, 1523155.5000, 1520897.0000, 1520630.1250],
        [1420188.0000, 1404552.8750, 1392303.3750, 1392153.3750, 1382661.2500,
         1379155.5000, 1353472.6250, 1351661.5000, 1350418.1250, 1339408.2500],
        [1334668.7500, 1289881.2500, 1284810.8750, 1277541.0000, 1274450.1250,
         1267000.8750, 1253411.8750, 1242374.0000, 1230091.6250, 1229069.1250],
        [1368580.7500, 1327687.7500, 1112934.8750, 1086292.5000,  959920.5000,
          942846.2500,  940521.1875,  935588.4375,  917125.0625,  915733.6875],
        [1135104.2500, 1134103.2500, 1084299.0000, 1080588.0000, 1049387.3750,
          988107.6875,  987399.2500,  910871.8125,  908055.6250,  876775.8750],
        [1449537.6250, 1390969.6250, 1386079.3750, 1383814.1250, 1382900.0000,
         1376925.3750, 1374971.5000, 1370415.7500, 1368471.1250, 1358843.7500],
        [1476001.6250, 1474207.8750, 1470237.3750, 1463532.2500, 1459147.7500,
         1459072.6250, 1458175.5000, 1453338.6250, 1452507.2500, 1449561.1250],
        [1463656.3750, 1453782.1250, 1452888.2500, 1448704.2500, 1442971.0000,
         1439046.1250, 1433851.5000, 1430158.7500, 1429178.5000, 1424023.3750],
        [1414784.7500, 1389647.6250, 1383648.0000, 1375421.3750, 1359664.2500,
         1326742.2500, 1313277.6250, 1305722.0000, 1285487.3750, 1272278.7500],
        [1485562.1250, 1474057.5000, 1456561.8750, 1448592.5000, 1437112.2500,
         1427998.6250, 1422716.1250, 1420411.3750, 1419356.7500, 1366197.1250],
        [1423199.2500, 1422625.2500, 1410169.8750, 1372668.2500, 1343089.6250,
         1337852.1250, 1330288.5000, 1324029.6250, 1323585.3750, 1321647.8750],
        [1491857.2500, 1479585.5000, 1479381.0000, 1478857.6250, 1475791.8750,
         1469903.6250, 1468046.0000, 1467038.3750, 1457989.1250, 1457989.1250],
        [1500471.0000, 1493041.5000, 1487030.5000, 1486866.0000, 1471926.5000,
         1468827.5000, 1468151.1250, 1457107.8750, 1453787.7500, 1453464.7500],
        [1483821.8750, 1417019.6250, 1405133.0000, 1398820.8750, 1378183.8750,
         1377259.0000, 1360142.7500, 1347076.5000, 1346765.6250, 1346293.0000],
        [1458377.1250, 1439666.6250, 1430031.8750, 1385976.2500, 1358019.7500,
         1336244.1250, 1334830.3750, 1329670.8750, 1323163.7500, 1301398.5000],
        [1449175.5000, 1443847.8750, 1441672.5000, 1422347.2500, 1405859.5000,
         1390091.7500, 1389157.3750, 1373228.6250, 1367778.3750, 1365825.7500],
        [1524536.2500, 1494799.5000, 1478434.5000, 1455884.1250, 1446572.6250,
         1432561.2500, 1423169.3750, 1398048.7500, 1390569.1250, 1380925.7500],
        [1395250.2500, 1370882.5000, 1358645.5000, 1345639.6250, 1340270.8750,
         1340089.3750, 1329177.6250, 1325308.1250, 1323054.0000, 1320632.3750],
        [1435522.1250, 1412023.0000, 1345365.0000, 1329905.5000, 1314698.6250,
         1310326.3750, 1294972.8750, 1283638.7500, 1283416.0000, 1281998.2500],
        [1449221.1250, 1430471.1250, 1417648.1250, 1399702.8750, 1390387.3750,
         1383447.3750, 1313511.7500, 1300047.5000, 1295417.6250, 1280909.2500],
        [1465990.7500, 1463239.1250, 1446527.1250, 1438859.5000, 1425159.1250,
         1421624.3750, 1418634.0000, 1415894.3750, 1414199.3750, 1406102.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1532514.2500,       0.0000],
         [1529890.0000,       0.0000],
         [1514030.2500,       0.0000],
         ...,
         [1502719.5000,       0.0000],
         [1495526.7500,       0.0000],
         [1493860.3750,       0.0000]],

        [[1544523.5000,       0.0000],
         [1536696.8750,       0.0000],
         [1533710.2500,       0.0000],
         ...,
         [1530065.1250,       0.0000],
         [1529957.1250,       0.0000],
         [1527841.6250,       0.0000]],

        [[1225173.2500,       0.0000],
         [1075692.7500,       0.0000],
         [      0.0000, 1067703.3750],
         ...,
         [ 990031.8125,       0.0000],
         [      0.0000,  984510.7500],
         [      0.0000,  960753.0000]],

        ...,

        [[1435522.1250,       0.0000],
         [1412023.0000,       0.0000],
         [1345365.0000,       0.0000],
         ...,
         [      0.0000, 1283638.7500],
         [      0.0000, 1283416.0000],
         [      0.0000, 1281998.2500]],

        [[1449221.1250,       0.0000],
         [1430471.1250,       0.0000],
         [1417648.1250,       0.0000],
         ...,
         [      0.0000, 1300047.5000],
         [      0.0000, 1295417.6250],
         [1280909.2500,       0.0000]],

        [[      0.0000, 1465990.7500],
         [      0.0000, 1463239.1250],
         [      0.0000, 1446527.1250],
         ...,
         [      0.0000, 1415894.3750],
         [1414199.3750,       0.0000],
         [1406102.2500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15095673.0000,        0.0000],
        [15332097.0000,        0.0000],
        [ 6362930.0000,  4050057.5000],
        [14335953.0000,        0.0000],
        [10693921.0000,  2679090.0000],
        [10578750.0000,  1221218.7500],
        [ 4141945.5000,  6174951.5000],
        [10043986.0000,  1018647.4375],
        [13891355.0000,  1536075.7500],
        [12001358.0000,  1347077.6250],
        [15485977.0000,        0.0000],
        [12923176.0000,  1390286.6250],
        [13986620.0000,        0.0000],
        [15581121.0000,        0.0000],
        [15591802.0000,        0.0000],
        [15543167.0000,        0.0000],
        [15111814.0000,        0.0000],
        [10510122.0000,  4502967.0000],
        [14653944.0000,        0.0000],
        [15456726.0000,        0.0000],
        [15488647.0000,        0.0000],
        [11768667.0000,  2968781.7500],
        [15481505.0000,        0.0000],
        [15655942.0000,        0.0000],
        [10433994.0000,  4494736.0000],
        [15617375.0000,        0.0000],
        [15507506.0000,        0.0000],
        [15632886.0000,        0.0000],
        [15714040.0000,        0.0000],
        [15702068.0000,        0.0000],
        [15697372.0000,        0.0000],
        [15698100.0000,        0.0000],
        [ 3391683.0000,  8470401.0000],
        [10652285.0000,  4571064.0000],
        [13902476.0000,  1543590.0000],
        [13660590.0000,  1520638.8750],
        [ 4891128.5000,  7620546.0000],
        [10484123.0000,  4503020.0000],
        [12812380.0000,  1433766.7500],
        [15063096.0000,        0.0000],
        [10135469.0000,  2574265.0000],
        [15539235.0000,        0.0000],
        [15455862.0000,        0.0000],
        [12197181.0000,  3053817.5000],
        [ 1351661.5000, 12414313.0000],
        [       0.0000, 12683299.0000],
        [ 5611735.0000,  4895496.0000],
        [       0.0000, 10154692.0000],
        [ 9619521.0000,  4223407.0000],
        [10212190.0000,  4403593.0000],
        [11531521.0000,  2886739.7500],
        [ 2557766.0000, 10868908.0000],
        [       0.0000, 14358566.0000],
        [ 2647615.0000, 10961541.0000],
        [11755724.0000,  2970715.0000],
        [10285022.0000,  4455652.5000],
        [ 2737401.7500, 11123114.0000],
        [ 2743996.0000, 10953383.0000],
        [       0.0000, 14048984.0000],
        [ 1398048.7500, 13027452.0000],
        [10708060.0000,  2740890.0000],
        [ 8128115.0000,  5163751.5000],
        [ 9751787.0000,  3908977.0000],
        [ 2820301.5000, 11495928.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 261/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:50, 59.65s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.0398426055908203
Epoch 262/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:58, 59.95s/it]  7%|▋         | 2/29 [01:00<11:21, 25.23s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.0414938926696777
Epoch 263/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:20, 56.43s/it]  7%|▋         | 2/29 [00:57<10:42, 23.78s/it] 10%|█         | 3/29 [00:58<05:46, 13.34s/it] 14%|█▍        | 4/29 [00:59<03:38,  8.73s/it] 17%|█▋        | 5/29 [01:00<02:21,  5.91s/it] 21%|██        | 6/29 [01:01<01:36,  4.22s/it] 24%|██▍       | 7/29 [01:02<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:03<00:51,  2.43s/it] 31%|███       | 9/29 [01:04<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.87s/it]
Epoch loss is 3.027367115020752
Epoch 264/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.68s/it]  7%|▋         | 2/29 [00:57<10:44, 23.88s/it] 10%|█         | 3/29 [00:58<05:48, 13.40s/it] 14%|█▍        | 4/29 [00:59<03:31,  8.47s/it] 17%|█▋        | 5/29 [01:01<02:26,  6.11s/it] 21%|██        | 6/29 [01:02<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:03<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.49s/it] 31%|███       | 9/29 [01:05<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 3.0391383171081543
Epoch 265/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:41, 57.19s/it]  7%|▋         | 2/29 [00:58<10:50, 24.09s/it] 10%|█         | 3/29 [00:59<05:54, 13.65s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.63s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:35,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 3.0462911128997803
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0124, 0.0016,  ..., 0.0044, 0.0005, 0.0183],
        [0.0030, 0.0105, 0.0016,  ..., 0.0042, 0.0008, 0.0181],
        [0.0311, 0.0081, 0.0032,  ..., 0.0051, 0.0147, 0.0228],
        ...,
        [0.0060, 0.0076, 0.0226,  ..., 0.0046, 0.0012, 0.0225],
        [0.0057, 0.0107, 0.0185,  ..., 0.0043, 0.0034, 0.0205],
        [0.0084, 0.0068, 0.0041,  ..., 0.0018, 0.0036, 0.0205]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9967, 0.9965, 0.9958, 0.9955, 0.9953, 0.9952, 0.9952, 0.9950, 0.9947,
         0.9946],
        [0.9973, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9811, 0.9722, 0.9712, 0.9707, 0.9706, 0.9681, 0.9680, 0.9677, 0.9666,
         0.9651],
        [0.9932, 0.9927, 0.9921, 0.9918, 0.9916, 0.9916, 0.9913, 0.9910, 0.9906,
         0.9906],
        [0.9896, 0.9874, 0.9874, 0.9872, 0.9870, 0.9870, 0.9869, 0.9869, 0.9863,
         0.9860],
        [0.9871, 0.9855, 0.9805, 0.9803, 0.9778, 0.9765, 0.9747, 0.9745, 0.9743,
         0.9730],
        [0.9755, 0.9750, 0.9715, 0.9710, 0.9685, 0.9683, 0.9683, 0.9674, 0.9673,
         0.9667],
        [0.9828, 0.9822, 0.9757, 0.9716, 0.9716, 0.9702, 0.9683, 0.9668, 0.9659,
         0.9641],
        [0.9979, 0.9975, 0.9973, 0.9972, 0.9972, 0.9971, 0.9970, 0.9970, 0.9970,
         0.9969],
        [0.9934, 0.9878, 0.9875, 0.9871, 0.9864, 0.9860, 0.9860, 0.9851, 0.9835,
         0.9827],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9972],
        [0.9944, 0.9940, 0.9931, 0.9929, 0.9917, 0.9910, 0.9909, 0.9902, 0.9900,
         0.9899],
        [0.9939, 0.9926, 0.9912, 0.9901, 0.9899, 0.9894, 0.9894, 0.9888, 0.9883,
         0.9881],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9977, 0.9977,
         0.9976],
        [0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9977],
        [0.9964, 0.9962, 0.9961, 0.9960, 0.9959, 0.9956, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9957, 0.9956, 0.9954, 0.9954, 0.9952, 0.9951, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9945, 0.9940, 0.9940, 0.9937, 0.9936, 0.9932, 0.9932, 0.9931, 0.9930,
         0.9929],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9956, 0.9948, 0.9946, 0.9943, 0.9940, 0.9935, 0.9935, 0.9934, 0.9934,
         0.9928],
        [0.9986, 0.9982, 0.9978, 0.9976, 0.9975, 0.9975, 0.9975, 0.9971, 0.9971,
         0.9970],
        [0.9987, 0.9986, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9955, 0.9953, 0.9952, 0.9952, 0.9947, 0.9946, 0.9946, 0.9945, 0.9942,
         0.9942],
        [0.9987, 0.9985, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9986, 0.9985, 0.9985, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9988, 0.9988, 0.9988, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9899, 0.9867, 0.9816, 0.9799, 0.9785, 0.9776, 0.9760, 0.9748, 0.9745,
         0.9712],
        [0.9966, 0.9965, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9960,
         0.9959],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9966, 0.9965, 0.9962, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9894, 0.9867, 0.9849, 0.9810, 0.9809, 0.9806, 0.9802, 0.9802, 0.9785,
         0.9778],
        [0.9954, 0.9954, 0.9953, 0.9952, 0.9949, 0.9949, 0.9948, 0.9947, 0.9947,
         0.9947],
        [0.9941, 0.9930, 0.9920, 0.9919, 0.9911, 0.9910, 0.9906, 0.9904, 0.9903,
         0.9901],
        [0.9959, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9952, 0.9952,
         0.9952],
        [0.9858, 0.9857, 0.9854, 0.9851, 0.9840, 0.9838, 0.9838, 0.9814, 0.9814,
         0.9808],
        [0.9982, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9978, 0.9977, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9967, 0.9966, 0.9966, 0.9966, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9911, 0.9906, 0.9895, 0.9894, 0.9892, 0.9889, 0.9877, 0.9875, 0.9874,
         0.9868],
        [0.9872, 0.9838, 0.9835, 0.9833, 0.9831, 0.9830, 0.9819, 0.9815, 0.9807,
         0.9805],
        [0.9886, 0.9878, 0.9749, 0.9723, 0.9644, 0.9625, 0.9615, 0.9613, 0.9607,
         0.9605],
        [0.9765, 0.9761, 0.9738, 0.9729, 0.9716, 0.9672, 0.9669, 0.9618, 0.9597,
         0.9570],
        [0.9924, 0.9900, 0.9893, 0.9893, 0.9892, 0.9891, 0.9887, 0.9884, 0.9884,
         0.9880],
        [0.9937, 0.9937, 0.9933, 0.9932, 0.9931, 0.9930, 0.9930, 0.9926, 0.9924,
         0.9924],
        [0.9931, 0.9930, 0.9929, 0.9927, 0.9926, 0.9924, 0.9918, 0.9916, 0.9914,
         0.9912],
        [0.9909, 0.9898, 0.9893, 0.9888, 0.9881, 0.9861, 0.9856, 0.9847, 0.9834,
         0.9828],
        [0.9946, 0.9941, 0.9933, 0.9927, 0.9924, 0.9917, 0.9915, 0.9915, 0.9913,
         0.9888],
        [0.9914, 0.9914, 0.9905, 0.9889, 0.9873, 0.9869, 0.9863, 0.9863, 0.9862,
         0.9861],
        [0.9949, 0.9942, 0.9941, 0.9941, 0.9938, 0.9938, 0.9937, 0.9935, 0.9930,
         0.9929],
        [0.9952, 0.9949, 0.9946, 0.9945, 0.9938, 0.9935, 0.9934, 0.9931, 0.9930,
         0.9929],
        [0.9946, 0.9912, 0.9904, 0.9902, 0.9894, 0.9893, 0.9887, 0.9877, 0.9877,
         0.9876],
        [0.9933, 0.9922, 0.9920, 0.9897, 0.9884, 0.9871, 0.9869, 0.9868, 0.9865,
         0.9854],
        [0.9926, 0.9926, 0.9925, 0.9918, 0.9905, 0.9901, 0.9892, 0.9891, 0.9885,
         0.9884],
        [0.9965, 0.9950, 0.9942, 0.9930, 0.9927, 0.9921, 0.9915, 0.9901, 0.9898,
         0.9892],
        [0.9904, 0.9892, 0.9880, 0.9877, 0.9874, 0.9874, 0.9869, 0.9866, 0.9864,
         0.9863],
        [0.9926, 0.9914, 0.9874, 0.9870, 0.9862, 0.9861, 0.9850, 0.9845, 0.9844,
         0.9843],
        [0.9926, 0.9917, 0.9910, 0.9901, 0.9896, 0.9889, 0.9851, 0.9844, 0.9843,
         0.9838],
        [0.9934, 0.9932, 0.9926, 0.9921, 0.9916, 0.9915, 0.9912, 0.9907, 0.9907,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 0, 1, 1, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1526369.1250, 1522834.6250, 1507305.2500, 1499767.2500, 1497334.8750,
         1495208.6250, 1494806.6250, 1489804.1250, 1484474.3750, 1482000.2500],
        [1540548.7500, 1532824.0000, 1529904.7500, 1529086.3750, 1528500.2500,
         1528261.3750, 1527419.1250, 1527408.8750, 1525689.5000, 1523373.3750],
        [1221266.5000, 1075177.8750, 1061151.8750, 1053591.0000, 1052133.1250,
         1014172.1250, 1012759.0625, 1008118.2500,  992870.2500,  972230.1250],
        [1452010.1250, 1442134.5000, 1429023.0000, 1422623.8750, 1419673.3750,
         1418661.0000, 1412762.3750, 1407422.3750, 1399863.1250, 1399848.3750],
        [1379235.7500, 1337053.6250, 1335909.1250, 1332387.1250, 1329928.2500,
         1328308.2500, 1327697.8750, 1326482.8750, 1315364.6250, 1309852.8750],
        [1330528.3750, 1301661.6250, 1211037.0000, 1208588.7500, 1166103.2500,
         1143518.3750, 1115132.0000, 1112061.7500, 1108492.3750, 1088790.0000],
        [1127136.7500, 1119808.2500, 1065721.6250, 1057478.6250, 1020856.0000,
         1017830.8125, 1017213.5625, 1004226.2500, 1002848.0625,  994555.2500],
        [1251410.1250, 1240147.2500, 1130269.1250, 1067008.1250, 1066564.5000,
         1045490.6250, 1017683.1875,  995858.4375,  982901.8125,  958113.3125],
        [1552083.6250, 1545235.2500, 1540193.2500, 1537774.5000, 1537754.0000,
         1535738.7500, 1533427.8750, 1532628.2500, 1532163.5000, 1531554.2500],
        [1456628.5000, 1345265.0000, 1338685.5000, 1331856.1250, 1317976.3750,
         1311076.3750, 1310057.7500, 1293711.3750, 1263835.3750, 1250465.3750],
        [1552092.3750, 1549267.8750, 1548204.5000, 1548049.3750, 1546122.6250,
         1544451.5000, 1542420.1250, 1541787.8750, 1539674.8750, 1538283.3750],
        [1476400.0000, 1468638.3750, 1450963.5000, 1446651.2500, 1421018.5000,
         1407319.0000, 1404558.2500, 1391492.3750, 1386423.1250, 1386178.5000],
        [1467447.0000, 1438834.8750, 1410523.5000, 1388377.3750, 1386062.1250,
         1375341.3750, 1375096.0000, 1363467.5000, 1354444.8750, 1350257.1250],
        [1561341.5000, 1558815.2500, 1558170.2500, 1557556.6250, 1554278.8750,
         1552099.8750, 1552028.8750, 1549134.8750, 1547795.5000, 1546837.8750],
        [1561678.1250, 1559179.5000, 1559117.1250, 1558439.2500, 1558021.6250,
         1556451.8750, 1556178.7500, 1555368.6250, 1554997.7500, 1554447.7500],
        [1557243.2500, 1555752.8750, 1554653.8750, 1554041.6250, 1551176.5000,
         1551146.8750, 1550179.7500, 1549532.3750, 1549380.1250, 1549219.1250],
        [1519873.2500, 1515376.5000, 1513797.7500, 1512026.0000, 1510293.7500,
         1503024.6250, 1496946.5000, 1496842.2500, 1495914.6250, 1495863.3750],
        [1504022.6250, 1503152.2500, 1498663.5000, 1497576.2500, 1495126.0000,
         1491625.3750, 1488086.0000, 1488017.8750, 1486403.7500, 1484886.3750],
        [1480253.0000, 1469575.6250, 1469205.7500, 1462819.1250, 1461456.8750,
         1451525.5000, 1451147.6250, 1449201.7500, 1448861.7500, 1445053.1250],
        [1547618.3750, 1545810.0000, 1544488.2500, 1541249.6250, 1540847.0000,
         1540657.5000, 1540315.1250, 1540268.2500, 1539754.1250, 1539523.6250],
        [1552923.1250, 1552733.5000, 1550689.8750, 1547922.5000, 1544657.7500,
         1544193.6250, 1541865.6250, 1540046.3750, 1539990.5000, 1537881.5000],
        [1501866.8750, 1485923.3750, 1481792.6250, 1475198.1250, 1469385.1250,
         1458107.2500, 1457490.1250, 1456368.7500, 1456367.3750, 1444522.7500],
        [1568939.0000, 1560795.2500, 1551525.6250, 1547174.2500, 1545017.1250,
         1544212.8750, 1543986.1250, 1535497.1250, 1535441.5000, 1533964.7500],
        [1569823.5000, 1568159.7500, 1564192.6250, 1563063.7500, 1562548.1250,
         1562205.3750, 1561352.0000, 1561310.2500, 1561276.0000, 1561194.1250],
        [1500622.8750, 1496618.1250, 1494362.0000, 1493749.2500, 1483270.1250,
         1481809.5000, 1480769.7500, 1479523.3750, 1474057.5000, 1472548.5000],
        [1569959.7500, 1566998.1250, 1561685.5000, 1561411.5000, 1559477.0000,
         1559117.1250, 1558409.5000, 1557880.5000, 1555948.7500, 1555564.3750],
        [1557699.2500, 1555674.2500, 1554003.1250, 1550945.7500, 1549173.2500,
         1547602.1250, 1546863.0000, 1543992.0000, 1542618.7500, 1542034.8750],
        [1567714.0000, 1566635.0000, 1565504.3750, 1562414.0000, 1561015.5000,
         1560588.2500, 1559359.5000, 1558952.1250, 1558650.2500, 1557948.7500],
        [1574696.6250, 1573552.7500, 1570307.2500, 1570128.8750, 1569612.5000,
         1569106.6250, 1568930.1250, 1568912.1250, 1567901.0000, 1567684.1250],
        [1574072.1250, 1573825.8750, 1572183.2500, 1568810.2500, 1567685.6250,
         1566508.0000, 1566278.0000, 1566143.5000, 1564113.6250, 1564094.2500],
        [1571784.5000, 1571084.6250, 1569600.5000, 1569361.1250, 1568271.7500,
         1568256.8750, 1568080.3750, 1566845.7500, 1566367.5000, 1565562.6250],
        [1571313.8750, 1570353.6250, 1569732.2500, 1568966.0000, 1568645.8750,
         1568590.5000, 1567424.0000, 1565720.8750, 1564416.5000, 1563806.2500],
        [1384762.1250, 1323693.8750, 1230605.5000, 1200168.3750, 1177304.2500,
         1161801.8750, 1135391.1250, 1116396.1250, 1111980.0000, 1060597.3750],
        [1523530.3750, 1522885.5000, 1520920.1250, 1516980.0000, 1515986.5000,
         1515662.7500, 1514873.6250, 1513506.1250, 1512086.5000, 1509049.8750],
        [1548062.7500, 1546056.2500, 1544388.1250, 1542101.0000, 1542101.0000,
         1539523.6250, 1539080.2500, 1538973.1250, 1538089.8750, 1537814.0000],
        [1523409.7500, 1521650.0000, 1514795.6250, 1512830.8750, 1511703.0000,
         1510259.2500, 1508655.5000, 1508131.8750, 1507265.0000, 1504583.6250],
        [1376393.6250, 1323124.6250, 1290581.3750, 1219428.7500, 1217443.0000,
         1212214.5000, 1205762.3750, 1205637.1250, 1177183.0000, 1164791.7500],
        [1499042.1250, 1499030.7500, 1496511.1250, 1493321.8750, 1488854.0000,
         1487477.2500, 1485182.5000, 1484365.3750, 1483690.2500, 1482714.2500],
        [1471070.5000, 1448792.7500, 1428001.2500, 1424474.2500, 1408927.7500,
         1407684.0000, 1399896.5000, 1395093.2500, 1393128.2500, 1389523.0000],
        [1509521.8750, 1504955.2500, 1504252.2500, 1503464.7500, 1503099.2500,
         1500883.2500, 1500330.8750, 1494125.3750, 1493591.1250, 1493591.1250],
        [1307229.7500, 1305201.7500, 1298439.2500, 1293109.3750, 1273355.5000,
         1269289.0000, 1269038.5000, 1227671.5000, 1227337.8750, 1215890.5000],
        [1559645.0000, 1556310.8750, 1554498.2500, 1550525.7500, 1549204.3750,
         1548612.1250, 1547922.5000, 1547893.0000, 1547791.1250, 1547621.3750],
        [1550820.1250, 1548730.2500, 1543520.8750, 1542387.8750, 1540454.6250,
         1540432.6250, 1539902.5000, 1539708.6250, 1539174.1250, 1538904.2500],
        [1526046.1250, 1525157.1250, 1523498.3750, 1523449.0000, 1518284.1250,
         1518184.2500, 1518009.0000, 1517813.6250, 1517198.5000, 1516993.1250],
        [1408403.7500, 1399609.5000, 1377604.3750, 1374495.5000, 1371353.2500,
         1364815.3750, 1341584.1250, 1338819.5000, 1336886.6250, 1325927.6250],
        [1332171.1250, 1269076.0000, 1264248.8750, 1260060.0000, 1257655.3750,
         1254635.3750, 1235113.3750, 1229157.0000, 1215275.0000, 1211466.7500],
        [1358977.2500, 1344785.2500, 1118398.3750, 1077707.3750,  962253.1250,
          936759.7500,  922754.8125,  920743.5000,  912185.3125,  910008.8125],
        [1143309.8750, 1137101.0000, 1100421.0000, 1086781.6250, 1067191.3750,
         1001617.9375,  997217.4375,  927535.8750,  900037.5000,  865765.6250],
        [1434733.7500, 1388145.6250, 1373125.1250, 1372783.5000, 1370549.1250,
         1368600.3750, 1362551.1250, 1355747.5000, 1355618.2500, 1348112.2500],
        [1463402.5000, 1461568.3750, 1454876.5000, 1451841.1250, 1450121.1250,
         1447424.1250, 1447355.1250, 1439424.8750, 1436653.2500, 1435151.1250],
        [1449830.7500, 1447283.3750, 1444993.8750, 1440845.0000, 1440173.3750,
         1436361.5000, 1423082.5000, 1419535.3750, 1416168.5000, 1410785.8750],
        [1406165.2500, 1382613.8750, 1373326.7500, 1363262.1250, 1349603.1250,
         1311967.0000, 1302693.5000, 1286835.5000, 1262308.0000, 1251111.7500],
        [1482432.8750, 1470731.0000, 1454329.8750, 1441103.3750, 1435937.0000,
         1421621.6250, 1418132.1250, 1417181.7500, 1413634.3750, 1363320.6250],
        [1415872.7500, 1415189.6250, 1396363.1250, 1365928.6250, 1334830.3750,
         1326670.1250, 1315669.3750, 1315103.6250, 1313173.6250, 1311329.0000],
        [1487614.8750, 1473551.6250, 1471522.2500, 1471404.3750, 1464756.7500,
         1464367.1250, 1462470.5000, 1459243.8750, 1448205.6250, 1446877.6250],
        [1494644.1250, 1488304.5000, 1482128.8750, 1480217.7500, 1465047.3750,
         1459289.8750, 1456866.1250, 1450085.1250, 1447816.1250, 1445418.5000],
        [1482277.3750, 1412249.2500, 1395476.5000, 1392069.7500, 1376133.7500,
         1373696.2500, 1361721.0000, 1343331.7500, 1342179.2500, 1341282.2500],
        [1454017.8750, 1430965.0000, 1426739.3750, 1381479.0000, 1355094.7500,
         1331533.6250, 1326997.8750, 1325568.6250, 1320531.6250, 1298747.6250],
        [1440225.5000, 1439684.5000, 1438290.1250, 1422705.3750, 1396993.1250,
         1389070.0000, 1372044.0000, 1369806.8750, 1358547.0000, 1355379.1250],
        [1521844.3750, 1489569.7500, 1473009.1250, 1447732.0000, 1441524.0000,
         1429046.1250, 1417754.8750, 1390013.5000, 1383187.5000, 1372490.1250],
        [1395469.7500, 1371600.3750, 1348164.8750, 1342403.2500, 1337253.8750,
         1336865.0000, 1327592.7500, 1321075.7500, 1317021.3750, 1315710.8750],
        [1440415.0000, 1416206.3750, 1336325.7500, 1329033.1250, 1313922.7500,
         1312982.0000, 1291604.5000, 1283237.3750, 1280770.1250, 1278583.1250],
        [1440704.8750, 1420629.6250, 1407254.6250, 1388786.5000, 1379005.6250,
         1366483.7500, 1292940.5000, 1280967.8750, 1279044.1250, 1269377.3750],
        [1455802.2500, 1451733.1250, 1438998.1250, 1429010.7500, 1419322.7500,
         1416441.3750, 1411114.2500, 1401907.2500, 1401736.1250, 1392554.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1526369.1250,       0.0000],
         [1522834.6250,       0.0000],
         [1507305.2500,       0.0000],
         ...,
         [1489804.1250,       0.0000],
         [1484474.3750,       0.0000],
         [      0.0000, 1482000.2500]],

        [[1540548.7500,       0.0000],
         [1532824.0000,       0.0000],
         [1529904.7500,       0.0000],
         ...,
         [1527408.8750,       0.0000],
         [1525689.5000,       0.0000],
         [1523373.3750,       0.0000]],

        [[1221266.5000,       0.0000],
         [      0.0000, 1075177.8750],
         [1061151.8750,       0.0000],
         ...,
         [      0.0000, 1008118.2500],
         [ 992870.2500,       0.0000],
         [      0.0000,  972230.1250]],

        ...,

        [[1440415.0000,       0.0000],
         [1416206.3750,       0.0000],
         [1336325.7500,       0.0000],
         ...,
         [1283237.3750,       0.0000],
         [      0.0000, 1280770.1250],
         [      0.0000, 1278583.1250]],

        [[1440704.8750,       0.0000],
         [1420629.6250,       0.0000],
         [1407254.6250,       0.0000],
         ...,
         [      0.0000, 1280967.8750],
         [      0.0000, 1279044.1250],
         [1269377.3750,       0.0000]],

        [[      0.0000, 1455802.2500],
         [      0.0000, 1451733.1250],
         [      0.0000, 1438998.1250],
         ...,
         [      0.0000, 1401907.2500],
         [1401736.1250,       0.0000],
         [      0.0000, 1392554.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13517906.0000,  1482000.2500],
        [15293017.0000,        0.0000],
        [ 6355811.0000,  4107659.2500],
        [14204022.0000,        0.0000],
        [10662136.0000,  2660085.0000],
        [ 9488535.0000,  2297378.7500],
        [ 4160725.7500,  6266949.5000],
        [ 8801474.0000,  1953971.7500],
        [13846999.0000,  1531554.2500],
        [11880872.0000,  1338685.5000],
        [15450355.0000,        0.0000],
        [14239644.0000,        0.0000],
        [13909852.0000,        0.0000],
        [15538060.0000,        0.0000],
        [15573880.0000,        0.0000],
        [15522326.0000,        0.0000],
        [15059958.0000,        0.0000],
        [11946390.0000,  2991170.0000],
        [14589101.0000,        0.0000],
        [15420532.0000,        0.0000],
        [15452905.0000,        0.0000],
        [11725901.0000,  2961121.5000],
        [15466554.0000,        0.0000],
        [15635124.0000,        0.0000],
        [10387410.0000,  4469921.0000],
        [15606452.0000,        0.0000],
        [15490606.0000,        0.0000],
        [15618782.0000,        0.0000],
        [15700833.0000,        0.0000],
        [15683715.0000,        0.0000],
        [15685216.0000,        0.0000],
        [15678969.0000,        0.0000],
        [ 3399703.5000,  8502997.0000],
        [10611595.0000,  4553886.5000],
        [13877110.0000,  1539080.2500],
        [13608489.0000,  1514795.6250],
        [ 4793634.0000,  7598926.0000],
        [11904647.0000,  2995542.0000],
        [12742117.0000,  1424474.2500],
        [15007815.0000,        0.0000],
        [10124164.0000,  2562398.5000],
        [15510025.0000,        0.0000],
        [15424036.0000,        0.0000],
        [13681186.0000,  1523449.0000],
        [ 1336886.6250, 12302613.0000],
        [       0.0000, 12528859.0000],
        [ 5564705.5000,  4899868.5000],
        [       0.0000, 10226979.0000],
        [ 8188426.0000,  5541541.0000],
        [10124018.0000,  4363800.0000],
        [11462241.0000,  2866818.7500],
        [ 1262308.0000, 12027578.0000],
        [       0.0000, 14318425.0000],
        [ 2626432.5000, 10883697.0000],
        [11688848.0000,  2961166.5000],
        [10233756.0000,  4436063.0000],
        [ 2735417.2500, 11085000.0000],
        [ 2736573.7500, 10915102.0000],
        [       0.0000, 13982745.0000],
        [ 1390013.5000, 12976158.0000],
        [10680434.0000,  2732723.5000],
        [ 9410744.0000,  3872335.0000],
        [ 9672242.0000,  3852952.5000],
        [ 1401736.1250, 12816884.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 266/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<28:57, 62.05s/it]  7%|▋         | 2/29 [01:02<11:44, 26.09s/it] 10%|█         | 3/29 [01:03<06:19, 14.60s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.20s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.21s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.04s/it]
Epoch loss is 3.0306169986724854
Epoch 267/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:10, 58.23s/it]  7%|▋         | 2/29 [00:59<11:02, 24.52s/it] 10%|█         | 3/29 [01:00<05:57, 13.74s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.68s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.88s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.0251967906951904
Epoch 268/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:38, 61.39s/it]  7%|▋         | 2/29 [01:02<11:37, 25.82s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 3.0166168212890625
Epoch 269/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:20, 60.74s/it]  7%|▋         | 2/29 [01:01<11:29, 25.55s/it] 10%|█         | 3/29 [01:02<06:11, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.020219564437866
Epoch 270/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.43s/it]  7%|▋         | 2/29 [01:00<11:29, 25.52s/it] 10%|█         | 3/29 [01:01<06:11, 14.29s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.10s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.0205276012420654
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0122, 0.0017,  ..., 0.0045, 0.0004, 0.0180],
        [0.0028, 0.0104, 0.0016,  ..., 0.0041, 0.0006, 0.0172],
        [0.0301, 0.0080, 0.0037,  ..., 0.0054, 0.0145, 0.0224],
        ...,
        [0.0061, 0.0077, 0.0221,  ..., 0.0048, 0.0012, 0.0225],
        [0.0055, 0.0105, 0.0181,  ..., 0.0042, 0.0035, 0.0199],
        [0.0077, 0.0067, 0.0042,  ..., 0.0019, 0.0032, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9967, 0.9967, 0.9960, 0.9955, 0.9955, 0.9954, 0.9952, 0.9952, 0.9948,
         0.9948],
        [0.9974, 0.9972, 0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9812, 0.9712, 0.9704, 0.9698, 0.9698, 0.9686, 0.9679, 0.9669, 0.9651,
         0.9649],
        [0.9930, 0.9926, 0.9924, 0.9919, 0.9916, 0.9913, 0.9912, 0.9909, 0.9908,
         0.9901],
        [0.9892, 0.9870, 0.9867, 0.9866, 0.9865, 0.9865, 0.9864, 0.9862, 0.9859,
         0.9858],
        [0.9867, 0.9853, 0.9798, 0.9792, 0.9777, 0.9752, 0.9738, 0.9737, 0.9723,
         0.9722],
        [0.9760, 0.9736, 0.9720, 0.9687, 0.9685, 0.9684, 0.9672, 0.9663, 0.9656,
         0.9648],
        [0.9827, 0.9815, 0.9758, 0.9715, 0.9702, 0.9692, 0.9689, 0.9673, 0.9659,
         0.9619],
        [0.9979, 0.9975, 0.9973, 0.9972, 0.9972, 0.9972, 0.9970, 0.9970, 0.9969,
         0.9968],
        [0.9933, 0.9881, 0.9877, 0.9861, 0.9855, 0.9854, 0.9852, 0.9849, 0.9822,
         0.9819],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9945, 0.9940, 0.9930, 0.9929, 0.9918, 0.9915, 0.9906, 0.9903, 0.9900,
         0.9899],
        [0.9939, 0.9924, 0.9909, 0.9898, 0.9892, 0.9891, 0.9889, 0.9883, 0.9881,
         0.9880],
        [0.9984, 0.9983, 0.9983, 0.9983, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9964, 0.9964, 0.9962, 0.9961, 0.9961, 0.9956, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9957, 0.9956, 0.9955, 0.9953, 0.9953, 0.9953, 0.9951, 0.9951, 0.9950,
         0.9950],
        [0.9947, 0.9943, 0.9941, 0.9938, 0.9936, 0.9934, 0.9934, 0.9933, 0.9932,
         0.9931],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9957, 0.9949, 0.9946, 0.9946, 0.9944, 0.9939, 0.9938, 0.9935, 0.9933,
         0.9932],
        [0.9987, 0.9983, 0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9972, 0.9971,
         0.9971],
        [0.9987, 0.9987, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9953, 0.9953, 0.9953, 0.9952, 0.9946, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9942],
        [0.9987, 0.9986, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9986, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9896, 0.9870, 0.9816, 0.9804, 0.9772, 0.9766, 0.9760, 0.9744, 0.9730,
         0.9695],
        [0.9967, 0.9967, 0.9967, 0.9965, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9967, 0.9966, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9958],
        [0.9889, 0.9862, 0.9843, 0.9813, 0.9799, 0.9797, 0.9785, 0.9781, 0.9776,
         0.9771],
        [0.9954, 0.9953, 0.9953, 0.9952, 0.9952, 0.9949, 0.9948, 0.9948, 0.9948,
         0.9947],
        [0.9940, 0.9928, 0.9920, 0.9919, 0.9910, 0.9907, 0.9905, 0.9903, 0.9902,
         0.9901],
        [0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9955],
        [0.9851, 0.9850, 0.9848, 0.9843, 0.9842, 0.9838, 0.9835, 0.9816, 0.9802,
         0.9797],
        [0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9979, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9912, 0.9908, 0.9897, 0.9895, 0.9894, 0.9889, 0.9878, 0.9876, 0.9875,
         0.9871],
        [0.9874, 0.9830, 0.9829, 0.9827, 0.9826, 0.9824, 0.9817, 0.9809, 0.9804,
         0.9803],
        [0.9887, 0.9879, 0.9763, 0.9730, 0.9654, 0.9642, 0.9626, 0.9624, 0.9623,
         0.9608],
        [0.9765, 0.9755, 0.9731, 0.9725, 0.9708, 0.9669, 0.9661, 0.9604, 0.9590,
         0.9564],
        [0.9923, 0.9904, 0.9897, 0.9894, 0.9893, 0.9890, 0.9886, 0.9885, 0.9885,
         0.9882],
        [0.9941, 0.9940, 0.9937, 0.9935, 0.9933, 0.9933, 0.9932, 0.9931, 0.9930,
         0.9929],
        [0.9936, 0.9929, 0.9929, 0.9929, 0.9929, 0.9923, 0.9920, 0.9920, 0.9914,
         0.9912],
        [0.9911, 0.9901, 0.9894, 0.9892, 0.9884, 0.9859, 0.9858, 0.9846, 0.9840,
         0.9832],
        [0.9945, 0.9941, 0.9936, 0.9925, 0.9925, 0.9921, 0.9917, 0.9915, 0.9914,
         0.9887],
        [0.9914, 0.9912, 0.9907, 0.9889, 0.9871, 0.9866, 0.9864, 0.9863, 0.9861,
         0.9861],
        [0.9950, 0.9944, 0.9944, 0.9943, 0.9943, 0.9941, 0.9940, 0.9939, 0.9934,
         0.9934],
        [0.9954, 0.9953, 0.9949, 0.9948, 0.9941, 0.9938, 0.9936, 0.9936, 0.9934,
         0.9933],
        [0.9948, 0.9914, 0.9907, 0.9900, 0.9897, 0.9894, 0.9885, 0.9882, 0.9881,
         0.9880],
        [0.9934, 0.9923, 0.9918, 0.9899, 0.9884, 0.9875, 0.9874, 0.9874, 0.9872,
         0.9860],
        [0.9929, 0.9927, 0.9926, 0.9916, 0.9906, 0.9905, 0.9895, 0.9887, 0.9884,
         0.9880],
        [0.9965, 0.9949, 0.9942, 0.9931, 0.9925, 0.9918, 0.9915, 0.9902, 0.9897,
         0.9890],
        [0.9905, 0.9887, 0.9880, 0.9879, 0.9876, 0.9874, 0.9869, 0.9867, 0.9864,
         0.9864],
        [0.9927, 0.9914, 0.9878, 0.9870, 0.9862, 0.9860, 0.9847, 0.9844, 0.9843,
         0.9842],
        [0.9929, 0.9917, 0.9911, 0.9901, 0.9900, 0.9892, 0.9855, 0.9846, 0.9839,
         0.9838],
        [0.9936, 0.9933, 0.9927, 0.9924, 0.9916, 0.9915, 0.9915, 0.9912, 0.9910,
         0.9905]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 0, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [1., 0.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1527598.2500, 1525587.6250, 1511890.5000, 1499815.7500, 1499690.0000,
         1499374.0000, 1494078.3750, 1493780.6250, 1485664.1250, 1485297.1250],
        [1541876.0000, 1536790.7500, 1532809.5000, 1532476.2500, 1531323.5000,
         1531219.8750, 1530797.8750, 1529510.8750, 1528149.0000, 1527840.1250],
        [1222574.0000, 1060293.0000, 1049079.1250, 1039122.8750, 1039001.9375,
         1022153.5625, 1011336.4375,  997375.3125,  972589.9375,  969664.2500],
        [1447050.1250, 1440373.8750, 1435613.7500, 1424812.6250, 1419933.3750,
         1414030.8750, 1411636.5000, 1405125.0000, 1402898.2500, 1390054.5000],
        [1370817.1250, 1328333.6250, 1322675.5000, 1321729.8750, 1320521.6250,
         1320153.8750, 1317782.8750, 1313439.2500, 1307838.2500, 1307191.1250],
        [1324115.6250, 1297684.1250, 1199013.0000, 1188454.1250, 1164362.0000,
         1123287.6250, 1100734.7500, 1098627.8750, 1076599.0000, 1075154.2500],
        [1135881.7500, 1097805.7500, 1072798.6250, 1023532.0000, 1020203.8750,
         1019427.8125, 1002073.7500,  988617.6250,  978970.8125,  967594.0625],
        [1249183.8750, 1228419.8750, 1132092.2500, 1065152.6250, 1044910.4375,
         1030549.7500, 1026745.5000, 1002480.8750,  983764.5625,  928228.7500],
        [1552398.8750, 1544049.3750, 1539442.8750, 1537800.8750, 1537751.0000,
         1536738.0000, 1533672.2500, 1532811.0000, 1531161.3750, 1529232.2500],
        [1454834.8750, 1350322.8750, 1342727.1250, 1312040.7500, 1300210.0000,
         1298428.1250, 1296207.2500, 1290501.3750, 1240825.2500, 1236311.8750],
        [1555689.1250, 1553040.1250, 1550891.1250, 1550595.2500, 1550238.8750,
         1549139.3750, 1546612.2500, 1546121.1250, 1544805.0000, 1544585.5000],
        [1479413.3750, 1469472.0000, 1447820.3750, 1444996.6250, 1423802.0000,
         1418187.6250, 1398640.7500, 1392962.1250, 1386610.8750, 1384544.2500],
        [1466529.1250, 1435115.5000, 1404791.3750, 1382943.5000, 1370566.1250,
         1369513.0000, 1365825.7500, 1354948.7500, 1350930.7500, 1347297.3750],
        [1563302.2500, 1562050.5000, 1561081.0000, 1560996.1250, 1554633.1250,
         1554398.8750, 1554034.1250, 1550165.0000, 1549780.6250, 1548344.7500],
        [1564444.7500, 1562394.6250, 1562305.2500, 1562120.5000, 1561441.3750,
         1561292.3750, 1559305.8750, 1559188.5000, 1559149.8750, 1558075.1250],
        [1560490.1250, 1559026.3750, 1557626.3750, 1556560.2500, 1553558.6250,
         1552976.5000, 1552942.3750, 1552601.7500, 1552002.1250, 1551768.3750],
        [1520696.8750, 1519418.2500, 1515087.5000, 1514622.3750, 1514316.1250,
         1502384.1250, 1500946.2500, 1500229.2500, 1498962.1250, 1498276.1250],
        [1504108.6250, 1502279.5000, 1499878.7500, 1497407.7500, 1497220.6250,
         1495993.1250, 1492126.1250, 1491872.8750, 1490149.5000, 1490014.3750],
        [1483553.0000, 1474778.7500, 1471038.1250, 1465684.6250, 1460626.5000,
         1456582.6250, 1455974.3750, 1455174.8750, 1452379.7500, 1449399.3750],
        [1550150.1250, 1548631.2500, 1548309.3750, 1545979.5000, 1544793.1250,
         1544582.5000, 1544071.5000, 1543884.3750, 1543350.1250, 1541258.6250],
        [1555560.0000, 1555386.3750, 1553268.1250, 1552059.8750, 1550332.1250,
         1548228.1250, 1546525.2500, 1543869.7500, 1543389.7500, 1542252.5000],
        [1504289.5000, 1487646.1250, 1482376.2500, 1481382.8750, 1477185.8750,
         1466653.6250, 1465549.0000, 1458432.7500, 1453211.1250, 1451907.6250],
        [1570286.2500, 1562214.3750, 1553558.6250, 1549514.6250, 1546845.2500,
         1545118.7500, 1543849.1250, 1536528.3750, 1535258.5000, 1534412.5000],
        [1571421.7500, 1571215.0000, 1566209.2500, 1564693.8750, 1564313.3750,
         1564009.1250, 1563964.3750, 1562776.1250, 1562771.6250, 1562734.3750],
        [1496712.3750, 1496675.2500, 1496280.0000, 1494644.1250, 1482407.3750,
         1476557.7500, 1476263.5000, 1475914.2500, 1474849.1250, 1473130.0000],
        [1570494.5000, 1568150.6250, 1562716.5000, 1562141.3750, 1560376.8750,
         1560317.5000, 1559704.5000, 1559393.6250, 1559102.1250, 1556959.5000],
        [1559038.2500, 1556204.0000, 1556086.7500, 1552942.3750, 1551975.6250,
         1548618.0000, 1548411.2500, 1545689.2500, 1545080.5000, 1544018.5000],
        [1568470.7500, 1567386.7500, 1566648.3750, 1564316.3750, 1562017.6250,
         1560930.6250, 1560265.3750, 1559349.0000, 1559103.7500, 1558787.0000],
        [1575473.2500, 1575339.6250, 1572684.1250, 1572303.1250, 1570452.3750,
         1569808.5000, 1569649.8750, 1569459.7500, 1569407.3750, 1569141.0000],
        [1575570.8750, 1574228.2500, 1574177.2500, 1570355.1250, 1569605.0000,
         1568650.2500, 1567760.3750, 1567733.5000, 1567365.7500, 1566254.0000],
        [1574057.0000, 1573492.7500, 1571490.7500, 1570503.3750, 1570358.1250,
         1569898.3750, 1568970.3750, 1568807.3750, 1568361.6250, 1568183.5000],
        [1573896.3750, 1572118.8750, 1571727.5000, 1571066.6250, 1570785.0000,
         1569929.7500, 1569697.7500, 1567797.8750, 1566851.6250, 1566155.3750],
        [1379837.0000, 1328183.0000, 1229627.1250, 1210030.3750, 1156040.2500,
         1145029.6250, 1135954.2500, 1109602.8750, 1088598.8750, 1034588.1875],
        [1526859.8750, 1526615.2500, 1525552.7500, 1521574.5000, 1518791.0000,
         1518621.5000, 1518556.3750, 1516896.2500, 1516502.7500, 1513623.1250],
        [1550020.1250, 1548428.8750, 1546128.5000, 1544427.8750, 1544427.8750,
         1543479.6250, 1542401.0000, 1542193.6250, 1541102.7500, 1540409.2500],
        [1527135.1250, 1524941.8750, 1517521.2500, 1517414.2500, 1516158.6250,
         1513848.3750, 1513230.5000, 1511821.2500, 1511442.1250, 1507241.8750],
        [1366236.1250, 1313382.7500, 1278252.6250, 1224442.0000, 1200597.7500,
         1196926.8750, 1177524.3750, 1170711.8750, 1161503.8750, 1153775.8750],
        [1499225.2500, 1497337.6250, 1496121.6250, 1495084.6250, 1494805.2500,
         1488120.1250, 1485960.2500, 1485921.8750, 1485355.2500, 1483953.3750],
        [1467866.8750, 1443038.3750, 1428333.6250, 1425117.1250, 1406369.0000,
         1402035.5000, 1396256.5000, 1393801.8750, 1390986.8750, 1388527.0000],
        [1511638.1250, 1509031.1250, 1507165.7500, 1506779.1250, 1506203.0000,
         1505430.3750, 1503953.8750, 1501836.8750, 1501836.8750, 1499957.5000],
        [1293952.0000, 1291249.8750, 1287115.2500, 1277923.6250, 1277525.1250,
         1268918.7500, 1264346.6250, 1230758.1250, 1206413.5000, 1197701.0000],
        [1560750.5000, 1557911.6250, 1557016.0000, 1553262.2500, 1552028.8750,
         1551978.5000, 1551749.1250, 1551083.3750, 1550855.6250, 1550357.1250],
        [1553945.3750, 1551926.7500, 1546358.6250, 1545734.8750, 1544824.1250,
         1544081.7500, 1543750.5000, 1542861.5000, 1542804.1250, 1542533.3750],
        [1530082.7500, 1529526.8750, 1527113.2500, 1525069.7500, 1523460.6250,
         1521947.5000, 1521883.6250, 1520705.5000, 1520361.8750, 1520295.2500],
        [1411392.8750, 1402858.1250, 1381459.2500, 1376816.3750, 1376276.8750,
         1366026.3750, 1343921.1250, 1341350.1250, 1338185.1250, 1330169.2500],
        [1336717.1250, 1255173.8750, 1252904.0000, 1250685.8750, 1248070.6250,
         1244401.6250, 1232803.3750, 1217865.7500, 1209954.1250, 1206940.5000],
        [1362115.8750, 1346103.0000, 1140382.8750, 1088074.7500,  976169.3750,
          960172.3125,  938209.0000,  935417.1250,  934582.5000,  913580.9375],
        [1144372.5000, 1127405.5000, 1089323.7500, 1079890.5000, 1053954.7500,
          997010.1250,  986635.8750,  909381.5000,  890729.1875,  858643.2500],
        [1433266.3750, 1395207.7500, 1382028.5000, 1375776.8750, 1373002.0000,
         1368420.2500, 1360193.5000, 1357033.3750, 1357003.5000, 1351857.5000],
        [1470366.3750, 1469260.3750, 1462548.5000, 1457570.6250, 1454418.7500,
         1453403.7500, 1452141.6250, 1451023.1250, 1447885.2500, 1446594.7500],
        [1460414.6250, 1446770.0000, 1446539.5000, 1446178.1250, 1445020.1250,
         1433733.8750, 1427704.5000, 1427241.5000, 1416190.0000, 1410553.1250],
        [1408946.5000, 1389843.7500, 1375153.7500, 1371311.3750, 1356355.3750,
         1308195.0000, 1305631.2500, 1284355.1250, 1273983.5000, 1258758.1250],
        [1478974.7500, 1470766.0000, 1461040.1250, 1438656.3750, 1436928.7500,
         1428569.2500, 1422240.0000, 1418266.1250, 1415461.0000, 1362134.0000],
        [1414712.0000, 1411348.3750, 1400582.8750, 1364724.2500, 1330407.7500,
         1321394.6250, 1317261.3750, 1316078.6250, 1311549.1250, 1311401.5000],
        [1489755.8750, 1478063.7500, 1477619.7500, 1475624.3750, 1474759.1250,
         1470443.5000, 1468470.3750, 1466063.5000, 1457027.3750, 1457027.3750],
        [1498644.8750, 1496251.3750, 1486949.7500, 1486440.6250, 1470289.2500,
         1465202.5000, 1460609.7500, 1460551.1250, 1455531.5000, 1453607.5000],
        [1484808.5000, 1414533.8750, 1401907.2500, 1387096.2500, 1380648.0000,
         1375301.8750, 1357854.0000, 1352845.5000, 1349632.7500, 1348021.0000],
        [1455370.5000, 1434294.6250, 1423413.7500, 1385118.6250, 1355772.1250,
         1339435.1250, 1336856.0000, 1336681.3750, 1332217.0000, 1309966.5000],
        [1445794.8750, 1441077.2500, 1439976.8750, 1420033.5000, 1398931.6250,
         1397674.1250, 1376552.5000, 1362290.0000, 1356792.6250, 1347365.5000],
        [1522525.2500, 1487612.1250, 1472081.0000, 1449821.0000, 1437402.8750,
         1424071.0000, 1416573.7500, 1391325.1250, 1381949.5000, 1367816.1250],
        [1398139.3750, 1361203.0000, 1347893.7500, 1345367.6250, 1340319.3750,
         1335763.8750, 1327101.6250, 1324013.2500, 1318377.3750, 1317309.0000],
        [1442358.7500, 1415809.2500, 1344025.0000, 1329371.6250, 1313226.2500,
         1310426.3750, 1285628.3750, 1280809.1250, 1279640.7500, 1277617.7500],
        [1446463.6250, 1421023.8750, 1408954.6250, 1388418.3750, 1388001.3750,
         1371701.1250, 1300236.0000, 1284720.1250, 1272049.5000, 1270094.2500],
        [1459765.8750, 1455004.2500, 1441660.1250, 1434810.3750, 1419841.2500,
         1417951.0000, 1417909.0000, 1410464.5000, 1406387.8750, 1396766.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1527598.2500,       0.0000],
         [1525587.6250,       0.0000],
         [1511890.5000,       0.0000],
         ...,
         [1493780.6250,       0.0000],
         [1485664.1250,       0.0000],
         [      0.0000, 1485297.1250]],

        [[1541876.0000,       0.0000],
         [1536790.7500,       0.0000],
         [1532809.5000,       0.0000],
         ...,
         [1529510.8750,       0.0000],
         [1528149.0000,       0.0000],
         [1527840.1250,       0.0000]],

        [[1222574.0000,       0.0000],
         [1060293.0000,       0.0000],
         [1049079.1250,       0.0000],
         ...,
         [      0.0000,  997375.3125],
         [ 972589.9375,       0.0000],
         [      0.0000,  969664.2500]],

        ...,

        [[1442358.7500,       0.0000],
         [1415809.2500,       0.0000],
         [1344025.0000,       0.0000],
         ...,
         [1280809.1250,       0.0000],
         [      0.0000, 1279640.7500],
         [      0.0000, 1277617.7500]],

        [[1446463.6250,       0.0000],
         [1421023.8750,       0.0000],
         [1408954.6250,       0.0000],
         ...,
         [      0.0000, 1284720.1250],
         [      0.0000, 1272049.5000],
         [1270094.2500,       0.0000]],

        [[      0.0000, 1459765.8750],
         [      0.0000, 1455004.2500],
         [      0.0000, 1441660.1250],
         ...,
         [1410464.5000,       0.0000],
         [      0.0000, 1406387.8750],
         [1396766.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13537480.0000,  1485297.1250],
        [15322793.0000,        0.0000],
        [ 6338026.0000,  4045164.5000],
        [14191528.0000,        0.0000],
        [10588231.0000,  2642251.5000],
        [ 9384424.0000,  2263608.5000],
        [ 4085598.0000,  6221308.0000],
        [ 9689048.0000,  1002480.8750],
        [13842248.0000,  1532811.0000],
        [11779682.0000,  1342727.1250],
        [15491718.0000,        0.0000],
        [14246450.0000,        0.0000],
        [13848461.0000,        0.0000],
        [15558786.0000,        0.0000],
        [15609718.0000,        0.0000],
        [15549553.0000,        0.0000],
        [15084940.0000,        0.0000],
        [11966900.0000,  2994152.5000],
        [14625192.0000,        0.0000],
        [15455011.0000,        0.0000],
        [15490872.0000,        0.0000],
        [11759606.0000,  2969029.0000],
        [15477587.0000,        0.0000],
        [15654108.0000,        0.0000],
        [10377228.0000,  4466205.5000],
        [15619357.0000,        0.0000],
        [15508064.0000,        0.0000],
        [15627276.0000,        0.0000],
        [15713719.0000,        0.0000],
        [15701700.0000,        0.0000],
        [15704123.0000,        0.0000],
        [15700026.0000,        0.0000],
        [ 3326582.7500,  8490909.0000],
        [10638656.0000,  4564937.0000],
        [13902610.0000,  1540409.2500],
        [13643341.0000,  1517414.2500],
        [ 4702610.0000,  7540744.0000],
        [11916538.0000,  2995347.0000],
        [12713999.0000,  1428333.6250],
        [15053832.0000,        0.0000],
        [10040455.0000,  2555448.7500],
        [15536992.0000,        0.0000],
        [15458822.0000,        0.0000],
        [12193494.0000,  3046953.5000],
        [ 1341350.1250, 12327106.0000],
        [       0.0000, 12455518.0000],
        [ 5658131.0000,  4936677.0000],
        [  858643.2500,  9278704.0000],
        [ 8192120.0000,  5561669.5000],
        [10182381.0000,  4382832.0000],
        [11472226.0000,  2888119.0000],
        [ 2532741.5000, 10799792.0000],
        [       0.0000, 14333036.0000],
        [ 2627627.7500, 10871832.0000],
        [11747036.0000,  2967819.5000],
        [10283282.0000,  4450797.0000],
        [ 2733156.0000, 11119493.0000],
        [ 2740890.7500, 10968235.0000],
        [       0.0000, 13986490.0000],
        [ 1391325.1250, 12959852.0000],
        [ 9363208.0000,  4052280.5000],
        [ 9411229.0000,  3867684.7500],
        [ 9694657.0000,  3857005.5000],
        [ 2807231.0000, 11453329.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 271/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:55, 59.83s/it]  7%|▋         | 2/29 [01:00<11:19, 25.18s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.90s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 3.0047225952148438
Epoch 272/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:11, 58.26s/it]  7%|▋         | 2/29 [00:59<11:03, 24.57s/it] 10%|█         | 3/29 [01:00<05:58, 13.77s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.70s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.90s/it] 21%|██        | 6/29 [01:02<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 3.0164575576782227
Epoch 273/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:53, 59.77s/it]  7%|▋         | 2/29 [01:01<11:32, 25.66s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 3.0058019161224365
Epoch 274/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.49s/it]  7%|▋         | 2/29 [01:00<11:16, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 3.0003252029418945
Epoch 275/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:30, 61.09s/it]  7%|▋         | 2/29 [01:02<11:33, 25.70s/it] 10%|█         | 3/29 [01:02<06:13, 14.38s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 3.0077009201049805
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0122, 0.0016,  ..., 0.0044, 0.0003, 0.0179],
        [0.0028, 0.0103, 0.0016,  ..., 0.0043, 0.0006, 0.0173],
        [0.0283, 0.0088, 0.0037,  ..., 0.0054, 0.0137, 0.0226],
        ...,
        [0.0062, 0.0078, 0.0218,  ..., 0.0049, 0.0012, 0.0223],
        [0.0055, 0.0105, 0.0179,  ..., 0.0043, 0.0036, 0.0197],
        [0.0080, 0.0067, 0.0042,  ..., 0.0021, 0.0031, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9971, 0.9970, 0.9962, 0.9960, 0.9958, 0.9957, 0.9957, 0.9954, 0.9952,
         0.9952],
        [0.9974, 0.9971, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9799, 0.9712, 0.9705, 0.9695, 0.9690, 0.9649, 0.9647, 0.9631, 0.9628,
         0.9625],
        [0.9940, 0.9935, 0.9932, 0.9928, 0.9927, 0.9926, 0.9925, 0.9921, 0.9921,
         0.9912],
        [0.9903, 0.9879, 0.9876, 0.9875, 0.9875, 0.9871, 0.9870, 0.9867, 0.9865,
         0.9862],
        [0.9870, 0.9855, 0.9818, 0.9809, 0.9798, 0.9777, 0.9768, 0.9767, 0.9766,
         0.9741],
        [0.9759, 0.9709, 0.9709, 0.9707, 0.9662, 0.9656, 0.9654, 0.9643, 0.9632,
         0.9628],
        [0.9833, 0.9823, 0.9736, 0.9735, 0.9711, 0.9677, 0.9669, 0.9663, 0.9649,
         0.9643],
        [0.9980, 0.9977, 0.9975, 0.9974, 0.9974, 0.9972, 0.9972, 0.9971, 0.9970,
         0.9969],
        [0.9944, 0.9891, 0.9882, 0.9880, 0.9879, 0.9877, 0.9870, 0.9852, 0.9838,
         0.9838],
        [0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9953, 0.9951, 0.9938, 0.9934, 0.9933, 0.9926, 0.9924, 0.9923, 0.9923,
         0.9921],
        [0.9951, 0.9937, 0.9929, 0.9918, 0.9912, 0.9909, 0.9906, 0.9898, 0.9888,
         0.9885],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9980, 0.9979, 0.9979, 0.9978, 0.9977,
         0.9977],
        [0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9958, 0.9957, 0.9956, 0.9956,
         0.9956],
        [0.9960, 0.9957, 0.9956, 0.9954, 0.9954, 0.9952, 0.9952, 0.9951, 0.9951,
         0.9950],
        [0.9948, 0.9945, 0.9943, 0.9942, 0.9940, 0.9939, 0.9936, 0.9934, 0.9933,
         0.9932],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9974],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9960, 0.9956, 0.9953, 0.9952, 0.9951, 0.9948, 0.9944, 0.9940, 0.9939,
         0.9937],
        [0.9987, 0.9983, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9973, 0.9972,
         0.9971],
        [0.9988, 0.9987, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9958, 0.9957, 0.9955, 0.9954, 0.9954, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9947],
        [0.9987, 0.9986, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976,
         0.9975],
        [0.9986, 0.9986, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9989, 0.9989, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9894, 0.9881, 0.9811, 0.9799, 0.9766, 0.9755, 0.9749, 0.9738, 0.9725,
         0.9686],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9968, 0.9968, 0.9965, 0.9965, 0.9965, 0.9963, 0.9963, 0.9962, 0.9962,
         0.9961],
        [0.9885, 0.9864, 0.9845, 0.9806, 0.9792, 0.9790, 0.9774, 0.9774, 0.9764,
         0.9763],
        [0.9958, 0.9957, 0.9956, 0.9955, 0.9953, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9951],
        [0.9948, 0.9934, 0.9933, 0.9922, 0.9921, 0.9920, 0.9917, 0.9916, 0.9915,
         0.9915],
        [0.9960, 0.9958, 0.9958, 0.9958, 0.9958, 0.9956, 0.9956, 0.9954, 0.9954,
         0.9953],
        [0.9849, 0.9848, 0.9847, 0.9846, 0.9842, 0.9833, 0.9831, 0.9817, 0.9798,
         0.9783],
        [0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9980, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9969, 0.9968, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9913, 0.9906, 0.9894, 0.9894, 0.9894, 0.9888, 0.9876, 0.9875, 0.9869,
         0.9868],
        [0.9858, 0.9853, 0.9844, 0.9837, 0.9836, 0.9834, 0.9832, 0.9831, 0.9813,
         0.9812],
        [0.9888, 0.9883, 0.9769, 0.9731, 0.9656, 0.9647, 0.9633, 0.9633, 0.9619,
         0.9608],
        [0.9766, 0.9762, 0.9729, 0.9727, 0.9700, 0.9665, 0.9654, 0.9618, 0.9592,
         0.9564],
        [0.9937, 0.9903, 0.9902, 0.9899, 0.9899, 0.9896, 0.9895, 0.9894, 0.9888,
         0.9887],
        [0.9943, 0.9941, 0.9940, 0.9936, 0.9935, 0.9934, 0.9933, 0.9932, 0.9932,
         0.9930],
        [0.9934, 0.9928, 0.9927, 0.9926, 0.9923, 0.9922, 0.9921, 0.9916, 0.9912,
         0.9912],
        [0.9912, 0.9901, 0.9895, 0.9895, 0.9886, 0.9861, 0.9856, 0.9844, 0.9838,
         0.9837],
        [0.9942, 0.9939, 0.9936, 0.9925, 0.9922, 0.9921, 0.9921, 0.9915, 0.9912,
         0.9892],
        [0.9916, 0.9906, 0.9901, 0.9884, 0.9864, 0.9862, 0.9861, 0.9860, 0.9859,
         0.9855],
        [0.9949, 0.9945, 0.9942, 0.9941, 0.9941, 0.9941, 0.9936, 0.9935, 0.9934,
         0.9934],
        [0.9954, 0.9951, 0.9948, 0.9947, 0.9941, 0.9938, 0.9937, 0.9934, 0.9932,
         0.9931],
        [0.9947, 0.9912, 0.9908, 0.9897, 0.9895, 0.9893, 0.9886, 0.9883, 0.9880,
         0.9879],
        [0.9933, 0.9922, 0.9916, 0.9897, 0.9884, 0.9875, 0.9874, 0.9873, 0.9870,
         0.9865],
        [0.9927, 0.9925, 0.9923, 0.9918, 0.9908, 0.9902, 0.9894, 0.9882, 0.9880,
         0.9876],
        [0.9965, 0.9949, 0.9941, 0.9930, 0.9926, 0.9917, 0.9913, 0.9902, 0.9895,
         0.9894],
        [0.9905, 0.9883, 0.9874, 0.9873, 0.9871, 0.9870, 0.9865, 0.9864, 0.9862,
         0.9858],
        [0.9927, 0.9912, 0.9878, 0.9867, 0.9863, 0.9860, 0.9844, 0.9844, 0.9840,
         0.9839],
        [0.9928, 0.9916, 0.9911, 0.9900, 0.9900, 0.9890, 0.9855, 0.9842, 0.9840,
         0.9837],
        [0.9933, 0.9933, 0.9928, 0.9923, 0.9916, 0.9914, 0.9914, 0.9909, 0.9906,
         0.9904]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1535088.6250, 1532363.6250, 1516525.8750, 1510450.7500, 1506852.3750,
         1505594.1250, 1505004.0000, 1498692.1250, 1495154.5000, 1494371.8750],
        [1541539.2500, 1535050.6250, 1534898.2500, 1534608.5000, 1533738.0000,
         1530536.5000, 1530041.8750, 1528880.8750, 1528561.5000, 1528433.2500],
        [1200435.2500, 1060175.6250, 1050525.8750, 1034699.6875, 1027211.6250,
          969786.3125,  966407.1875,  944111.3750,  941037.0625,  936983.1875],
        [1468032.0000, 1459383.0000, 1451466.0000, 1444838.2500, 1441306.7500,
         1440584.0000, 1438046.0000, 1429149.7500, 1428557.0000, 1410496.7500],
        [1393994.7500, 1346859.2500, 1341347.5000, 1338557.8750, 1338113.7500,
         1330369.7500, 1329030.6250, 1323259.7500, 1319216.2500, 1314706.1250],
        [1328879.7500, 1300469.1250, 1234205.5000, 1218776.5000, 1199835.5000,
         1163193.2500, 1148935.7500, 1147595.3750, 1146183.3750, 1106002.3750],
        [1134874.7500, 1056704.3750, 1055499.7500, 1052377.0000,  987801.4375,
          979590.0000,  976556.6875,  961108.5000,  945876.8750,  940615.3750],
        [1261406.7500, 1243038.8750, 1098059.1250, 1096630.7500, 1059625.8750,
         1009297.6250,  996886.4375,  988483.7500,  969658.7500,  961475.2500],
        [1555199.5000, 1548200.0000, 1544810.8750, 1542808.5000, 1541049.8750,
         1538238.0000, 1536761.3750, 1536187.0000, 1533792.1250, 1531028.6250],
        [1476764.6250, 1370282.5000, 1351849.7500, 1347461.8750, 1346471.5000,
         1342422.3750, 1329407.1250, 1295371.8750, 1270348.6250, 1268825.5000],
        [1556020.0000, 1555932.5000, 1554876.2500, 1551752.1250, 1551616.0000,
         1549392.0000, 1549304.8750, 1548739.0000, 1548172.0000, 1547664.2500],
        [1495351.2500, 1491107.6250, 1465033.3750, 1457106.3750, 1453829.3750,
         1439541.6250, 1434694.1250, 1433940.3750, 1433707.8750, 1429771.3750],
        [1492521.7500, 1463255.8750, 1445018.7500, 1424232.5000, 1411575.8750,
         1404449.7500, 1399748.3750, 1382582.2500, 1363190.6250, 1357714.2500],
        [1564432.8750, 1559985.6250, 1559447.2500, 1559170.6250, 1554913.3750,
         1553929.0000, 1552618.1250, 1550079.2500, 1549383.1250, 1547540.1250],
        [1566639.5000, 1565011.8750, 1564783.5000, 1563397.7500, 1563229.2500,
         1562129.5000, 1561642.3750, 1560972.3750, 1560743.1250, 1560165.6250],
        [1560518.3750, 1560128.5000, 1559552.7500, 1557425.8750, 1557020.5000,
         1554774.0000, 1554392.8750, 1552892.0000, 1552884.6250, 1552573.6250],
        [1522272.6250, 1522253.7500, 1519777.6250, 1519412.5000, 1518846.0000,
         1506363.8750, 1504437.2500, 1503649.7500, 1503172.3750, 1502253.7500],
        [1511254.7500, 1505980.5000, 1502884.2500, 1499491.1250, 1497659.0000,
         1494057.0000, 1494005.6250, 1492823.6250, 1492299.7500, 1491032.2500],
        [1486463.3750, 1478632.0000, 1475831.2500, 1472016.3750, 1469844.7500,
         1467232.8750, 1460945.5000, 1456188.2500, 1454875.1250, 1451845.2500],
        [1552259.7500, 1551920.8750, 1550199.0000, 1549692.0000, 1547991.8750,
         1547501.7500, 1547491.6250, 1547122.6250, 1544252.6250, 1542761.5000],
        [1555827.0000, 1555064.6250, 1553250.5000, 1551275.6250, 1550060.0000,
         1547808.8750, 1547668.5000, 1545702.5000, 1543563.5000, 1543375.1250],
        [1511342.7500, 1502455.7500, 1496374.1250, 1494788.0000, 1491643.8750,
         1485685.3750, 1476560.5000, 1468973.1250, 1466841.1250, 1461785.7500],
        [1570012.1250, 1562677.7500, 1553982.2500, 1550904.3750, 1548027.2500,
         1545916.1250, 1545419.5000, 1540688.3750, 1538122.1250, 1535924.7500],
        [1572079.8750, 1571427.7500, 1566839.6250, 1565629.8750, 1565084.8750,
         1565070.0000, 1564938.6250, 1564676.0000, 1564377.5000, 1563970.3750],
        [1507092.5000, 1504682.6250, 1501726.5000, 1499355.3750, 1498527.6250,
         1490683.8750, 1490213.3750, 1489996.0000, 1487100.0000, 1483973.2500],
        [1570647.2500, 1568963.0000, 1563059.3750, 1561906.0000, 1560079.3750,
         1560022.7500, 1559457.6250, 1558919.3750, 1558671.0000, 1556883.8750],
        [1558871.7500, 1556845.2500, 1554194.3750, 1553386.7500, 1552359.0000,
         1550187.2500, 1550139.8750, 1545690.6250, 1545295.6250, 1544974.3750],
        [1569648.5000, 1568369.1250, 1565629.8750, 1564653.6250, 1562859.5000,
         1561468.1250, 1561022.8750, 1560677.6250, 1558993.7500, 1558940.1250],
        [1574927.8750, 1574779.3750, 1573437.2500, 1572094.7500, 1570470.5000,
         1570167.8750, 1569627.5000, 1569509.1250, 1568799.7500, 1568746.0000],
        [1576689.2500, 1575441.7500, 1574379.8750, 1571032.1250, 1570830.0000,
         1569075.1250, 1568527.6250, 1568484.2500, 1568056.3750, 1567944.3750],
        [1574713.2500, 1574549.5000, 1572423.2500, 1571624.1250, 1570588.7500,
         1570226.3750, 1569446.2500, 1569184.5000, 1568979.3750, 1568894.1250],
        [1574699.6250, 1571931.3750, 1571327.3750, 1571315.3750, 1569928.3750,
         1569853.5000, 1569129.1250, 1566926.3750, 1566318.2500, 1565979.2500],
        [1374667.2500, 1349398.6250, 1222443.3750, 1201178.3750, 1146360.3750,
         1128152.0000, 1117561.5000, 1101404.7500, 1080692.1250, 1022436.3125],
        [1531896.1250, 1529487.5000, 1526609.3750, 1524770.2500, 1522057.8750,
         1520183.5000, 1518408.6250, 1518381.1250, 1517518.3750, 1516076.2500],
        [1552101.3750, 1550783.0000, 1549281.2500, 1546724.2500, 1546724.2500,
         1543578.2500, 1542868.8750, 1542536.3750, 1542253.8750, 1542252.5000],
        [1529760.2500, 1527743.8750, 1522269.7500, 1521670.2500, 1521303.1250,
         1517470.6250, 1516954.0000, 1516714.0000, 1515219.0000, 1514025.8750],
        [1357267.6250, 1317872.0000, 1281975.0000, 1212910.6250, 1188101.6250,
         1185390.0000, 1159342.5000, 1158386.6250, 1141773.6250, 1140739.6250],
        [1507158.6250, 1505691.7500, 1502442.8750, 1500069.0000, 1496790.8750,
         1495555.2500, 1493917.3750, 1493027.1250, 1492047.8750, 1491447.5000],
        [1485794.3750, 1457063.5000, 1453615.7500, 1432162.3750, 1429340.6250,
         1428183.7500, 1421797.8750, 1418724.7500, 1418256.6250, 1416384.5000],
        [1511191.3750, 1507446.0000, 1507372.7500, 1507168.6250, 1506447.2500,
         1503820.3750, 1503688.5000, 1499086.5000, 1499086.5000, 1497429.1250],
        [1289666.0000, 1287643.1250, 1287010.8750, 1284847.6250, 1277374.1250,
         1261451.2500, 1256596.7500, 1232456.5000, 1199786.2500, 1174333.7500],
        [1559624.1250, 1557693.2500, 1556585.5000, 1553139.2500, 1552745.3750,
         1552338.1250, 1551349.6250, 1550812.6250, 1550626.3750, 1550407.5000],
        [1555278.2500, 1552708.3750, 1547774.8750, 1547349.8750, 1546781.8750,
         1545478.3750, 1545067.2500, 1545059.7500, 1544698.8750, 1544398.3750],
        [1530908.8750, 1529274.5000, 1526228.0000, 1524720.7500, 1523642.2500,
         1521017.5000, 1520968.0000, 1520614.2500, 1520543.1250, 1519487.7500],
        [1412619.6250, 1399856.5000, 1376045.8750, 1375744.0000, 1375096.0000,
         1363275.1250, 1340297.6250, 1338951.1250, 1327049.7500, 1326079.3750],
        [1306377.2500, 1297458.8750, 1280524.6250, 1267412.8750, 1266079.1250,
         1262618.6250, 1259544.6250, 1257619.3750, 1225604.5000, 1222867.7500],
        [1363063.1250, 1353770.7500, 1150888.8750, 1089846.5000,  978971.8125,
          966420.1250,  948009.0000,  946852.5000,  928936.3750,  914422.9375],
        [1145313.6250, 1139570.7500, 1086421.0000, 1082827.6250, 1042319.7500,
          992343.0000,  975577.3750,  926779.0625,  893793.3750,  858637.5625],
        [1461574.0000, 1392805.3750, 1390429.8750, 1385845.3750, 1385114.7500,
         1380062.1250, 1378102.5000, 1376181.0000, 1363816.1250, 1361081.0000],
        [1474814.0000, 1470221.8750, 1468756.0000, 1461335.6250, 1459288.3750,
         1455699.5000, 1454621.2500, 1453147.3750, 1451708.2500, 1447570.5000],
        [1456664.6250, 1444485.5000, 1442654.5000, 1440655.5000, 1434188.0000,
         1431764.8750, 1428531.1250, 1419251.0000, 1410600.2500, 1410391.7500],
        [1410602.8750, 1389524.5000, 1376916.2500, 1376799.2500, 1360458.0000,
         1312540.1250, 1302642.6250, 1280905.7500, 1269481.5000, 1267707.8750],
        [1473443.3750, 1466685.7500, 1461012.3750, 1437237.1250, 1431430.5000,
         1430008.6250, 1428892.2500, 1417975.3750, 1410452.3750, 1372481.0000],
        [1419921.1250, 1400043.3750, 1390045.3750, 1356621.8750, 1318083.1250,
         1313296.3750, 1312652.7500, 1310435.0000, 1308579.3750, 1301052.2500],
        [1487275.7500, 1480202.2500, 1472784.5000, 1471473.1250, 1471188.2500,
         1470660.7500, 1460388.2500, 1457448.3750, 1455645.3750, 1455645.3750],
        [1499228.1250, 1492372.3750, 1486402.3750, 1483561.5000, 1471971.3750,
         1465171.7500, 1461843.0000, 1457078.7500, 1451899.2500, 1449826.5000],
        [1483632.3750, 1410623.2500, 1403026.6250, 1382244.6250, 1377255.0000,
         1372698.2500, 1359104.2500, 1354461.7500, 1349038.2500, 1347009.6250],
        [1453609.0000, 1430731.6250, 1420022.7500, 1380916.5000, 1356136.7500,
         1338601.2500, 1336183.0000, 1334052.8750, 1329739.2500, 1319485.5000],
        [1442500.3750, 1436864.2500, 1433046.2500, 1422685.0000, 1403780.1250,
         1391435.2500, 1374770.8750, 1352468.6250, 1347291.0000, 1339781.3750],
        [1522782.2500, 1487239.0000, 1470627.1250, 1449063.5000, 1440047.0000,
         1421022.6250, 1413962.0000, 1391221.6250, 1378336.3750, 1374957.0000],
        [1396989.1250, 1353805.6250, 1335772.7500, 1334737.5000, 1331790.1250,
         1328480.6250, 1320515.2500, 1317060.3750, 1313957.8750, 1306073.2500],
        [1442358.7500, 1412024.2500, 1343671.1250, 1323472.8750, 1315649.3750,
         1310478.7500, 1280872.6250, 1280491.6250, 1273785.3750, 1271779.0000],
        [1444251.3750, 1418927.6250, 1408393.1250, 1387482.6250, 1386666.5000,
         1368002.7500, 1300005.3750, 1277352.1250, 1272417.1250, 1268723.7500],
        [1454098.3750, 1453784.8750, 1443827.1250, 1432762.1250, 1420147.3750,
         1415408.3750, 1414564.8750, 1404373.3750, 1399087.7500, 1395997.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1535088.6250,       0.0000],
         [1532363.6250,       0.0000],
         [1516525.8750,       0.0000],
         ...,
         [1498692.1250,       0.0000],
         [1495154.5000,       0.0000],
         [1494371.8750,       0.0000]],

        [[1541539.2500,       0.0000],
         [1535050.6250,       0.0000],
         [1534898.2500,       0.0000],
         ...,
         [1528880.8750,       0.0000],
         [1528561.5000,       0.0000],
         [1528433.2500,       0.0000]],

        [[1200435.2500,       0.0000],
         [1060175.6250,       0.0000],
         [1050525.8750,       0.0000],
         ...,
         [      0.0000,  944111.3750],
         [      0.0000,  941037.0625],
         [ 936983.1875,       0.0000]],

        ...,

        [[1442358.7500,       0.0000],
         [1412024.2500,       0.0000],
         [1343671.1250,       0.0000],
         ...,
         [1280491.6250,       0.0000],
         [1273785.3750,       0.0000],
         [      0.0000, 1271779.0000]],

        [[1444251.3750,       0.0000],
         [1418927.6250,       0.0000],
         [1408393.1250,       0.0000],
         ...,
         [      0.0000, 1277352.1250],
         [1272417.1250,       0.0000],
         [      0.0000, 1268723.7500]],

        [[      0.0000, 1454098.3750],
         [      0.0000, 1453784.8750],
         [      0.0000, 1443827.1250],
         ...,
         [      0.0000, 1404373.3750],
         [      0.0000, 1399087.7500],
         [1395997.0000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15100098.0000,        0.0000],
        [15326288.0000,        0.0000],
        [ 6184313.5000,  3947059.7500],
        [14411860.0000,        0.0000],
        [10706972.0000,  2668483.5000],
        [10775300.0000,  1218776.5000],
        [ 4139284.5000,  5951720.0000],
        [ 9714904.0000,   969658.7500],
        [13871314.0000,  1536761.3750],
        [12028924.0000,  1370282.5000],
        [15513469.0000,        0.0000],
        [14534083.0000,        0.0000],
        [14144290.0000,        0.0000],
        [15551500.0000,        0.0000],
        [15628715.0000,        0.0000],
        [15562164.0000,        0.0000],
        [15122439.0000,        0.0000],
        [11976177.0000,  3005311.7500],
        [14673874.0000,        0.0000],
        [15481192.0000,        0.0000],
        [15493596.0000,        0.0000],
        [11868433.0000,  2988018.0000],
        [15491675.0000,        0.0000],
        [15664094.0000,        0.0000],
        [11944532.0000,  3008819.0000],
        [15618610.0000,        0.0000],
        [15511946.0000,        0.0000],
        [15632264.0000,        0.0000],
        [15712560.0000,        0.0000],
        [15710460.0000,        0.0000],
        [15710630.0000,        0.0000],
        [15697408.0000,        0.0000],
        [ 3296948.5000,  8447346.0000],
        [12171436.0000,  3053954.0000],
        [15459104.0000,        0.0000],
        [13681828.0000,  1521303.1250],
        [ 3503119.0000,  8640640.0000],
        [11968546.0000,  3009601.5000],
        [11511342.0000,  2849981.5000],
        [15042736.0000,        0.0000],
        [ 9986148.0000,  2565017.2500],
        [15535322.0000,        0.0000],
        [15474596.0000,        0.0000],
        [13716437.0000,  1520968.0000],
        [ 1338951.1250, 12296064.0000],
        [       0.0000, 12646107.0000],
        [ 5683612.5000,  4957569.5000],
        [       0.0000, 10143583.0000],
        [ 9649490.0000,  4225522.0000],
        [10205038.0000,  4392125.5000],
        [11428334.0000,  2890852.5000],
        [ 2537189.5000, 10810390.0000],
        [       0.0000, 14329618.0000],
        [ 2623087.7500, 10807643.0000],
        [11715234.0000,  2967478.0000],
        [10268553.0000,  4450802.5000],
        [ 2731802.5000, 11107292.0000],
        [ 2737053.2500, 10962426.0000],
        [       0.0000, 13944624.0000],
        [ 1391221.6250, 12958036.0000],
        [10613713.0000,  2725469.7500],
        [10672326.0000,  2582257.7500],
        [ 9686141.0000,  3846081.0000],
        [ 1395997.0000, 12838054.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 276/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:36, 61.32s/it]  7%|▋         | 2/29 [01:02<11:36, 25.80s/it] 10%|█         | 3/29 [01:03<06:15, 14.44s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.999584436416626
Epoch 277/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.12s/it]  7%|▋         | 2/29 [01:01<11:23, 25.30s/it] 10%|█         | 3/29 [01:02<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9929802417755127
Epoch 278/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:42, 59.36s/it]  7%|▋         | 2/29 [01:00<11:22, 25.30s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.9983763694763184
Epoch 279/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:05, 60.21s/it]  7%|▋         | 2/29 [01:01<11:23, 25.33s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.99189829826355
Epoch 280/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.61s/it]  7%|▋         | 2/29 [01:00<11:17, 25.09s/it] 10%|█         | 3/29 [01:01<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.986720085144043
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0129, 0.0018,  ..., 0.0045, 0.0004, 0.0170],
        [0.0030, 0.0103, 0.0018,  ..., 0.0042, 0.0006, 0.0168],
        [0.0297, 0.0082, 0.0038,  ..., 0.0053, 0.0146, 0.0226],
        ...,
        [0.0059, 0.0078, 0.0215,  ..., 0.0048, 0.0012, 0.0215],
        [0.0050, 0.0106, 0.0166,  ..., 0.0042, 0.0035, 0.0195],
        [0.0082, 0.0064, 0.0041,  ..., 0.0023, 0.0032, 0.0203]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9967, 0.9967, 0.9960, 0.9955, 0.9954, 0.9954, 0.9953, 0.9949, 0.9948,
         0.9947],
        [0.9973, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967,
         0.9967],
        [0.9804, 0.9708, 0.9701, 0.9698, 0.9685, 0.9656, 0.9651, 0.9644, 0.9633,
         0.9625],
        [0.9931, 0.9923, 0.9922, 0.9919, 0.9918, 0.9917, 0.9913, 0.9912, 0.9911,
         0.9900],
        [0.9897, 0.9873, 0.9867, 0.9867, 0.9864, 0.9864, 0.9861, 0.9860, 0.9858,
         0.9858],
        [0.9854, 0.9854, 0.9795, 0.9793, 0.9788, 0.9772, 0.9745, 0.9734, 0.9734,
         0.9729],
        [0.9755, 0.9737, 0.9706, 0.9701, 0.9670, 0.9668, 0.9665, 0.9662, 0.9656,
         0.9647],
        [0.9818, 0.9809, 0.9736, 0.9704, 0.9671, 0.9668, 0.9659, 0.9654, 0.9645,
         0.9609],
        [0.9979, 0.9975, 0.9973, 0.9972, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9939, 0.9883, 0.9875, 0.9868, 0.9863, 0.9863, 0.9851, 0.9833, 0.9823,
         0.9823],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9948, 0.9947, 0.9934, 0.9923, 0.9922, 0.9920, 0.9918, 0.9913, 0.9909,
         0.9909],
        [0.9946, 0.9930, 0.9915, 0.9907, 0.9903, 0.9892, 0.9891, 0.9882, 0.9881,
         0.9878],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9979, 0.9979, 0.9979, 0.9976, 0.9976,
         0.9975],
        [0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9964, 0.9962, 0.9962, 0.9961, 0.9961, 0.9953, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9956, 0.9954, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949,
         0.9948],
        [0.9947, 0.9943, 0.9940, 0.9940, 0.9937, 0.9936, 0.9932, 0.9931, 0.9930,
         0.9929],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9958, 0.9949, 0.9948, 0.9948, 0.9948, 0.9944, 0.9942, 0.9936, 0.9934,
         0.9934],
        [0.9986, 0.9984, 0.9980, 0.9978, 0.9977, 0.9977, 0.9976, 0.9973, 0.9973,
         0.9972],
        [0.9988, 0.9987, 0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9955, 0.9954, 0.9953, 0.9950, 0.9948, 0.9947, 0.9945, 0.9943, 0.9943,
         0.9943],
        [0.9987, 0.9986, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9982, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9989, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9890, 0.9880, 0.9806, 0.9796, 0.9762, 0.9756, 0.9751, 0.9744, 0.9729,
         0.9691],
        [0.9968, 0.9967, 0.9965, 0.9965, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9960],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9967, 0.9966, 0.9964, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9959],
        [0.9884, 0.9865, 0.9845, 0.9792, 0.9790, 0.9780, 0.9765, 0.9765, 0.9763,
         0.9750],
        [0.9954, 0.9954, 0.9954, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9938, 0.9930, 0.9928, 0.9920, 0.9918, 0.9917, 0.9914, 0.9908, 0.9907,
         0.9907],
        [0.9958, 0.9957, 0.9956, 0.9955, 0.9955, 0.9955, 0.9954, 0.9953, 0.9952,
         0.9952],
        [0.9852, 0.9851, 0.9851, 0.9848, 0.9843, 0.9840, 0.9838, 0.9827, 0.9798,
         0.9795],
        [0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9979, 0.9979, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9914, 0.9907, 0.9898, 0.9893, 0.9892, 0.9890, 0.9878, 0.9877, 0.9874,
         0.9868],
        [0.9864, 0.9843, 0.9841, 0.9828, 0.9828, 0.9827, 0.9819, 0.9819, 0.9811,
         0.9810],
        [0.9891, 0.9889, 0.9768, 0.9724, 0.9645, 0.9637, 0.9631, 0.9627, 0.9611,
         0.9610],
        [0.9764, 0.9759, 0.9734, 0.9730, 0.9711, 0.9668, 0.9661, 0.9620, 0.9590,
         0.9567],
        [0.9931, 0.9899, 0.9899, 0.9895, 0.9892, 0.9891, 0.9885, 0.9885, 0.9880,
         0.9880],
        [0.9940, 0.9939, 0.9938, 0.9934, 0.9931, 0.9931, 0.9931, 0.9930, 0.9928,
         0.9928],
        [0.9936, 0.9923, 0.9922, 0.9921, 0.9920, 0.9918, 0.9917, 0.9913, 0.9909,
         0.9904],
        [0.9913, 0.9901, 0.9897, 0.9896, 0.9892, 0.9868, 0.9855, 0.9838, 0.9838,
         0.9833],
        [0.9942, 0.9938, 0.9936, 0.9925, 0.9924, 0.9921, 0.9919, 0.9916, 0.9911,
         0.9897],
        [0.9917, 0.9906, 0.9897, 0.9881, 0.9864, 0.9863, 0.9861, 0.9859, 0.9857,
         0.9856],
        [0.9947, 0.9946, 0.9941, 0.9941, 0.9940, 0.9938, 0.9937, 0.9935, 0.9933,
         0.9933],
        [0.9955, 0.9951, 0.9946, 0.9945, 0.9940, 0.9937, 0.9937, 0.9933, 0.9932,
         0.9930],
        [0.9946, 0.9912, 0.9909, 0.9900, 0.9896, 0.9896, 0.9889, 0.9884, 0.9880,
         0.9879],
        [0.9932, 0.9920, 0.9916, 0.9897, 0.9883, 0.9875, 0.9873, 0.9871, 0.9870,
         0.9867],
        [0.9929, 0.9923, 0.9922, 0.9915, 0.9910, 0.9902, 0.9898, 0.9882, 0.9879,
         0.9876],
        [0.9965, 0.9950, 0.9941, 0.9929, 0.9925, 0.9914, 0.9913, 0.9901, 0.9896,
         0.9893],
        [0.9903, 0.9881, 0.9874, 0.9873, 0.9873, 0.9867, 0.9866, 0.9863, 0.9860,
         0.9856],
        [0.9927, 0.9913, 0.9879, 0.9868, 0.9863, 0.9861, 0.9848, 0.9846, 0.9841,
         0.9841],
        [0.9927, 0.9916, 0.9907, 0.9900, 0.9897, 0.9887, 0.9858, 0.9844, 0.9841,
         0.9837],
        [0.9934, 0.9929, 0.9929, 0.9922, 0.9916, 0.9914, 0.9913, 0.9912, 0.9906,
         0.9904]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 1, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1527167.1250, 1525859.8750, 1510708.6250, 1501732.2500, 1498444.7500,
         1497856.1250, 1495866.2500, 1487226.1250, 1485744.8750, 1484682.5000],
        [1539920.0000, 1533580.0000, 1531108.8750, 1528644.6250, 1528252.5000,
         1528041.2500, 1527896.8750, 1527688.6250, 1527647.8750, 1526463.7500],
        [1209145.5000, 1053943.7500, 1043989.0625, 1039646.2500, 1020561.0625,
          978744.0625,  971693.4375,  961832.9375,  947944.8750,  936832.1250],
        [1450670.2500, 1433996.5000, 1431061.8750, 1425091.1250, 1423535.8750,
         1421716.6250, 1412530.7500, 1410900.2500, 1409124.0000, 1387167.7500],
        [1380880.8750, 1334153.3750, 1324137.0000, 1322872.3750, 1317932.3750,
         1317471.1250, 1312318.5000, 1310511.3750, 1306756.1250, 1305722.0000],
        [1299882.6250, 1298523.5000, 1194133.5000, 1190004.5000, 1182391.2500,
         1154978.0000, 1111376.8750, 1095139.3750, 1094224.8750, 1086446.8750],
        [1127713.1250, 1099496.8750, 1051793.0000, 1043346.1250,  999180.3750,
          995591.5000,  992372.3125,  987134.6875,  978870.0625,  966144.5625],
        [1233572.5000, 1218481.3750, 1097452.0000, 1048249.1250,  999733.1875,
          996087.2500,  983120.2500,  975915.2500,  963327.4375,  915819.3125],
        [1552886.1250, 1544860.8750, 1540379.8750, 1536751.1250, 1535576.2500,
         1534225.1250, 1531701.8750, 1531187.7500, 1528697.0000, 1528256.8750],
        [1466113.8750, 1353222.2500, 1338919.2500, 1325529.3750, 1316526.6250,
         1316147.6250, 1294081.5000, 1260135.7500, 1242977.2500, 1242458.1250],
        [1553930.3750, 1552357.3750, 1551502.0000, 1549034.3750, 1548073.1250,
         1547767.5000, 1546612.2500, 1545053.8750, 1544965.6250, 1544366.0000],
        [1484732.0000, 1483534.6250, 1457324.6250, 1434472.3750, 1431412.7500,
         1427229.3750, 1422737.8750, 1412814.8750, 1405543.1250, 1404926.6250],
        [1481282.5000, 1447747.1250, 1417796.8750, 1400609.6250, 1392264.8750,
         1371317.8750, 1370436.7500, 1352239.1250, 1349444.8750, 1344137.7500],
        [1563156.2500, 1560900.8750, 1559491.7500, 1559198.7500, 1553127.5000,
         1552782.5000, 1552686.2500, 1546743.5000, 1546386.5000, 1545210.1250],
        [1566263.0000, 1565202.8750, 1564779.0000, 1563178.6250, 1562163.6250,
         1561761.5000, 1561268.6250, 1560329.3750, 1560079.3750, 1559546.7500],
        [1561332.6250, 1560397.7500, 1560315.8750, 1559236.0000, 1557974.0000,
         1555241.0000, 1553914.2500, 1553809.0000, 1553755.6250, 1553529.0000],
        [1519566.0000, 1515522.5000, 1514982.0000, 1514428.7500, 1513888.7500,
         1497182.0000, 1496979.2500, 1496304.2500, 1496184.3750, 1495850.5000],
        [1502917.1250, 1498039.0000, 1494557.2500, 1492859.1250, 1490248.8750,
         1489000.1250, 1488297.3750, 1487232.0000, 1486873.1250, 1485981.5000],
        [1483403.1250, 1475244.5000, 1468740.7500, 1467876.6250, 1463315.8750,
         1461440.1250, 1451419.0000, 1449381.5000, 1448690.5000, 1446160.2500],
        [1550649.8750, 1549737.7500, 1548790.7500, 1546820.1250, 1546445.6250,
         1546250.8750, 1545453.2500, 1545419.5000, 1542958.6250, 1541637.7500],
        [1554791.7500, 1554498.2500, 1552373.7500, 1551772.7500, 1551727.0000,
         1547158.0000, 1546992.7500, 1546273.0000, 1541908.3750, 1541704.0000],
        [1506542.0000, 1488778.7500, 1486287.6250, 1485434.5000, 1485249.0000,
         1476411.2500, 1472036.0000, 1461246.5000, 1456848.1250, 1455695.2500],
        [1569305.7500, 1563822.7500, 1554825.8750, 1551879.2500, 1548761.1250,
         1547488.5000, 1546537.0000, 1539796.7500, 1539266.6250, 1536573.8750],
        [1572600.1250, 1570478.0000, 1567726.1250, 1564979.0000, 1564908.7500,
         1564635.7500, 1564619.2500, 1564229.8750, 1563964.3750, 1563478.2500],
        [1501746.6250, 1497673.2500, 1495926.1250, 1490747.8750, 1485617.2500,
         1482704.3750, 1479361.1250, 1475164.2500, 1475129.1250, 1474733.8750],
        [1571331.8750, 1568143.2500, 1563345.6250, 1562536.2500, 1560897.8750,
         1560845.7500, 1560662.6250, 1559643.5000, 1559643.5000, 1558235.6250],
        [1559622.7500, 1559500.6250, 1555081.0000, 1554338.0000, 1552532.1250,
         1551618.8750, 1550830.3750, 1548369.8750, 1546975.1250, 1545434.1250],
        [1569697.7500, 1568859.7500, 1565626.8750, 1564813.3750, 1564511.8750,
         1562429.0000, 1560762.5000, 1560231.1250, 1559819.0000, 1559793.7500],
        [1574777.7500, 1574289.7500, 1574286.7500, 1572358.6250, 1570997.6250,
         1569717.2500, 1569608.0000, 1569431.3750, 1569386.5000, 1568840.2500],
        [1576160.0000, 1575040.6250, 1574941.5000, 1571442.7500, 1571201.5000,
         1569133.5000, 1569121.6250, 1568808.8750, 1566899.3750, 1566857.6250],
        [1575048.1250, 1574869.3750, 1572025.8750, 1571763.5000, 1571212.0000,
         1570424.0000, 1569633.3750, 1569165.0000, 1568837.2500, 1568714.6250],
        [1574924.8750, 1572306.1250, 1571369.3750, 1570933.2500, 1570486.8750,
         1570311.6250, 1569413.5000, 1567187.8750, 1566343.7500, 1565826.8750],
        [1368098.0000, 1347952.8750, 1212449.2500, 1195552.1250, 1139537.1250,
         1129777.7500, 1120690.6250, 1110937.0000, 1086501.7500, 1029743.1875],
        [1527748.3750, 1527697.3750, 1523062.6250, 1522240.7500, 1518848.8750,
         1517836.7500, 1516726.8750, 1516051.6250, 1513841.1250, 1511037.1250],
        [1550716.5000, 1549551.6250, 1546299.5000, 1543863.8750, 1543863.8750,
         1542155.3750, 1541909.8750, 1540673.6250, 1540566.5000, 1540391.5000],
        [1527264.6250, 1524230.8750, 1519663.2500, 1517904.7500, 1516589.5000,
         1513955.1250, 1513753.0000, 1513693.8750, 1512672.1250, 1509475.8750],
        [1356438.1250, 1319061.5000, 1282081.3750, 1188683.0000, 1186186.1250,
         1168595.8750, 1144275.3750, 1143269.5000, 1141500.3750, 1119995.1250],
        [1499378.2500, 1498737.7500, 1498184.6250, 1491660.8750, 1490698.1250,
         1489667.7500, 1487956.7500, 1487210.5000, 1486629.1250, 1486607.8750],
        [1463958.0000, 1448683.5000, 1443017.7500, 1428196.0000, 1423869.8750,
         1421166.1250, 1415824.1250, 1404179.2500, 1401499.5000, 1401109.2500],
        [1506391.1250, 1505463.5000, 1503014.6250, 1501368.6250, 1500375.2500,
         1500127.6250, 1499352.5000, 1495495.3750, 1495171.6250, 1495171.6250],
        [1296224.6250, 1294237.0000, 1293123.0000, 1287287.1250, 1279384.5000,
         1272573.7500, 1268814.6250, 1249522.3750, 1199991.1250, 1194529.8750],
        [1557786.8750, 1556530.5000, 1555623.7500, 1553720.1250, 1552364.8750,
         1552185.7500, 1550837.7500, 1550689.8750, 1549798.3750, 1549698.0000],
        [1553940.8750, 1552242.0000, 1547301.2500, 1546514.8750, 1546043.0000,
         1544120.1250, 1544015.6250, 1543750.5000, 1543531.1250, 1543338.2500],
        [1530657.7500, 1528558.6250, 1526308.0000, 1525656.1250, 1523422.8750,
         1521602.1250, 1521385.8750, 1520953.6250, 1519889.2500, 1519298.0000],
        [1415940.2500, 1401504.8750, 1382500.3750, 1373375.2500, 1372392.0000,
         1366782.1250, 1343556.0000, 1342043.5000, 1337435.0000, 1324503.2500],
        [1317588.0000, 1279585.7500, 1275695.2500, 1251579.5000, 1251522.2500,
         1250160.0000, 1235805.0000, 1235510.3750, 1221546.0000, 1219694.0000],
        [1368610.8750, 1365600.3750, 1149312.7500, 1079502.3750,  963325.6250,
          952191.5000,  944052.8125,  939091.6250,  917519.6875,  916495.5625],
        [1143120.2500, 1134141.1250, 1094154.8750, 1087768.7500, 1058428.1250,
          996524.3125,  985623.0000,  929414.8750,  891488.0625,  861819.0000],
        [1449369.0000, 1386285.6250, 1384738.2500, 1377205.1250, 1371028.8750,
         1369522.1250, 1358506.8750, 1357521.2500, 1347553.1250, 1347325.6250],
        [1468127.2500, 1466302.6250, 1464576.6250, 1457220.5000, 1451095.0000,
         1450328.6250, 1450009.1250, 1447831.3750, 1444653.5000, 1443573.8750],
        [1459861.8750, 1434041.6250, 1430977.2500, 1429057.0000, 1426716.2500,
         1423170.7500, 1421974.2500, 1412656.0000, 1404681.5000, 1394812.6250],
        [1413399.7500, 1389930.0000, 1382155.0000, 1380185.7500, 1371176.7500,
         1324661.2500, 1300996.3750, 1270386.2500, 1269043.2500, 1260474.7500],
        [1473271.8750, 1465304.5000, 1460356.2500, 1438059.7500, 1434896.5000,
         1428735.5000, 1425363.1250, 1418726.0000, 1408819.0000, 1382041.7500],
        [1420790.7500, 1399139.7500, 1381948.1250, 1349414.0000, 1317419.6250,
         1315049.7500, 1312764.2500, 1308327.2500, 1304120.3750, 1302053.8750],
        [1483342.1250, 1480676.6250, 1470736.6250, 1470123.7500, 1469365.5000,
         1465697.2500, 1461994.8750, 1458416.1250, 1455244.2500, 1455244.2500],
        [1500607.1250, 1491534.2500, 1480724.6250, 1479970.7500, 1468067.0000,
         1463501.5000, 1463433.1250, 1455222.1250, 1452972.7500, 1448664.2500],
        [1481905.6250, 1412224.8750, 1404767.1250, 1386399.2500, 1378478.3750,
         1378414.0000, 1366600.8750, 1355823.7500, 1347442.6250, 1346721.8750],
        [1452832.7500, 1427889.6250, 1419356.7500, 1380815.1250, 1354677.3750,
         1339349.5000, 1334224.6250, 1330234.0000, 1329783.7500, 1323051.5000],
        [1445899.6250, 1434067.5000, 1431669.2500, 1417445.2500, 1408089.6250,
         1392186.6250, 1383352.3750, 1352328.1250, 1347219.0000, 1341180.0000],
        [1522833.1250, 1490240.3750, 1471108.2500, 1446843.0000, 1437327.5000,
         1415736.3750, 1413949.8750, 1389279.3750, 1379685.7500, 1373294.1250],
        [1394168.8750, 1350097.5000, 1336421.2500, 1335347.3750, 1335062.0000,
         1323596.7500, 1321756.2500, 1315319.3750, 1310676.3750, 1302364.2500],
        [1441048.5000, 1412670.7500, 1345332.8750, 1325101.0000, 1316522.8750,
         1313002.1250, 1287756.1250, 1283571.3750, 1275746.3750, 1274275.1250],
        [1442347.7500, 1418482.5000, 1402067.6250, 1386977.2500, 1381064.1250,
         1362400.3750, 1305840.3750, 1280978.8750, 1275363.1250, 1268722.6250],
        [1455337.1250, 1446924.5000, 1445619.7500, 1431386.7500, 1419565.1250,
         1414475.8750, 1413918.8750, 1411462.7500, 1398768.8750, 1395307.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1527167.1250,       0.0000],
         [1525859.8750,       0.0000],
         [1510708.6250,       0.0000],
         ...,
         [1487226.1250,       0.0000],
         [1485744.8750,       0.0000],
         [      0.0000, 1484682.5000]],

        [[1539920.0000,       0.0000],
         [1533580.0000,       0.0000],
         [1531108.8750,       0.0000],
         ...,
         [1527688.6250,       0.0000],
         [1527647.8750,       0.0000],
         [1526463.7500,       0.0000]],

        [[1209145.5000,       0.0000],
         [1053943.7500,       0.0000],
         [1043989.0625,       0.0000],
         ...,
         [ 961832.9375,       0.0000],
         [      0.0000,  947944.8750],
         [      0.0000,  936832.1250]],

        ...,

        [[1441048.5000,       0.0000],
         [1412670.7500,       0.0000],
         [1345332.8750,       0.0000],
         ...,
         [1283571.3750,       0.0000],
         [1275746.3750,       0.0000],
         [      0.0000, 1274275.1250]],

        [[1442347.7500,       0.0000],
         [1418482.5000,       0.0000],
         [1402067.6250,       0.0000],
         ...,
         [      0.0000, 1280978.8750],
         [1275363.1250,       0.0000],
         [      0.0000, 1268722.6250]],

        [[      0.0000, 1455337.1250],
         [      0.0000, 1446924.5000],
         [      0.0000, 1445619.7500],
         ...,
         [      0.0000, 1411462.7500],
         [      0.0000, 1398768.8750],
         [      0.0000, 1395307.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13530606.0000,  1484682.5000],
        [15299245.0000,        0.0000],
        [ 5240605.0000,  4923728.5000],
        [14205796.0000,        0.0000],
        [10598106.0000,  2634648.5000],
        [ 9421958.0000,  2285144.0000],
        [ 3178686.5000,  7062956.0000],
        [ 8552610.0000,  1879146.7500],
        [13832821.0000,  1531701.8750],
        [11802889.0000,  1353222.2500],
        [15483662.0000,        0.0000],
        [14364727.0000,        0.0000],
        [13927277.0000,        0.0000],
        [15539684.0000,        0.0000],
        [15624572.0000,        0.0000],
        [15569505.0000,        0.0000],
        [15060888.0000,        0.0000],
        [10440234.0000,  4475772.0000],
        [14615672.0000,        0.0000],
        [15464164.0000,        0.0000],
        [15489200.0000,        0.0000],
        [11800316.0000,  2974213.2500],
        [15498257.0000,        0.0000],
        [15661621.0000,        0.0000],
        [11859384.0000,  2999420.0000],
        [15625286.0000,        0.0000],
        [15524304.0000,        0.0000],
        [15636544.0000,        0.0000],
        [15713694.0000,        0.0000],
        [15709606.0000,        0.0000],
        [15711692.0000,        0.0000],
        [15699104.0000,        0.0000],
        [ 3299058.0000,  8442182.0000],
        [12149506.0000,  3045585.0000],
        [13899320.0000,  1540673.6250],
        [13652614.0000,  1516589.5000],
        [ 3456140.7500,  8593946.0000],
        [11919810.0000,  2996922.5000],
        [12823307.0000,  1428196.0000],
        [15001931.0000,        0.0000],
        [10060078.0000,  2575609.0000],
        [15529236.0000,        0.0000],
        [15464798.0000,        0.0000],
        [13714310.0000,  1523422.8750],
        [ 1342043.5000, 12317989.0000],
        [ 1219694.0000, 11318992.0000],
        [ 5632676.5000,  4963026.5000],
        [  861819.0000,  9320664.0000],
        [ 8196367.0000,  5552689.0000],
        [10161744.0000,  4381974.0000],
        [11349030.0000,  2888919.0000],
        [ 2539429.5000, 10822980.0000],
        [       0.0000, 14335576.0000],
        [ 2623377.0000, 10787651.0000],
        [11706822.0000,  2964018.7500],
        [10260687.0000,  4444011.0000],
        [ 2745079.2500, 11113699.0000],
        [ 2735492.5000, 10956722.0000],
        [       0.0000, 13953438.0000],
        [ 1389279.3750, 12951018.0000],
        [10595579.0000,  2729231.0000],
        [10687750.0000,  2587277.2500],
        [ 9668703.0000,  3855542.0000],
        [       0.0000, 14232768.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 281/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:31, 61.11s/it]  7%|▋         | 2/29 [01:02<11:34, 25.71s/it] 10%|█         | 3/29 [01:02<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.9973344802856445
Epoch 282/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.79s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9861886501312256
Epoch 283/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:40, 61.43s/it]  7%|▋         | 2/29 [01:02<11:37, 25.84s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.12s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.9894487857818604
Epoch 284/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:17, 60.64s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9921743869781494
Epoch 285/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:30, 61.08s/it]  7%|▋         | 2/29 [01:01<11:33, 25.69s/it] 10%|█         | 3/29 [01:02<06:13, 14.38s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.9753215312957764
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0131, 0.0019,  ..., 0.0044, 0.0002, 0.0164],
        [0.0031, 0.0105, 0.0020,  ..., 0.0042, 0.0006, 0.0170],
        [0.0284, 0.0084, 0.0038,  ..., 0.0055, 0.0144, 0.0226],
        ...,
        [0.0059, 0.0080, 0.0216,  ..., 0.0048, 0.0012, 0.0211],
        [0.0048, 0.0107, 0.0163,  ..., 0.0043, 0.0038, 0.0194],
        [0.0082, 0.0062, 0.0042,  ..., 0.0023, 0.0032, 0.0204]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9966, 0.9959, 0.9955, 0.9955, 0.9954, 0.9953, 0.9951, 0.9950,
         0.9948],
        [0.9972, 0.9971, 0.9969, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9809, 0.9718, 0.9714, 0.9704, 0.9697, 0.9664, 0.9647, 0.9643, 0.9637,
         0.9623],
        [0.9932, 0.9926, 0.9924, 0.9920, 0.9919, 0.9918, 0.9915, 0.9914, 0.9912,
         0.9903],
        [0.9897, 0.9871, 0.9868, 0.9867, 0.9865, 0.9864, 0.9863, 0.9862, 0.9859,
         0.9858],
        [0.9855, 0.9854, 0.9802, 0.9800, 0.9797, 0.9782, 0.9753, 0.9751, 0.9736,
         0.9733],
        [0.9761, 0.9742, 0.9725, 0.9708, 0.9686, 0.9684, 0.9664, 0.9663, 0.9658,
         0.9644],
        [0.9816, 0.9813, 0.9743, 0.9701, 0.9680, 0.9668, 0.9661, 0.9656, 0.9647,
         0.9615],
        [0.9979, 0.9975, 0.9973, 0.9972, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968,
         0.9967],
        [0.9940, 0.9885, 0.9875, 0.9873, 0.9873, 0.9866, 0.9859, 0.9837, 0.9832,
         0.9832],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9946, 0.9945, 0.9936, 0.9924, 0.9919, 0.9918, 0.9912, 0.9909, 0.9909,
         0.9908],
        [0.9948, 0.9933, 0.9917, 0.9911, 0.9902, 0.9891, 0.9890, 0.9889, 0.9881,
         0.9877],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9979, 0.9978, 0.9978, 0.9976, 0.9975,
         0.9975],
        [0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9963, 0.9962, 0.9962, 0.9960, 0.9959, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9952],
        [0.9956, 0.9954, 0.9953, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9947, 0.9943, 0.9940, 0.9939, 0.9938, 0.9936, 0.9931, 0.9931, 0.9930,
         0.9930],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9958, 0.9948, 0.9948, 0.9947, 0.9947, 0.9944, 0.9941, 0.9936, 0.9935,
         0.9935],
        [0.9986, 0.9984, 0.9980, 0.9979, 0.9977, 0.9977, 0.9976, 0.9973, 0.9973,
         0.9972],
        [0.9988, 0.9987, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9958, 0.9954, 0.9953, 0.9952, 0.9949, 0.9948, 0.9947, 0.9946, 0.9944,
         0.9944],
        [0.9987, 0.9986, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9982, 0.9982, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977,
         0.9976],
        [0.9987, 0.9987, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9985],
        [0.9889, 0.9884, 0.9793, 0.9793, 0.9756, 0.9749, 0.9746, 0.9743, 0.9725,
         0.9679],
        [0.9968, 0.9968, 0.9966, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9968, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961,
         0.9960],
        [0.9886, 0.9864, 0.9845, 0.9792, 0.9784, 0.9781, 0.9767, 0.9763, 0.9762,
         0.9749],
        [0.9955, 0.9955, 0.9954, 0.9950, 0.9950, 0.9950, 0.9950, 0.9949, 0.9949,
         0.9949],
        [0.9937, 0.9932, 0.9931, 0.9923, 0.9922, 0.9922, 0.9916, 0.9910, 0.9910,
         0.9910],
        [0.9958, 0.9957, 0.9955, 0.9955, 0.9954, 0.9953, 0.9952, 0.9952, 0.9951,
         0.9951],
        [0.9853, 0.9847, 0.9846, 0.9844, 0.9844, 0.9836, 0.9834, 0.9825, 0.9794,
         0.9793],
        [0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9979, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9914, 0.9908, 0.9898, 0.9893, 0.9891, 0.9888, 0.9877, 0.9874, 0.9872,
         0.9867],
        [0.9863, 0.9845, 0.9843, 0.9830, 0.9828, 0.9826, 0.9825, 0.9816, 0.9815,
         0.9810],
        [0.9892, 0.9889, 0.9777, 0.9735, 0.9646, 0.9645, 0.9639, 0.9638, 0.9629,
         0.9621],
        [0.9765, 0.9762, 0.9738, 0.9733, 0.9708, 0.9672, 0.9669, 0.9626, 0.9591,
         0.9568],
        [0.9932, 0.9899, 0.9897, 0.9894, 0.9894, 0.9894, 0.9888, 0.9885, 0.9880,
         0.9880],
        [0.9939, 0.9938, 0.9937, 0.9934, 0.9931, 0.9931, 0.9930, 0.9929, 0.9928,
         0.9928],
        [0.9935, 0.9922, 0.9920, 0.9919, 0.9918, 0.9917, 0.9914, 0.9910, 0.9910,
         0.9904],
        [0.9915, 0.9902, 0.9900, 0.9898, 0.9897, 0.9874, 0.9855, 0.9843, 0.9840,
         0.9837],
        [0.9942, 0.9938, 0.9935, 0.9925, 0.9924, 0.9920, 0.9918, 0.9914, 0.9911,
         0.9900],
        [0.9918, 0.9905, 0.9893, 0.9876, 0.9867, 0.9863, 0.9861, 0.9860, 0.9859,
         0.9856],
        [0.9946, 0.9946, 0.9941, 0.9940, 0.9939, 0.9938, 0.9937, 0.9935, 0.9933,
         0.9933],
        [0.9957, 0.9951, 0.9945, 0.9944, 0.9940, 0.9939, 0.9938, 0.9935, 0.9934,
         0.9930],
        [0.9947, 0.9913, 0.9910, 0.9899, 0.9897, 0.9895, 0.9892, 0.9884, 0.9879,
         0.9879],
        [0.9932, 0.9921, 0.9914, 0.9897, 0.9883, 0.9876, 0.9874, 0.9870, 0.9868,
         0.9865],
        [0.9930, 0.9921, 0.9921, 0.9913, 0.9912, 0.9903, 0.9899, 0.9884, 0.9883,
         0.9878],
        [0.9966, 0.9951, 0.9941, 0.9928, 0.9926, 0.9915, 0.9910, 0.9903, 0.9896,
         0.9893],
        [0.9902, 0.9881, 0.9876, 0.9872, 0.9870, 0.9867, 0.9865, 0.9863, 0.9862,
         0.9855],
        [0.9924, 0.9911, 0.9880, 0.9866, 0.9860, 0.9857, 0.9846, 0.9842, 0.9842,
         0.9841],
        [0.9927, 0.9916, 0.9903, 0.9899, 0.9893, 0.9885, 0.9856, 0.9844, 0.9841,
         0.9840],
        [0.9934, 0.9928, 0.9927, 0.9921, 0.9919, 0.9916, 0.9911, 0.9911, 0.9906,
         0.9905]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 1, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1525405.8750, 1524620.5000, 1509277.2500, 1501235.5000, 1499651.3750,
         1498240.3750, 1495742.1250, 1491367.8750, 1490237.5000, 1484988.3750],
        [1538600.2500, 1534295.3750, 1529906.1250, 1527644.8750, 1527499.1250,
         1526667.6250, 1525311.2500, 1525116.3750, 1525026.1250, 1524813.8750],
        [1218905.6250, 1069872.5000, 1063592.5000, 1048702.0000, 1037653.3750,
          990268.8750,  966917.9375,  961471.6250,  953104.5625,  934430.0625],
        [1451896.5000, 1440272.2500, 1435869.7500, 1427287.8750, 1425543.8750,
         1423966.3750, 1416616.8750, 1416055.0000, 1410261.3750, 1393324.8750],
        [1381313.0000, 1331140.0000, 1326180.6250, 1323490.6250, 1319547.1250,
         1317302.8750, 1315298.1250, 1313376.6250, 1308236.2500, 1307075.1250],
        [1300752.0000, 1298596.5000, 1206699.8750, 1202475.8750, 1197319.6250,
         1172354.2500, 1124898.8750, 1120946.1250, 1097589.1250, 1092901.2500],
        [1137685.7500, 1107673.2500, 1079655.7500, 1054158.8750, 1021954.8125,
         1018518.2500,  990310.4375,  988980.6250,  981350.7500,  962908.6250],
        [1230116.2500, 1225948.1250, 1107932.1250, 1043881.5625, 1013411.1875,
          996223.0625,  985996.2500,  978541.5000,  966250.5000,  922999.5000],
        [1552344.1250, 1543955.1250, 1539119.8750, 1537177.7500, 1534730.0000,
         1533738.0000, 1531327.8750, 1530751.1250, 1528179.6250, 1527234.1250],
        [1469621.8750, 1357411.2500, 1338649.7500, 1335681.1250, 1334458.7500,
         1321101.0000, 1308385.8750, 1268208.5000, 1259483.3750, 1258162.8750],
        [1553044.6250, 1551357.0000, 1548940.0000, 1548536.7500, 1547614.0000,
         1546883.5000, 1545575.6250, 1544142.1250, 1544070.0000, 1542508.3750],
        [1481511.3750, 1479230.0000, 1460845.1250, 1436346.5000, 1426185.6250,
         1424333.0000, 1411431.8750, 1406174.6250, 1405911.7500, 1404025.1250],
        [1484866.6250, 1454901.3750, 1421202.8750, 1408360.8750, 1391714.0000,
         1368895.3750, 1368019.7500, 1365962.5000, 1350751.7500, 1342485.1250],
        [1563877.8750, 1561046.7500, 1559041.2500, 1558922.3750, 1553013.3750,
         1550842.2500, 1550518.3750, 1545596.3750, 1544799.1250, 1543715.1250],
        [1567022.0000, 1566968.1250, 1566342.1250, 1564137.3750, 1563376.8750,
         1562533.2500, 1562363.3750, 1561959.6250, 1561520.2500, 1561213.5000],
        [1562643.5000, 1561892.6250, 1561582.7500, 1560768.3750, 1559634.6250,
         1557800.2500, 1557264.0000, 1556471.1250, 1555554.0000, 1554597.5000],
        [1518791.0000, 1515616.5000, 1515181.3750, 1510839.7500, 1509592.5000,
         1498081.8750, 1496335.6250, 1495746.3750, 1495103.1250, 1494447.3750],
        [1503860.6250, 1498100.3750, 1495589.5000, 1490820.3750, 1490159.3750,
         1488090.2500, 1487927.0000, 1487085.8750, 1486625.0000, 1485838.2500],
        [1484107.6250, 1474922.3750, 1468950.7500, 1466203.3750, 1464657.6250,
         1460070.7500, 1450559.5000, 1449203.1250, 1447642.2500, 1447617.3750],
        [1550493.2500, 1549164.5000, 1548325.5000, 1546377.7500, 1545776.1250,
         1545182.1250, 1545039.2500, 1544339.5000, 1543575.3750, 1541533.3750],
        [1554782.8750, 1554354.3750, 1553071.1250, 1552726.1250, 1551425.0000,
         1550845.2500, 1547321.7500, 1545587.3750, 1542359.8750, 1541626.0000],
        [1506645.5000, 1486663.1250, 1486409.5000, 1484406.3750, 1483516.2500,
         1476992.8750, 1470266.7500, 1460782.3750, 1458873.7500, 1457460.8750],
        [1568834.2500, 1565029.6250, 1555876.0000, 1552969.0000, 1548869.0000,
         1547631.7500, 1547205.1250, 1539228.5000, 1539093.3750, 1536840.6250],
        [1572070.7500, 1571511.6250, 1569599.0000, 1565541.7500, 1565416.2500,
         1565240.1250, 1564646.1250, 1564573.0000, 1564077.7500, 1563509.5000],
        [1506888.3750, 1497604.8750, 1495482.5000, 1494494.5000, 1487450.3750,
         1485509.6250, 1483268.6250, 1481139.7500, 1478245.6250, 1477619.7500],
        [1571134.1250, 1569198.0000, 1564856.5000, 1563381.3750, 1562046.0000,
         1562023.6250, 1561480.1250, 1561316.2500, 1560488.6250, 1559323.7500],
        [1560758.0000, 1559474.0000, 1556074.8750, 1553151.2500, 1553066.7500,
         1552695.0000, 1551220.8750, 1550397.1250, 1549430.5000, 1547041.3750],
        [1570217.2500, 1569946.2500, 1567439.0000, 1567187.8750, 1565643.2500,
         1564276.2500, 1562297.7500, 1562037.0000, 1561523.1250, 1561311.7500],
        [1574777.7500, 1574369.3750, 1573335.2500, 1572690.1250, 1570690.5000,
         1570254.7500, 1569834.1250, 1569742.7500, 1569600.5000, 1568928.5000],
        [1576364.5000, 1575557.3750, 1575145.7500, 1572661.6250, 1571742.5000,
         1570126.0000, 1569450.7500, 1569293.6250, 1567738.0000, 1567249.1250],
        [1576094.0000, 1575805.3750, 1573354.7500, 1572660.1250, 1572255.2500,
         1571024.6250, 1570714.5000, 1570045.1250, 1569679.8750, 1569616.8750],
        [1575683.6250, 1573627.7500, 1572865.6250, 1572022.8750, 1571409.7500,
         1571185.0000, 1570260.7500, 1568213.5000, 1567524.2500, 1567048.8750],
        [1366349.5000, 1356105.6250, 1190853.6250, 1189904.6250, 1129449.1250,
         1118479.3750, 1113645.2500, 1108708.0000, 1081014.6250, 1012337.0625],
        [1528326.8750, 1527757.0000, 1523517.2500, 1522277.0000, 1522195.6250,
         1519360.3750, 1518644.7500, 1518240.7500, 1515904.1250, 1514476.3750],
        [1550576.0000, 1549941.7500, 1545359.0000, 1545359.0000, 1545300.1250,
         1541859.7500, 1541731.8750, 1541508.5000, 1541490.7500, 1541217.3750],
        [1528533.8750, 1523341.5000, 1520070.5000, 1518944.5000, 1517783.2500,
         1517580.6250, 1515850.6250, 1513741.5000, 1513634.6250, 1511995.7500],
        [1360401.0000, 1318247.8750, 1282891.0000, 1188948.3750, 1175625.7500,
         1169939.5000, 1147500.2500, 1139974.0000, 1139413.2500, 1117583.8750],
        [1501579.0000, 1500269.3750, 1498842.0000, 1490666.8750, 1490338.5000,
         1490203.3750, 1489635.0000, 1488433.6250, 1487893.0000, 1487121.2500],
        [1461705.0000, 1451838.3750, 1450581.7500, 1433634.0000, 1432292.0000,
         1430965.0000, 1419825.1250, 1407343.1250, 1407317.6250, 1406375.7500],
        [1507391.3750, 1504080.1250, 1500710.1250, 1499800.1250, 1497783.2500,
         1496622.5000, 1494783.8750, 1494088.3750, 1492016.6250, 1491256.8750],
        [1297984.8750, 1285744.8750, 1284334.3750, 1280914.2500, 1280613.7500,
         1265713.3750, 1263226.8750, 1245549.8750, 1192486.7500, 1190216.6250],
        [1557381.3750, 1556978.8750, 1554564.8750, 1554095.0000, 1554087.6250,
         1553169.0000, 1550990.1250, 1550744.6250, 1550675.1250, 1550481.3750],
        [1553084.5000, 1552536.6250, 1546585.6250, 1546250.8750, 1545789.5000,
         1545275.0000, 1544363.0000, 1543560.5000, 1543386.8750, 1543303.0000],
        [1531198.0000, 1529715.1250, 1529127.2500, 1526085.2500, 1524904.1250,
         1523746.8750, 1522761.8750, 1521496.1250, 1519589.2500, 1519034.3750],
        [1414861.7500, 1403971.6250, 1382886.8750, 1373288.8750, 1370516.5000,
         1363234.7500, 1342376.3750, 1336018.6250, 1332970.5000, 1324187.6250],
        [1316756.5000, 1283365.7500, 1278552.6250, 1255255.3750, 1251155.8750,
         1248289.6250, 1245949.0000, 1230169.0000, 1228441.0000, 1220625.0000],
        [1371375.5000, 1365200.6250, 1163247.6250, 1095243.7500,  964983.4375,
          963560.7500,  955889.1250,  954672.8750,  942620.6250,  931414.0625],
        [1143714.6250, 1138886.3750, 1101200.0000, 1092773.1250, 1054202.1250,
         1001317.1250,  997564.6250,  938183.1250,  892563.3750,  862949.7500],
        [1452253.7500, 1385202.0000, 1381177.2500, 1376209.8750, 1375526.2500,
         1375477.7500, 1363719.8750, 1357139.3750, 1348037.7500, 1347491.5000],
        [1467100.0000, 1464128.2500, 1463080.1250, 1455367.7500, 1450379.7500,
         1449312.3750, 1448600.7500, 1446252.7500, 1444188.0000, 1442892.6250],
        [1457950.2500, 1430817.6250, 1427241.5000, 1426155.7500, 1423697.5000,
         1421090.3750, 1415088.3750, 1408137.8750, 1406719.2500, 1396203.3750],
        [1416596.6250, 1391926.3750, 1386675.6250, 1383922.5000, 1380499.1250,
         1335791.8750, 1301296.7500, 1278463.6250, 1273501.2500, 1267628.1250],
        [1473169.2500, 1464427.1250, 1458602.5000, 1437008.1250, 1435819.1250,
         1426904.0000, 1423754.5000, 1416163.0000, 1409668.2500, 1387756.5000],
        [1423773.5000, 1396521.5000, 1373253.5000, 1341324.5000, 1324061.2500,
         1315938.0000, 1312085.7500, 1309945.2500, 1307481.5000, 1301847.7500],
        [1482452.6250, 1480953.3750, 1471153.2500, 1467992.7500, 1467101.2500,
         1464173.0000, 1462522.1250, 1458802.7500, 1454877.8750, 1454877.8750],
        [1504088.6250, 1491663.6250, 1479165.1250, 1477796.0000, 1468372.2500,
         1465837.0000, 1465082.2500, 1458428.5000, 1456267.3750, 1448414.2500],
        [1483147.0000, 1412864.7500, 1406473.7500, 1386158.7500, 1381562.0000,
         1377942.1250, 1371876.3750, 1355430.8750, 1346375.1250, 1345802.6250],
        [1451571.1250, 1430306.0000, 1415307.1250, 1380986.3750, 1353659.7500,
         1339654.8750, 1335983.0000, 1329894.0000, 1324949.3750, 1319912.2500],
        [1448408.7500, 1429327.0000, 1428521.6250, 1413986.3750, 1412274.7500,
         1392351.2500, 1385377.7500, 1355470.8750, 1353529.3750, 1344021.1250],
        [1523918.3750, 1491295.3750, 1471004.5000, 1444307.7500, 1439599.2500,
         1417596.7500, 1407588.7500, 1393190.6250, 1380345.1250, 1373097.7500],
        [1391765.7500, 1350217.2500, 1341356.3750, 1332356.6250, 1329820.3750,
         1322859.6250, 1320506.3750, 1315083.6250, 1314169.7500, 1300259.6250],
        [1436123.1250, 1409453.1250, 1347408.0000, 1321747.5000, 1310565.1250,
         1305390.8750, 1284920.0000, 1277660.3750, 1276369.5000, 1275816.8750],
        [1440959.1250, 1418640.7500, 1393447.1250, 1384961.5000, 1374415.5000,
         1357529.0000, 1303455.2500, 1280525.7500, 1275281.7500, 1273047.1250],
        [1455856.3750, 1442991.6250, 1442510.0000, 1429755.1250, 1425339.8750,
         1420056.6250, 1410216.8750, 1409341.6250, 1398850.2500, 1397742.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1525405.8750,       0.0000],
         [1524620.5000,       0.0000],
         [1509277.2500,       0.0000],
         ...,
         [1491367.8750,       0.0000],
         [1490237.5000,       0.0000],
         [1484988.3750,       0.0000]],

        [[1538600.2500,       0.0000],
         [1534295.3750,       0.0000],
         [1529906.1250,       0.0000],
         ...,
         [1525116.3750,       0.0000],
         [1525026.1250,       0.0000],
         [1524813.8750,       0.0000]],

        [[1218905.6250,       0.0000],
         [1069872.5000,       0.0000],
         [1063592.5000,       0.0000],
         ...,
         [ 961471.6250,       0.0000],
         [      0.0000,  953104.5625],
         [      0.0000,  934430.0625]],

        ...,

        [[1436123.1250,       0.0000],
         [1409453.1250,       0.0000],
         [1347408.0000,       0.0000],
         ...,
         [      0.0000, 1277660.3750],
         [1276369.5000,       0.0000],
         [1275816.8750,       0.0000]],

        [[1440959.1250,       0.0000],
         [1418640.7500,       0.0000],
         [1393447.1250,       0.0000],
         ...,
         [1280525.7500,       0.0000],
         [      0.0000, 1275281.7500],
         [      0.0000, 1273047.1250]],

        [[      0.0000, 1455856.3750],
         [      0.0000, 1442991.6250],
         [      0.0000, 1442510.0000],
         ...,
         [      0.0000, 1409341.6250],
         [      0.0000, 1398850.2500],
         [      0.0000, 1397742.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15020768.0000,        0.0000],
        [15284881.0000,        0.0000],
        [ 5304111.0000,  4940808.0000],
        [14241095.0000,        0.0000],
        [10603403.0000,  2639557.2500],
        [ 9510244.0000,  2304289.0000],
        [ 3235859.7500,  7107337.5000],
        [ 9505050.0000,   966250.5000],
        [13827229.0000,  1531327.8750],
        [11893754.0000,  1357411.2500],
        [15472673.0000,        0.0000],
        [14335995.0000,        0.0000],
        [13957160.0000,        0.0000],
        [15531373.0000,        0.0000],
        [15637437.0000,        0.0000],
        [15588208.0000,        0.0000],
        [12058952.0000,  2990783.0000],
        [11923150.0000,  2990946.5000],
        [14613934.0000,        0.0000],
        [15459807.0000,        0.0000],
        [15494100.0000,        0.0000],
        [11801201.0000,  2970816.0000],
        [15501576.0000,        0.0000],
        [15666186.0000,        0.0000],
        [11883210.0000,  3004493.2500],
        [15635248.0000,        0.0000],
        [15533310.0000,        0.0000],
        [15651880.0000,        0.0000],
        [15714225.0000,        0.0000],
        [15715329.0000,        0.0000],
        [15721250.0000,        0.0000],
        [15709842.0000,        0.0000],
        [ 3260265.5000,  8406581.0000],
        [12164702.0000,  3045997.7500],
        [13902836.0000,  1541508.5000],
        [13663694.0000,  1517783.2500],
        [ 3457413.7500,  8583111.0000],
        [11925870.0000,  2999111.5000],
        [12870913.0000,  1430965.0000],
        [14978532.0000,        0.0000],
        [10007887.0000,  2578899.0000],
        [15533168.0000,        0.0000],
        [15464136.0000,        0.0000],
        [13722754.0000,  1524904.1250],
        [ 2666564.0000, 10977750.0000],
        [ 1230169.0000, 11328391.0000],
        [ 5713141.0000,  4995067.0000],
        [  862949.7500,  9360404.0000],
        [ 9548569.0000,  4213665.5000],
        [10153714.0000,  4377588.0000],
        [11327910.0000,  2885191.7500],
        [ 2551965.0000, 10864336.0000],
        [       0.0000, 14333272.0000],
        [ 2628023.7500, 10778209.0000],
        [11701502.0000,  2963406.0000],
        [10267394.0000,  4447721.5000],
        [ 2753438.5000, 11114194.0000],
        [ 2734646.0000, 10947578.0000],
        [       0.0000, 13963269.0000],
        [ 1393190.6250, 12948753.0000],
        [10594273.0000,  2724122.5000],
        [10662404.0000,  2583051.2500],
        [ 9650478.0000,  3851784.2500],
        [       0.0000, 14232660.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 286/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:15, 58.42s/it]  7%|▋         | 2/29 [01:00<11:24, 25.34s/it] 10%|█         | 3/29 [01:01<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.961639642715454
Epoch 287/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:28, 61.03s/it]  7%|▋         | 2/29 [01:01<11:33, 25.67s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.9822161197662354
Epoch 288/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:03, 60.12s/it]  7%|▋         | 2/29 [01:01<11:23, 25.30s/it] 10%|█         | 3/29 [01:01<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.9610350131988525
Epoch 289/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:14, 60.54s/it]  7%|▋         | 2/29 [01:01<11:27, 25.47s/it] 10%|█         | 3/29 [01:02<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9682998657226562
Epoch 290/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:12, 60.44s/it]  7%|▋         | 2/29 [01:01<11:26, 25.43s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.959111452102661
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0144, 0.0024,  ..., 0.0047, 0.0002, 0.0160],
        [0.0035, 0.0108, 0.0023,  ..., 0.0042, 0.0005, 0.0167],
        [0.0303, 0.0081, 0.0040,  ..., 0.0053, 0.0153, 0.0225],
        ...,
        [0.0058, 0.0078, 0.0214,  ..., 0.0048, 0.0012, 0.0204],
        [0.0053, 0.0110, 0.0168,  ..., 0.0047, 0.0039, 0.0189],
        [0.0088, 0.0061, 0.0046,  ..., 0.0023, 0.0033, 0.0205]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9963, 0.9956, 0.9951, 0.9949, 0.9949, 0.9947, 0.9945, 0.9943,
         0.9943],
        [0.9972, 0.9969, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9811, 0.9706, 0.9703, 0.9695, 0.9691, 0.9679, 0.9671, 0.9649, 0.9647,
         0.9640],
        [0.9924, 0.9922, 0.9920, 0.9914, 0.9913, 0.9912, 0.9906, 0.9903, 0.9902,
         0.9895],
        [0.9892, 0.9870, 0.9867, 0.9865, 0.9865, 0.9861, 0.9860, 0.9857, 0.9856,
         0.9855],
        [0.9856, 0.9852, 0.9800, 0.9790, 0.9783, 0.9766, 0.9754, 0.9743, 0.9742,
         0.9737],
        [0.9765, 0.9757, 0.9708, 0.9704, 0.9694, 0.9685, 0.9684, 0.9684, 0.9662,
         0.9658],
        [0.9812, 0.9789, 0.9749, 0.9684, 0.9672, 0.9659, 0.9652, 0.9646, 0.9641,
         0.9609],
        [0.9977, 0.9973, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965,
         0.9964],
        [0.9936, 0.9878, 0.9868, 0.9867, 0.9861, 0.9858, 0.9852, 0.9840, 0.9829,
         0.9827],
        [0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9972, 0.9972,
         0.9972],
        [0.9939, 0.9938, 0.9930, 0.9921, 0.9908, 0.9907, 0.9906, 0.9906, 0.9901,
         0.9900],
        [0.9943, 0.9927, 0.9909, 0.9905, 0.9899, 0.9884, 0.9881, 0.9877, 0.9876,
         0.9869],
        [0.9983, 0.9982, 0.9980, 0.9980, 0.9977, 0.9977, 0.9975, 0.9974, 0.9973,
         0.9972],
        [0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9961, 0.9959, 0.9959, 0.9958, 0.9958, 0.9952, 0.9952, 0.9950, 0.9949,
         0.9949],
        [0.9952, 0.9950, 0.9948, 0.9947, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944,
         0.9944],
        [0.9946, 0.9942, 0.9938, 0.9935, 0.9935, 0.9934, 0.9930, 0.9929, 0.9929,
         0.9928],
        [0.9975, 0.9975, 0.9974, 0.9973, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971,
         0.9971],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9974, 0.9973, 0.9971,
         0.9971],
        [0.9955, 0.9944, 0.9943, 0.9942, 0.9942, 0.9941, 0.9936, 0.9933, 0.9933,
         0.9931],
        [0.9986, 0.9984, 0.9980, 0.9979, 0.9977, 0.9977, 0.9976, 0.9973, 0.9972,
         0.9972],
        [0.9986, 0.9986, 0.9986, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9955, 0.9949, 0.9949, 0.9949, 0.9947, 0.9945, 0.9944, 0.9943, 0.9941,
         0.9940],
        [0.9987, 0.9986, 0.9985, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9976],
        [0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9982],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9892, 0.9886, 0.9799, 0.9795, 0.9757, 0.9750, 0.9748, 0.9747, 0.9719,
         0.9676],
        [0.9966, 0.9965, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9959,
         0.9959],
        [0.9977, 0.9977, 0.9975, 0.9975, 0.9974, 0.9973, 0.9973, 0.9973, 0.9973,
         0.9972],
        [0.9965, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9892, 0.9867, 0.9845, 0.9793, 0.9782, 0.9782, 0.9777, 0.9775, 0.9774,
         0.9749],
        [0.9952, 0.9952, 0.9951, 0.9948, 0.9947, 0.9947, 0.9947, 0.9945, 0.9945,
         0.9945],
        [0.9931, 0.9930, 0.9929, 0.9922, 0.9920, 0.9918, 0.9913, 0.9909, 0.9907,
         0.9906],
        [0.9957, 0.9954, 0.9953, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948, 0.9948,
         0.9947],
        [0.9857, 0.9857, 0.9851, 0.9847, 0.9845, 0.9841, 0.9839, 0.9834, 0.9807,
         0.9802],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9977, 0.9977, 0.9974, 0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9972,
         0.9972],
        [0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9962,
         0.9962],
        [0.9912, 0.9910, 0.9898, 0.9889, 0.9889, 0.9883, 0.9874, 0.9871, 0.9870,
         0.9866],
        [0.9861, 0.9842, 0.9830, 0.9825, 0.9823, 0.9822, 0.9819, 0.9817, 0.9815,
         0.9808],
        [0.9894, 0.9882, 0.9780, 0.9742, 0.9652, 0.9644, 0.9636, 0.9636, 0.9630,
         0.9619],
        [0.9756, 0.9755, 0.9739, 0.9726, 0.9722, 0.9676, 0.9674, 0.9614, 0.9594,
         0.9588],
        [0.9925, 0.9893, 0.9893, 0.9889, 0.9888, 0.9884, 0.9882, 0.9877, 0.9873,
         0.9873],
        [0.9934, 0.9933, 0.9933, 0.9929, 0.9928, 0.9926, 0.9926, 0.9922, 0.9920,
         0.9918],
        [0.9932, 0.9917, 0.9917, 0.9913, 0.9913, 0.9908, 0.9904, 0.9903, 0.9903,
         0.9902],
        [0.9914, 0.9902, 0.9901, 0.9900, 0.9900, 0.9876, 0.9851, 0.9847, 0.9841,
         0.9840],
        [0.9940, 0.9937, 0.9936, 0.9926, 0.9923, 0.9918, 0.9916, 0.9913, 0.9908,
         0.9902],
        [0.9917, 0.9904, 0.9890, 0.9875, 0.9865, 0.9862, 0.9860, 0.9857, 0.9856,
         0.9854],
        [0.9946, 0.9946, 0.9939, 0.9938, 0.9938, 0.9937, 0.9935, 0.9932, 0.9930,
         0.9928],
        [0.9956, 0.9947, 0.9941, 0.9941, 0.9936, 0.9935, 0.9933, 0.9932, 0.9928,
         0.9924],
        [0.9946, 0.9912, 0.9909, 0.9899, 0.9896, 0.9895, 0.9892, 0.9884, 0.9878,
         0.9877],
        [0.9930, 0.9921, 0.9913, 0.9894, 0.9882, 0.9873, 0.9869, 0.9868, 0.9867,
         0.9865],
        [0.9930, 0.9919, 0.9918, 0.9914, 0.9912, 0.9901, 0.9897, 0.9887, 0.9882,
         0.9879],
        [0.9966, 0.9950, 0.9939, 0.9926, 0.9923, 0.9916, 0.9907, 0.9903, 0.9893,
         0.9891],
        [0.9904, 0.9883, 0.9880, 0.9879, 0.9875, 0.9870, 0.9862, 0.9861, 0.9858,
         0.9855],
        [0.9927, 0.9916, 0.9880, 0.9869, 0.9863, 0.9859, 0.9850, 0.9846, 0.9843,
         0.9841],
        [0.9923, 0.9913, 0.9897, 0.9897, 0.9890, 0.9880, 0.9851, 0.9850, 0.9845,
         0.9833],
        [0.9932, 0.9927, 0.9923, 0.9923, 0.9919, 0.9915, 0.9912, 0.9910, 0.9908,
         0.9906]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 0, 1, 1, 0, 0, 1, 0, 0, 0],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1517165.3750, 1517007.5000, 1502374.0000, 1492220.0000, 1488854.0000,
         1487067.3750, 1482991.3750, 1478454.2500, 1475988.8750, 1475648.2500],
        [1537246.6250, 1531563.0000, 1525865.6250, 1524767.3750, 1524010.0000,
         1522804.0000, 1522502.1250, 1522496.1250, 1521798.0000, 1519783.5000],
        [1221773.2500, 1050942.7500, 1047349.6875, 1034456.9375, 1029907.2500,
         1012199.9375, 1000510.5000,  969345.2500,  966394.3125,  957352.5000],
        [1435349.5000, 1432203.2500, 1427297.3750, 1414439.5000, 1413265.0000,
         1412083.5000, 1398919.5000, 1392737.6250, 1391357.0000, 1377516.3750],
        [1370855.0000, 1328944.3750, 1324308.7500, 1319445.2500, 1318914.3750,
         1312103.3750, 1309841.6250, 1305100.8750, 1302006.7500, 1301590.8750],
        [1301929.7500, 1295291.6250, 1202075.6250, 1185704.2500, 1173536.6250,
         1145639.1250, 1126634.8750, 1108664.6250, 1107200.2500, 1099416.0000],
        [1144619.1250, 1130318.7500, 1054469.6250, 1048849.1250, 1033610.8125,
         1019827.4375, 1019387.9375, 1018728.0625,  987764.6250,  981355.4375],
        [1222716.2500, 1183284.6250, 1118516.7500, 1018365.7500, 1001434.5625,
          983566.6250,  972869.1875,  965062.5625,  957583.5000,  915717.9375],
        [1548423.0000, 1539212.3750, 1532539.0000, 1531596.6250, 1530865.0000,
         1528134.3750, 1527717.7500, 1523822.5000, 1522952.1250, 1520248.7500],
        [1460377.1250, 1345080.2500, 1325710.2500, 1323603.0000, 1312570.1250,
         1307141.1250, 1294680.2500, 1272632.0000, 1252614.8750, 1250604.7500],
        [1548798.1250, 1546665.2500, 1546596.0000, 1544133.3750, 1543983.1250,
         1543651.8750, 1540970.3750, 1538349.5000, 1538265.8750, 1538076.6250],
        [1467158.7500, 1463944.0000, 1447396.6250, 1429681.3750, 1403758.7500,
         1401364.5000, 1400114.1250, 1398966.2500, 1389499.2500, 1387437.5000],
        [1474310.6250, 1441701.3750, 1405528.3750, 1396463.0000, 1384855.8750,
         1356562.3750, 1349980.3750, 1341538.0000, 1340490.7500, 1327696.6250],
        [1561456.2500, 1559677.7500, 1556345.0000, 1555803.2500, 1547831.0000,
         1547805.8750, 1544192.1250, 1541858.3750, 1539643.8750, 1536516.7500],
        [1566173.3750, 1565968.8750, 1565358.0000, 1563171.1250, 1561862.7500,
         1561843.5000, 1560426.0000, 1560311.5000, 1560194.0000, 1559521.5000],
        [1563709.3750, 1561365.3750, 1559944.0000, 1558824.1250, 1557336.7500,
         1555978.3750, 1555634.2500, 1555396.8750, 1553937.8750, 1553740.7500],
        [1513328.7500, 1508701.6250, 1508344.7500, 1506849.5000, 1506756.1250,
         1494252.2500, 1494185.1250, 1490302.8750, 1488930.6250, 1488842.5000],
        [1494638.5000, 1490095.5000, 1486639.1250, 1483329.5000, 1482044.1250,
         1481967.8750, 1479973.6250, 1478335.7500, 1478042.6250, 1477343.6250],
        [1481374.3750, 1472572.3750, 1463666.2500, 1458278.3750, 1457527.6250,
         1456325.7500, 1448944.7500, 1446804.3750, 1446781.0000, 1444471.7500],
        [1544544.2500, 1543700.5000, 1541978.8750, 1538760.2500, 1538434.5000,
         1538387.6250, 1538287.8750, 1537553.1250, 1535456.1250, 1535325.8750],
        [1551876.3750, 1549256.1250, 1549030.1250, 1547764.6250, 1546604.8750,
         1546385.0000, 1542424.6250, 1539437.0000, 1535857.3750, 1535769.6250],
        [1500220.7500, 1477598.6250, 1474206.5000, 1474074.3750, 1472316.7500,
         1470198.1250, 1460006.7500, 1454461.7500, 1453500.7500, 1449474.0000],
        [1568378.0000, 1565193.8750, 1555971.0000, 1553423.7500, 1548700.6250,
         1547825.1250, 1545899.8750, 1539089.1250, 1537193.8750, 1536707.1250],
        [1568915.0000, 1568820.7500, 1568732.5000, 1562481.1250, 1562326.0000,
         1562156.2500, 1562104.1250, 1562040.0000, 1561925.3750, 1561335.6250],
        [1499854.5000, 1488324.5000, 1488086.0000, 1487342.5000, 1483267.2500,
         1478722.2500, 1476481.7500, 1474361.1250, 1470684.7500, 1469570.1250],
        [1570762.5000, 1568620.2500, 1565776.1250, 1562884.8750, 1561244.7500,
         1560994.6250, 1560527.2500, 1560302.5000, 1559621.1250, 1559323.7500],
        [1562680.7500, 1559360.8750, 1557066.5000, 1555241.0000, 1551442.8750,
         1550789.0000, 1550629.2500, 1550610.1250, 1550531.6250, 1547225.8750],
        [1569174.0000, 1569027.3750, 1567576.5000, 1567383.7500, 1564523.8750,
         1563789.8750, 1563323.2500, 1562361.7500, 1561973.0000, 1559957.3750],
        [1573815.3750, 1573788.3750, 1571736.5000, 1571615.1250, 1569928.3750,
         1569847.5000, 1569718.7500, 1569076.7500, 1567942.7500, 1567803.7500],
        [1574970.1250, 1574292.7500, 1573530.2500, 1571908.8750, 1569946.2500,
         1569090.2500, 1568553.0000, 1566730.6250, 1566415.3750, 1566310.8750],
        [1575791.8750, 1574831.8750, 1572760.5000, 1572337.7500, 1571050.1250,
         1570925.7500, 1570256.2500, 1569046.7500, 1568568.0000, 1568316.7500],
        [1573973.0000, 1573162.7500, 1571300.3750, 1571038.1250, 1570892.8750,
         1570160.5000, 1568393.0000, 1567610.8750, 1567518.1250, 1566648.3750],
        [1371944.3750, 1360394.5000, 1201467.1250, 1193514.1250, 1131150.1250,
         1120194.8750, 1116269.3750, 1115482.0000, 1071667.6250, 1006832.6250],
        [1524326.8750, 1523078.6250, 1518440.5000, 1518030.7500, 1518013.3750,
         1516517.2500, 1515133.7500, 1513748.6250, 1509592.5000, 1509295.8750],
        [1548613.5000, 1547667.1250, 1543316.2500, 1543316.2500, 1541883.3750,
         1540816.2500, 1540711.8750, 1539288.6250, 1538869.0000, 1538544.6250],
        [1521378.6250, 1516473.8750, 1514622.3750, 1514011.5000, 1510531.3750,
         1509740.8750, 1509293.0000, 1508185.1250, 1508006.7500, 1506267.6250],
        [1370923.0000, 1322747.3750, 1282231.7500, 1191227.3750, 1172073.6250,
         1171274.7500, 1164229.7500, 1160179.7500, 1158893.7500, 1118129.6250],
        [1495003.3750, 1495000.5000, 1492746.6250, 1486466.1250, 1484257.7500,
         1483401.6250, 1483312.5000, 1479713.8750, 1479465.5000, 1479101.5000],
        [1449199.0000, 1448694.6250, 1445485.8750, 1432357.6250, 1426472.6250,
         1422515.3750, 1412770.5000, 1404827.5000, 1400707.1250, 1398888.8750],
        [1504235.0000, 1498106.2500, 1497136.3750, 1490082.6250, 1489365.2500,
         1488821.2500, 1485727.7500, 1485037.8750, 1484934.6250, 1483390.3750],
        [1304903.0000, 1304852.0000, 1293699.0000, 1285801.2500, 1282872.6250,
         1274746.7500, 1270958.1250, 1262167.2500, 1215135.8750, 1206441.1250],
        [1555330.1250, 1554053.5000, 1553068.2500, 1552478.8750, 1551981.5000,
         1551738.7500, 1549366.8750, 1549230.8750, 1548999.0000, 1548598.7500],
        [1549590.0000, 1548462.8750, 1542437.8750, 1541107.1250, 1540766.1250,
         1539968.5000, 1539459.0000, 1537803.7500, 1537739.3750, 1537663.0000],
        [1529026.6250, 1526532.2500, 1525353.5000, 1523748.3750, 1522924.6250,
         1521699.2500, 1520348.8750, 1519889.2500, 1516475.2500, 1515829.0000],
        [1411523.5000, 1406668.1250, 1383997.7500, 1366479.7500, 1365002.7500,
         1354634.7500, 1336096.3750, 1330294.8750, 1328816.5000, 1322055.1250],
        [1312942.0000, 1276336.6250, 1255315.1250, 1246328.1250, 1242548.1250,
         1240512.8750, 1236138.6250, 1231410.8750, 1228494.8750, 1217222.3750],
        [1375595.8750, 1351484.8750, 1169310.5000, 1106608.0000,  973508.6250,
          962230.2500,  951458.0000,  950891.9375,  942840.8750,  929099.4375],
        [1128958.1250, 1127269.0000, 1102613.3750, 1082553.0000, 1076339.2500,
         1007636.6250, 1004940.0000,  921408.5000,  896147.3125,  888103.1250],
        [1437748.5000, 1374302.8750, 1373911.1250, 1366000.3750, 1363013.8750,
         1355967.2500, 1352837.6250, 1341492.0000, 1334696.7500, 1333938.2500],
        [1456146.5000, 1453534.0000, 1453406.6250, 1445527.3750, 1443477.5000,
         1439404.3750, 1439309.6250, 1430610.2500, 1428437.1250, 1423861.7500],
        [1452968.6250, 1420937.2500, 1420653.8750, 1413213.8750, 1412338.1250,
         1403630.2500, 1395444.5000, 1393449.7500, 1392906.2500, 1391302.6250],
        [1415219.3750, 1390839.6250, 1389932.6250, 1388182.6250, 1387853.1250,
         1341472.8750, 1293209.2500, 1286613.3750, 1275397.2500, 1274038.1250],
        [1469336.1250, 1462919.6250, 1459939.8750, 1440511.2500, 1433375.7500,
         1424153.8750, 1419295.7500, 1413393.1250, 1404093.5000, 1391118.2500],
        [1420719.0000, 1394235.3750, 1368172.3750, 1338972.7500, 1319481.7500,
         1314456.7500, 1310313.8750, 1305318.7500, 1301867.7500, 1298455.3750],
        [1481445.0000, 1481429.3750, 1466357.1250, 1464649.2500, 1463639.7500,
         1463304.7500, 1457428.8750, 1452228.8750, 1447600.8750, 1444444.2500],
        [1502368.3750, 1484202.6250, 1471704.6250, 1471247.2500, 1460544.2500,
         1459310.7500, 1454447.7500, 1451752.5000, 1444781.7500, 1434748.8750],
        [1481360.2500, 1411306.7500, 1406015.0000, 1385648.5000, 1379255.6250,
         1376657.5000, 1372381.5000, 1356417.3750, 1344982.8750, 1341968.0000],
        [1448175.2500, 1428704.1250, 1413719.3750, 1376137.6250, 1352072.7500,
         1335523.0000, 1327998.0000, 1324797.7500, 1323244.5000, 1319398.7500],
        [1446997.6250, 1424747.3750, 1423111.1250, 1415454.2500, 1411559.7500,
         1388991.7500, 1380679.5000, 1361657.3750, 1351998.0000, 1346047.7500],
        [1525050.8750, 1489909.2500, 1467784.2500, 1440616.8750, 1433199.3750,
         1418612.3750, 1400484.0000, 1392640.7500, 1373476.1250, 1370116.5000],
        [1395661.5000, 1354138.7500, 1347974.6250, 1346033.6250, 1338611.5000,
         1329271.3750, 1313312.6250, 1311309.0000, 1307405.5000, 1301811.7500],
        [1440882.1250, 1419760.1250, 1348648.5000, 1328024.6250, 1316178.8750,
         1308286.0000, 1290837.3750, 1283977.8750, 1278983.1250, 1275937.3750],
        [1433675.0000, 1413367.5000, 1382202.5000, 1381730.6250, 1367271.1250,
         1347874.3750, 1293574.5000, 1292101.0000, 1281932.2500, 1259996.5000],
        [1452294.0000, 1441939.2500, 1434308.2500, 1433224.0000, 1425020.5000,
         1416660.2500, 1410405.2500, 1407512.2500, 1402661.3750, 1399633.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1517165.3750,       0.0000],
         [1517007.5000,       0.0000],
         [1502374.0000,       0.0000],
         ...,
         [1478454.2500,       0.0000],
         [1475988.8750,       0.0000],
         [1475648.2500,       0.0000]],

        [[1537246.6250,       0.0000],
         [1531563.0000,       0.0000],
         [1525865.6250,       0.0000],
         ...,
         [1522496.1250,       0.0000],
         [1521798.0000,       0.0000],
         [1519783.5000,       0.0000]],

        [[1221773.2500,       0.0000],
         [      0.0000, 1050942.7500],
         [1047349.6875,       0.0000],
         ...,
         [      0.0000,  969345.2500],
         [      0.0000,  966394.3125],
         [ 957352.5000,       0.0000]],

        ...,

        [[1440882.1250,       0.0000],
         [1419760.1250,       0.0000],
         [1348648.5000,       0.0000],
         ...,
         [      0.0000, 1283977.8750],
         [1278983.1250,       0.0000],
         [1275937.3750,       0.0000]],

        [[1433675.0000,       0.0000],
         [1413367.5000,       0.0000],
         [1382202.5000,       0.0000],
         ...,
         [      0.0000, 1292101.0000],
         [1281932.2500,       0.0000],
         [      0.0000, 1259996.5000]],

        [[      0.0000, 1452294.0000],
         [      0.0000, 1441939.2500],
         [      0.0000, 1434308.2500],
         ...,
         [      0.0000, 1407512.2500],
         [      0.0000, 1402661.3750],
         [      0.0000, 1399633.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14917772.0000,        0.0000],
        [15252836.0000,        0.0000],
        [ 5273132.5000,  5017100.0000],
        [14095168.0000,        0.0000],
        [10568566.0000,  2624546.0000],
        [ 9435353.0000,  2310740.2500],
        [ 3198995.5000,  7239935.5000],
        [ 9374055.0000,   965062.5625],
        [13777794.0000,  1527717.7500],
        [11799933.0000,  1345080.2500],
        [15429489.0000,        0.0000],
        [14189322.0000,        0.0000],
        [13819127.0000,        0.0000],
        [15491130.0000,        0.0000],
        [15624830.0000,        0.0000],
        [15575867.0000,        0.0000],
        [12017400.0000,  2983094.7500],
        [11859436.0000,  2972974.2500],
        [14576747.0000,        0.0000],
        [15392430.0000,        0.0000],
        [15444406.0000,        0.0000],
        [11734253.0000,  2951805.0000],
        [15498382.0000,        0.0000],
        [15640837.0000,        0.0000],
        [11829498.0000,  2987197.0000],
        [15630060.0000,        0.0000],
        [15535578.0000,        0.0000],
        [15649092.0000,        0.0000],
        [15705273.0000,        0.0000],
        [15701748.0000,        0.0000],
        [15713886.0000,        0.0000],
        [15700699.0000,        0.0000],
        [ 3242509.5000,  8446407.0000],
        [12126582.0000,  3039596.0000],
        [12343446.0000,  3079581.0000],
        [13609218.0000,  1509293.0000],
        [ 3494398.2500,  8617512.0000],
        [11870722.0000,  2987747.0000],
        [12819403.0000,  1422515.3750],
        [14906838.0000,        0.0000],
        [10110873.0000,  2590704.2500],
        [15514847.0000,        0.0000],
        [15414998.0000,        0.0000],
        [13698902.0000,  1522924.6250],
        [ 2666391.2500, 10939179.0000],
        [ 1236138.6250, 11251111.0000],
        [ 5710029.0000,  5002999.0000],
        [  896147.3125,  9339821.0000],
        [ 8103411.0000,  5530497.5000],
        [10067370.0000,  4346345.0000],
        [11231538.0000,  2865306.7500],
        [ 2562010.5000, 10880748.0000],
        [       0.0000, 14318138.0000],
        [ 2624770.5000, 10747223.0000],
        [10215209.0000,  4407318.5000],
        [10200948.0000,  4434160.0000],
        [ 2751637.0000, 11104356.0000],
        [ 2728210.5000, 10921561.0000],
        [       0.0000, 13951244.0000],
        [ 1392640.7500, 12919249.0000],
        [ 9294488.0000,  4051041.5000],
        [10699253.0000,  2592264.0000],
        [ 9608053.0000,  3845672.0000],
        [       0.0000, 14223658.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 291/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:55, 57.70s/it]  7%|▋         | 2/29 [01:01<11:34, 25.72s/it] 10%|█         | 3/29 [01:01<06:14, 14.40s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.08s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.14s/it] 21%|██        | 6/29 [01:04<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.959690570831299
Epoch 292/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:43, 61.57s/it]  7%|▋         | 2/29 [01:02<11:39, 25.89s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.9667224884033203
Epoch 293/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:50, 59.65s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.9530978202819824
Epoch 294/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:15, 60.54s/it]  7%|▋         | 2/29 [01:01<11:27, 25.47s/it] 10%|█         | 3/29 [01:02<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:03<03:44,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.969564914703369
Epoch 295/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:13, 60.48s/it]  7%|▋         | 2/29 [01:01<11:27, 25.44s/it] 10%|█         | 3/29 [01:02<06:10, 14.25s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.967778205871582
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0140, 0.0021,  ..., 0.0046, 0.0002, 0.0165],
        [0.0032, 0.0106, 0.0023,  ..., 0.0041, 0.0006, 0.0171],
        [0.0294, 0.0084, 0.0040,  ..., 0.0054, 0.0147, 0.0227],
        ...,
        [0.0053, 0.0077, 0.0207,  ..., 0.0045, 0.0012, 0.0208],
        [0.0050, 0.0107, 0.0160,  ..., 0.0047, 0.0039, 0.0190],
        [0.0082, 0.0059, 0.0043,  ..., 0.0022, 0.0032, 0.0206]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9965, 0.9957, 0.9954, 0.9952, 0.9951, 0.9950, 0.9948, 0.9948,
         0.9946],
        [0.9972, 0.9971, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9965],
        [0.9802, 0.9709, 0.9705, 0.9691, 0.9685, 0.9671, 0.9662, 0.9637, 0.9637,
         0.9633],
        [0.9929, 0.9928, 0.9926, 0.9919, 0.9916, 0.9916, 0.9912, 0.9912, 0.9912,
         0.9899],
        [0.9899, 0.9874, 0.9869, 0.9868, 0.9867, 0.9866, 0.9865, 0.9862, 0.9860,
         0.9856],
        [0.9856, 0.9852, 0.9818, 0.9809, 0.9796, 0.9779, 0.9772, 0.9766, 0.9749,
         0.9749],
        [0.9766, 0.9757, 0.9730, 0.9705, 0.9692, 0.9682, 0.9664, 0.9655, 0.9654,
         0.9642],
        [0.9807, 0.9795, 0.9745, 0.9683, 0.9666, 0.9656, 0.9650, 0.9633, 0.9616,
         0.9606],
        [0.9978, 0.9974, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9966,
         0.9966],
        [0.9940, 0.9887, 0.9876, 0.9875, 0.9871, 0.9863, 0.9857, 0.9847, 0.9846,
         0.9841],
        [0.9979, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9941, 0.9937, 0.9931, 0.9920, 0.9913, 0.9909, 0.9907, 0.9907, 0.9905,
         0.9904],
        [0.9946, 0.9929, 0.9914, 0.9909, 0.9899, 0.9893, 0.9891, 0.9881, 0.9874,
         0.9870],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9977, 0.9977, 0.9975, 0.9975, 0.9972,
         0.9972],
        [0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9980,
         0.9980],
        [0.9963, 0.9961, 0.9960, 0.9959, 0.9958, 0.9954, 0.9954, 0.9953, 0.9951,
         0.9951],
        [0.9955, 0.9951, 0.9950, 0.9948, 0.9947, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9944],
        [0.9947, 0.9943, 0.9937, 0.9936, 0.9935, 0.9934, 0.9930, 0.9930, 0.9929,
         0.9929],
        [0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9974, 0.9973,
         0.9973],
        [0.9955, 0.9947, 0.9945, 0.9945, 0.9945, 0.9943, 0.9940, 0.9935, 0.9933,
         0.9932],
        [0.9986, 0.9985, 0.9981, 0.9980, 0.9978, 0.9977, 0.9977, 0.9973, 0.9973,
         0.9973],
        [0.9987, 0.9987, 0.9987, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9956, 0.9950, 0.9950, 0.9948, 0.9947, 0.9945, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9987, 0.9987, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9984, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9891, 0.9886, 0.9793, 0.9791, 0.9749, 0.9748, 0.9747, 0.9732, 0.9715,
         0.9668],
        [0.9967, 0.9967, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9960],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9965, 0.9963, 0.9963, 0.9963, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960,
         0.9960],
        [0.9889, 0.9865, 0.9844, 0.9800, 0.9784, 0.9783, 0.9781, 0.9769, 0.9763,
         0.9755],
        [0.9954, 0.9953, 0.9952, 0.9949, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948,
         0.9947],
        [0.9935, 0.9932, 0.9932, 0.9923, 0.9922, 0.9919, 0.9915, 0.9912, 0.9910,
         0.9910],
        [0.9957, 0.9955, 0.9953, 0.9952, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9949],
        [0.9856, 0.9856, 0.9850, 0.9850, 0.9842, 0.9839, 0.9835, 0.9827, 0.9801,
         0.9797],
        [0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9979, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9964,
         0.9964],
        [0.9913, 0.9910, 0.9901, 0.9890, 0.9889, 0.9885, 0.9874, 0.9871, 0.9871,
         0.9868],
        [0.9858, 0.9842, 0.9842, 0.9827, 0.9825, 0.9823, 0.9820, 0.9816, 0.9816,
         0.9810],
        [0.9898, 0.9883, 0.9781, 0.9741, 0.9646, 0.9644, 0.9639, 0.9637, 0.9624,
         0.9624],
        [0.9753, 0.9744, 0.9734, 0.9717, 0.9708, 0.9668, 0.9666, 0.9608, 0.9592,
         0.9578],
        [0.9929, 0.9897, 0.9894, 0.9893, 0.9892, 0.9884, 0.9881, 0.9879, 0.9877,
         0.9877],
        [0.9937, 0.9937, 0.9936, 0.9932, 0.9931, 0.9930, 0.9928, 0.9926, 0.9925,
         0.9924],
        [0.9933, 0.9917, 0.9916, 0.9916, 0.9915, 0.9914, 0.9907, 0.9907, 0.9906,
         0.9902],
        [0.9915, 0.9903, 0.9903, 0.9901, 0.9900, 0.9880, 0.9851, 0.9849, 0.9842,
         0.9840],
        [0.9941, 0.9937, 0.9937, 0.9927, 0.9924, 0.9919, 0.9916, 0.9913, 0.9910,
         0.9903],
        [0.9918, 0.9901, 0.9887, 0.9872, 0.9868, 0.9865, 0.9865, 0.9858, 0.9851,
         0.9851],
        [0.9948, 0.9946, 0.9941, 0.9940, 0.9940, 0.9939, 0.9935, 0.9935, 0.9933,
         0.9933],
        [0.9958, 0.9950, 0.9945, 0.9944, 0.9940, 0.9939, 0.9936, 0.9936, 0.9934,
         0.9928],
        [0.9948, 0.9913, 0.9913, 0.9900, 0.9900, 0.9900, 0.9896, 0.9886, 0.9881,
         0.9880],
        [0.9930, 0.9922, 0.9914, 0.9896, 0.9885, 0.9877, 0.9873, 0.9873, 0.9870,
         0.9867],
        [0.9931, 0.9919, 0.9918, 0.9915, 0.9913, 0.9901, 0.9899, 0.9890, 0.9881,
         0.9881],
        [0.9967, 0.9951, 0.9941, 0.9928, 0.9926, 0.9917, 0.9907, 0.9905, 0.9894,
         0.9891],
        [0.9905, 0.9885, 0.9880, 0.9877, 0.9877, 0.9868, 0.9867, 0.9867, 0.9865,
         0.9860],
        [0.9930, 0.9918, 0.9886, 0.9873, 0.9865, 0.9862, 0.9852, 0.9848, 0.9848,
         0.9846],
        [0.9925, 0.9915, 0.9899, 0.9899, 0.9892, 0.9883, 0.9856, 0.9849, 0.9845,
         0.9836],
        [0.9931, 0.9928, 0.9927, 0.9921, 0.9920, 0.9916, 0.9912, 0.9910, 0.9909,
         0.9906]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 1, 1],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1522911.5000, 1522432.3750, 1505005.5000, 1499052.2500, 1494936.3750,
         1492520.3750, 1489673.3750, 1486430.7500, 1485342.5000, 1481890.1250],
        [1537506.1250, 1535276.0000, 1529139.0000, 1527760.0000, 1526600.6250,
         1525632.7500, 1525606.6250, 1524149.5000, 1524123.2500, 1523093.1250],
        [1205216.3750, 1056398.1250, 1049598.5000, 1028539.8750, 1021091.6250,
         1000624.1250,  986889.0000,  952929.1875,  952555.6875,  946954.5000],
        [1446518.8750, 1443842.2500, 1439343.8750, 1424506.8750, 1420049.8750,
         1418678.6250, 1411220.6250, 1411002.5000, 1410799.5000, 1385023.5000],
        [1384405.6250, 1336104.0000, 1327780.2500, 1325571.1250, 1322683.0000,
         1321269.7500, 1319332.0000, 1314738.7500, 1309655.5000, 1303664.1250],
        [1302795.3750, 1295788.3750, 1233306.5000, 1218823.0000, 1195601.1250,
         1167546.6250, 1154951.5000, 1146206.2500, 1117813.0000, 1117490.1250],
        [1145330.0000, 1131587.1250, 1088319.7500, 1050337.5000, 1031010.8125,
         1016149.0625,  989838.3125,  977686.0625,  975590.4375,  959407.0625],
        [1215022.2500, 1193803.2500, 1111645.0000, 1016808.1875,  993258.5625,
          979484.5000,  970351.5625,  946934.6250,  924813.6875,  912074.8750],
        [1551126.2500, 1541642.2500, 1533784.7500, 1532238.0000, 1531945.7500,
         1529750.1250, 1529704.8750, 1526887.5000, 1525531.0000, 1524752.7500],
        [1468270.1250, 1362491.3750, 1340672.2500, 1338699.5000, 1330434.5000,
         1315216.6250, 1304008.6250, 1285552.3750, 1284835.3750, 1274400.2500],
        [1552258.2500, 1547915.1250, 1547103.3750, 1545552.0000, 1545176.2500,
         1544893.3750, 1544479.3750, 1542935.1250, 1542176.0000, 1542131.8750],
        [1470092.8750, 1463339.6250, 1449335.8750, 1428304.8750, 1412708.5000,
         1404578.2500, 1402126.5000, 1401579.6250, 1398196.7500, 1394907.0000],
        [1480524.1250, 1446396.1250, 1416030.7500, 1404323.8750, 1385384.2500,
         1372609.3750, 1370030.3750, 1350901.2500, 1337230.8750, 1329388.1250],
        [1562852.1250, 1560116.6250, 1556983.3750, 1556560.2500, 1549034.3750,
         1548770.1250, 1543235.2500, 1543210.2500, 1538364.1250, 1538152.8750],
        [1568864.2500, 1568093.8750, 1567809.7500, 1566040.5000, 1565211.7500,
         1564313.3750, 1563690.0000, 1563660.1250, 1562972.8750, 1562707.6250],
        [1564479.0000, 1564077.7500, 1562817.8750, 1561763.0000, 1560819.0000,
         1559655.5000, 1559404.0000, 1559027.8750, 1556190.6250, 1555763.2500],
        [1518485.3750, 1514145.7500, 1511067.5000, 1508940.5000, 1506599.5000,
         1498376.2500, 1498114.7500, 1497236.3750, 1492561.6250, 1491835.8750],
        [1501670.7500, 1491964.0000, 1489146.5000, 1485581.8750, 1484542.3750,
         1484311.5000, 1483630.8750, 1481888.6250, 1481022.6250, 1477249.2500],
        [1482828.8750, 1475722.8750, 1462389.6250, 1460107.0000, 1458823.6250,
         1457223.2500, 1448598.0000, 1447229.5000, 1446723.0000, 1446633.3750],
        [1549285.7500, 1547558.0000, 1545770.2500, 1543186.7500, 1542685.0000,
         1542526.0000, 1542464.3750, 1542280.3750, 1541514.3750, 1540318.1250],
        [1553195.6250, 1552601.7500, 1551675.1250, 1551123.2500, 1550481.3750,
         1548011.0000, 1545925.0000, 1542573.1250, 1540438.5000, 1539937.7500],
        [1501699.3750, 1483776.6250, 1480227.7500, 1479781.6250, 1479249.6250,
         1475236.0000, 1468005.3750, 1457698.5000, 1453566.0000, 1452906.2500],
        [1568557.5000, 1566387.0000, 1557433.2500, 1554152.8750, 1550193.1250,
         1549133.5000, 1548092.2500, 1540272.5000, 1539793.7500, 1538712.0000],
        [1570758.0000, 1570714.5000, 1570708.6250, 1565150.6250, 1565083.5000,
         1564626.7500, 1564558.1250, 1564315.0000, 1564058.3750, 1562820.8750],
        [1503830.3750, 1489737.3750, 1489224.6250, 1486758.2500, 1484611.6250,
         1479347.1250, 1478754.6250, 1478663.0000, 1477209.8750, 1476997.1250],
        [1571240.3750, 1570317.7500, 1566527.3750, 1563367.8750, 1562315.6250,
         1561888.1250, 1561850.8750, 1561244.7500, 1561097.2500, 1560902.3750],
        [1563734.7500, 1560731.1250, 1557589.2500, 1554719.1250, 1553174.8750,
         1551951.8750, 1551894.1250, 1551761.0000, 1551727.0000, 1548591.3750],
        [1570725.1250, 1570531.8750, 1569064.6250, 1568802.8750, 1566850.1250,
         1565482.0000, 1564488.0000, 1563889.7500, 1562396.1250, 1561733.2500],
        [1574941.5000, 1574687.7500, 1573654.7500, 1572640.6250, 1570723.5000,
         1570678.6250, 1570540.7500, 1570118.5000, 1569263.6250, 1569218.8750],
        [1577169.0000, 1576169.1250, 1575243.3750, 1573140.1250, 1571628.5000,
         1570912.3750, 1570609.7500, 1569361.1250, 1569021.3750, 1568545.5000],
        [1577214.1250, 1576717.7500, 1574632.1250, 1574406.7500, 1573296.2500,
         1572048.2500, 1571372.3750, 1571131.1250, 1571090.6250, 1570785.0000],
        [1575969.2500, 1574587.0000, 1572973.6250, 1572559.6250, 1572039.3750,
         1571276.3750, 1570066.1250, 1568943.5000, 1568014.6250, 1567881.5000],
        [1368922.7500, 1360275.1250, 1190488.0000, 1186850.2500, 1117458.1250,
         1115946.8750, 1115344.7500, 1091351.5000, 1065165.8750,  996095.8125],
        [1527714.7500, 1526120.2500, 1522157.8750, 1522024.3750, 1521227.7500,
         1520736.0000, 1518049.5000, 1517116.1250, 1514870.7500, 1511687.1250],
        [1550666.2500, 1548545.5000, 1545932.3750, 1545932.3750, 1543250.0000,
         1542888.0000, 1542386.3750, 1541683.3750, 1541332.1250, 1541042.5000],
        [1522875.2500, 1518976.3750, 1517563.1250, 1517101.6250, 1512729.8750,
         1511795.3750, 1511089.1250, 1510914.6250, 1510743.2500, 1510426.3750],
        [1365321.7500, 1319514.3750, 1280256.0000, 1202814.2500, 1176201.0000,
         1173123.7500, 1170291.0000, 1150623.2500, 1141400.2500, 1128241.2500],
        [1498766.3750, 1496101.6250, 1495268.6250, 1488236.3750, 1487871.7500,
         1487736.8750, 1487017.7500, 1485084.6250, 1484848.1250, 1484557.8750],
        [1457815.3750, 1453067.0000, 1451652.8750, 1433955.3750, 1432058.5000,
         1424962.1250, 1417304.7500, 1411920.6250, 1406929.8750, 1406786.2500],
        [1505640.0000, 1499966.0000, 1497207.7500, 1494850.7500, 1492342.5000,
         1491773.2500, 1490809.0000, 1490770.6250, 1489172.0000, 1488852.5000],
        [1303616.8750, 1303211.7500, 1291018.3750, 1290783.2500, 1276532.6250,
         1271833.5000, 1264431.0000, 1249859.5000, 1204780.8750, 1196665.5000],
        [1557681.5000, 1557466.0000, 1556573.6250, 1554606.3750, 1554510.0000,
         1554183.8750, 1551607.1250, 1550899.8750, 1550790.5000, 1550645.5000],
        [1553204.5000, 1552076.1250, 1547755.6250, 1545762.8750, 1544841.7500,
         1543777.0000, 1543244.1250, 1542989.5000, 1542745.2500, 1542660.0000],
        [1532572.6250, 1531529.5000, 1529681.5000, 1528007.6250, 1526314.0000,
         1525398.6250, 1524021.5000, 1523831.1250, 1520778.0000, 1519364.6250],
        [1412370.5000, 1407884.1250, 1389168.0000, 1367979.2500, 1365969.0000,
         1358724.5000, 1336709.5000, 1331444.7500, 1330520.6250, 1325377.6250],
        [1305839.1250, 1276895.3750, 1276820.0000, 1249819.1250, 1247123.5000,
         1242024.5000, 1238273.0000, 1230454.2500, 1230198.2500, 1220616.7500],
        [1382555.8750, 1354783.2500, 1170188.3750, 1106119.5000,  964636.5625,
          962369.6875,  955946.5625,  952463.0625,  935633.0625,  935063.8750],
        [1124128.8750, 1110079.1250, 1094428.2500, 1067605.6250, 1054482.6250,
          995755.8125,  992981.0000,  914757.0000,  893860.7500,  875681.1875],
        [1446226.3750, 1380432.0000, 1375144.5000, 1373093.7500, 1371826.7500,
         1356482.1250, 1350460.7500, 1345963.0000, 1342253.5000, 1341487.0000],
        [1462770.3750, 1461990.7500, 1461459.6250, 1452593.1250, 1450067.1250,
         1448977.8750, 1443484.3750, 1440603.2500, 1437427.6250, 1436671.1250],
        [1454680.8750, 1421852.1250, 1419949.6250, 1419232.1250, 1416483.2500,
         1414389.6250, 1401585.0000, 1400911.5000, 1398430.1250, 1391327.7500],
        [1417517.0000, 1393513.6250, 1392828.0000, 1388642.1250, 1388135.1250,
         1347419.3750, 1292896.1250, 1288892.6250, 1277096.3750, 1274132.8750],
        [1471548.8750, 1463120.5000, 1462151.1250, 1442224.0000, 1435012.8750,
         1426038.8750, 1418878.8750, 1413820.3750, 1407305.5000, 1393675.7500],
        [1424062.7500, 1388435.6250, 1361782.0000, 1333202.0000, 1324427.5000,
         1320490.0000, 1319834.1250, 1306548.0000, 1294133.3750, 1292857.8750],
        [1485030.8750, 1482565.7500, 1470743.5000, 1469141.2500, 1468590.8750,
         1465976.8750, 1459300.8750, 1458759.6250, 1454042.8750, 1454042.8750],
        [1506615.3750, 1489936.2500, 1480095.0000, 1476245.1250, 1469207.1250,
         1467017.3750, 1461377.3750, 1459676.7500, 1456763.3750, 1444316.1250],
        [1486131.6250, 1413838.0000, 1412285.5000, 1387466.6250, 1387353.0000,
         1386677.0000, 1380316.1250, 1360673.5000, 1349206.7500, 1348076.2500],
        [1448347.8750, 1431841.3750, 1416132.0000, 1379710.7500, 1357612.0000,
         1343298.3750, 1335029.0000, 1334181.3750, 1328220.8750, 1322649.0000],
        [1450056.1250, 1425492.2500, 1422505.8750, 1417706.2500, 1414222.3750,
         1388620.8750, 1384492.7500, 1366945.0000, 1351070.0000, 1349255.7500],
        [1526958.7500, 1491437.5000, 1470913.3750, 1444485.5000, 1439629.5000,
         1422267.1250, 1401963.3750, 1397972.7500, 1375236.3750, 1369645.0000],
        [1397227.6250, 1357362.0000, 1347999.1250, 1342617.1250, 1342363.6250,
         1325157.7500, 1323740.5000, 1323113.2500, 1318960.8750, 1310488.8750],
        [1447587.0000, 1422850.5000, 1359074.3750, 1334467.6250, 1319388.6250,
         1314084.5000, 1295595.5000, 1288659.1250, 1288348.2500, 1285116.0000],
        [1437027.3750, 1417567.0000, 1385978.8750, 1385825.6250, 1371176.7500,
         1354792.3750, 1302949.3750, 1289967.3750, 1282303.8750, 1265653.0000],
        [1451053.5000, 1444827.2500, 1440950.8750, 1428848.6250, 1427227.8750,
         1418658.3750, 1412219.5000, 1407109.6250, 1404389.5000, 1398616.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1522911.5000,       0.0000],
         [1522432.3750,       0.0000],
         [1505005.5000,       0.0000],
         ...,
         [1486430.7500,       0.0000],
         [1485342.5000,       0.0000],
         [1481890.1250,       0.0000]],

        [[1537506.1250,       0.0000],
         [1535276.0000,       0.0000],
         [1529139.0000,       0.0000],
         ...,
         [1524149.5000,       0.0000],
         [1524123.2500,       0.0000],
         [1523093.1250,       0.0000]],

        [[1205216.3750,       0.0000],
         [1056398.1250,       0.0000],
         [1049598.5000,       0.0000],
         ...,
         [      0.0000,  952929.1875],
         [ 952555.6875,       0.0000],
         [      0.0000,  946954.5000]],

        ...,

        [[1447587.0000,       0.0000],
         [1422850.5000,       0.0000],
         [1359074.3750,       0.0000],
         ...,
         [      0.0000, 1288659.1250],
         [1288348.2500,       0.0000],
         [1285116.0000,       0.0000]],

        [[1437027.3750,       0.0000],
         [1417567.0000,       0.0000],
         [1385978.8750,       0.0000],
         ...,
         [      0.0000, 1289967.3750],
         [1282303.8750,       0.0000],
         [      0.0000, 1265653.0000]],

        [[      0.0000, 1451053.5000],
         [      0.0000, 1444827.2500],
         [      0.0000, 1440950.8750],
         ...,
         [      0.0000, 1407109.6250],
         [      0.0000, 1404389.5000],
         [      0.0000, 1398616.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14980196.0000,        0.0000],
        [15278888.0000,        0.0000],
        [ 5264392.5000,  4936404.0000],
        [14210986.0000,        0.0000],
        [ 9311077.0000,  3954127.2500],
        [10717015.0000,  1233306.5000],
        [ 3249798.7500,  7115457.5000],
        [ 9317262.0000,   946934.6250],
        [13797614.0000,  1529750.1250],
        [11942090.0000,  1362491.3750],
        [15454621.0000,        0.0000],
        [14225170.0000,        0.0000],
        [13892819.0000,        0.0000],
        [15497278.0000,        0.0000],
        [15653364.0000,        0.0000],
        [15603998.0000,        0.0000],
        [10554852.0000,  4482512.0000],
        [13359338.0000,  1501670.7500],
        [13139646.0000,  1446633.3750],
        [15437589.0000,        0.0000],
        [15475962.0000,        0.0000],
        [11773116.0000,  2959031.2500],
        [15512728.0000,        0.0000],
        [15662794.0000,        0.0000],
        [11851566.0000,  2993567.7500],
        [15640752.0000,        0.0000],
        [15545874.0000,        0.0000],
        [15663962.0000,        0.0000],
        [15716469.0000,        0.0000],
        [15721800.0000,        0.0000],
        [15732694.0000,        0.0000],
        [15714311.0000,        0.0000],
        [ 3227387.5000,  8380512.0000],
        [12152762.0000,  3048942.5000],
        [12359588.0000,  3084069.7500],
        [13633471.0000,  1510743.2500],
        [ 3497115.2500,  8610671.0000],
        [10416897.0000,  4478593.0000],
        [12879148.0000,  1417304.7500],
        [14941384.0000,        0.0000],
        [10058738.0000,  2593995.0000],
        [15538965.0000,        0.0000],
        [15459056.0000,        0.0000],
        [13735185.0000,  1526314.0000],
        [ 2667230.0000, 10958918.0000],
        [ 1230198.2500, 11287866.0000],
        [ 5706112.5000,  5013647.0000],
        [  875681.1875,  9248079.0000],
        [ 6805164.5000,  6878205.0000],
        [10122528.0000,  4373517.5000],
        [11264212.0000,  2874630.5000],
        [ 2563025.5000, 10898048.0000],
        [       0.0000, 14333776.0000],
        [ 2644917.5000, 10720856.0000],
        [11700599.0000,  2967596.5000],
        [10255332.0000,  4455917.5000],
        [ 2766993.0000, 11145030.0000],
        [ 2737322.7500, 10959699.0000],
        [       0.0000, 13970367.0000],
        [ 1397972.7500, 12942536.0000],
        [10649185.0000,  2739844.7500],
        [10752428.0000,  2602743.5000],
        [ 9634672.0000,  3858570.0000],
        [       0.0000, 14233902.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 296/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:24, 58.74s/it]  7%|▋         | 2/29 [01:02<11:47, 26.21s/it] 10%|█         | 3/29 [01:03<06:21, 14.66s/it] 14%|█▍        | 4/29 [01:04<03:50,  9.24s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.24s/it] 21%|██        | 6/29 [01:05<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.9548158645629883
Epoch 297/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.22s/it]  7%|▋         | 2/29 [01:01<11:24, 25.34s/it] 10%|█         | 3/29 [01:02<06:09, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.942403554916382
Epoch 298/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:09, 58.19s/it]  7%|▋         | 2/29 [00:59<11:07, 24.72s/it] 10%|█         | 3/29 [01:01<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.15s/it] 21%|██        | 6/29 [01:04<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.948657751083374
Epoch 299/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:15, 58.41s/it]  7%|▋         | 2/29 [00:59<11:04, 24.59s/it] 10%|█         | 3/29 [01:00<05:58, 13.78s/it] 14%|█▍        | 4/29 [01:01<03:44,  9.00s/it] 17%|█▋        | 5/29 [01:02<02:26,  6.09s/it] 21%|██        | 6/29 [01:03<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.9494900703430176
Epoch 300/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:39, 57.11s/it]  7%|▋         | 2/29 [00:58<10:57, 24.34s/it] 10%|█         | 3/29 [00:59<05:54, 13.65s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.62s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:35,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.9481053352355957
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.9646e-03, 1.3296e-02, 2.0073e-03,  ..., 4.2528e-03, 8.6613e-05,
         1.6794e-02],
        [2.7127e-03, 1.0035e-02, 2.2316e-03,  ..., 3.6864e-03, 4.7563e-04,
         1.6657e-02],
        [3.0142e-02, 8.4339e-03, 4.3208e-03,  ..., 5.6665e-03, 1.4636e-02,
         2.2603e-02],
        ...,
        [5.2630e-03, 7.4622e-03, 2.0476e-02,  ..., 4.2541e-03, 1.2169e-03,
         2.0967e-02],
        [4.8780e-03, 1.0184e-02, 1.6208e-02,  ..., 4.4389e-03, 3.8261e-03,
         1.9164e-02],
        [7.6696e-03, 6.0188e-03, 4.4587e-03,  ..., 2.2871e-03, 3.1196e-03,
         2.0607e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9967, 0.9967, 0.9958, 0.9956, 0.9954, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9948],
        [0.9973, 0.9973, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9800, 0.9711, 0.9693, 0.9678, 0.9676, 0.9663, 0.9661, 0.9638, 0.9632,
         0.9627],
        [0.9929, 0.9926, 0.9925, 0.9918, 0.9914, 0.9914, 0.9913, 0.9912, 0.9912,
         0.9902],
        [0.9897, 0.9872, 0.9870, 0.9869, 0.9866, 0.9863, 0.9861, 0.9857, 0.9854,
         0.9853],
        [0.9854, 0.9847, 0.9811, 0.9803, 0.9793, 0.9766, 0.9765, 0.9763, 0.9748,
         0.9745],
        [0.9761, 0.9748, 0.9698, 0.9698, 0.9669, 0.9660, 0.9658, 0.9646, 0.9633,
         0.9627],
        [0.9804, 0.9791, 0.9746, 0.9664, 0.9656, 0.9654, 0.9636, 0.9616, 0.9606,
         0.9590],
        [0.9979, 0.9975, 0.9972, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9967],
        [0.9938, 0.9890, 0.9879, 0.9872, 0.9868, 0.9855, 0.9845, 0.9843, 0.9842,
         0.9841],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9941, 0.9935, 0.9929, 0.9920, 0.9914, 0.9912, 0.9909, 0.9905, 0.9903,
         0.9899],
        [0.9945, 0.9927, 0.9911, 0.9902, 0.9897, 0.9888, 0.9886, 0.9878, 0.9872,
         0.9870],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9979, 0.9978, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9982,
         0.9982],
        [0.9964, 0.9964, 0.9962, 0.9961, 0.9961, 0.9957, 0.9957, 0.9956, 0.9955,
         0.9954],
        [0.9957, 0.9952, 0.9951, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9949, 0.9944, 0.9939, 0.9938, 0.9936, 0.9934, 0.9934, 0.9931, 0.9931,
         0.9931],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9982, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9956, 0.9948, 0.9948, 0.9947, 0.9945, 0.9944, 0.9942, 0.9935, 0.9935,
         0.9933],
        [0.9987, 0.9986, 0.9982, 0.9980, 0.9979, 0.9978, 0.9977, 0.9975, 0.9973,
         0.9973],
        [0.9989, 0.9988, 0.9988, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9958, 0.9952, 0.9949, 0.9948, 0.9947, 0.9946, 0.9945, 0.9944, 0.9942,
         0.9942],
        [0.9988, 0.9988, 0.9986, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9984, 0.9983, 0.9982, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9891, 0.9887, 0.9796, 0.9790, 0.9760, 0.9748, 0.9723, 0.9722, 0.9694,
         0.9629],
        [0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9966, 0.9965, 0.9964, 0.9964, 0.9963, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9889, 0.9860, 0.9835, 0.9814, 0.9794, 0.9782, 0.9773, 0.9766, 0.9765,
         0.9751],
        [0.9956, 0.9954, 0.9952, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9949,
         0.9948],
        [0.9933, 0.9932, 0.9931, 0.9917, 0.9916, 0.9915, 0.9913, 0.9913, 0.9910,
         0.9909],
        [0.9959, 0.9958, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,
         0.9954],
        [0.9859, 0.9852, 0.9848, 0.9839, 0.9839, 0.9836, 0.9834, 0.9818, 0.9799,
         0.9789],
        [0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9912, 0.9909, 0.9903, 0.9890, 0.9888, 0.9887, 0.9872, 0.9872, 0.9868,
         0.9867],
        [0.9860, 0.9838, 0.9837, 0.9825, 0.9824, 0.9822, 0.9816, 0.9816, 0.9810,
         0.9806],
        [0.9893, 0.9884, 0.9781, 0.9740, 0.9658, 0.9655, 0.9649, 0.9645, 0.9636,
         0.9629],
        [0.9743, 0.9724, 0.9722, 0.9704, 0.9697, 0.9657, 0.9656, 0.9580, 0.9576,
         0.9568],
        [0.9928, 0.9897, 0.9896, 0.9895, 0.9895, 0.9881, 0.9879, 0.9879, 0.9877,
         0.9877],
        [0.9943, 0.9941, 0.9940, 0.9937, 0.9936, 0.9935, 0.9933, 0.9932, 0.9931,
         0.9928],
        [0.9939, 0.9921, 0.9920, 0.9919, 0.9918, 0.9917, 0.9913, 0.9911, 0.9910,
         0.9906],
        [0.9914, 0.9906, 0.9904, 0.9904, 0.9900, 0.9884, 0.9854, 0.9848, 0.9848,
         0.9845],
        [0.9938, 0.9936, 0.9935, 0.9925, 0.9922, 0.9919, 0.9910, 0.9910, 0.9908,
         0.9904],
        [0.9915, 0.9896, 0.9884, 0.9868, 0.9868, 0.9865, 0.9865, 0.9851, 0.9844,
         0.9841],
        [0.9949, 0.9947, 0.9945, 0.9944, 0.9943, 0.9942, 0.9942, 0.9941, 0.9941,
         0.9940],
        [0.9961, 0.9955, 0.9950, 0.9948, 0.9945, 0.9944, 0.9943, 0.9940, 0.9939,
         0.9935],
        [0.9948, 0.9914, 0.9912, 0.9902, 0.9897, 0.9897, 0.9893, 0.9886, 0.9880,
         0.9879],
        [0.9929, 0.9924, 0.9913, 0.9895, 0.9882, 0.9880, 0.9876, 0.9871, 0.9867,
         0.9865],
        [0.9931, 0.9918, 0.9916, 0.9913, 0.9909, 0.9899, 0.9897, 0.9886, 0.9880,
         0.9876],
        [0.9968, 0.9949, 0.9942, 0.9929, 0.9925, 0.9918, 0.9905, 0.9904, 0.9893,
         0.9889],
        [0.9905, 0.9880, 0.9879, 0.9875, 0.9875, 0.9869, 0.9869, 0.9868, 0.9864,
         0.9857],
        [0.9931, 0.9920, 0.9889, 0.9875, 0.9865, 0.9863, 0.9852, 0.9851, 0.9851,
         0.9851],
        [0.9929, 0.9918, 0.9904, 0.9902, 0.9899, 0.9889, 0.9866, 0.9849, 0.9844,
         0.9842],
        [0.9931, 0.9931, 0.9930, 0.9920, 0.9918, 0.9917, 0.9915, 0.9909, 0.9906,
         0.9906]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 0, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1527426.3750, 1526244.1250, 1507404.3750, 1502260.8750, 1498293.3750,
         1496683.8750, 1494917.8750, 1492976.0000, 1492546.0000, 1486807.8750],
        [1539259.3750, 1538889.5000, 1534033.3750, 1531964.7500, 1529696.0000,
         1529566.2500, 1529464.1250, 1529079.1250, 1528618.3750, 1528316.6250],
        [1202274.1250, 1059473.2500, 1031796.6875, 1010147.8750, 1006805.7500,
          989011.7500,  985996.2500,  954790.3750,  945661.2500,  939722.4375],
        [1445519.0000, 1439061.2500, 1438645.5000, 1424391.3750, 1416199.5000,
         1415764.7500, 1414280.2500, 1411621.6250, 1411574.5000, 1390410.0000],
        [1382329.1250, 1333381.2500, 1328476.7500, 1326333.6250, 1320953.5000,
         1315566.6250, 1312615.1250, 1304824.6250, 1299243.2500, 1296998.7500],
        [1298603.8750, 1286895.5000, 1221186.1250, 1208577.1250, 1190129.2500,
         1145510.2500, 1144305.8750, 1140825.6250, 1116117.2500, 1111016.5000],
        [1137736.6250, 1116673.0000, 1039857.5000, 1039764.2500,  997263.9375,
          984884.4375,  981133.6250,  964541.7500,  946909.3750,  939122.1250],
        [1209665.6250, 1186940.8750, 1113162.0000,  990614.5625,  979633.0000,
          976687.0625,  950956.3750,  924612.6250,  912122.6875,  890967.0625],
        [1552966.0000, 1543382.5000, 1537759.7500, 1532859.1250, 1531517.7500,
         1531259.2500, 1530386.2500, 1529314.0000, 1527968.3750, 1527559.0000],
        [1463909.1250, 1366801.7500, 1346876.0000, 1333407.8750, 1324649.8750,
         1300554.7500, 1282083.8750, 1278680.6250, 1276801.6250, 1274608.1250],
        [1555447.2500, 1551115.8750, 1550454.7500, 1550014.1250, 1549359.5000,
         1549112.7500, 1548988.7500, 1548402.3750, 1547699.6250, 1546517.7500],
        [1470593.5000, 1458521.7500, 1445073.8750, 1428284.5000, 1415967.2500,
         1411304.1250, 1404511.3750, 1397420.8750, 1392796.0000, 1385568.0000],
        [1479681.5000, 1441423.6250, 1409734.2500, 1391979.3750, 1381160.1250,
         1364255.7500, 1360214.1250, 1344335.1250, 1332419.0000, 1328322.2500],
        [1566334.6250, 1563588.6250, 1560588.2500, 1560387.3750, 1552139.8750,
         1551146.8750, 1546985.3750, 1546803.8750, 1543999.3750, 1543570.8750],
        [1572169.7500, 1571018.6250, 1570451.0000, 1570152.8750, 1568623.3750,
         1568384.0000, 1567715.6250, 1567150.5000, 1567062.3750, 1566745.5000],
        [1568197.0000, 1566527.3750, 1566051.0000, 1565910.6250, 1565826.8750,
         1565437.2500, 1563496.1250, 1563199.5000, 1560427.6250, 1560088.2500],
        [1519980.6250, 1519577.7500, 1515318.7500, 1514677.1250, 1513792.1250,
         1505578.3750, 1504497.5000, 1502851.2500, 1501590.5000, 1499402.6250],
        [1504015.5000, 1494530.0000, 1491680.8750, 1489429.1250, 1488002.2500,
         1487891.5000, 1485960.2500, 1485035.0000, 1483654.8750, 1483388.8750],
        [1487490.0000, 1476829.3750, 1467553.2500, 1463856.1250, 1461345.3750,
         1457185.6250, 1455644.0000, 1449722.8750, 1449367.5000, 1449216.8750],
        [1554633.1250, 1552176.8750, 1551778.7500, 1547885.6250, 1547845.6250,
         1547664.2500, 1547495.8750, 1547313.0000, 1546293.6250, 1546237.6250],
        [1558889.6250, 1555634.2500, 1554904.3750, 1554707.2500, 1552609.1250,
         1551186.8750, 1550463.6250, 1548136.5000, 1546714.0000, 1546343.7500],
        [1503006.0000, 1486673.1250, 1485518.1250, 1483456.7500, 1478450.0000,
         1477728.3750, 1473984.3750, 1458357.6250, 1458233.8750, 1454497.7500],
        [1570358.1250, 1568463.3750, 1559969.2500, 1555721.7500, 1552579.6250,
         1549933.0000, 1547546.1250, 1544027.2500, 1540753.0000, 1539641.0000],
        [1575267.5000, 1573830.5000, 1573627.7500, 1569573.5000, 1568834.2500,
         1568478.2500, 1568354.1250, 1567860.5000, 1567340.3750, 1566851.6250],
        [1506907.0000, 1493487.1250, 1487440.3750, 1485475.6250, 1483656.3750,
         1481065.0000, 1480439.5000, 1476811.1250, 1473949.2500, 1473290.1250],
        [1572766.6250, 1572510.1250, 1567603.3750, 1565258.0000, 1564962.5000,
         1564197.1250, 1563967.3750, 1563277.0000, 1563183.1250, 1562422.8750],
        [1565132.6250, 1562129.5000, 1559552.7500, 1556199.5000, 1555887.8750,
         1555819.6250, 1554031.2500, 1553917.2500, 1553277.1250, 1552852.0000],
        [1572673.6250, 1571316.8750, 1570485.3750, 1570392.6250, 1569753.1250,
         1567781.3750, 1566116.6250, 1565241.6250, 1564355.1250, 1564003.2500],
        [1577182.6250, 1576307.5000, 1575933.1250, 1575240.3750, 1572934.6250,
         1572756.1250, 1572369.1250, 1571976.3750, 1571808.3750, 1571750.0000],
        [1578950.8750, 1578834.8750, 1576665.1250, 1575079.6250, 1574857.3750,
         1574457.8750, 1573060.6250, 1572103.7500, 1571760.5000, 1571736.5000],
        [1579300.2500, 1579214.5000, 1577217.1250, 1576746.5000, 1575835.3750,
         1573964.0000, 1573947.5000, 1573881.5000, 1573866.3750, 1573677.2500],
        [1578124.3750, 1576606.5000, 1576305.8750, 1574994.0000, 1574411.3750,
         1573149.1250, 1572954.1250, 1571262.8750, 1571108.6250, 1570711.6250],
        [1369095.1250, 1361139.3750, 1195416.5000, 1185592.2500, 1135909.8750,
         1116809.2500, 1077112.5000, 1075968.7500, 1033317.1875,  941507.4375],
        [1531344.0000, 1529737.0000, 1528147.5000, 1527515.2500, 1525501.8750,
         1523521.7500, 1521594.8750, 1521181.3750, 1520074.8750, 1517163.8750],
        [1552351.5000, 1549158.6250, 1548267.8750, 1548267.8750, 1546439.6250,
         1545223.5000, 1544508.8750, 1543722.5000, 1543462.0000, 1542994.0000],
        [1525391.2500, 1522400.5000, 1520926.0000, 1520380.7500, 1517133.5000,
         1514667.1250, 1514508.2500, 1512718.3750, 1512434.1250, 1511936.6250],
        [1365517.1250, 1311093.8750, 1263606.3750, 1226193.7500, 1192702.8750,
         1172052.5000, 1157283.5000, 1145349.7500, 1143480.0000, 1120897.0000],
        [1502328.2500, 1498484.7500, 1495002.0000, 1493826.1250, 1492943.1250,
         1489292.7500, 1489109.5000, 1488560.1250, 1487908.6250, 1485615.8750],
        [1453410.6250, 1452798.2500, 1450265.0000, 1421987.7500, 1420114.8750,
         1416756.1250, 1412897.1250, 1412319.2500, 1407598.2500, 1404401.5000],
        [1509104.5000, 1506299.2500, 1502442.8750, 1500067.6250, 1499479.7500,
         1499419.6250, 1499245.2500, 1499179.5000, 1498069.1250, 1498069.1250],
        [1308331.0000, 1295259.5000, 1288801.7500, 1272323.6250, 1270917.0000,
         1266357.0000, 1262389.8750, 1234787.1250, 1201268.8750, 1184117.7500],
        [1561066.1250, 1559658.3750, 1559435.3750, 1559020.3750, 1558816.7500,
         1557942.8750, 1557059.1250, 1555598.6250, 1555085.3750, 1554728.0000],
        [1557344.2500, 1555352.3750, 1553388.1250, 1551595.1250, 1548309.3750,
         1547410.3750, 1547258.3750, 1547109.2500, 1546792.1250, 1546705.1250],
        [1537273.0000, 1537078.0000, 1535752.0000, 1535747.6250, 1532808.0000,
         1531852.2500, 1530447.5000, 1529650.8750, 1528707.2500, 1528625.6250],
        [1411528.7500, 1406118.2500, 1393049.8750, 1367070.2500, 1363346.5000,
         1361819.7500, 1332993.5000, 1332133.1250, 1324915.1250, 1324250.7500],
        [1310418.8750, 1269424.6250, 1267364.6250, 1245926.5000, 1245208.8750,
         1241093.8750, 1231161.8750, 1230605.5000, 1219196.2500, 1212722.0000],
        [1372653.7500, 1355914.2500, 1171087.1250, 1103827.5000,  982490.3750,
          977639.4375,  969473.7500,  963963.3125,  950906.5000,  941786.8125],
        [1108462.7500, 1078842.6250, 1075837.3750, 1048171.1250, 1037573.1875,
          979987.1250,  979368.6875,  878173.3750,  873403.4375,  863076.5625],
        [1443543.6250, 1382016.6250, 1379639.7500, 1377311.5000, 1377236.6250,
         1350584.3750, 1346312.2500, 1345576.7500, 1342163.8750, 1341841.3750],
        [1474205.1250, 1471888.5000, 1469821.0000, 1463539.2500, 1460119.3750,
         1458296.5000, 1454771.1250, 1451600.2500, 1450383.8750, 1444368.3750],
        [1466495.6250, 1430252.7500, 1427771.1250, 1425121.1250, 1423268.5000,
         1421365.5000, 1413193.6250, 1408344.7500, 1407845.1250, 1400163.5000],
        [1414856.3750, 1400167.6250, 1395441.8750, 1394274.0000, 1386958.6250,
         1356149.7500, 1299777.2500, 1287773.2500, 1287725.3750, 1282399.3750],
        [1465280.7500, 1460221.1250, 1458648.3750, 1438026.8750, 1431573.8750,
         1425185.0000, 1407763.2500, 1407713.6250, 1402480.8750, 1395017.3750],
        [1416476.5000, 1379017.5000, 1356473.0000, 1324475.5000, 1324390.8750,
         1320189.1250, 1319294.2500, 1292909.7500, 1281183.0000, 1275849.8750],
        [1488440.7500, 1484416.3750, 1478684.1250, 1477404.2500, 1475134.6250,
         1473918.3750, 1472492.2500, 1471807.1250, 1471807.1250, 1468784.0000],
        [1513152.6250, 1499956.0000, 1490564.5000, 1485971.5000, 1479874.7500,
         1476446.5000, 1475025.0000, 1469784.5000, 1465778.2500, 1458990.6250],
        [1486213.8750, 1415097.8750, 1411787.2500, 1390546.5000, 1382130.0000,
         1381668.7500, 1373023.0000, 1358947.3750, 1347842.3750, 1345390.7500],
        [1445621.1250, 1435271.5000, 1413364.7500, 1376882.1250, 1352706.0000,
         1347305.1250, 1340414.0000, 1330105.7500, 1323495.6250, 1320452.2500],
        [1450602.5000, 1422746.0000, 1420292.2500, 1413447.0000, 1404417.6250,
         1384570.6250, 1380414.8750, 1359118.5000, 1348123.8750, 1340610.8750],
        [1528720.3750, 1487785.1250, 1472228.2500, 1444958.1250, 1437904.7500,
         1423869.8750, 1397150.3750, 1394550.5000, 1373113.3750, 1365699.3750],
        [1396308.5000, 1348930.2500, 1346705.1250, 1338628.0000, 1338039.6250,
         1326808.1250, 1326498.1250, 1325085.7500, 1317564.1250, 1305389.6250],
        [1450551.2500, 1427342.3750, 1365487.1250, 1339389.1250, 1318999.8750,
         1315059.7500, 1294672.8750, 1293843.5000, 1293446.1250, 1293271.0000],
        [1445497.0000, 1423052.6250, 1394700.7500, 1391972.8750, 1385161.0000,
         1366595.7500, 1321368.1250, 1288997.1250, 1280157.1250, 1277232.7500],
        [1450648.1250, 1450288.5000, 1448218.1250, 1428215.1250, 1423867.1250,
         1421215.0000, 1417106.0000, 1404401.5000, 1398871.6250, 1398432.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1527426.3750,       0.0000],
         [1526244.1250,       0.0000],
         [1507404.3750,       0.0000],
         ...,
         [1492976.0000,       0.0000],
         [1492546.0000,       0.0000],
         [1486807.8750,       0.0000]],

        [[1539259.3750,       0.0000],
         [1538889.5000,       0.0000],
         [1534033.3750,       0.0000],
         ...,
         [1529079.1250,       0.0000],
         [1528618.3750,       0.0000],
         [1528316.6250,       0.0000]],

        [[1202274.1250,       0.0000],
         [1059473.2500,       0.0000],
         [1031796.6875,       0.0000],
         ...,
         [ 954790.3750,       0.0000],
         [      0.0000,  945661.2500],
         [      0.0000,  939722.4375]],

        ...,

        [[1450551.2500,       0.0000],
         [1427342.3750,       0.0000],
         [1365487.1250,       0.0000],
         ...,
         [      0.0000, 1293843.5000],
         [1293446.1250,       0.0000],
         [1293271.0000,       0.0000]],

        [[1445497.0000,       0.0000],
         [1423052.6250,       0.0000],
         [1394700.7500,       0.0000],
         ...,
         [1288997.1250,       0.0000],
         [      0.0000, 1280157.1250],
         [      0.0000, 1277232.7500]],

        [[      0.0000, 1450648.1250],
         [      0.0000, 1450288.5000],
         [      0.0000, 1448218.1250],
         ...,
         [      0.0000, 1404401.5000],
         [      0.0000, 1398871.6250],
         [      0.0000, 1398432.7500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[15025561.0000,        0.0000],
        [15318888.0000,        0.0000],
        [ 5255140.5000,  4870539.5000],
        [14207468.0000,        0.0000],
        [ 9268914.0000,  3951809.0000],
        [10641981.0000,  1221186.1250],
        [ 4101600.5000,  6046286.0000],
        [ 8319782.0000,  1815579.7500],
        [12287027.0000,  3057945.2500],
        [11881572.0000,  1366801.7500],
        [15497112.0000,        0.0000],
        [14210042.0000,        0.0000],
        [13833524.0000,        0.0000],
        [15535545.0000,        0.0000],
        [15689474.0000,        0.0000],
        [15645161.0000,        0.0000],
        [12091178.0000,  3006088.0000],
        [11906184.0000,  2987404.5000],
        [14618211.0000,        0.0000],
        [15489324.0000,        0.0000],
        [15519590.0000,        0.0000],
        [11796660.0000,  2963246.5000],
        [15528993.0000,        0.0000],
        [15700018.0000,        0.0000],
        [11842127.0000,  3000394.0000],
        [15660148.0000,        0.0000],
        [15568799.0000,        0.0000],
        [15682120.0000,        0.0000],
        [15738258.0000,        0.0000],
        [15747508.0000,        0.0000],
        [15757650.0000,        0.0000],
        [15739629.0000,        0.0000],
        [ 3094588.7500,  8397280.0000],
        [12188936.0000,  3056846.0000],
        [12377212.0000,  3087184.5000],
        [15172496.0000,        0.0000],
        [ 4631002.0000,  7467175.0000],
        [11922258.0000,  3000813.0000],
        [12835793.0000,  1416756.1250],
        [15011377.0000,        0.0000],
        [ 9987421.0000,  2597132.7500],
        [15578411.0000,        0.0000],
        [15501264.0000,        0.0000],
        [13795134.0000,  1532808.0000],
        [ 2657908.5000, 10959318.0000],
        [ 1219196.2500, 11253926.0000],
        [ 5786260.5000,  5003482.5000],
        [  878173.3750,  9044723.0000],
        [ 6793306.0000,  6892920.5000],
        [10191428.0000,  4407565.0000],
        [11329555.0000,  2894266.7500],
        [ 3869902.0000,  9635622.0000],
        [       0.0000, 14291910.0000],
        [ 3920430.0000,  9369829.0000],
        [11790032.0000,  2972857.0000],
        [10331952.0000,  4483592.0000],
        [ 2755153.0000, 11137495.0000],
        [ 2729588.0000, 10956030.0000],
        [       0.0000, 13924344.0000],
        [ 2770263.7500, 11555716.0000],
        [10635021.0000,  2734936.5000],
        [10783159.0000,  2608903.2500],
        [ 9695977.0000,  3878758.0000],
        [       0.0000, 14241264.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 301/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.82s/it]  7%|▋         | 2/29 [01:01<11:30, 25.58s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.941418409347534
Epoch 302/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:29, 58.89s/it]  7%|▋         | 2/29 [00:59<11:09, 24.79s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.9430177211761475
Epoch 303/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.41s/it]  7%|▋         | 2/29 [01:01<11:36, 25.81s/it] 10%|█         | 3/29 [01:02<06:15, 14.44s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9513182640075684
Epoch 304/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:42, 61.53s/it]  7%|▋         | 2/29 [01:02<11:38, 25.88s/it] 10%|█         | 3/29 [01:03<06:16, 14.48s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.9396166801452637
Epoch 305/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:30, 58.96s/it]  7%|▋         | 2/29 [01:01<11:40, 25.95s/it] 10%|█         | 3/29 [01:02<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:05<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.9381134510040283
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0135, 0.0023,  ..., 0.0041, 0.0001, 0.0169],
        [0.0030, 0.0103, 0.0026,  ..., 0.0037, 0.0005, 0.0169],
        [0.0302, 0.0075, 0.0043,  ..., 0.0055, 0.0150, 0.0225],
        ...,
        [0.0055, 0.0079, 0.0214,  ..., 0.0043, 0.0013, 0.0205],
        [0.0051, 0.0101, 0.0165,  ..., 0.0046, 0.0040, 0.0189],
        [0.0083, 0.0058, 0.0050,  ..., 0.0023, 0.0033, 0.0208]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9965, 0.9957, 0.9954, 0.9952, 0.9951, 0.9950, 0.9950, 0.9948,
         0.9946],
        [0.9972, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9799, 0.9711, 0.9698, 0.9693, 0.9680, 0.9666, 0.9665, 0.9638, 0.9637,
         0.9634],
        [0.9927, 0.9926, 0.9926, 0.9920, 0.9915, 0.9915, 0.9913, 0.9911, 0.9909,
         0.9902],
        [0.9898, 0.9874, 0.9869, 0.9869, 0.9868, 0.9863, 0.9862, 0.9857, 0.9856,
         0.9855],
        [0.9860, 0.9849, 0.9811, 0.9809, 0.9793, 0.9770, 0.9768, 0.9768, 0.9746,
         0.9746],
        [0.9765, 0.9757, 0.9706, 0.9701, 0.9673, 0.9671, 0.9665, 0.9655, 0.9644,
         0.9639],
        [0.9799, 0.9792, 0.9750, 0.9667, 0.9660, 0.9646, 0.9639, 0.9612, 0.9601,
         0.9587],
        [0.9978, 0.9973, 0.9970, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9937, 0.9888, 0.9876, 0.9872, 0.9871, 0.9858, 0.9851, 0.9850, 0.9848,
         0.9847],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9940, 0.9935, 0.9927, 0.9917, 0.9910, 0.9909, 0.9904, 0.9903, 0.9901,
         0.9900],
        [0.9945, 0.9925, 0.9912, 0.9902, 0.9901, 0.9891, 0.9885, 0.9878, 0.9874,
         0.9867],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9973],
        [0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9981,
         0.9981],
        [0.9963, 0.9963, 0.9960, 0.9960, 0.9959, 0.9956, 0.9955, 0.9955, 0.9954,
         0.9953],
        [0.9956, 0.9950, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947, 0.9946,
         0.9946],
        [0.9947, 0.9941, 0.9935, 0.9934, 0.9934, 0.9933, 0.9932, 0.9930, 0.9928,
         0.9927],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9954, 0.9946, 0.9946, 0.9946, 0.9943, 0.9943, 0.9940, 0.9935, 0.9934,
         0.9932],
        [0.9985, 0.9985, 0.9981, 0.9979, 0.9978, 0.9976, 0.9975, 0.9973, 0.9972,
         0.9971],
        [0.9989, 0.9988, 0.9988, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9958, 0.9951, 0.9949, 0.9947, 0.9946, 0.9945, 0.9945, 0.9944, 0.9942,
         0.9941],
        [0.9988, 0.9987, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9983, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9889, 0.9888, 0.9792, 0.9775, 0.9749, 0.9737, 0.9735, 0.9731, 0.9695,
         0.9656],
        [0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9978, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9965, 0.9964, 0.9963, 0.9963, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959,
         0.9959],
        [0.9890, 0.9862, 0.9838, 0.9802, 0.9781, 0.9779, 0.9775, 0.9754, 0.9751,
         0.9749],
        [0.9953, 0.9953, 0.9952, 0.9950, 0.9949, 0.9948, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9933, 0.9931, 0.9930, 0.9918, 0.9917, 0.9916, 0.9912, 0.9911, 0.9911,
         0.9910],
        [0.9958, 0.9956, 0.9954, 0.9954, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9952],
        [0.9859, 0.9856, 0.9844, 0.9842, 0.9838, 0.9837, 0.9834, 0.9827, 0.9803,
         0.9793],
        [0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9971, 0.9970, 0.9969, 0.9969, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9908, 0.9904, 0.9899, 0.9884, 0.9882, 0.9882, 0.9867, 0.9865, 0.9865,
         0.9860],
        [0.9861, 0.9829, 0.9827, 0.9821, 0.9816, 0.9815, 0.9808, 0.9806, 0.9802,
         0.9799],
        [0.9898, 0.9884, 0.9777, 0.9734, 0.9653, 0.9644, 0.9641, 0.9635, 0.9627,
         0.9624],
        [0.9735, 0.9721, 0.9712, 0.9696, 0.9687, 0.9651, 0.9646, 0.9592, 0.9581,
         0.9564],
        [0.9925, 0.9895, 0.9893, 0.9892, 0.9892, 0.9878, 0.9875, 0.9874, 0.9873,
         0.9871],
        [0.9940, 0.9939, 0.9939, 0.9935, 0.9934, 0.9932, 0.9929, 0.9928, 0.9927,
         0.9925],
        [0.9937, 0.9919, 0.9918, 0.9917, 0.9915, 0.9915, 0.9911, 0.9908, 0.9906,
         0.9905],
        [0.9910, 0.9901, 0.9897, 0.9897, 0.9896, 0.9876, 0.9847, 0.9840, 0.9840,
         0.9833],
        [0.9936, 0.9936, 0.9934, 0.9926, 0.9921, 0.9919, 0.9909, 0.9908, 0.9906,
         0.9904],
        [0.9915, 0.9892, 0.9878, 0.9867, 0.9864, 0.9862, 0.9861, 0.9850, 0.9839,
         0.9837],
        [0.9947, 0.9946, 0.9942, 0.9942, 0.9941, 0.9939, 0.9938, 0.9938, 0.9938,
         0.9937],
        [0.9958, 0.9952, 0.9949, 0.9944, 0.9943, 0.9941, 0.9939, 0.9938, 0.9936,
         0.9932],
        [0.9949, 0.9912, 0.9912, 0.9901, 0.9899, 0.9896, 0.9893, 0.9888, 0.9879,
         0.9877],
        [0.9928, 0.9924, 0.9911, 0.9896, 0.9882, 0.9878, 0.9876, 0.9869, 0.9867,
         0.9863],
        [0.9931, 0.9919, 0.9915, 0.9912, 0.9910, 0.9896, 0.9895, 0.9885, 0.9883,
         0.9872],
        [0.9968, 0.9948, 0.9939, 0.9927, 0.9926, 0.9918, 0.9904, 0.9901, 0.9890,
         0.9886],
        [0.9904, 0.9884, 0.9879, 0.9875, 0.9871, 0.9869, 0.9868, 0.9864, 0.9863,
         0.9861],
        [0.9928, 0.9917, 0.9883, 0.9871, 0.9860, 0.9855, 0.9847, 0.9846, 0.9844,
         0.9842],
        [0.9925, 0.9915, 0.9900, 0.9899, 0.9895, 0.9885, 0.9859, 0.9845, 0.9840,
         0.9833],
        [0.9928, 0.9928, 0.9927, 0.9918, 0.9916, 0.9914, 0.9912, 0.9905, 0.9904,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 0, 1, 1],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 0, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1523742.5000, 1523203.5000, 1504687.0000, 1498130.5000, 1493913.1250,
         1491295.3750, 1490925.5000, 1489410.6250, 1485479.8750, 1482500.7500],
        [1536516.7500, 1534052.5000, 1530524.8750, 1530021.3750, 1527797.8750,
         1527293.8750, 1526305.1250, 1526105.7500, 1525795.7500, 1525458.2500],
        [1200408.8750, 1059233.8750, 1039869.3750, 1032582.2500, 1012727.1875,
          993744.6250,  991677.0000,  954666.5000,  952778.3125,  948090.3750],
        [1441282.1250, 1440189.7500, 1438779.8750, 1427072.7500, 1418079.3750,
         1417787.3750, 1412761.1250, 1409234.1250, 1404763.2500, 1390805.1250],
        [1382546.6250, 1337395.3750, 1328062.5000, 1326720.7500, 1324442.6250,
         1315008.3750, 1314578.2500, 1303984.8750, 1302616.5000, 1300769.2500],
        [1309710.3750, 1289545.5000, 1220791.3750, 1219032.3750, 1191195.5000,
         1152473.7500, 1149009.1250, 1148851.3750, 1114096.6250, 1112913.7500],
        [1143145.3750, 1130807.1250, 1051155.2500, 1044052.8125, 1002444.6250,
         1000709.9375,  991554.0625,  977604.9375,  962125.6250,  954907.8125],
        [1201474.0000, 1188225.1250, 1120150.0000,  994639.6875,  984711.6250,
          965162.9375,  955896.3750,  919413.3125,  904710.4375,  887060.3125],
        [1551473.8750, 1539077.2500, 1533786.2500, 1528375.0000, 1527658.0000,
         1526511.8750, 1526425.8750, 1526085.2500, 1525231.3750, 1524973.8750],
        [1463096.8750, 1364474.3750, 1339803.0000, 1332698.5000, 1330604.3750,
         1306834.6250, 1292839.3750, 1291247.3750, 1287143.3750, 1286447.6250],
        [1553441.5000, 1548715.3750, 1548399.3750, 1548254.6250, 1548136.5000,
         1547277.5000, 1546520.7500, 1546473.6250, 1544986.1250, 1544827.1250],
        [1469500.0000, 1458332.6250, 1441078.6250, 1421072.7500, 1407227.7500,
         1404587.7500, 1395459.1250, 1393782.0000, 1389340.2500, 1387647.8750],
        [1478672.8750, 1438454.7500, 1410491.2500, 1390904.6250, 1389910.0000,
         1368938.5000, 1358175.2500, 1345094.3750, 1336490.1250, 1322728.5000],
        [1566140.5000, 1562564.5000, 1559695.5000, 1559332.6250, 1549414.2500,
         1547841.3750, 1545280.8750, 1543909.5000, 1542133.3750, 1540127.2500],
        [1570045.1250, 1569072.1250, 1568536.5000, 1568321.1250, 1566987.6250,
         1566759.0000, 1565806.0000, 1565668.6250, 1565225.2500, 1564662.6250],
        [1566104.6250, 1564595.5000, 1564089.6250, 1563940.5000, 1563558.7500,
         1563473.7500, 1562013.2500, 1561128.6250, 1557935.3750, 1557889.3750],
        [1517994.6250, 1517406.8750, 1511496.8750, 1510917.5000, 1508752.0000,
         1502630.5000, 1501444.5000, 1501428.7500, 1498634.8750, 1496738.1250],
        [1502735.2500, 1490558.7500, 1488188.2500, 1486423.6250, 1486246.5000,
         1485967.3750, 1485886.5000, 1484542.3750, 1481515.6250, 1481298.1250],
        [1484373.8750, 1471268.2500, 1457933.5000, 1456992.5000, 1455730.1250,
         1454586.6250, 1452113.8750, 1447277.7500, 1442900.7500, 1442836.2500],
        [1552474.3750, 1550897.0000, 1547825.1250, 1546737.6250, 1546141.7500,
         1545923.6250, 1545883.7500, 1545524.0000, 1545459.1250, 1545136.5000],
        [1558507.6250, 1554679.1250, 1554249.1250, 1553109.6250, 1550919.1250,
         1549241.2500, 1549161.5000, 1546053.2500, 1545844.0000, 1545656.7500],
        [1498309.0000, 1482482.3750, 1481628.7500, 1480642.7500, 1475109.5000,
         1474378.0000, 1469400.5000, 1458300.6250, 1456007.7500, 1451328.8750],
        [1567328.3750, 1565274.5000, 1558127.1250, 1552660.8750, 1550400.1250,
         1547326.2500, 1545235.2500, 1540758.7500, 1536688.1250, 1536272.0000],
        [1574809.3750, 1573182.2500, 1573102.6250, 1568280.8750, 1568092.3750,
         1567766.3750, 1567588.5000, 1566774.0000, 1565753.7500, 1565344.6250],
        [1506086.7500, 1492580.1250, 1487600.6250, 1483113.1250, 1480589.0000,
         1479228.5000, 1479066.3750, 1476367.6250, 1472892.6250, 1471436.6250],
        [1572069.3750, 1571477.2500, 1565093.7500, 1563678.0000, 1563269.5000,
         1562125.0000, 1562014.7500, 1561821.1250, 1561432.3750, 1559927.6250],
        [1562741.7500, 1560365.0000, 1556687.8750, 1553863.7500, 1552471.5000,
         1552398.8750, 1551496.0000, 1551234.1250, 1550931.0000, 1550120.6250],
        [1571101.1250, 1568502.2500, 1568349.5000, 1568325.7500, 1568123.7500,
         1565640.3750, 1562902.8750, 1562788.0000, 1562697.1250, 1560749.1250],
        [1576078.8750, 1575121.7500, 1575016.5000, 1573839.5000, 1571474.2500,
         1571228.5000, 1571045.6250, 1570728.0000, 1570518.3750, 1570233.7500],
        [1578484.1250, 1577785.8750, 1575695.6250, 1574078.1250, 1573696.7500,
         1573402.6250, 1572111.2500, 1571339.3750, 1571185.0000, 1571033.6250],
        [1578399.8750, 1577469.8750, 1576039.7500, 1575655.0000, 1574328.7500,
         1572726.1250, 1572721.6250, 1572676.6250, 1572169.7500, 1572021.2500],
        [1576872.7500, 1575637.0000, 1575566.5000, 1573537.7500, 1572585.1250,
         1572171.3750, 1571233.0000, 1570304.2500, 1570016.7500, 1569347.6250],
        [1365023.6250, 1362863.0000, 1188901.8750, 1160729.8750, 1118026.2500,
         1099685.5000, 1095467.2500, 1090185.3750, 1034519.1250,  978863.5000],
        [1529645.1250, 1526632.6250, 1526578.8750, 1524789.1250, 1523425.7500,
         1519880.6250, 1519201.0000, 1517893.2500, 1516757.3750, 1515908.5000],
        [1550191.5000, 1547118.1250, 1545241.1250, 1545241.1250, 1545107.0000,
         1542621.7500, 1542589.3750, 1542380.5000, 1542233.3750, 1540591.3750],
        [1521851.7500, 1519537.1250, 1518010.5000, 1517823.7500, 1512647.6250,
         1511164.0000, 1510927.6250, 1509801.2500, 1509287.2500, 1508868.6250],
        [1367088.5000, 1313593.2500, 1269619.5000, 1206633.2500, 1169940.6250,
         1167577.7500, 1160417.7500, 1126657.5000, 1120974.0000, 1117571.0000],
        [1497300.6250, 1495499.6250, 1493652.3750, 1490381.1250, 1487514.1250,
         1486748.3750, 1486501.6250, 1484777.3750, 1484671.1250, 1482879.6250],
        [1454443.7500, 1449623.3750, 1448635.1250, 1424308.6250, 1421328.8750,
         1418510.8750, 1411574.5000, 1410026.0000, 1409263.7500, 1406519.2500],
        [1507667.3750, 1502392.6250, 1499250.8750, 1497806.1250, 1496585.3750,
         1496334.2500, 1496090.2500, 1495113.1250, 1494822.2500, 1494822.2500],
        [1308455.7500, 1303097.3750, 1281262.3750, 1277370.3750, 1269915.0000,
         1267138.5000, 1262800.5000, 1249918.0000, 1208601.3750, 1190112.2500],
        [1558690.3750, 1558148.0000, 1557562.5000, 1556607.7500, 1555972.5000,
         1555859.7500, 1553970.5000, 1553102.3750, 1552350.1250, 1552123.6250],
        [1555331.5000, 1553967.5000, 1551200.2500, 1550008.2500, 1545992.7500,
         1545633.1250, 1545049.6250, 1544931.6250, 1544645.8750, 1544592.8750],
        [1534526.6250, 1533011.2500, 1531211.1250, 1531125.0000, 1527346.2500,
         1526989.5000, 1526615.2500, 1525302.5000, 1523822.5000, 1523576.8750],
        [1403139.1250, 1395997.0000, 1385973.6250, 1355243.3750, 1352433.8750,
         1351717.0000, 1322681.8750, 1320373.0000, 1320145.1250, 1310440.1250],
        [1311442.7500, 1254148.5000, 1249770.2500, 1238571.8750, 1231060.8750,
         1228171.5000, 1216680.3750, 1213388.3750, 1206612.5000, 1200935.5000],
        [1384022.7500, 1355372.6250, 1163760.2500, 1095000.3750,  975199.7500,
          961733.9375,  958543.7500,  950287.3125,  938970.7500,  934617.2500],
        [1095829.8750, 1074480.8750, 1060184.7500, 1036404.2500, 1023554.3750,
          972432.2500,  964953.0000,  893349.3750,  879178.0625,  858074.3125],
        [1436993.1250, 1377756.7500, 1372640.7500, 1371970.6250, 1370686.3750,
         1344703.1250, 1338730.1250, 1336570.5000, 1334136.8750, 1331865.1250],
        [1468345.7500, 1466815.8750, 1466439.6250, 1459447.1250, 1455756.3750,
         1452086.2500, 1446401.6250, 1443210.5000, 1441942.0000, 1438436.8750],
        [1463278.2500, 1425994.0000, 1422695.8750, 1421221.7500, 1417810.3750,
         1417783.3750, 1409008.3750, 1402336.5000, 1399565.5000, 1397103.7500],
        [1407163.2500, 1389474.0000, 1381400.0000, 1380958.6250, 1379869.8750,
         1340998.3750, 1285568.2500, 1273239.0000, 1273188.0000, 1261073.5000],
        [1461141.8750, 1459511.1250, 1456497.8750, 1440518.0000, 1430385.1250,
         1426457.7500, 1405885.0000, 1403402.6250, 1398606.1250, 1396102.1250],
        [1416342.6250, 1371497.0000, 1343655.8750, 1323633.2500, 1318285.5000,
         1314033.0000, 1312392.3750, 1291689.6250, 1270689.1250, 1267574.8750],
        [1482575.7500, 1482100.7500, 1473383.0000, 1472415.0000, 1471008.7500,
         1467589.6250, 1464776.3750, 1464576.6250, 1464576.6250, 1463274.0000],
        [1507701.8750, 1494002.8750, 1488244.8750, 1477529.7500, 1474251.5000,
         1471240.2500, 1467763.3750, 1464710.6250, 1460586.0000, 1451801.0000],
        [1488660.8750, 1411687.6250, 1410916.5000, 1389684.7500, 1384322.3750,
         1378866.2500, 1374073.5000, 1364301.2500, 1345928.5000, 1341660.8750],
        [1444241.6250, 1435438.6250, 1408888.7500, 1378924.1250, 1351795.6250,
         1344944.2500, 1341458.7500, 1326288.1250, 1324135.7500, 1315756.0000],
        [1449250.1250, 1425042.3750, 1416404.7500, 1412154.8750, 1406756.7500,
         1378607.2500, 1377685.8750, 1357714.2500, 1354153.0000, 1333507.1250],
        [1527832.7500, 1485682.5000, 1466495.6250, 1442496.3750, 1438775.7500,
         1422971.2500, 1394445.3750, 1388580.0000, 1367112.0000, 1359867.8750],
        [1395199.6250, 1355838.0000, 1346079.8750, 1337973.2500, 1330093.1250,
         1328124.6250, 1325792.3750, 1317753.8750, 1315656.8750, 1313038.3750],
        [1444135.7500, 1421507.8750, 1353839.2500, 1330296.1250, 1310346.3750,
         1299995.5000, 1285725.2500, 1284975.0000, 1281410.2500, 1277498.3750],
        [1438089.8750, 1416552.0000, 1386864.7500, 1385186.1250, 1376574.8750,
         1357580.8750, 1307842.0000, 1281681.6250, 1272460.7500, 1261279.1250],
        [1443759.7500, 1443330.2500, 1442463.2500, 1422808.5000, 1419274.1250,
         1415570.3750, 1411715.8750, 1397420.8750, 1395815.8750, 1393681.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1523742.5000,       0.0000],
         [1523203.5000,       0.0000],
         [1504687.0000,       0.0000],
         ...,
         [1489410.6250,       0.0000],
         [1485479.8750,       0.0000],
         [1482500.7500,       0.0000]],

        [[1536516.7500,       0.0000],
         [1534052.5000,       0.0000],
         [1530524.8750,       0.0000],
         ...,
         [1526105.7500,       0.0000],
         [1525795.7500,       0.0000],
         [1525458.2500,       0.0000]],

        [[1200408.8750,       0.0000],
         [1059233.8750,       0.0000],
         [1039869.3750,       0.0000],
         ...,
         [ 954666.5000,       0.0000],
         [      0.0000,  952778.3125],
         [      0.0000,  948090.3750]],

        ...,

        [[1444135.7500,       0.0000],
         [1421507.8750,       0.0000],
         [1353839.2500,       0.0000],
         ...,
         [1284975.0000,       0.0000],
         [      0.0000, 1281410.2500],
         [1277498.3750,       0.0000]],

        [[1438089.8750,       0.0000],
         [1416552.0000,       0.0000],
         [1386864.7500,       0.0000],
         ...,
         [1281681.6250,       0.0000],
         [      0.0000, 1272460.7500],
         [      0.0000, 1261279.1250]],

        [[      0.0000, 1443759.7500],
         [      0.0000, 1443330.2500],
         [      0.0000, 1442463.2500],
         ...,
         [      0.0000, 1397420.8750],
         [      0.0000, 1395815.8750],
         [      0.0000, 1393681.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14983289.0000,        0.0000],
        [15289872.0000,        0.0000],
        [ 5266906.0000,  4918872.5000],
        [14200755.0000,        0.0000],
        [ 9278725.0000,  3957399.7500],
        [10688587.0000,  1219032.3750],
        [ 3184407.0000,  7074101.0000],
        [ 8314970.0000,  1806473.6250],
        [13781940.0000,  1527658.0000],
        [11930716.0000,  1364474.3750],
        [15477032.0000,        0.0000],
        [14168029.0000,        0.0000],
        [13839861.0000,        0.0000],
        [15516440.0000,        0.0000],
        [15671084.0000,        0.0000],
        [15624730.0000,        0.0000],
        [12067382.0000,  3000063.5000],
        [13370627.0000,  1502735.2500],
        [14566014.0000,        0.0000],
        [15472002.0000,        0.0000],
        [15507421.0000,        0.0000],
        [11770728.0000,  2956860.5000],
        [15500072.0000,        0.0000],
        [15690694.0000,        0.0000],
        [11830295.0000,  2998667.0000],
        [15642909.0000,        0.0000],
        [15542310.0000,        0.0000],
        [15659180.0000,        0.0000],
        [15725286.0000,        0.0000],
        [15738812.0000,        0.0000],
        [15744208.0000,        0.0000],
        [15727272.0000,        0.0000],
        [ 3174016.2500,  8320249.0000],
        [12167642.0000,  3053071.0000],
        [12358460.0000,  3084855.0000],
        [15139919.0000,        0.0000],
        [ 3464176.0000,  8555897.0000],
        [10410624.0000,  4479302.0000],
        [12844970.0000,  1409263.7500],
        [14980884.0000,        0.0000],
        [10034312.0000,  2584359.7500],
        [15554387.0000,        0.0000],
        [15481354.0000,        0.0000],
        [13756912.0000,  1526615.2500],
        [ 2642827.0000, 10875317.0000],
        [ 1206612.5000, 11144170.0000],
        [ 5719353.0000,  4998156.0000],
        [  879178.0625,  8979264.0000],
        [ 6755609.0000,  6860444.5000],
        [10144650.0000,  4394232.5000],
        [11292298.0000,  2884500.0000],
        [ 2546641.7500, 10826291.0000],
        [       0.0000, 14278508.0000],
        [ 3905241.2500,  9324552.0000],
        [11741600.0000,  2964676.5000],
        [10287634.0000,  4470198.5000],
        [ 2758396.0000, 11131707.0000],
        [ 2730719.7500, 10941152.0000],
        [       0.0000, 13911276.0000],
        [ 2748448.0000, 11545811.0000],
        [10640257.0000,  2725292.7500],
        [10708324.0000,  2581405.7500],
        [ 9642531.0000,  3841582.0000],
        [       0.0000, 14185840.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 306/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:44, 57.32s/it]  7%|▋         | 2/29 [01:01<11:41, 26.00s/it] 10%|█         | 3/29 [01:02<06:18, 14.55s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.20s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.934358596801758
Epoch 307/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:58, 57.82s/it]  7%|▋         | 2/29 [01:01<11:39, 25.89s/it] 10%|█         | 3/29 [01:02<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:05<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.932468891143799
Epoch 308/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:35, 61.25s/it]  7%|▋         | 2/29 [01:02<11:35, 25.76s/it] 10%|█         | 3/29 [01:03<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.9198927879333496
Epoch 309/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:21, 60.78s/it]  7%|▋         | 2/29 [01:01<11:30, 25.57s/it] 10%|█         | 3/29 [01:02<06:12, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9324593544006348
Epoch 310/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.64s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.00s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.9151687622070312
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0143, 0.0027,  ..., 0.0044, 0.0003, 0.0173],
        [0.0033, 0.0106, 0.0028,  ..., 0.0037, 0.0005, 0.0171],
        [0.0317, 0.0073, 0.0042,  ..., 0.0053, 0.0159, 0.0223],
        ...,
        [0.0057, 0.0079, 0.0211,  ..., 0.0043, 0.0014, 0.0203],
        [0.0052, 0.0100, 0.0166,  ..., 0.0048, 0.0042, 0.0189],
        [0.0087, 0.0057, 0.0051,  ..., 0.0023, 0.0035, 0.0211]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9954, 0.9950, 0.9946, 0.9946, 0.9946, 0.9944, 0.9944,
         0.9944],
        [0.9971, 0.9970, 0.9968, 0.9968, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9965],
        [0.9792, 0.9691, 0.9682, 0.9679, 0.9669, 0.9658, 0.9653, 0.9645, 0.9641,
         0.9639],
        [0.9923, 0.9923, 0.9922, 0.9918, 0.9914, 0.9910, 0.9908, 0.9907, 0.9905,
         0.9898],
        [0.9895, 0.9875, 0.9866, 0.9866, 0.9863, 0.9860, 0.9857, 0.9856, 0.9856,
         0.9851],
        [0.9859, 0.9848, 0.9803, 0.9801, 0.9782, 0.9763, 0.9762, 0.9761, 0.9749,
         0.9743],
        [0.9764, 0.9758, 0.9706, 0.9702, 0.9670, 0.9668, 0.9658, 0.9656, 0.9641,
         0.9630],
        [0.9795, 0.9775, 0.9739, 0.9666, 0.9641, 0.9629, 0.9627, 0.9600, 0.9578,
         0.9574],
        [0.9977, 0.9971, 0.9969, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9937, 0.9888, 0.9874, 0.9871, 0.9870, 0.9856, 0.9845, 0.9843, 0.9842,
         0.9842],
        [0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9939, 0.9933, 0.9921, 0.9916, 0.9905, 0.9905, 0.9903, 0.9902, 0.9900,
         0.9900],
        [0.9942, 0.9920, 0.9908, 0.9904, 0.9900, 0.9893, 0.9877, 0.9874, 0.9872,
         0.9862],
        [0.9984, 0.9982, 0.9981, 0.9981, 0.9976, 0.9975, 0.9974, 0.9973, 0.9972,
         0.9971],
        [0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981,
         0.9980],
        [0.9961, 0.9959, 0.9959, 0.9959, 0.9958, 0.9955, 0.9954, 0.9954, 0.9952,
         0.9952],
        [0.9954, 0.9947, 0.9946, 0.9946, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944,
         0.9943],
        [0.9946, 0.9939, 0.9933, 0.9933, 0.9931, 0.9931, 0.9929, 0.9928, 0.9927,
         0.9927],
        [0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9952, 0.9945, 0.9944, 0.9940, 0.9940, 0.9939, 0.9937, 0.9933, 0.9932,
         0.9931],
        [0.9985, 0.9985, 0.9981, 0.9979, 0.9978, 0.9976, 0.9976, 0.9973, 0.9972,
         0.9971],
        [0.9988, 0.9988, 0.9987, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9954, 0.9950, 0.9948, 0.9944, 0.9944, 0.9943, 0.9942, 0.9940, 0.9940,
         0.9940],
        [0.9988, 0.9987, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977,
         0.9977],
        [0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9889, 0.9889, 0.9791, 0.9780, 0.9751, 0.9726, 0.9725, 0.9725, 0.9689,
         0.9640],
        [0.9966, 0.9964, 0.9964, 0.9964, 0.9963, 0.9961, 0.9961, 0.9960, 0.9959,
         0.9959],
        [0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9963, 0.9962, 0.9961, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9891, 0.9861, 0.9835, 0.9794, 0.9786, 0.9778, 0.9774, 0.9757, 0.9754,
         0.9747],
        [0.9951, 0.9951, 0.9949, 0.9949, 0.9947, 0.9946, 0.9945, 0.9945, 0.9945,
         0.9944],
        [0.9934, 0.9932, 0.9925, 0.9918, 0.9918, 0.9918, 0.9911, 0.9911, 0.9909,
         0.9908],
        [0.9956, 0.9953, 0.9951, 0.9951, 0.9951, 0.9950, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9864, 0.9855, 0.9846, 0.9841, 0.9840, 0.9838, 0.9831, 0.9828, 0.9807,
         0.9794],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9979, 0.9979, 0.9977, 0.9976, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9970, 0.9969, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9963],
        [0.9904, 0.9903, 0.9899, 0.9880, 0.9878, 0.9878, 0.9868, 0.9863, 0.9860,
         0.9858],
        [0.9857, 0.9824, 0.9820, 0.9813, 0.9810, 0.9809, 0.9804, 0.9801, 0.9796,
         0.9792],
        [0.9899, 0.9881, 0.9778, 0.9737, 0.9663, 0.9650, 0.9647, 0.9644, 0.9633,
         0.9623],
        [0.9727, 0.9721, 0.9707, 0.9704, 0.9676, 0.9653, 0.9648, 0.9601, 0.9578,
         0.9578],
        [0.9920, 0.9892, 0.9887, 0.9885, 0.9883, 0.9879, 0.9868, 0.9866, 0.9865,
         0.9864],
        [0.9937, 0.9936, 0.9935, 0.9932, 0.9931, 0.9927, 0.9927, 0.9924, 0.9923,
         0.9921],
        [0.9934, 0.9915, 0.9915, 0.9912, 0.9912, 0.9910, 0.9908, 0.9904, 0.9902,
         0.9899],
        [0.9908, 0.9902, 0.9897, 0.9897, 0.9896, 0.9878, 0.9848, 0.9843, 0.9835,
         0.9835],
        [0.9934, 0.9934, 0.9933, 0.9927, 0.9923, 0.9920, 0.9908, 0.9908, 0.9906,
         0.9901],
        [0.9913, 0.9889, 0.9875, 0.9865, 0.9864, 0.9862, 0.9862, 0.9848, 0.9836,
         0.9833],
        [0.9947, 0.9945, 0.9941, 0.9940, 0.9939, 0.9938, 0.9936, 0.9935, 0.9935,
         0.9935],
        [0.9958, 0.9948, 0.9948, 0.9942, 0.9941, 0.9937, 0.9936, 0.9935, 0.9931,
         0.9926],
        [0.9948, 0.9911, 0.9911, 0.9899, 0.9898, 0.9895, 0.9891, 0.9888, 0.9879,
         0.9876],
        [0.9926, 0.9922, 0.9911, 0.9895, 0.9885, 0.9881, 0.9875, 0.9864, 0.9862,
         0.9861],
        [0.9928, 0.9919, 0.9914, 0.9912, 0.9910, 0.9893, 0.9891, 0.9884, 0.9883,
         0.9870],
        [0.9967, 0.9948, 0.9936, 0.9926, 0.9923, 0.9917, 0.9899, 0.9897, 0.9888,
         0.9885],
        [0.9907, 0.9884, 0.9877, 0.9877, 0.9876, 0.9865, 0.9864, 0.9861, 0.9860,
         0.9855],
        [0.9930, 0.9922, 0.9883, 0.9873, 0.9861, 0.9857, 0.9849, 0.9847, 0.9845,
         0.9844],
        [0.9923, 0.9914, 0.9902, 0.9900, 0.9896, 0.9884, 0.9858, 0.9846, 0.9843,
         0.9833],
        [0.9926, 0.9926, 0.9925, 0.9917, 0.9917, 0.9915, 0.9914, 0.9905, 0.9904,
         0.9904]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 0, 1],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 1, 0, 1, 1, 1, 0, 0, 0],
        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1518501.2500, 1514795.6250, 1497643.2500, 1489321.1250, 1481754.3750,
         1481380.0000, 1481375.7500, 1477078.7500, 1476763.2500, 1476463.3750],
        [1534500.2500, 1532663.2500, 1528344.2500, 1527904.2500, 1526251.2500,
         1524440.2500, 1522950.7500, 1522831.6250, 1522410.5000, 1522155.0000],
        [1188564.0000, 1029012.8125, 1016490.1875, 1011435.6875,  996686.8750,
          982206.5000,  974500.6250,  964391.8750,  957907.7500,  955836.1875],
        [1434376.6250, 1433326.5000, 1432379.5000, 1423026.8750, 1414380.1250,
         1407017.0000, 1404211.3750, 1401955.2500, 1397730.0000, 1383564.8750],
        [1378211.6250, 1338739.1250, 1321562.1250, 1321521.8750, 1315082.3750,
         1310186.5000, 1305332.3750, 1303204.1250, 1303019.1250, 1292837.0000],
        [1308543.1250, 1287543.6250, 1207645.1250, 1204207.5000, 1171769.6250,
         1141313.1250, 1138936.2500, 1136810.5000, 1118421.8750, 1108197.3750],
        [1142661.3750, 1132034.0000, 1051662.6250, 1045326.0625,  999419.5625,
          996199.3750,  981259.0000,  979664.8125,  958201.0000,  943696.3750],
        [1194155.1250, 1160722.1250, 1101688.3750,  993391.2500,  957587.1250,
          941643.0625,  939928.5000,  903529.1250,  876050.4375,  870718.0000],
        [1549693.5000, 1535841.2500, 1531834.7500, 1525966.0000, 1525146.8750,
         1522670.3750, 1521626.7500, 1521581.7500, 1520756.2500, 1519363.2500],
        [1462639.2500, 1364630.5000, 1336248.0000, 1330634.8750, 1329621.2500,
         1303066.2500, 1281658.3750, 1279367.3750, 1277263.2500, 1276132.1250],
        [1550060.0000, 1546604.8750, 1546085.6250, 1544273.1250, 1544204.0000,
         1544089.1250, 1543506.1250, 1542370.1250, 1541711.2500, 1541483.3750],
        [1465954.3750, 1454400.6250, 1430531.1250, 1419882.0000, 1397940.7500,
         1397205.0000, 1392360.5000, 1390301.1250, 1387853.1250, 1386655.7500],
        [1472392.6250, 1426600.5000, 1402664.0000, 1394446.7500, 1387313.1250,
         1372623.7500, 1342355.8750, 1336335.8750, 1332116.5000, 1314132.0000],
        [1564653.6250, 1560097.2500, 1557709.6250, 1556781.3750, 1547013.3750,
         1544261.5000, 1541486.3750, 1540259.2500, 1538377.3750, 1535920.3750],
        [1569247.2500, 1568832.7500, 1568170.1250, 1567881.5000, 1567869.6250,
         1566197.3750, 1566041.8750, 1564523.8750, 1564067.3750, 1564021.1250],
        [1565946.3750, 1564126.8750, 1562555.6250, 1562431.8750, 1562302.2500,
         1561898.5000, 1560444.0000, 1559200.3750, 1556500.8750, 1556196.6250],
        [1513341.7500, 1510239.0000, 1509978.3750, 1509078.6250, 1506569.3750,
         1500283.6250, 1499316.7500, 1497814.7500, 1494078.3750, 1493998.5000],
        [1497824.7500, 1484194.1250, 1481952.2500, 1481706.5000, 1481341.8750,
         1480490.2500, 1480075.2500, 1477793.1250, 1477756.5000, 1476024.1250],
        [1481584.8750, 1466835.3750, 1455224.8750, 1454386.8750, 1450003.5000,
         1449875.0000, 1445058.7500, 1443674.3750, 1442689.0000, 1441616.1250],
        [1549588.6250, 1548130.6250, 1544460.2500, 1543980.2500, 1543541.3750,
         1543119.1250, 1543042.6250, 1542764.3750, 1542449.5000, 1542289.2500],
        [1556808.1250, 1551910.5000, 1551115.8750, 1549718.6250, 1547918.1250,
         1547161.0000, 1546455.7500, 1543681.3750, 1543208.8750, 1542252.5000],
        [1494381.8750, 1479152.3750, 1477662.0000, 1469651.3750, 1469324.7500,
         1467382.5000, 1462073.1250, 1454676.7500, 1452228.8750, 1449816.8750],
        [1566685.8750, 1565402.8750, 1557561.1250, 1552788.3750, 1550484.3750,
         1547343.8750, 1545767.2500, 1540485.6250, 1538601.8750, 1536226.6250],
        [1573176.1250, 1572186.2500, 1571105.5000, 1567440.5000, 1566992.1250,
         1566788.8750, 1566389.8750, 1565386.5000, 1564726.7500, 1564617.8750],
        [1499532.6250, 1489554.1250, 1484763.1250, 1478101.7500, 1476584.3750,
         1475625.7500, 1473808.7500, 1469871.5000, 1469624.7500, 1468813.5000],
        [1572466.6250, 1570704.0000, 1564411.8750, 1562609.1250, 1562163.6250,
         1562159.2500, 1561021.5000, 1559655.5000, 1559503.6250, 1559362.3750],
        [1562943.0000, 1561006.5000, 1556506.7500, 1555898.2500, 1553189.7500,
         1551584.8750, 1551046.3750, 1550963.5000, 1549619.6250, 1549579.6250],
        [1570457.0000, 1567909.8750, 1567844.1250, 1567477.8750, 1567382.1250,
         1564883.3750, 1562375.2500, 1561995.3750, 1561579.7500, 1560811.6250],
        [1575094.6250, 1574169.6250, 1574000.1250, 1573093.6250, 1570928.8750,
         1570251.7500, 1569513.7500, 1569377.5000, 1569179.8750, 1569166.5000],
        [1577026.1250, 1576137.5000, 1574533.0000, 1573003.6250, 1572081.2500,
         1571742.5000, 1571559.7500, 1569661.7500, 1569037.8750, 1568804.3750],
        [1576956.8750, 1576714.7500, 1574611.1250, 1573964.0000, 1573449.2500,
         1571393.2500, 1571319.8750, 1570805.8750, 1570725.1250, 1570266.7500],
        [1575431.2500, 1575181.8750, 1575006.1250, 1572525.1250, 1571231.5000,
         1571069.6250, 1569914.8750, 1569606.3750, 1569494.2500, 1569166.5000],
        [1366581.3750, 1364836.2500, 1186969.1250, 1169332.7500, 1121162.1250,
         1082336.1250, 1080812.6250, 1079827.6250, 1026319.6250,  957210.0000],
        [1523869.0000, 1520981.1250, 1520434.3750, 1519793.6250, 1518670.7500,
         1514447.5000, 1513735.6250, 1511172.6250, 1509585.2500, 1509015.3750],
        [1548956.2500, 1546144.7500, 1544685.6250, 1541934.8750, 1541934.8750,
         1541340.8750, 1541287.8750, 1541013.0000, 1540557.5000, 1539680.7500],
        [1518753.3750, 1515892.6250, 1513929.1250, 1512431.2500, 1507092.5000,
         1506279.1250, 1505879.8750, 1505262.5000, 1505248.0000, 1503727.1250],
        [1369426.7500, 1311839.3750, 1265110.1250, 1191494.3750, 1178087.0000,
         1164580.6250, 1158131.5000, 1130480.3750, 1126712.2500, 1114290.0000],
        [1491200.1250, 1491087.7500, 1487839.0000, 1486902.8750, 1483691.6250,
         1481436.5000, 1480312.3750, 1479797.1250, 1478978.8750, 1476947.8750],
        [1457267.6250, 1451424.5000, 1436830.1250, 1424197.2500, 1423658.1250,
         1423523.6250, 1410153.7500, 1409705.8750, 1405027.1250, 1403678.5000],
        [1502934.3750, 1496284.2500, 1492454.8750, 1492144.6250, 1491562.7500,
         1490671.0000, 1490098.2500, 1489814.1250, 1489177.7500, 1489177.7500],
        [1317140.7500, 1301211.0000, 1285139.3750, 1274276.3750, 1272773.8750,
         1270491.6250, 1257817.3750, 1252540.7500, 1214676.0000, 1192813.2500],
        [1558761.7500, 1556604.7500, 1554950.3750, 1554185.5000, 1553804.5000,
         1553106.7500, 1552988.2500, 1551321.5000, 1550456.2500, 1549859.0000],
        [1552899.5000, 1552529.1250, 1548728.6250, 1546231.7500, 1542484.8750,
         1541651.0000, 1541454.1250, 1541077.7500, 1540714.7500, 1540498.8750],
        [1533158.8750, 1531155.6250, 1526717.2500, 1525110.6250, 1524428.6250,
         1521819.7500, 1521619.5000, 1521551.3750, 1519021.3750, 1518983.6250],
        [1395797.2500, 1394156.8750, 1386144.1250, 1348311.5000, 1344923.7500,
         1344344.1250, 1325835.3750, 1315599.1250, 1310323.8750, 1306108.1250],
        [1304519.7500, 1244199.8750, 1237412.3750, 1225723.6250, 1219252.0000,
         1218715.0000, 1209972.6250, 1204902.6250, 1195671.8750, 1189213.6250],
        [1385751.6250, 1350834.2500, 1165039.5000, 1099096.3750,  989298.5625,
          970625.5625,  967076.5000,  961804.5000,  947037.6250,  933823.4375],
        [1083318.1250, 1074164.2500, 1052515.3750, 1048804.0000, 1007505.0000,
          975174.6875,  968420.3125,  905652.2500,  876040.3750,  875846.5000],
        [1428205.6250, 1372074.0000, 1361812.0000, 1358618.3750, 1354389.2500,
         1346676.8750, 1325237.3750, 1320676.3750, 1319371.0000, 1317188.6250],
        [1462828.8750, 1460420.2500, 1459072.6250, 1451183.6250, 1449958.0000,
         1441288.8750, 1441100.6250, 1436377.8750, 1433404.3750, 1429399.1250],
        [1456367.3750, 1418247.1250, 1416918.2500, 1411493.8750, 1411224.6250,
         1407570.0000, 1403729.3750, 1394884.3750, 1391578.6250, 1385233.7500],
        [1404018.5000, 1391667.5000, 1380546.5000, 1380475.5000, 1378784.7500,
         1345254.6250, 1287553.5000, 1278072.2500, 1264962.7500, 1264117.5000],
        [1456389.6250, 1455906.3750, 1454296.6250, 1441272.5000, 1434145.5000,
         1427797.0000, 1404002.3750, 1402719.0000, 1398228.7500, 1389446.2500],
        [1413247.5000, 1366161.8750, 1338155.8750, 1318748.3750, 1317682.2500,
         1313769.8750, 1313063.3750, 1287391.5000, 1266893.2500, 1259942.2500],
        [1482765.1250, 1480162.7500, 1470241.6250, 1469713.0000, 1467375.5000,
         1465519.7500, 1460382.7500, 1458228.2500, 1458228.2500, 1457850.1250],
        [1506601.0000, 1485939.0000, 1485254.6250, 1472891.1250, 1470660.7500,
         1462893.1250, 1461291.0000, 1458417.5000, 1449830.7500, 1440114.1250],
        [1485249.0000, 1409827.0000, 1409222.0000, 1385452.8750, 1383177.0000,
         1376725.7500, 1369604.5000, 1362779.7500, 1345919.3750, 1340218.3750],
        [1440156.7500, 1432360.3750, 1409742.2500, 1378078.7500, 1358102.7500,
         1349667.5000, 1337972.1250, 1318163.6250, 1314431.6250, 1311686.7500],
        [1444055.7500, 1426185.6250, 1414555.5000, 1412017.6250, 1407070.7500,
         1374052.5000, 1369882.6250, 1355823.7500, 1354101.2500, 1328236.1250],
        [1526657.3750, 1485800.1250, 1461362.1250, 1439335.6250, 1432838.6250,
         1421772.1250, 1386017.2500, 1381594.8750, 1364637.0000, 1357834.6250],
        [1400577.5000, 1356478.1250, 1342289.2500, 1342147.2500, 1339746.8750,
         1318916.8750, 1317241.2500, 1311301.5000, 1309408.2500, 1301234.6250],
        [1448056.3750, 1431874.2500, 1353980.0000, 1334542.6250, 1312982.0000,
         1304329.3750, 1289762.0000, 1285629.6250, 1282223.2500, 1280944.7500],
        [1434599.7500, 1415752.6250, 1390344.8750, 1386919.0000, 1379834.3750,
         1356639.8750, 1306321.2500, 1284214.3750, 1279599.2500, 1260253.5000],
        [1440641.6250, 1439989.2500, 1437161.7500, 1422185.7500, 1421216.3750,
         1416656.1250, 1415868.6250, 1397287.6250, 1396179.3750, 1394750.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1518501.2500,       0.0000],
         [1514795.6250,       0.0000],
         [1497643.2500,       0.0000],
         ...,
         [1477078.7500,       0.0000],
         [1476763.2500,       0.0000],
         [1476463.3750,       0.0000]],

        [[1534500.2500,       0.0000],
         [1532663.2500,       0.0000],
         [1528344.2500,       0.0000],
         ...,
         [1522831.6250,       0.0000],
         [1522410.5000,       0.0000],
         [1522155.0000,       0.0000]],

        [[1188564.0000,       0.0000],
         [1029012.8125,       0.0000],
         [      0.0000, 1016490.1875],
         ...,
         [      0.0000,  964391.8750],
         [      0.0000,  957907.7500],
         [      0.0000,  955836.1875]],

        ...,

        [[1448056.3750,       0.0000],
         [1431874.2500,       0.0000],
         [1353980.0000,       0.0000],
         ...,
         [1285629.6250,       0.0000],
         [      0.0000, 1282223.2500],
         [1280944.7500,       0.0000]],

        [[1434599.7500,       0.0000],
         [1415752.6250,       0.0000],
         [1390344.8750,       0.0000],
         ...,
         [      0.0000, 1284214.3750],
         [1279599.2500,       0.0000],
         [      0.0000, 1260253.5000]],

        [[      0.0000, 1440641.6250],
         [      0.0000, 1439989.2500],
         [      0.0000, 1437161.7500],
         ...,
         [      0.0000, 1397287.6250],
         [      0.0000, 1396179.3750],
         [      0.0000, 1394750.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14895077.0000,        0.0000],
        [15264451.0000,        0.0000],
        [ 4211219.0000,  5865813.5000],
        [14131969.0000,        0.0000],
        [ 9265151.0000,  3924545.5000],
        [10615743.0000,  1207645.1250],
        [ 3179896.0000,  7050228.5000],
        [ 8165166.0000,  1774247.1250],
        [13749334.0000,  1525146.8750],
        [11876630.0000,  1364630.5000],
        [15444387.0000,        0.0000],
        [14123083.0000,        0.0000],
        [13780980.0000,        0.0000],
        [15486560.0000,        0.0000],
        [15666854.0000,        0.0000],
        [15611604.0000,        0.0000],
        [12040418.0000,  2994282.0000],
        [13321334.0000,  1497824.7500],
        [14530949.0000,        0.0000],
        [15443366.0000,        0.0000],
        [15480230.0000,        0.0000],
        [11729816.0000,  2946535.0000],
        [15501348.0000,        0.0000],
        [15678811.0000,        0.0000],
        [11797193.0000,  2989086.7500],
        [15634058.0000,        0.0000],
        [15542339.0000,        0.0000],
        [15652717.0000,        0.0000],
        [15714777.0000,        0.0000],
        [15723588.0000,        0.0000],
        [15730207.0000,        0.0000],
        [15718628.0000,        0.0000],
        [ 3117850.2500,  8317537.0000],
        [12119165.0000,  3042539.7500],
        [12345638.0000,  3081898.5000],
        [15094496.0000,        0.0000],
        [ 3469380.0000,  8540773.0000],
        [10369003.0000,  4469191.0000],
        [12841788.0000,  1403678.5000],
        [14924320.0000,        0.0000],
        [10052530.0000,  2586350.5000],
        [15536039.0000,        0.0000],
        [15448270.0000,        0.0000],
        [13721947.0000,  1521619.5000],
        [ 2636159.2500, 10835384.0000],
        [ 1195671.8750, 11053911.0000],
        [ 5769666.5000,  5000722.0000],
        [ 1781498.7500,  8085942.0000],
        [ 6687928.0000,  6816321.5000],
        [10091949.0000,  4373085.0000],
        [11229655.0000,  2867592.0000],
        [ 2552516.2500, 10822937.0000],
        [       0.0000, 14264204.0000],
        [ 2632518.2500, 10562538.0000],
        [11707539.0000,  2962928.0000],
        [10231376.0000,  4462516.5000],
        [ 2752781.5000, 11115394.0000],
        [ 2727746.2500, 10922616.0000],
        [       0.0000, 13885982.0000],
        [ 1381594.8750, 12876256.0000],
        [10599017.0000,  2740324.5000],
        [10737772.0000,  2586552.5000],
        [ 9643690.0000,  3850789.0000],
        [       0.0000, 14181938.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 311/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:20, 58.58s/it]  7%|▋         | 2/29 [01:01<11:33, 25.69s/it] 10%|█         | 3/29 [01:02<06:13, 14.38s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:04<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.9225077629089355
Epoch 312/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.89s/it]  7%|▋         | 2/29 [00:58<10:58, 24.38s/it] 10%|█         | 3/29 [00:59<05:55, 13.67s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.64s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:05<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 2.928492546081543
Epoch 313/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:05, 60.21s/it]  7%|▋         | 2/29 [01:01<11:34, 25.71s/it] 10%|█         | 3/29 [01:02<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9281728267669678
Epoch 314/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:43, 61.56s/it]  7%|▋         | 2/29 [01:02<11:39, 25.89s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.925232410430908
Epoch 315/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<28:57, 62.04s/it]  7%|▋         | 2/29 [01:02<11:44, 26.09s/it] 10%|█         | 3/29 [01:03<06:19, 14.60s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.20s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.21s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.920560359954834
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0137, 0.0026,  ..., 0.0041, 0.0002, 0.0179],
        [0.0029, 0.0102, 0.0026,  ..., 0.0034, 0.0005, 0.0171],
        [0.0320, 0.0072, 0.0042,  ..., 0.0053, 0.0158, 0.0220],
        ...,
        [0.0056, 0.0081, 0.0208,  ..., 0.0041, 0.0014, 0.0201],
        [0.0048, 0.0100, 0.0157,  ..., 0.0047, 0.0042, 0.0192],
        [0.0084, 0.0057, 0.0051,  ..., 0.0023, 0.0033, 0.0209]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9964, 0.9955, 0.9952, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948,
         0.9946],
        [0.9972, 0.9971, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9779, 0.9696, 0.9676, 0.9666, 0.9666, 0.9659, 0.9651, 0.9640, 0.9639,
         0.9637],
        [0.9929, 0.9927, 0.9926, 0.9919, 0.9914, 0.9914, 0.9913, 0.9909, 0.9907,
         0.9901],
        [0.9897, 0.9878, 0.9870, 0.9868, 0.9864, 0.9862, 0.9860, 0.9855, 0.9855,
         0.9854],
        [0.9858, 0.9848, 0.9799, 0.9799, 0.9776, 0.9771, 0.9771, 0.9757, 0.9755,
         0.9751],
        [0.9759, 0.9752, 0.9703, 0.9698, 0.9658, 0.9657, 0.9643, 0.9642, 0.9628,
         0.9618],
        [0.9780, 0.9774, 0.9736, 0.9642, 0.9623, 0.9614, 0.9607, 0.9569, 0.9550,
         0.9545],
        [0.9978, 0.9973, 0.9971, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9938, 0.9894, 0.9882, 0.9872, 0.9871, 0.9859, 0.9857, 0.9855, 0.9850,
         0.9850],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9941, 0.9933, 0.9922, 0.9914, 0.9909, 0.9909, 0.9907, 0.9904, 0.9903,
         0.9902],
        [0.9944, 0.9921, 0.9912, 0.9905, 0.9903, 0.9892, 0.9880, 0.9877, 0.9875,
         0.9871],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9973],
        [0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9962, 0.9961, 0.9959, 0.9959, 0.9959, 0.9957, 0.9955, 0.9955, 0.9954,
         0.9953],
        [0.9955, 0.9948, 0.9947, 0.9947, 0.9947, 0.9947, 0.9946, 0.9945, 0.9945,
         0.9945],
        [0.9948, 0.9941, 0.9935, 0.9933, 0.9931, 0.9931, 0.9929, 0.9929, 0.9928,
         0.9928],
        [0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9982, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9952, 0.9947, 0.9946, 0.9944, 0.9941, 0.9940, 0.9938, 0.9934, 0.9933,
         0.9930],
        [0.9986, 0.9985, 0.9982, 0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9973,
         0.9973],
        [0.9989, 0.9988, 0.9988, 0.9986, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9956, 0.9950, 0.9947, 0.9946, 0.9945, 0.9944, 0.9943, 0.9941, 0.9940,
         0.9940],
        [0.9988, 0.9987, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9984, 0.9984, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9887, 0.9885, 0.9790, 0.9776, 0.9753, 0.9715, 0.9713, 0.9710, 0.9675,
         0.9624],
        [0.9968, 0.9966, 0.9965, 0.9965, 0.9965, 0.9963, 0.9963, 0.9962, 0.9961,
         0.9961],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9966, 0.9964, 0.9963, 0.9962, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959,
         0.9959],
        [0.9887, 0.9855, 0.9831, 0.9793, 0.9779, 0.9772, 0.9770, 0.9744, 0.9743,
         0.9742],
        [0.9952, 0.9952, 0.9951, 0.9950, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947,
         0.9946],
        [0.9936, 0.9931, 0.9923, 0.9919, 0.9919, 0.9917, 0.9916, 0.9913, 0.9911,
         0.9909],
        [0.9957, 0.9955, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952,
         0.9952],
        [0.9859, 0.9853, 0.9845, 0.9837, 0.9833, 0.9831, 0.9828, 0.9826, 0.9804,
         0.9792],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9981, 0.9980, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9972, 0.9971, 0.9969, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9905, 0.9903, 0.9900, 0.9880, 0.9879, 0.9876, 0.9866, 0.9863, 0.9860,
         0.9858],
        [0.9852, 0.9823, 0.9819, 0.9818, 0.9809, 0.9809, 0.9806, 0.9794, 0.9791,
         0.9791],
        [0.9902, 0.9885, 0.9778, 0.9736, 0.9663, 0.9651, 0.9650, 0.9637, 0.9635,
         0.9613],
        [0.9724, 0.9710, 0.9702, 0.9695, 0.9660, 0.9646, 0.9639, 0.9595, 0.9565,
         0.9560],
        [0.9922, 0.9896, 0.9890, 0.9887, 0.9885, 0.9877, 0.9871, 0.9867, 0.9866,
         0.9865],
        [0.9939, 0.9938, 0.9936, 0.9934, 0.9933, 0.9928, 0.9928, 0.9927, 0.9925,
         0.9925],
        [0.9934, 0.9918, 0.9916, 0.9915, 0.9914, 0.9913, 0.9911, 0.9905, 0.9901,
         0.9900],
        [0.9909, 0.9903, 0.9899, 0.9896, 0.9896, 0.9881, 0.9848, 0.9844, 0.9837,
         0.9836],
        [0.9933, 0.9932, 0.9929, 0.9928, 0.9924, 0.9919, 0.9910, 0.9908, 0.9902,
         0.9896],
        [0.9911, 0.9886, 0.9876, 0.9864, 0.9864, 0.9863, 0.9862, 0.9844, 0.9837,
         0.9835],
        [0.9949, 0.9947, 0.9944, 0.9944, 0.9942, 0.9940, 0.9940, 0.9939, 0.9939,
         0.9937],
        [0.9958, 0.9951, 0.9950, 0.9945, 0.9943, 0.9940, 0.9940, 0.9936, 0.9934,
         0.9931],
        [0.9948, 0.9911, 0.9911, 0.9901, 0.9896, 0.9893, 0.9888, 0.9887, 0.9877,
         0.9876],
        [0.9926, 0.9923, 0.9910, 0.9894, 0.9885, 0.9879, 0.9876, 0.9864, 0.9860,
         0.9859],
        [0.9927, 0.9922, 0.9915, 0.9914, 0.9910, 0.9892, 0.9891, 0.9882, 0.9881,
         0.9869],
        [0.9968, 0.9947, 0.9937, 0.9926, 0.9924, 0.9916, 0.9899, 0.9898, 0.9886,
         0.9886],
        [0.9903, 0.9882, 0.9875, 0.9873, 0.9871, 0.9867, 0.9866, 0.9862, 0.9862,
         0.9859],
        [0.9930, 0.9922, 0.9886, 0.9873, 0.9862, 0.9857, 0.9850, 0.9847, 0.9844,
         0.9844],
        [0.9924, 0.9916, 0.9902, 0.9902, 0.9898, 0.9886, 0.9859, 0.9844, 0.9842,
         0.9832],
        [0.9927, 0.9927, 0.9927, 0.9919, 0.9915, 0.9915, 0.9914, 0.9905, 0.9904,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 1, 0, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 1, 1, 0, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1522586.2500, 1520192.2500, 1501448.7500, 1494045.5000, 1488262.0000,
         1488218.0000, 1486378.3750, 1485574.8750, 1485536.5000, 1481570.7500],
        [1537440.1250, 1535437.1250, 1532828.5000, 1531218.3750, 1528235.0000,
         1527920.2500, 1527244.3750, 1527117.5000, 1525958.7500, 1525356.3750],
        [1166829.7500, 1037059.7500, 1008074.0000,  992976.3750,  992736.8125,
          983016.1875,  971573.8750,  956508.3125,  955826.2500,  952182.4375],
        [1445173.1250, 1441333.0000, 1440235.1250, 1424762.3750, 1415571.6250,
         1414319.5000, 1413929.6250, 1404524.7500, 1401749.5000, 1390120.8750],
        [1381483.0000, 1345076.3750, 1328884.8750, 1325453.6250, 1317614.3750,
         1313175.0000, 1310446.3750, 1301285.5000, 1300451.8750, 1299795.8750],
        [1305661.1250, 1287775.7500, 1201578.2500, 1201057.0000, 1161972.5000,
         1153802.2500, 1153640.5000, 1130478.2500, 1128200.3750, 1121178.1250],
        [1133997.3750, 1122410.6250, 1047574.5000, 1040165.9375,  981578.1875,
          979977.8125,  960773.1250,  959365.0000,  941273.1875,  927704.0000],
        [1168416.3750, 1159362.5000, 1097049.0000,  959523.3125,  933296.3750,
          922018.5625,  912511.6875,  864610.5000,  840978.6875,  835833.5000],
        [1551722.5000, 1540576.6250, 1535627.5000, 1528229.2500, 1526814.7500,
         1524923.0000, 1524584.2500, 1523813.7500, 1523678.6250, 1522971.0000],
        [1464265.2500, 1374591.2500, 1351750.5000, 1333526.2500, 1331865.1250,
         1307928.0000, 1305090.8750, 1301036.1250, 1292329.1250, 1291844.7500],
        [1553409.0000, 1550676.6250, 1548186.7500, 1548136.5000, 1547839.7500,
         1547774.8750, 1546188.8750, 1545527.0000, 1545422.3750, 1544691.5000],
        [1470527.6250, 1454775.2500, 1431087.8750, 1415585.2500, 1404941.3750,
         1404765.8750, 1401067.8750, 1394348.3750, 1393433.7500, 1391930.2500],
        [1476628.1250, 1430075.5000, 1411045.6250, 1397407.5000, 1393133.5000,
         1371372.8750, 1348504.3750, 1341841.3750, 1338813.2500, 1331730.3750],
        [1566753.0000, 1561441.3750, 1559410.0000, 1558861.3750, 1548990.1250,
         1546233.2500, 1544707.7500, 1543092.5000, 1542165.7500, 1539784.8750],
        [1571857.8750, 1571265.8750, 1570966.2500, 1570296.7500, 1570018.1250,
         1569244.2500, 1568107.3750, 1567989.1250, 1567868.0000, 1567473.3750],
        [1568161.1250, 1566106.2500, 1565773.1250, 1565507.3750, 1565344.6250,
         1564501.3750, 1562704.6250, 1561459.1250, 1559347.6250, 1558919.3750],
        [1515080.2500, 1513242.0000, 1510270.7500, 1510025.8750, 1509958.2500,
         1504719.8750, 1501400.1250, 1501136.6250, 1497510.5000, 1495404.0000],
        [1501183.8750, 1486052.2500, 1484221.0000, 1483905.3750, 1483612.5000,
         1483050.8750, 1481371.5000, 1479172.1250, 1479135.3750, 1478747.5000],
        [1485723.5000, 1469914.8750, 1459107.5000, 1454493.6250, 1450361.7500,
         1449884.6250, 1446418.2500, 1446296.7500, 1444097.1250, 1443801.0000],
        [1552837.2500, 1551507.8750, 1547996.3750, 1547034.1250, 1546758.1250,
         1546449.8750, 1546286.2500, 1546096.0000, 1545388.3750, 1544862.3750],
        [1559474.0000, 1553185.2500, 1552415.1250, 1550694.3750, 1549386.0000,
         1548064.2500, 1547532.8750, 1545938.2500, 1544488.2500, 1544473.5000],
        [1495291.5000, 1482995.7500, 1480953.3750, 1478118.7500, 1470552.8750,
         1469571.5000, 1465241.6250, 1455730.1250, 1455140.1250, 1448469.3750],
        [1568108.7500, 1566932.3750, 1559204.8750, 1554317.3750, 1553334.8750,
         1550454.7500, 1547962.3750, 1545475.3750, 1540559.0000, 1539886.2500],
        [1575330.6250, 1573642.8750, 1573423.7500, 1569645.3750, 1569362.5000,
         1569218.8750, 1569129.1250, 1567606.3750, 1567470.3750, 1566912.8750],
        [1502812.6250, 1490389.6250, 1484378.1250, 1481885.7500, 1479301.8750,
         1478324.6250, 1474334.5000, 1471598.0000, 1469383.6250, 1468025.1250],
        [1573744.8750, 1571965.8750, 1565096.7500, 1564143.3750, 1563857.0000,
         1563192.0000, 1562518.2500, 1561262.6250, 1560936.6250, 1560720.7500],
        [1564309.0000, 1563250.1250, 1558446.5000, 1557332.2500, 1556233.7500,
         1553854.8750, 1553524.5000, 1553474.1250, 1552804.6250, 1551710.6250],
        [1572252.2500, 1570819.3750, 1570588.7500, 1570191.8750, 1569822.0000,
         1567198.2500, 1564738.7500, 1564735.6250, 1564443.2500, 1563178.6250],
        [1575922.6250, 1575889.5000, 1575805.3750, 1574427.8750, 1572892.6250,
         1571838.3750, 1571369.3750, 1571228.5000, 1570957.2500, 1570952.7500],
        [1578759.6250, 1577757.2500, 1576337.3750, 1575016.5000, 1573584.3750,
         1573536.2500, 1572895.6250, 1571814.5000, 1571149.0000, 1571053.2500],
        [1578871.0000, 1578136.5000, 1575877.5000, 1575548.3750, 1574968.5000,
         1572901.6250, 1572886.6250, 1572589.6250, 1572127.7500, 1572114.2500],
        [1577128.3750, 1577054.7500, 1576397.6250, 1574213.2500, 1573261.6250,
         1573084.6250, 1571634.6250, 1571262.8750, 1571135.5000, 1571048.6250],
        [1361630.1250, 1357239.1250, 1186144.2500, 1161255.7500, 1124868.8750,
         1065317.2500, 1061705.5000, 1057433.3750, 1006293.1875,  935254.7500],
        [1528045.5000, 1523848.6250, 1522753.2500, 1522731.5000, 1522333.6250,
         1517807.8750, 1517336.0000, 1516621.3750, 1514161.6250, 1513312.8750],
        [1550237.3750, 1547743.8750, 1546606.3750, 1544318.8750, 1544318.8750,
         1543740.1250, 1543554.7500, 1542951.2500, 1542593.7500, 1541433.5000],
        [1523823.8750, 1521139.2500, 1517644.2500, 1514979.1250, 1511671.2500,
         1510449.2500, 1509984.1250, 1509457.1250, 1509193.7500, 1508928.8750],
        [1360824.0000, 1300048.8750, 1256227.6250, 1191187.6250, 1167453.0000,
         1155825.3750, 1152760.6250, 1110180.7500, 1107831.8750, 1107631.1250],
        [1494688.3750, 1493351.8750, 1491778.8750, 1489896.5000, 1485472.8750,
         1485107.3750, 1484046.8750, 1483509.1250, 1482879.6250, 1482137.5000],
        [1459527.7500, 1450487.6250, 1434441.0000, 1426294.5000, 1424809.8750,
         1422094.8750, 1418573.1250, 1412309.7500, 1408323.2500, 1405638.2500],
        [1504651.0000, 1499941.7500, 1497129.2500, 1495827.6250, 1495827.6250,
         1495561.0000, 1495441.1250, 1495292.7500, 1495168.7500, 1494675.5000],
        [1308545.6250, 1296562.1250, 1283312.0000, 1268636.6250, 1260173.0000,
         1257690.1250, 1250880.3750, 1248326.5000, 1209217.1250, 1189059.5000],
        [1561139.1250, 1558764.6250, 1557198.7500, 1556554.2500, 1556285.5000,
         1555334.5000, 1555273.7500, 1553860.8750, 1553023.7500, 1552834.2500],
        [1556399.8750, 1555652.0000, 1552296.7500, 1549564.8750, 1546529.5000,
         1546209.6250, 1545558.0000, 1544844.6250, 1544800.5000, 1544676.8750],
        [1536922.6250, 1534727.1250, 1530384.7500, 1530084.2500, 1526823.3750,
         1525554.2500, 1523760.0000, 1523710.5000, 1523573.8750, 1523265.8750],
        [1396343.1250, 1392717.7500, 1386829.0000, 1348658.7500, 1347197.2500,
         1340821.8750, 1322327.5000, 1316406.1250, 1310522.5000, 1306153.0000],
        [1295678.2500, 1243137.2500, 1236218.7500, 1234793.0000, 1217825.0000,
         1217523.1250, 1212402.8750, 1192473.1250, 1187417.5000, 1186904.6250],
        [1390502.6250, 1357595.1250, 1166013.1250, 1097849.7500,  989212.6250,
          971527.5625,  970325.6250,  953274.5625,  949467.5000,  920745.2500],
        [1078300.6250, 1057348.6250, 1045800.6875, 1034390.8125,  983979.4375,
          964990.7500,  955212.9375,  897643.3750,  860161.1250,  853326.5000],
        [1432294.7500, 1378479.6250, 1367949.2500, 1361334.1250, 1357552.3750,
         1342210.0000, 1331364.7500, 1323042.6250, 1322118.1250, 1318968.3750],
        [1467318.1250, 1463801.6250, 1460147.2500, 1456721.5000, 1454587.8750,
         1444883.7500, 1444043.3750, 1442108.3750, 1438443.7500, 1437653.7500],
        [1456852.1250, 1423047.2500, 1419000.6250, 1416661.5000, 1414880.6250,
         1413201.7500, 1409154.8750, 1397275.6250, 1389748.3750, 1387919.2500],
        [1405620.8750, 1393194.6250, 1386238.0000, 1380158.1250, 1379313.3750,
         1350149.1250, 1288594.0000, 1280177.8750, 1267265.5000, 1266766.5000],
        [1454740.6250, 1452877.1250, 1445057.3750, 1444046.2500, 1435081.2500,
         1424986.6250, 1407584.7500, 1403995.7500, 1391870.6250, 1380255.6250],
        [1408680.5000, 1359406.2500, 1340934.3750, 1318048.0000, 1316814.2500,
         1316568.1250, 1313860.1250, 1280920.2500, 1267655.8750, 1264692.6250],
        [1487080.1250, 1484465.7500, 1477622.6250, 1476714.0000, 1473267.6250,
         1469187.5000, 1469187.5000, 1467775.8750, 1467321.0000, 1462915.5000],
        [1508025.5000, 1492479.1250, 1490150.8750, 1480367.3750, 1474172.7500,
         1468826.1250, 1468271.5000, 1461381.6250, 1455799.5000, 1449123.0000],
        [1485095.8750, 1409390.1250, 1408790.6250, 1388471.3750, 1380183.1250,
         1374199.3750, 1364661.7500, 1361653.5000, 1341602.0000, 1341329.6250],
        [1439117.5000, 1433563.0000, 1406862.7500, 1375854.2500, 1358505.5000,
         1345382.8750, 1339681.7500, 1318459.1250, 1310833.8750, 1308130.1250],
        [1442012.1250, 1432490.1250, 1418070.0000, 1414515.0000, 1406884.1250,
         1370974.0000, 1369424.2500, 1351827.7500, 1349475.7500, 1327416.7500],
        [1527825.6250, 1483640.7500, 1462796.8750, 1440246.0000, 1436204.0000,
         1419620.6250, 1385360.5000, 1383388.0000, 1360203.7500, 1359917.1250],
        [1393316.8750, 1352325.5000, 1338440.5000, 1335688.7500, 1330623.5000,
         1322509.1250, 1322235.3750, 1313802.5000, 1313169.8750, 1308039.0000],
        [1448432.1250, 1430947.2500, 1359926.2500, 1335422.5000, 1313496.8750,
         1305368.5000, 1291681.0000, 1286096.8750, 1280994.8750, 1280710.2500],
        [1436260.1250, 1418424.2500, 1391179.2500, 1390782.6250, 1382499.0000,
         1359843.1250, 1309277.1250, 1280906.8750, 1276782.2500, 1257990.1250],
        [1442517.0000, 1441782.5000, 1441359.1250, 1424958.0000, 1417614.2500,
         1417361.5000, 1415524.3750, 1396408.3750, 1395859.7500, 1392349.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1522586.2500,       0.0000],
         [1520192.2500,       0.0000],
         [1501448.7500,       0.0000],
         ...,
         [1485574.8750,       0.0000],
         [1485536.5000,       0.0000],
         [1481570.7500,       0.0000]],

        [[1537440.1250,       0.0000],
         [1535437.1250,       0.0000],
         [1532828.5000,       0.0000],
         ...,
         [1527117.5000,       0.0000],
         [1525958.7500,       0.0000],
         [1525356.3750,       0.0000]],

        [[1166829.7500,       0.0000],
         [1037059.7500,       0.0000],
         [      0.0000, 1008074.0000],
         ...,
         [      0.0000,  956508.3125],
         [      0.0000,  955826.2500],
         [      0.0000,  952182.4375]],

        ...,

        [[1448432.1250,       0.0000],
         [1430947.2500,       0.0000],
         [1359926.2500,       0.0000],
         ...,
         [1286096.8750,       0.0000],
         [1280994.8750,       0.0000],
         [      0.0000, 1280710.2500]],

        [[1436260.1250,       0.0000],
         [1418424.2500,       0.0000],
         [1391179.2500,       0.0000],
         ...,
         [1280906.8750,       0.0000],
         [      0.0000, 1276782.2500],
         [      0.0000, 1257990.1250]],

        [[      0.0000, 1442517.0000],
         [      0.0000, 1441782.5000],
         [      0.0000, 1441359.1250],
         ...,
         [      0.0000, 1396408.3750],
         [      0.0000, 1395859.7500],
         [      0.0000, 1392349.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14953814.0000,        0.0000],
        [15298757.0000,        0.0000],
        [ 4179882.0000,  5836902.0000],
        [14191720.0000,        0.0000],
        [ 9277372.0000,  3946295.0000],
        [10643766.0000,  1201578.2500],
        [ 3161549.7500,  6933270.0000],
        [ 7152178.0000,  2541422.7500],
        [13776126.0000,  1526814.7500],
        [11979636.0000,  1374591.2500],
        [15477854.0000,        0.0000],
        [14162464.0000,        0.0000],
        [13840553.0000,        0.0000],
        [15511440.0000,        0.0000],
        [15695088.0000,        0.0000],
        [15637824.0000,        0.0000],
        [13554028.0000,  1504719.8750],
        [13339268.0000,  1501183.8750],
        [14550100.0000,        0.0000],
        [15475216.0000,        0.0000],
        [15495652.0000,        0.0000],
        [11753828.0000,  2948237.5000],
        [15526236.0000,        0.0000],
        [15701743.0000,        0.0000],
        [11807232.0000,  2993202.2500],
        [15647439.0000,        0.0000],
        [15564940.0000,        0.0000],
        [15677970.0000,        0.0000],
        [15731286.0000,        0.0000],
        [15741904.0000,        0.0000],
        [15746021.0000,        0.0000],
        [15736222.0000,        0.0000],
        [ 3062277.5000,  8254865.0000],
        [12148573.0000,  3050379.0000],
        [12361954.0000,  3085545.0000],
        [15137270.0000,        0.0000],
        [ 3430909.5000,  8479062.0000],
        [10393050.0000,  4479819.0000],
        [14262500.0000,        0.0000],
        [14969516.0000,        0.0000],
        [ 9992528.0000,  2579874.0000],
        [15560269.0000,        0.0000],
        [15486532.0000,        0.0000],
        [13755233.0000,  1523573.8750],
        [ 2628480.5000, 10839496.0000],
        [       0.0000, 12224374.0000],
        [ 5754553.0000,  5011961.0000],
        [ 1757804.5000,  7973350.5000],
        [ 6703943.0000,  6831371.0000],
        [10121868.0000,  4387841.0000],
        [11254228.0000,  2873513.5000],
        [ 2555360.5000, 10842118.0000],
        [       0.0000, 14240496.0000],
        [ 3899564.0000,  9288017.0000],
        [11763992.0000,  2971546.0000],
        [10276248.0000,  4472349.0000],
        [ 2741836.5000, 11113541.0000],
        [ 2721237.0000, 10915153.0000],
        [       0.0000, 13883090.0000],
        [ 2743591.7500, 11515612.0000],
        [10614325.0000,  2715826.0000],
        [10746998.0000,  2586078.7500],
        [ 9659896.0000,  3844049.5000],
        [       0.0000, 14185734.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 316/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:51, 59.68s/it]  7%|▋         | 2/29 [01:00<11:18, 25.12s/it] 10%|█         | 3/29 [01:01<06:05, 14.07s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.910712480545044
Epoch 317/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:31, 58.98s/it]  7%|▋         | 2/29 [00:59<11:10, 24.83s/it] 10%|█         | 3/29 [01:00<06:03, 13.98s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.82s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.915221929550171
Epoch 318/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:11, 58.27s/it]  7%|▋         | 2/29 [00:59<11:02, 24.54s/it] 10%|█         | 3/29 [01:00<05:59, 13.82s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.73s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.22s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 2.9153687953948975
Epoch 319/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.44s/it]  7%|▋         | 2/29 [01:00<11:31, 25.61s/it] 10%|█         | 3/29 [01:01<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.13s/it] 21%|██        | 6/29 [01:04<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.50s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.916715383529663
Epoch 320/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:32, 61.17s/it]  7%|▋         | 2/29 [01:02<11:34, 25.73s/it] 10%|█         | 3/29 [01:03<06:14, 14.40s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.917179584503174
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0144, 0.0028,  ..., 0.0043, 0.0003, 0.0179],
        [0.0032, 0.0101, 0.0027,  ..., 0.0034, 0.0004, 0.0170],
        [0.0336, 0.0063, 0.0038,  ..., 0.0051, 0.0170, 0.0223],
        ...,
        [0.0060, 0.0082, 0.0207,  ..., 0.0044, 0.0015, 0.0201],
        [0.0050, 0.0099, 0.0160,  ..., 0.0049, 0.0044, 0.0192],
        [0.0088, 0.0056, 0.0052,  ..., 0.0023, 0.0034, 0.0213]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9960, 0.9953, 0.9947, 0.9946, 0.9946, 0.9945, 0.9943, 0.9943,
         0.9942],
        [0.9971, 0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9785, 0.9682, 0.9681, 0.9677, 0.9670, 0.9666, 0.9664, 0.9659, 0.9652,
         0.9625],
        [0.9925, 0.9923, 0.9921, 0.9915, 0.9913, 0.9909, 0.9906, 0.9901, 0.9899,
         0.9896],
        [0.9893, 0.9872, 0.9863, 0.9861, 0.9859, 0.9858, 0.9855, 0.9854, 0.9852,
         0.9852],
        [0.9858, 0.9850, 0.9799, 0.9796, 0.9784, 0.9760, 0.9758, 0.9753, 0.9751,
         0.9745],
        [0.9785, 0.9755, 0.9695, 0.9692, 0.9688, 0.9671, 0.9662, 0.9648, 0.9648,
         0.9642],
        [0.9781, 0.9746, 0.9738, 0.9669, 0.9604, 0.9602, 0.9589, 0.9570, 0.9549,
         0.9548],
        [0.9977, 0.9972, 0.9970, 0.9967, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9935, 0.9892, 0.9876, 0.9871, 0.9865, 0.9848, 0.9848, 0.9842, 0.9842,
         0.9838],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9936, 0.9926, 0.9916, 0.9913, 0.9900, 0.9899, 0.9898, 0.9896, 0.9895,
         0.9894],
        [0.9936, 0.9912, 0.9904, 0.9897, 0.9894, 0.9885, 0.9865, 0.9865, 0.9861,
         0.9856],
        [0.9985, 0.9983, 0.9982, 0.9981, 0.9976, 0.9975, 0.9974, 0.9974, 0.9973,
         0.9972],
        [0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9981,
         0.9981],
        [0.9960, 0.9960, 0.9960, 0.9958, 0.9957, 0.9957, 0.9954, 0.9954, 0.9953,
         0.9952],
        [0.9954, 0.9946, 0.9946, 0.9946, 0.9945, 0.9943, 0.9943, 0.9943, 0.9943,
         0.9942],
        [0.9947, 0.9939, 0.9936, 0.9934, 0.9929, 0.9929, 0.9929, 0.9928, 0.9927,
         0.9927],
        [0.9978, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9981, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9951, 0.9944, 0.9942, 0.9937, 0.9936, 0.9935, 0.9934, 0.9934, 0.9932,
         0.9927],
        [0.9985, 0.9985, 0.9982, 0.9980, 0.9979, 0.9977, 0.9977, 0.9975, 0.9974,
         0.9973],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9953, 0.9949, 0.9946, 0.9945, 0.9942, 0.9941, 0.9941, 0.9939, 0.9938,
         0.9937],
        [0.9988, 0.9987, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9982, 0.9982,
         0.9982],
        [0.9984, 0.9984, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9888, 0.9886, 0.9792, 0.9766, 0.9751, 0.9727, 0.9726, 0.9715, 0.9686,
         0.9639],
        [0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9961, 0.9960, 0.9960, 0.9959,
         0.9958],
        [0.9978, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9964, 0.9963, 0.9961, 0.9959, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957,
         0.9957],
        [0.9886, 0.9860, 0.9834, 0.9785, 0.9782, 0.9771, 0.9761, 0.9752, 0.9742,
         0.9731],
        [0.9950, 0.9950, 0.9948, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9934, 0.9929, 0.9918, 0.9917, 0.9915, 0.9914, 0.9913, 0.9909, 0.9908,
         0.9906],
        [0.9956, 0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,
         0.9950],
        [0.9863, 0.9859, 0.9848, 0.9845, 0.9838, 0.9833, 0.9833, 0.9823, 0.9806,
         0.9795],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9980, 0.9979, 0.9978, 0.9976, 0.9974, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9971, 0.9970, 0.9968, 0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9902, 0.9899, 0.9897, 0.9876, 0.9873, 0.9870, 0.9864, 0.9855, 0.9853,
         0.9849],
        [0.9863, 0.9815, 0.9804, 0.9802, 0.9800, 0.9798, 0.9798, 0.9794, 0.9793,
         0.9784],
        [0.9897, 0.9879, 0.9775, 0.9738, 0.9665, 0.9647, 0.9647, 0.9646, 0.9631,
         0.9608],
        [0.9722, 0.9720, 0.9702, 0.9688, 0.9665, 0.9649, 0.9644, 0.9613, 0.9588,
         0.9567],
        [0.9915, 0.9897, 0.9886, 0.9885, 0.9883, 0.9883, 0.9870, 0.9868, 0.9865,
         0.9863],
        [0.9938, 0.9935, 0.9934, 0.9932, 0.9932, 0.9928, 0.9925, 0.9924, 0.9923,
         0.9921],
        [0.9933, 0.9915, 0.9915, 0.9914, 0.9912, 0.9911, 0.9910, 0.9906, 0.9904,
         0.9899],
        [0.9907, 0.9902, 0.9899, 0.9897, 0.9895, 0.9883, 0.9845, 0.9842, 0.9840,
         0.9838],
        [0.9933, 0.9932, 0.9929, 0.9929, 0.9926, 0.9919, 0.9912, 0.9909, 0.9902,
         0.9893],
        [0.9909, 0.9882, 0.9870, 0.9869, 0.9863, 0.9861, 0.9859, 0.9845, 0.9840,
         0.9831],
        [0.9948, 0.9947, 0.9943, 0.9942, 0.9941, 0.9939, 0.9939, 0.9939, 0.9939,
         0.9937],
        [0.9958, 0.9948, 0.9947, 0.9944, 0.9940, 0.9938, 0.9936, 0.9934, 0.9929,
         0.9928],
        [0.9946, 0.9910, 0.9910, 0.9903, 0.9897, 0.9891, 0.9890, 0.9886, 0.9875,
         0.9874],
        [0.9924, 0.9921, 0.9910, 0.9895, 0.9887, 0.9877, 0.9873, 0.9861, 0.9858,
         0.9856],
        [0.9926, 0.9918, 0.9917, 0.9913, 0.9905, 0.9890, 0.9890, 0.9887, 0.9884,
         0.9864],
        [0.9967, 0.9947, 0.9936, 0.9924, 0.9920, 0.9915, 0.9894, 0.9894, 0.9884,
         0.9884],
        [0.9906, 0.9886, 0.9876, 0.9874, 0.9868, 0.9867, 0.9865, 0.9864, 0.9861,
         0.9858],
        [0.9930, 0.9924, 0.9884, 0.9873, 0.9861, 0.9857, 0.9848, 0.9846, 0.9845,
         0.9844],
        [0.9923, 0.9915, 0.9903, 0.9903, 0.9899, 0.9885, 0.9857, 0.9847, 0.9843,
         0.9831],
        [0.9927, 0.9925, 0.9923, 0.9918, 0.9916, 0.9916, 0.9914, 0.9905, 0.9904,
         0.9902]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 1, 1, 0, 1, 1, 0, 0, 1],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515813.0000, 1512458.6250, 1496107.2500, 1482731.1250, 1481546.6250,
         1480644.1250, 1479945.3750, 1475784.8750, 1475165.6250, 1473780.6250],
        [1535201.5000, 1532835.7500, 1530498.6250, 1529725.2500, 1526098.3750,
         1525587.6250, 1524600.2500, 1524416.8750, 1523760.0000, 1523748.3750],
        [1177224.5000, 1016105.3750, 1014322.0625, 1008398.0000,  999279.4375,
          992546.5000,  990153.6250,  983322.7500,  973940.4375,  936849.1875],
        [1437729.2500, 1434297.3750, 1430117.8750, 1416445.3750, 1413990.2500,
         1405533.7500, 1399493.3750, 1389613.2500, 1385344.6250, 1380255.6250],
        [1373231.2500, 1332688.3750, 1315398.3750, 1311825.6250, 1307903.1250,
         1305842.8750, 1301554.7500, 1299010.2500, 1296083.6250, 1295048.2500],
        [1306504.3750, 1291778.2500, 1200054.0000, 1195237.5000, 1175003.7500,
         1135984.6250, 1132624.6250, 1123715.1250, 1121997.5000, 1110960.3750],
        [1177780.3750, 1127125.0000, 1035119.1250, 1030830.8750, 1024397.1250,
         1000099.3750,  987868.3125,  967831.2500,  967604.2500,  959141.7500],
        [1169642.7500, 1113449.7500, 1101138.0000,  997535.1250,  908322.4375,
          905893.2500,  889126.0000,  865229.1250,  839643.6250,  838640.8125],
        [1548691.7500, 1537994.5000, 1533426.5000, 1526372.1250, 1522670.3750,
         1522522.3750, 1522429.3750, 1521461.2500, 1520331.3750, 1520195.1250],
        [1459062.8750, 1370908.6250, 1339817.1250, 1331278.3750, 1320370.5000,
         1288830.0000, 1288807.7500, 1277714.0000, 1276992.7500, 1268929.5000],
        [1550931.0000, 1548798.1250, 1547493.0000, 1545963.2500, 1545662.6250,
         1543838.8750, 1543590.0000, 1543203.0000, 1543179.3750, 1542867.3750],
        [1460392.5000, 1439231.3750, 1419695.1250, 1414074.0000, 1386346.5000,
         1385233.7500, 1382791.8750, 1380037.0000, 1377752.8750, 1375447.6250],
        [1459992.7500, 1410768.3750, 1395701.5000, 1382155.0000, 1375278.3750,
         1358601.5000, 1320127.3750, 1319909.6250, 1311889.3750, 1302345.6250],
        [1565747.8750, 1560860.6250, 1559013.0000, 1557382.8750, 1546994.2500,
         1543286.7500, 1541692.1250, 1541255.6250, 1539525.1250, 1537718.7500],
        [1571295.8750, 1570269.7500, 1570263.7500, 1570167.8750, 1569037.8750,
         1568409.3750, 1568201.5000, 1567122.1250, 1567107.1250, 1566912.8750],
        [1567738.0000, 1565967.2500, 1565029.6250, 1564033.0000, 1563071.2500,
         1562764.1250, 1561573.8750, 1560185.1250, 1558427.2500, 1557794.3750],
        [1512416.7500, 1511177.0000, 1510579.0000, 1507345.3750, 1504639.6250,
         1504410.0000, 1498826.5000, 1497897.6250, 1496882.2500, 1494748.1250],
        [1498230.5000, 1481620.1250, 1481319.2500, 1480589.0000, 1479577.0000,
         1476093.0000, 1475517.5000, 1474989.8750, 1474899.7500, 1473820.0000],
        [1483239.0000, 1466586.5000, 1460768.5000, 1456027.2500, 1446837.5000,
         1445505.2500, 1445004.8750, 1444284.3750, 1441513.1250, 1441148.7500],
        [1550814.1250, 1549275.3750, 1544886.0000, 1543400.1250, 1543354.5000,
         1542935.1250, 1542814.5000, 1542707.0000, 1542179.0000, 1541948.1250],
        [1557558.1250, 1550867.3750, 1549330.0000, 1548257.6250, 1546913.1250,
         1545736.3750, 1544558.8750, 1543647.3750, 1542720.2500, 1541004.2500],
        [1491367.8750, 1477650.7500, 1472527.5000, 1463399.7500, 1459814.6250,
         1458560.7500, 1456663.2500, 1456411.8750, 1453029.5000, 1440920.6250],
        [1567101.1250, 1567057.8750, 1558990.7500, 1555005.2500, 1553889.0000,
         1549424.5000, 1547556.3750, 1544946.3750, 1541580.3750, 1539986.2500],
        [1574789.8750, 1572810.1250, 1571982.3750, 1568669.6250, 1568364.6250,
         1568171.6250, 1567489.7500, 1566905.3750, 1566082.2500, 1566044.8750],
        [1496312.7500, 1488785.8750, 1481058.0000, 1479914.2500, 1473117.3750,
         1471807.1250, 1470653.8750, 1466179.5000, 1464515.1250, 1462635.1250],
        [1573392.1250, 1571165.5000, 1563931.6250, 1563731.7500, 1563497.6250,
         1563151.7500, 1562585.3750, 1560697.0000, 1560321.8750, 1560244.5000],
        [1564356.7500, 1564076.2500, 1558739.3750, 1558266.7500, 1555647.6250,
         1554089.0000, 1553373.3750, 1552860.8750, 1551937.1250, 1551215.0000],
        [1572129.2500, 1570862.8750, 1570570.7500, 1569913.3750, 1569880.3750,
         1566016.6250, 1564480.5000, 1564177.7500, 1564003.2500, 1563514.0000],
        [1576193.1250, 1575948.1250, 1575139.7500, 1574348.2500, 1572865.6250,
         1572076.7500, 1571490.7500, 1571405.2500, 1571381.2500, 1570955.7500],
        [1578249.3750, 1577483.3750, 1575368.1250, 1574151.6250, 1572832.5000,
         1572801.1250, 1571925.3750, 1571439.7500, 1570639.6250, 1570428.5000],
        [1577830.8750, 1577791.8750, 1575192.3750, 1574531.5000, 1574120.1250,
         1572315.2500, 1572226.7500, 1571958.3750, 1571738.0000, 1571673.6250],
        [1576956.8750, 1576057.8750, 1575939.1250, 1573516.7500, 1572664.6250,
         1571727.5000, 1571006.7500, 1570811.8750, 1570644.2500, 1570593.2500],
        [1364655.2500, 1360713.7500, 1188828.1250, 1145916.7500, 1122015.7500,
         1083476.2500, 1082304.1250, 1065128.2500, 1022337.8750,  955127.3125],
        [1520373.5000, 1519406.7500, 1519303.7500, 1518397.0000, 1516971.3750,
         1512685.1250, 1511410.3750, 1510478.1250, 1509356.3750, 1507060.8750],
        [1549742.2500, 1546447.0000, 1546388.0000, 1543303.0000, 1542557.0000,
         1542189.1250, 1541651.0000, 1541651.0000, 1541631.8750, 1541179.1250],
        [1520984.0000, 1518437.6250, 1514192.0000, 1509857.5000, 1508511.6250,
         1508461.2500, 1506497.6250, 1505535.2500, 1504632.3750, 1504336.7500],
        [1359847.1250, 1310693.8750, 1262497.0000, 1177923.0000, 1172236.8750,
         1154492.3750, 1137463.3750, 1122305.7500, 1107741.0000, 1090164.6250],
        [1489997.5000, 1489893.6250, 1485802.8750, 1483630.8750, 1481731.7500,
         1481385.7500, 1478995.8750, 1478348.5000, 1477432.3750, 1477280.2500],
        [1455471.8750, 1445490.1250, 1423876.7500, 1422139.6250, 1418117.2500,
         1415736.3750, 1413474.0000, 1405332.7500, 1402658.7500, 1399791.0000],
        [1501805.3750, 1495777.7500, 1493689.3750, 1493689.3750, 1492966.0000,
         1492783.6250, 1492728.1250, 1492277.0000, 1491969.6250, 1490709.5000],
        [1316141.3750, 1308112.6250, 1287292.0000, 1282022.7500, 1269556.6250,
         1261229.8750, 1259819.7500, 1242594.3750, 1212830.7500, 1193667.7500],
        [1559307.3750, 1556557.2500, 1554728.0000, 1554166.2500, 1554068.3750,
         1553579.2500, 1553540.7500, 1552658.0000, 1551846.7500, 1551154.3750],
        [1554154.2500, 1552769.1250, 1549804.3750, 1545502.0000, 1542380.5000,
         1541852.3750, 1541493.7500, 1541383.5000, 1540758.7500, 1540619.2500],
        [1535522.0000, 1532637.0000, 1529235.1250, 1528440.5000, 1523735.2500,
         1523700.3750, 1523160.0000, 1522660.3750, 1520821.5000, 1519912.5000],
        [1390898.0000, 1384799.0000, 1380788.7500, 1340291.2500, 1334479.0000,
         1328305.7500, 1317937.3750, 1301676.5000, 1297314.1250, 1290380.7500],
        [1316383.5000, 1228195.0000, 1209743.0000, 1206548.1250, 1201840.7500,
         1199467.0000, 1198705.5000, 1192470.8750, 1190318.8750, 1174749.3750],
        [1380387.1250, 1345842.3750, 1160240.6250, 1100579.5000,  991414.1875,
          967163.2500,  965888.4375,  964860.0625,  945035.5625,  914234.6250],
        [1076490.1250, 1072326.1250, 1045274.2500, 1025157.5000,  991454.8125,
          969136.3750,  962562.5000,  920235.3125,  888983.5625,  861636.5625],
        [1417141.1250, 1380405.6250, 1359228.7500, 1357922.7500, 1354441.0000,
         1354074.1250, 1329615.0000, 1325462.3750, 1319318.1250, 1315436.0000],
        [1464026.5000, 1457447.0000, 1456661.8750, 1452238.5000, 1451627.8750,
         1444309.2500, 1437906.1250, 1435842.3750, 1432734.7500, 1430096.0000],
        [1454457.5000, 1417307.5000, 1416820.8750, 1415625.6250, 1410547.7500,
         1408425.2500, 1406605.1250, 1399163.8750, 1394905.7500, 1384829.5000],
        [1400712.5000, 1390630.0000, 1384601.0000, 1382148.3750, 1377255.0000,
         1353175.7500, 1282482.3750, 1276919.7500, 1273371.3750, 1270385.0000],
        [1454268.8750, 1451363.5000, 1445979.5000, 1445309.5000, 1439663.8750,
         1424698.5000, 1410299.0000, 1404282.2500, 1392096.2500, 1372571.3750],
        [1404836.8750, 1351249.1250, 1328722.6250, 1326828.2500, 1315841.2500,
         1312192.1250, 1308948.7500, 1281945.7500, 1273864.5000, 1257511.3750],
        [1486554.1250, 1484648.5000, 1476042.3750, 1472669.2500, 1470032.6250,
         1467339.1250, 1467339.1250, 1467049.5000, 1465891.5000, 1462282.2500],
        [1507223.2500, 1485798.6250, 1482772.2500, 1476804.1250, 1467963.5000,
         1464272.1250, 1459513.8750, 1456079.8750, 1445739.6250, 1443174.7500],
        [1480672.3750, 1407160.6250, 1406342.2500, 1392401.6250, 1381954.7500,
         1369242.7500, 1368232.3750, 1359307.7500, 1338418.6250, 1337047.2500],
        [1435130.6250, 1429337.8750, 1407069.3750, 1376530.1250, 1361754.7500,
         1343011.5000, 1333865.7500, 1312945.7500, 1306199.1250, 1303062.5000],
        [1439900.0000, 1424413.2500, 1420995.5000, 1413057.5000, 1397756.7500,
         1367877.5000, 1367022.0000, 1362639.5000, 1356420.0000, 1317730.0000],
        [1526747.7500, 1484110.6250, 1461270.1250, 1434673.5000, 1428416.7500,
         1416708.7500, 1376137.6250, 1375136.6250, 1356614.0000, 1355147.7500],
        [1399632.2500, 1359617.6250, 1341258.0000, 1337415.8750, 1325673.5000,
         1322673.0000, 1320119.8750, 1317036.5000, 1311964.5000, 1306903.1250],
        [1448984.7500, 1435516.5000, 1355536.7500, 1335492.5000, 1312142.1250,
         1304752.5000, 1287820.0000, 1284886.8750, 1282215.8750, 1279873.8750],
        [1434253.6250, 1417419.6250, 1393382.0000, 1392785.5000, 1385183.5000,
         1358030.2500, 1303915.2500, 1285846.6250, 1278585.5000, 1256426.6250],
        [1442616.0000, 1438114.5000, 1432676.0000, 1422505.8750, 1419345.7500,
         1419029.0000, 1414641.8750, 1396866.5000, 1394804.6250, 1391351.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515813.0000,       0.0000],
         [1512458.6250,       0.0000],
         [1496107.2500,       0.0000],
         ...,
         [1475784.8750,       0.0000],
         [1475165.6250,       0.0000],
         [1473780.6250,       0.0000]],

        [[1535201.5000,       0.0000],
         [1532835.7500,       0.0000],
         [1530498.6250,       0.0000],
         ...,
         [1524416.8750,       0.0000],
         [1523760.0000,       0.0000],
         [1523748.3750,       0.0000]],

        [[1177224.5000,       0.0000],
         [      0.0000, 1016105.3750],
         [      0.0000, 1014322.0625],
         ...,
         [ 983322.7500,       0.0000],
         [      0.0000,  973940.4375],
         [ 936849.1875,       0.0000]],

        ...,

        [[1448984.7500,       0.0000],
         [1435516.5000,       0.0000],
         [1355536.7500,       0.0000],
         ...,
         [1284886.8750,       0.0000],
         [1282215.8750,       0.0000],
         [1279873.8750,       0.0000]],

        [[1434253.6250,       0.0000],
         [1417419.6250,       0.0000],
         [1393382.0000,       0.0000],
         ...,
         [      0.0000, 1285846.6250],
         [1278585.5000,       0.0000],
         [      0.0000, 1256426.6250]],

        [[      0.0000, 1442616.0000],
         [      0.0000, 1438114.5000],
         [      0.0000, 1432676.0000],
         ...,
         [      0.0000, 1396866.5000],
         [      0.0000, 1394804.6250],
         [      0.0000, 1391351.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14873976.0000,        0.0000],
        [15276473.0000,        0.0000],
        [ 5089222.5000,  5002919.5000],
        [12712564.0000,  1380255.6250],
        [10521634.0000,  2616953.0000],
        [10593806.0000,  1200054.0000],
        [ 3162343.5000,  7115454.0000],
        [ 7085107.0000,  2543513.5000],
        [13753572.0000,  1522522.3750],
        [11851804.0000,  1370908.6250],
        [15455527.0000,        0.0000],
        [14021002.0000,        0.0000],
        [13636770.0000,        0.0000],
        [15493476.0000,        0.0000],
        [15688788.0000,        0.0000],
        [15626584.0000,        0.0000],
        [13534513.0000,  1504410.0000],
        [13298426.0000,  1498230.5000],
        [14530916.0000,        0.0000],
        [15444313.0000,        0.0000],
        [15470594.0000,        0.0000],
        [11696032.0000,  2934314.0000],
        [15525538.0000,        0.0000],
        [15691311.0000,        0.0000],
        [11769881.0000,  2985098.5000],
        [15642720.0000,        0.0000],
        [15564562.0000,        0.0000],
        [15675548.0000,        0.0000],
        [15731806.0000,        0.0000],
        [15735320.0000,        0.0000],
        [15739379.0000,        0.0000],
        [15729920.0000,        0.0000],
        [ 3120907.5000,  8269596.0000],
        [12106673.0000,  3038770.5000],
        [12351804.0000,  3084935.0000],
        [13595912.0000,  1505535.2500],
        [ 3417441.5000,  8477924.0000],
        [10358806.0000,  4465694.0000],
        [14202090.0000,        0.0000],
        [14938396.0000,        0.0000],
        [10037863.0000,  2595404.5000],
        [15541607.0000,        0.0000],
        [15450718.0000,        0.0000],
        [13736125.0000,  1523700.3750],
        [ 2608318.0000, 10758553.0000],
        [ 1174749.3750, 10943673.0000],
        [ 5748596.0000,  4987049.5000],
        [ 1809218.8750,  8004038.5000],
        [ 5379627.0000,  8133418.0000],
        [10089789.0000,  4373101.5000],
        [11243684.0000,  2865005.2500],
        [ 1282482.3750, 12109199.0000],
        [       0.0000, 14240532.0000],
        [ 3916534.0000,  9245407.0000],
        [11748646.0000,  2971202.5000],
        [10231383.0000,  4457959.0000],
        [ 2741262.5000, 11099518.0000],
        [ 2719541.5000, 10889366.0000],
        [       0.0000, 13867812.0000],
        [ 2731285.5000, 11483678.0000],
        [10619990.0000,  2722305.2500],
        [12022470.0000,  1304752.5000],
        [ 9659640.0000,  3846188.5000],
        [       0.0000, 14171952.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 321/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.81s/it]  7%|▋         | 2/29 [01:01<11:30, 25.58s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.9048116207122803
Epoch 322/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.41s/it]  7%|▋         | 2/29 [01:00<11:15, 25.01s/it] 10%|█         | 3/29 [01:01<06:04, 14.01s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.84s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.9114632606506348
Epoch 323/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:38, 61.39s/it]  7%|▋         | 2/29 [01:02<11:37, 25.82s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.89880108833313
Epoch 324/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:35, 61.26s/it]  7%|▋         | 2/29 [01:02<11:35, 25.77s/it] 10%|█         | 3/29 [01:03<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.91123628616333
Epoch 325/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:17, 58.48s/it]  7%|▋         | 2/29 [00:59<11:11, 24.88s/it] 10%|█         | 3/29 [01:00<06:02, 13.94s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.9025697708129883
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0128, 0.0023,  ..., 0.0042, 0.0002, 0.0186],
        [0.0028, 0.0099, 0.0026,  ..., 0.0034, 0.0004, 0.0175],
        [0.0321, 0.0066, 0.0043,  ..., 0.0053, 0.0157, 0.0229],
        ...,
        [0.0066, 0.0085, 0.0211,  ..., 0.0044, 0.0015, 0.0206],
        [0.0050, 0.0092, 0.0159,  ..., 0.0050, 0.0044, 0.0196],
        [0.0089, 0.0056, 0.0052,  ..., 0.0023, 0.0032, 0.0214]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9967, 0.9966, 0.9956, 0.9954, 0.9951, 0.9951, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9972, 0.9971, 0.9970, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9761, 0.9688, 0.9686, 0.9659, 0.9658, 0.9640, 0.9638, 0.9631, 0.9627,
         0.9616],
        [0.9937, 0.9931, 0.9931, 0.9925, 0.9922, 0.9920, 0.9918, 0.9915, 0.9915,
         0.9911],
        [0.9905, 0.9884, 0.9876, 0.9869, 0.9868, 0.9866, 0.9865, 0.9864, 0.9862,
         0.9861],
        [0.9862, 0.9859, 0.9815, 0.9801, 0.9796, 0.9780, 0.9778, 0.9772, 0.9771,
         0.9766],
        [0.9757, 0.9751, 0.9718, 0.9717, 0.9670, 0.9651, 0.9644, 0.9641, 0.9640,
         0.9630],
        [0.9768, 0.9763, 0.9716, 0.9647, 0.9612, 0.9591, 0.9581, 0.9533, 0.9532,
         0.9528],
        [0.9979, 0.9975, 0.9973, 0.9970, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9944, 0.9904, 0.9888, 0.9886, 0.9885, 0.9877, 0.9876, 0.9868, 0.9865,
         0.9864],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9944, 0.9936, 0.9924, 0.9917, 0.9916, 0.9913, 0.9912, 0.9911, 0.9909,
         0.9907],
        [0.9943, 0.9922, 0.9918, 0.9915, 0.9912, 0.9899, 0.9883, 0.9882, 0.9881,
         0.9876],
        [0.9986, 0.9983, 0.9982, 0.9981, 0.9978, 0.9976, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983,
         0.9982],
        [0.9963, 0.9962, 0.9961, 0.9961, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9959, 0.9951, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947, 0.9946,
         0.9946],
        [0.9948, 0.9940, 0.9935, 0.9934, 0.9932, 0.9932, 0.9932, 0.9930, 0.9929,
         0.9928],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9983, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9954, 0.9950, 0.9950, 0.9949, 0.9944, 0.9943, 0.9940, 0.9938, 0.9936,
         0.9934],
        [0.9985, 0.9985, 0.9981, 0.9980, 0.9980, 0.9979, 0.9977, 0.9977, 0.9974,
         0.9974],
        [0.9990, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9957, 0.9954, 0.9951, 0.9951, 0.9948, 0.9947, 0.9946, 0.9944, 0.9943,
         0.9943],
        [0.9988, 0.9988, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9984, 0.9983, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9977],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9984, 0.9984,
         0.9984],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9890, 0.9883, 0.9788, 0.9745, 0.9743, 0.9739, 0.9738, 0.9692, 0.9684,
         0.9654],
        [0.9967, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9960],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9968, 0.9967, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962, 0.9962, 0.9962,
         0.9961],
        [0.9881, 0.9862, 0.9833, 0.9784, 0.9773, 0.9769, 0.9755, 0.9739, 0.9736,
         0.9730],
        [0.9954, 0.9953, 0.9953, 0.9950, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948,
         0.9948],
        [0.9940, 0.9933, 0.9928, 0.9925, 0.9921, 0.9920, 0.9920, 0.9917, 0.9915,
         0.9914],
        [0.9957, 0.9956, 0.9955, 0.9954, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9862, 0.9858, 0.9845, 0.9845, 0.9835, 0.9830, 0.9830, 0.9827, 0.9807,
         0.9791],
        [0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9981, 0.9981, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9972, 0.9971, 0.9970, 0.9969, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9898, 0.9897, 0.9891, 0.9876, 0.9869, 0.9862, 0.9851, 0.9851, 0.9848,
         0.9846],
        [0.9856, 0.9819, 0.9819, 0.9816, 0.9810, 0.9807, 0.9801, 0.9794, 0.9791,
         0.9790],
        [0.9891, 0.9878, 0.9774, 0.9734, 0.9663, 0.9641, 0.9637, 0.9630, 0.9621,
         0.9613],
        [0.9726, 0.9722, 0.9689, 0.9681, 0.9662, 0.9650, 0.9646, 0.9612, 0.9594,
         0.9562],
        [0.9923, 0.9899, 0.9891, 0.9890, 0.9889, 0.9878, 0.9874, 0.9873, 0.9871,
         0.9869],
        [0.9941, 0.9940, 0.9938, 0.9936, 0.9936, 0.9931, 0.9931, 0.9930, 0.9929,
         0.9926],
        [0.9934, 0.9917, 0.9917, 0.9916, 0.9916, 0.9913, 0.9912, 0.9908, 0.9904,
         0.9904],
        [0.9907, 0.9901, 0.9899, 0.9898, 0.9893, 0.9883, 0.9841, 0.9839, 0.9837,
         0.9837],
        [0.9934, 0.9932, 0.9931, 0.9929, 0.9928, 0.9917, 0.9911, 0.9909, 0.9900,
         0.9895],
        [0.9910, 0.9878, 0.9873, 0.9871, 0.9863, 0.9862, 0.9861, 0.9845, 0.9844,
         0.9832],
        [0.9949, 0.9949, 0.9946, 0.9944, 0.9943, 0.9943, 0.9943, 0.9942, 0.9940,
         0.9937],
        [0.9959, 0.9950, 0.9949, 0.9946, 0.9942, 0.9939, 0.9938, 0.9935, 0.9933,
         0.9931],
        [0.9947, 0.9909, 0.9908, 0.9908, 0.9899, 0.9892, 0.9889, 0.9888, 0.9877,
         0.9875],
        [0.9924, 0.9921, 0.9911, 0.9896, 0.9889, 0.9879, 0.9875, 0.9864, 0.9859,
         0.9859],
        [0.9925, 0.9920, 0.9920, 0.9912, 0.9904, 0.9892, 0.9888, 0.9888, 0.9886,
         0.9860],
        [0.9967, 0.9946, 0.9938, 0.9925, 0.9924, 0.9914, 0.9896, 0.9894, 0.9884,
         0.9884],
        [0.9905, 0.9890, 0.9876, 0.9873, 0.9873, 0.9871, 0.9868, 0.9868, 0.9866,
         0.9862],
        [0.9927, 0.9918, 0.9881, 0.9865, 0.9853, 0.9847, 0.9843, 0.9837, 0.9836,
         0.9835],
        [0.9926, 0.9917, 0.9907, 0.9905, 0.9903, 0.9890, 0.9859, 0.9842, 0.9832,
         0.9832],
        [0.9928, 0.9925, 0.9925, 0.9919, 0.9915, 0.9914, 0.9913, 0.9905, 0.9904,
         0.9900]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1526591.8750, 1525014.6250, 1502945.8750, 1499228.1250, 1492830.6250,
         1492059.2500, 1490604.2500, 1490602.8750, 1487548.1250, 1486979.3750],
        [1538439.0000, 1535002.2500, 1533960.2500, 1533113.6250, 1531747.0000,
         1530192.2500, 1529442.2500, 1529244.0000, 1529013.5000, 1526458.0000],
        [1137924.3750, 1025300.2500, 1021707.2500,  983142.7500,  982469.7500,
          956230.0625,  953923.8750,  944283.3750,  939544.9375,  924106.6250],
        [1462929.3750, 1449887.3750, 1449277.7500, 1438268.1250, 1431500.0000,
         1428106.1250, 1424005.7500, 1418218.7500, 1418198.5000, 1408321.8750],
        [1397408.8750, 1356765.5000, 1340334.7500, 1327472.5000, 1324691.5000,
         1321747.5000, 1319882.0000, 1318288.1250, 1314125.8750, 1312780.5000],
        [1314768.7500, 1309295.8750, 1228177.3750, 1204054.8750, 1195954.6250,
         1169369.6250, 1166084.3750, 1154800.6250, 1153203.7500, 1146299.2500],
        [1131431.7500, 1121445.5000, 1068947.3750, 1068445.0000,  999439.5625,
          971564.6250,  962173.3125,  958179.9375,  956362.3750,  943626.1875],
        [1149635.0000, 1140516.6250, 1066464.8750,  967057.1875,  918721.8125,
          891750.8750,  879428.0000,  821753.6250,  820375.5000,  815658.1875],
        [1553649.0000, 1544429.3750, 1538987.7500, 1533170.6250, 1529919.2500,
         1529513.7500, 1529211.8750, 1528501.7500, 1528102.5000, 1528060.1250],
        [1478307.6250, 1396042.1250, 1363078.7500, 1360250.5000, 1357091.5000,
         1341991.1250, 1339827.3750, 1325959.2500, 1319076.6250, 1317610.6250],
        [1555577.7500, 1552615.1250, 1550175.3750, 1549615.1250, 1548777.3750,
         1548322.5000, 1548087.7500, 1548064.2500, 1547242.1250, 1546046.0000],
        [1478173.7500, 1460995.6250, 1435045.7500, 1420403.3750, 1420361.3750,
         1412866.2500, 1412247.7500, 1409039.3750, 1404567.6250, 1400703.1250],
        [1474254.2500, 1431227.0000, 1423700.2500, 1416561.5000, 1410912.3750,
         1384334.3750, 1353636.5000, 1351848.5000, 1350872.8750, 1341315.5000],
        [1567872.6250, 1560842.8750, 1560552.5000, 1558529.8750, 1551473.8750,
         1546761.1250, 1546287.7500, 1544158.3750, 1541567.2500, 1541514.3750],
        [1572432.2500, 1572253.6250, 1572057.2500, 1571378.2500, 1570587.2500,
         1570224.8750, 1570202.3750, 1569500.2500, 1568907.5000, 1568777.3750],
        [1569732.2500, 1567980.2500, 1567661.6250, 1566079.3750, 1564973.0000,
         1564028.5000, 1563657.2500, 1563247.1250, 1560887.5000, 1559753.5000],
        [1517415.6250, 1516569.2500, 1514095.1250, 1512647.6250, 1511605.1250,
         1507690.5000, 1506124.0000, 1505864.1250, 1504052.7500, 1502818.2500],
        [1508746.2500, 1492430.6250, 1489792.8750, 1488453.6250, 1487328.2500,
         1485958.7500, 1485835.5000, 1482646.3750, 1481021.2500, 1480775.5000],
        [1484705.1250, 1468473.1250, 1457798.6250, 1455724.5000, 1453137.7500,
         1452582.0000, 1452467.0000, 1448690.5000, 1446712.0000, 1443334.3750],
        [1555413.1250, 1555101.6250, 1551047.8750, 1550178.3750, 1548997.5000,
         1548113.0000, 1547661.2500, 1547472.2500, 1547336.6250, 1546789.2500],
        [1561021.5000, 1553706.7500, 1553423.7500, 1552695.0000, 1551892.6250,
         1550315.7500, 1549600.3750, 1548307.8750, 1546193.3750, 1546088.6250],
        [1497863.3750, 1489579.6250, 1489456.1250, 1488511.7500, 1477598.6250,
         1474823.8750, 1468620.1250, 1465356.1250, 1460341.0000, 1456175.7500],
        [1566410.8750, 1565504.3750, 1557807.7500, 1555448.7500, 1554677.5000,
         1552966.0000, 1549501.3750, 1548321.1250, 1542084.8750, 1541812.7500],
        [1576854.7500, 1574472.8750, 1574066.1250, 1571047.1250, 1570970.7500,
         1570662.1250, 1569521.2500, 1569169.3750, 1568479.7500, 1568358.6250],
        [1505407.3750, 1497479.1250, 1492775.1250, 1492274.1250, 1486194.0000,
         1483236.1250, 1481300.8750, 1478173.7500, 1475729.8750, 1474781.6250],
        [1573820.0000, 1572177.2500, 1564494.0000, 1563396.2500, 1563332.1250,
         1563178.6250, 1562251.6250, 1561328.1250, 1561109.2500, 1560683.5000],
        [1563713.7500, 1561698.8750, 1556993.7500, 1556284.1250, 1554943.0000,
         1554195.7500, 1553333.3750, 1552667.0000, 1552086.5000, 1549235.3750],
        [1572639.2500, 1571394.7500, 1571164.1250, 1570919.7500, 1570245.8750,
         1568062.3750, 1567724.5000, 1564229.8750, 1564152.3750, 1563576.7500],
        [1576779.5000, 1576734.3750, 1576543.5000, 1575737.7500, 1574099.0000,
         1573029.1250, 1572361.6250, 1572202.7500, 1571591.1250, 1571514.6250],
        [1579880.2500, 1578612.1250, 1576660.7500, 1575488.2500, 1574699.6250,
         1573147.6250, 1572874.6250, 1572715.6250, 1572606.1250, 1571955.3750],
        [1579556.3750, 1578911.7500, 1576254.8750, 1576134.5000, 1575093.2500,
         1574765.7500, 1573800.3750, 1573357.7500, 1573233.1250, 1573077.1250],
        [1577871.6250, 1577481.8750, 1576725.3750, 1574949.0000, 1573689.3750,
         1572489.1250, 1571914.8750, 1571873.0000, 1571808.3750, 1571417.2500],
        [1366980.2500, 1353565.5000, 1181513.1250, 1112524.2500, 1108521.8750,
         1102044.6250, 1100276.1250, 1030044.6875, 1018809.6250,  976102.3125],
        [1526098.3750, 1523151.2500, 1522507.8750, 1521449.7500, 1520454.6250,
         1517298.3750, 1516593.8750, 1516456.5000, 1516223.6250, 1511757.8750],
        [1551389.5000, 1548307.8750, 1547439.8750, 1546147.6250, 1545860.2500,
         1545860.2500, 1545272.0000, 1544841.7500, 1544267.2500, 1544022.8750],
        [1528274.3750, 1526019.8750, 1520646.1250, 1518688.1250, 1516083.3750,
         1516082.0000, 1516009.7500, 1515511.0000, 1515107.7500, 1514319.0000],
        [1350775.0000, 1313491.8750, 1260883.5000, 1175345.5000, 1156601.6250,
         1150741.8750, 1126990.6250, 1102045.6250, 1097517.8750, 1087481.3750],
        [1497999.0000, 1497136.3750, 1495816.2500, 1490519.0000, 1489866.7500,
         1489632.2500, 1487975.2500, 1486690.2500, 1486511.5000, 1486107.5000],
        [1469889.7500, 1454250.8750, 1444536.5000, 1437937.6250, 1428589.7500,
         1426974.7500, 1426961.2500, 1421071.2500, 1417948.2500, 1414435.3750],
        [1504283.7500, 1503677.0000, 1500119.1250, 1498792.1250, 1498589.1250,
         1498589.1250, 1497689.0000, 1497366.2500, 1497290.5000, 1495518.2500],
        [1314326.2500, 1306996.5000, 1281822.1250, 1281596.1250, 1265035.2500,
         1255111.6250, 1255020.7500, 1250674.0000, 1215531.1250, 1187434.3750],
        [1560749.1250, 1558843.5000, 1556780.0000, 1556426.6250, 1556178.7500,
         1555485.8750, 1554994.8750, 1554578.2500, 1553933.5000, 1553668.2500],
        [1556702.7500, 1556687.8750, 1553586.7500, 1551247.5000, 1546598.8750,
         1546467.7500, 1546206.6250, 1546205.1250, 1546017.8750, 1545957.3750],
        [1537850.7500, 1534740.2500, 1532843.1250, 1531008.1250, 1525675.0000,
         1525360.7500, 1525264.7500, 1524832.7500, 1524624.8750, 1524015.7500],
        [1383715.2500, 1381103.5000, 1370168.8750, 1341218.2500, 1326819.3750,
         1314908.0000, 1294101.3750, 1293742.2500, 1288673.8750, 1283703.7500],
        [1303364.5000, 1236394.3750, 1235274.7500, 1230551.5000, 1219307.8750,
         1215240.1250, 1203726.5000, 1191908.0000, 1186997.3750, 1185814.0000],
        [1369642.3750, 1345105.8750, 1158333.6250, 1094886.6250,  988621.3750,
          958731.1875,  953080.0625,  942842.6875,  930837.6875,  920083.5000],
        [1082652.0000, 1076345.3750, 1026787.5625, 1014898.6875,  987786.3750,
          970830.1250,  965326.7500,  918754.1875,  895423.7500,  856084.8125],
        [1434367.0000, 1384939.1250, 1368871.8750, 1368267.6250, 1366552.7500,
         1344113.3750, 1336225.1250, 1335188.1250, 1330130.0000, 1327899.1250],
        [1470524.8750, 1467960.6250, 1465593.8750, 1461454.0000, 1459942.6250,
         1449709.0000, 1449410.3750, 1447054.2500, 1445430.8750, 1440476.8750],
        [1455917.5000, 1421533.5000, 1421313.8750, 1419685.6250, 1418471.6250,
         1412947.0000, 1412227.6250, 1404222.0000, 1395081.2500, 1395062.7500],
        [1401844.3750, 1388681.8750, 1384422.7500, 1383541.0000, 1373799.7500,
         1353978.6250, 1275365.6250, 1270790.8750, 1268359.6250, 1267605.1250],
        [1455627.3750, 1452228.8750, 1449342.7500, 1446605.7500, 1444849.2500,
         1421288.2500, 1408385.0000, 1405950.6250, 1388227.7500, 1377261.5000],
        [1406901.6250, 1344877.6250, 1334121.5000, 1331518.3750, 1316017.0000,
         1313649.6250, 1312752.8750, 1283368.2500, 1279800.6250, 1258407.6250],
        [1487284.3750, 1487189.2500, 1481453.5000, 1478320.2500, 1476188.7500,
         1476188.7500, 1475706.0000, 1472497.8750, 1469399.1250, 1462141.3750],
        [1508652.6250, 1490971.1250, 1487890.1250, 1482365.0000, 1473398.2500,
         1467808.1250, 1465373.0000, 1458797.2500, 1453708.7500, 1450181.8750],
        [1482997.0000, 1404286.3750, 1402475.5000, 1402292.2500, 1385179.3750,
         1370648.5000, 1366156.6250, 1363453.2500, 1342946.1250, 1339165.6250],
        [1436551.8750, 1429571.0000, 1409667.0000, 1378867.6250, 1366378.1250,
         1346293.0000, 1337857.2500, 1318655.3750, 1308216.2500, 1308117.6250],
        [1438248.8750, 1427546.5000, 1427502.8750, 1411802.1250, 1395364.7500,
         1371758.7500, 1364650.0000, 1363463.6250, 1360141.5000, 1310535.1250],
        [1527462.7500, 1481644.2500, 1464723.2500, 1436768.3750, 1436487.5000,
         1415785.0000, 1378403.5000, 1375918.5000, 1356150.8750, 1355858.7500],
        [1397647.5000, 1366868.1250, 1341457.5000, 1334141.8750, 1333998.1250,
         1331189.5000, 1326061.6250, 1324748.3750, 1320704.1250, 1313567.0000],
        [1441293.1250, 1423420.5000, 1350504.5000, 1320112.3750, 1297654.3750,
         1286615.7500, 1277956.5000, 1268411.7500, 1265491.3750, 1263770.3750],
        [1439074.8750, 1422290.2500, 1400970.2500, 1396453.7500, 1394026.6250,
         1367633.5000, 1307659.8750, 1277789.6250, 1259095.5000, 1258760.5000],
        [1443236.6250, 1437793.6250, 1436932.7500, 1425651.2500, 1418308.0000,
         1416218.5000, 1413486.1250, 1397548.8750, 1395942.3750, 1387464.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1526591.8750,       0.0000],
         [1525014.6250,       0.0000],
         [1502945.8750,       0.0000],
         ...,
         [1490602.8750,       0.0000],
         [1487548.1250,       0.0000],
         [1486979.3750,       0.0000]],

        [[1538439.0000,       0.0000],
         [1535002.2500,       0.0000],
         [1533960.2500,       0.0000],
         ...,
         [1529244.0000,       0.0000],
         [1529013.5000,       0.0000],
         [1526458.0000,       0.0000]],

        [[1137924.3750,       0.0000],
         [      0.0000, 1025300.2500],
         [1021707.2500,       0.0000],
         ...,
         [      0.0000,  944283.3750],
         [ 939544.9375,       0.0000],
         [ 924106.6250,       0.0000]],

        ...,

        [[1441293.1250,       0.0000],
         [1423420.5000,       0.0000],
         [1350504.5000,       0.0000],
         ...,
         [1268411.7500,       0.0000],
         [1265491.3750,       0.0000],
         [1263770.3750,       0.0000]],

        [[1439074.8750,       0.0000],
         [1422290.2500,       0.0000],
         [1400970.2500,       0.0000],
         ...,
         [1277789.6250,       0.0000],
         [      0.0000, 1259095.5000],
         [      0.0000, 1258760.5000]],

        [[      0.0000, 1443236.6250],
         [      0.0000, 1437793.6250],
         [      0.0000, 1436932.7500],
         ...,
         [      0.0000, 1397548.8750],
         [      0.0000, 1395942.3750],
         [      0.0000, 1387464.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14994405.0000,        0.0000],
        [15316612.0000,        0.0000],
        [ 5005753.0000,  4862880.0000],
        [12920392.0000,  1408321.8750],
        [ 9359586.0000,  3973911.5000],
        [10837955.0000,  1204054.8750],
        [ 3189832.5000,  6991783.5000],
        [ 7829232.5000,  1642129.1250],
        [13813626.0000,  1529919.2500],
        [12203193.0000,  1396042.1250],
        [15494522.0000,        0.0000],
        [14254405.0000,        0.0000],
        [13938663.0000,        0.0000],
        [15519560.0000,        0.0000],
        [15706320.0000,        0.0000],
        [15648000.0000,        0.0000],
        [13586235.0000,  1512647.6250],
        [13374243.0000,  1508746.2500],
        [14563625.0000,        0.0000],
        [15498110.0000,        0.0000],
        [15513245.0000,        0.0000],
        [11818406.0000,  2949920.5000],
        [15534535.0000,        0.0000],
        [15713602.0000,        0.0000],
        [11864466.0000,  3002886.5000],
        [15645770.0000,        0.0000],
        [15555151.0000,        0.0000],
        [15684110.0000,        0.0000],
        [15740594.0000,        0.0000],
        [15748640.0000,        0.0000],
        [15754184.0000,        0.0000],
        [15740220.0000,        0.0000],
        [ 3178423.0000,  8171959.0000],
        [12145439.0000,  3046553.0000],
        [12374114.0000,  3089295.0000],
        [13672423.0000,  1514319.0000],
        [ 3381110.0000,  8440764.0000],
        [10417302.0000,  4490952.0000],
        [14342596.0000,        0.0000],
        [14991914.0000,        0.0000],
        [10024956.0000,  2588592.5000],
        [15561640.0000,        0.0000],
        [15495678.0000,        0.0000],
        [13760541.0000,  1525675.0000],
        [ 3866479.0000,  9411676.0000],
        [       0.0000, 12208580.0000],
        [ 5694196.5000,  4967968.5000],
        [ 1814178.0000,  7980711.5000],
        [ 6747028.0000,  6849525.5000],
        [10159129.0000,  4398428.0000],
        [11282074.0000,  2874389.0000],
        [ 1275365.6250, 12093024.0000],
        [ 1377261.5000, 12872506.0000],
        [ 3931139.2500,  9250275.0000],
        [11791896.0000,  2974473.5000],
        [10269205.0000,  4469941.0000],
        [ 2748632.5000, 11110968.0000],
        [ 2725160.5000, 10915014.0000],
        [       0.0000, 13871014.0000],
        [ 1375918.5000, 12853284.0000],
        [11992736.0000,  1397647.5000],
        [11908615.0000,  1286615.7500],
        [ 9698238.0000,  3825516.0000],
        [       0.0000, 14172582.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 326/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:27, 58.82s/it]  7%|▋         | 2/29 [01:00<11:13, 24.96s/it] 10%|█         | 3/29 [01:01<06:03, 13.98s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.83s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.901872396469116
Epoch 327/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:55, 57.69s/it]  7%|▋         | 2/29 [01:00<11:31, 25.63s/it] 10%|█         | 3/29 [01:01<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.8920648097991943
Epoch 328/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:52, 59.72s/it]  7%|▋         | 2/29 [01:00<11:18, 25.13s/it] 10%|█         | 3/29 [01:01<06:05, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8998045921325684
Epoch 329/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:51, 59.69s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:04<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.8942747116088867
Epoch 330/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:12, 60.44s/it]  7%|▋         | 2/29 [01:01<11:26, 25.43s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.8956546783447266
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0133, 0.0025,  ..., 0.0042, 0.0002, 0.0185],
        [0.0029, 0.0098, 0.0026,  ..., 0.0033, 0.0004, 0.0172],
        [0.0327, 0.0067, 0.0042,  ..., 0.0054, 0.0160, 0.0232],
        ...,
        [0.0066, 0.0085, 0.0208,  ..., 0.0044, 0.0015, 0.0205],
        [0.0049, 0.0090, 0.0156,  ..., 0.0050, 0.0045, 0.0196],
        [0.0086, 0.0054, 0.0053,  ..., 0.0022, 0.0031, 0.0213]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9965, 0.9955, 0.9952, 0.9950, 0.9949, 0.9948, 0.9947, 0.9947,
         0.9947],
        [0.9972, 0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9774, 0.9675, 0.9665, 0.9661, 0.9657, 0.9649, 0.9636, 0.9634, 0.9630,
         0.9614],
        [0.9929, 0.9926, 0.9926, 0.9919, 0.9918, 0.9916, 0.9910, 0.9907, 0.9905,
         0.9905],
        [0.9899, 0.9876, 0.9866, 0.9866, 0.9864, 0.9860, 0.9860, 0.9857, 0.9853,
         0.9852],
        [0.9859, 0.9855, 0.9804, 0.9791, 0.9785, 0.9757, 0.9756, 0.9754, 0.9753,
         0.9747],
        [0.9780, 0.9732, 0.9697, 0.9684, 0.9677, 0.9666, 0.9660, 0.9643, 0.9635,
         0.9625],
        [0.9780, 0.9753, 0.9729, 0.9679, 0.9599, 0.9595, 0.9595, 0.9564, 0.9554,
         0.9533],
        [0.9978, 0.9974, 0.9971, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9941, 0.9898, 0.9884, 0.9879, 0.9875, 0.9866, 0.9866, 0.9859, 0.9853,
         0.9850],
        [0.9980, 0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9942, 0.9932, 0.9922, 0.9912, 0.9908, 0.9907, 0.9907, 0.9903, 0.9901,
         0.9900],
        [0.9937, 0.9915, 0.9912, 0.9906, 0.9904, 0.9889, 0.9875, 0.9873, 0.9870,
         0.9866],
        [0.9985, 0.9983, 0.9983, 0.9982, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9961, 0.9961, 0.9959, 0.9959, 0.9959, 0.9957, 0.9957, 0.9955, 0.9955,
         0.9954],
        [0.9957, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9944],
        [0.9948, 0.9939, 0.9937, 0.9935, 0.9932, 0.9932, 0.9931, 0.9930, 0.9930,
         0.9929],
        [0.9980, 0.9980, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9982, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9953, 0.9947, 0.9947, 0.9943, 0.9942, 0.9941, 0.9937, 0.9935, 0.9932,
         0.9931],
        [0.9986, 0.9985, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9978, 0.9975,
         0.9975],
        [0.9990, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9953, 0.9952, 0.9950, 0.9948, 0.9945, 0.9943, 0.9942, 0.9942, 0.9941,
         0.9940],
        [0.9989, 0.9988, 0.9984, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9978],
        [0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9984],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9889, 0.9881, 0.9787, 0.9747, 0.9732, 0.9725, 0.9720, 0.9702, 0.9673,
         0.9635],
        [0.9965, 0.9965, 0.9964, 0.9963, 0.9963, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9960],
        [0.9978, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9967, 0.9966, 0.9964, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9878, 0.9857, 0.9827, 0.9777, 0.9774, 0.9765, 0.9749, 0.9744, 0.9733,
         0.9728],
        [0.9953, 0.9952, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9937, 0.9930, 0.9922, 0.9920, 0.9918, 0.9917, 0.9916, 0.9914, 0.9910,
         0.9909],
        [0.9957, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9953,
         0.9952],
        [0.9863, 0.9862, 0.9854, 0.9845, 0.9838, 0.9837, 0.9825, 0.9822, 0.9816,
         0.9800],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9970, 0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9966],
        [0.9902, 0.9896, 0.9892, 0.9879, 0.9870, 0.9860, 0.9853, 0.9853, 0.9851,
         0.9846],
        [0.9864, 0.9806, 0.9806, 0.9804, 0.9798, 0.9798, 0.9793, 0.9791, 0.9789,
         0.9784],
        [0.9887, 0.9875, 0.9770, 0.9733, 0.9664, 0.9643, 0.9640, 0.9633, 0.9624,
         0.9616],
        [0.9725, 0.9716, 0.9692, 0.9668, 0.9660, 0.9649, 0.9646, 0.9626, 0.9604,
         0.9540],
        [0.9917, 0.9894, 0.9888, 0.9888, 0.9887, 0.9883, 0.9870, 0.9866, 0.9866,
         0.9865],
        [0.9940, 0.9938, 0.9938, 0.9937, 0.9935, 0.9934, 0.9930, 0.9929, 0.9927,
         0.9926],
        [0.9933, 0.9917, 0.9916, 0.9916, 0.9913, 0.9913, 0.9908, 0.9908, 0.9906,
         0.9902],
        [0.9905, 0.9904, 0.9904, 0.9900, 0.9896, 0.9892, 0.9852, 0.9850, 0.9849,
         0.9848],
        [0.9933, 0.9933, 0.9931, 0.9930, 0.9927, 0.9917, 0.9911, 0.9908, 0.9899,
         0.9894],
        [0.9907, 0.9876, 0.9873, 0.9871, 0.9864, 0.9863, 0.9861, 0.9843, 0.9843,
         0.9838],
        [0.9950, 0.9950, 0.9949, 0.9947, 0.9946, 0.9946, 0.9946, 0.9943, 0.9943,
         0.9940],
        [0.9959, 0.9952, 0.9949, 0.9948, 0.9943, 0.9942, 0.9938, 0.9937, 0.9933,
         0.9933],
        [0.9946, 0.9908, 0.9907, 0.9906, 0.9898, 0.9893, 0.9890, 0.9887, 0.9879,
         0.9877],
        [0.9923, 0.9922, 0.9911, 0.9895, 0.9889, 0.9879, 0.9874, 0.9866, 0.9859,
         0.9858],
        [0.9925, 0.9921, 0.9920, 0.9913, 0.9905, 0.9891, 0.9887, 0.9885, 0.9885,
         0.9859],
        [0.9968, 0.9943, 0.9938, 0.9925, 0.9924, 0.9914, 0.9896, 0.9895, 0.9888,
         0.9886],
        [0.9908, 0.9888, 0.9875, 0.9872, 0.9871, 0.9870, 0.9867, 0.9865, 0.9862,
         0.9862],
        [0.9926, 0.9920, 0.9882, 0.9867, 0.9852, 0.9847, 0.9845, 0.9842, 0.9840,
         0.9836],
        [0.9927, 0.9919, 0.9910, 0.9908, 0.9907, 0.9893, 0.9864, 0.9846, 0.9839,
         0.9837],
        [0.9930, 0.9926, 0.9925, 0.9920, 0.9918, 0.9917, 0.9917, 0.9908, 0.9904,
         0.9903]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 0, 1, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 0, 1, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1523154.1250, 1521272.7500, 1499800.1250, 1494240.8750, 1489525.7500,
         1488243.5000, 1485045.0000, 1484402.1250, 1484358.2500, 1482865.6250],
        [1538384.7500, 1535059.3750, 1533461.6250, 1532911.7500, 1532284.7500,
         1530666.5000, 1527709.0000, 1527400.2500, 1527301.1250, 1527254.5000],
        [1159050.6250, 1006550.4375,  991802.7500,  986290.5625,  979822.6875,
          969248.1875,  951580.6250,  948569.6875,  943852.1250,  921638.7500],
        [1446792.0000, 1440217.2500, 1439508.6250, 1425456.8750, 1423227.7500,
         1419585.3750, 1407814.3750, 1401301.7500, 1398066.0000, 1397767.5000],
        [1384642.0000, 1340469.0000, 1321731.1250, 1320650.0000, 1318114.6250,
         1311061.3750, 1310642.5000, 1303708.8750, 1297654.3750, 1295588.1250],
        [1308589.2500, 1301625.6250, 1209725.7500, 1187367.6250, 1176640.8750,
         1130545.1250, 1129499.7500, 1125732.7500, 1124380.8750, 1114669.5000],
        [1168536.7500, 1090868.6250, 1037584.0625, 1018755.2500, 1008915.5625,
          993463.1875,  984240.3750,  961263.5000,  950424.1875,  936306.0625],
        [1167943.0000, 1124260.7500, 1086199.2500, 1011251.5625,  902331.3750,
          896923.6875,  896878.3125,  858569.5625,  846376.6250,  820822.3750],
        [1549974.3750, 1541682.0000, 1535620.1250, 1528860.3750, 1527458.3750,
         1526661.7500, 1525269.1250, 1524792.1250, 1523966.2500, 1521821.2500],
        [1470304.6250, 1384129.7500, 1355010.7500, 1345961.7500, 1337813.8750,
         1322162.2500, 1321611.3750, 1308611.7500, 1297794.2500, 1292300.6250],
        [1554797.6250, 1552061.3750, 1549544.1250, 1548799.5000, 1548430.3750,
         1548095.2500, 1547865.0000, 1547693.7500, 1547084.2500, 1546708.1250],
        [1472571.0000, 1451726.2500, 1430873.6250, 1411294.6250, 1404082.8750,
         1401754.7500, 1401307.0000, 1393526.8750, 1389892.8750, 1387870.2500],
        [1461909.8750, 1417868.5000, 1412251.8750, 1399803.1250, 1396123.3750,
         1364935.1250, 1338910.2500, 1333888.7500, 1329962.5000, 1322072.6250],
        [1567365.7500, 1562037.0000, 1560950.0000, 1559163.1250, 1551503.5000,
         1547704.0000, 1547122.6250, 1543855.0000, 1543113.2500, 1541752.5000],
        [1573444.6250, 1572918.1250, 1572888.0000, 1572729.1250, 1572120.2500,
         1570803.0000, 1570503.3750, 1570094.5000, 1569616.8750, 1569444.8750],
        [1570991.6250, 1569169.3750, 1568316.7500, 1567651.3750, 1565743.2500,
         1565620.8750, 1564996.8750, 1564425.3750, 1561505.3750, 1561122.7500],
        [1512771.7500, 1512672.1250, 1510309.6250, 1509474.5000, 1509169.3750,
         1505206.5000, 1504806.1250, 1501145.1250, 1499914.6250, 1498117.6250],
        [1505492.1250, 1486654.7500, 1486143.0000, 1485496.8750, 1484552.2500,
         1483043.7500, 1482864.1250, 1482089.3750, 1480510.0000, 1478268.1250],
        [1485800.1250, 1467574.2500, 1462541.6250, 1458717.8750, 1452686.0000,
         1451573.8750, 1451000.8750, 1448459.8750, 1448350.6250, 1446651.2500],
        [1555861.2500, 1554496.6250, 1549897.5000, 1548749.3750, 1546994.2500,
         1546907.2500, 1546792.1250, 1546748.0000, 1546691.8750, 1546579.7500],
        [1560515.3750, 1552398.8750, 1552268.6250, 1551940.1250, 1551263.7500,
         1550463.6250, 1547082.7500, 1546635.7500, 1545616.8750, 1544105.3750],
        [1495503.8750, 1484621.6250, 1483806.2500, 1474965.8750, 1473217.1250,
         1471257.1250, 1463317.3750, 1458635.8750, 1451417.5000, 1449624.7500],
        [1567847.2500, 1566703.7500, 1559053.1250, 1557874.5000, 1556391.0000,
         1554357.2500, 1552478.8750, 1550540.5000, 1544715.1250, 1544684.1250],
        [1576820.0000, 1574189.1250, 1574141.1250, 1571321.2500, 1571215.0000,
         1570597.7500, 1570313.1250, 1569473.2500, 1569242.7500, 1569091.6250],
        [1497343.3750, 1493807.6250, 1490158.0000, 1486778.0000, 1478866.0000,
         1475402.0000, 1473413.7500, 1472802.7500, 1471633.1250, 1468312.1250],
        [1575453.7500, 1572529.6250, 1565219.2500, 1564596.8750, 1564104.5000,
         1563883.8750, 1563341.0000, 1562272.5000, 1562077.2500, 1561124.1250],
        [1564564.1250, 1562242.6250, 1558867.3750, 1557491.2500, 1556814.0000,
         1555471.0000, 1555451.7500, 1554086.1250, 1553126.0000, 1551084.8750],
        [1573110.1250, 1573020.1250, 1572097.7500, 1571965.8750, 1571381.2500,
         1569670.8750, 1568614.3750, 1565635.7500, 1565386.5000, 1565186.3750],
        [1577573.7500, 1577023.1250, 1576899.7500, 1575918.0000, 1574785.2500,
         1573753.8750, 1573051.6250, 1572765.1250, 1572733.6250, 1572531.2500],
        [1579810.8750, 1579018.6250, 1576585.5000, 1575462.7500, 1575268.8750,
         1573573.7500, 1573318.7500, 1572678.1250, 1572414.1250, 1572042.3750],
        [1579987.2500, 1579057.8750, 1576669.7500, 1576311.8750, 1575438.7500,
         1575402.7500, 1574105.1250, 1574045.1250, 1573952.0000, 1573876.8750],
        [1578807.8750, 1577567.6250, 1577167.5000, 1575193.8750, 1573901.0000,
         1573252.6250, 1572855.0000, 1572312.1250, 1571738.0000, 1571460.7500],
        [1365510.5000, 1349303.3750, 1180830.5000, 1114758.7500, 1091059.1250,
         1080671.5000, 1073195.6250, 1045142.6875, 1002485.6875,  950421.4375],
        [1522425.1250, 1522372.7500, 1519625.5000, 1518610.0000, 1517641.3750,
         1514395.6250, 1513123.7500, 1512204.8750, 1511902.0000, 1510403.2500],
        [1550797.8750, 1548321.1250, 1547988.8750, 1545062.8750, 1544958.1250,
         1544862.3750, 1544451.5000, 1544451.5000, 1543563.5000, 1543406.0000],
        [1527290.8750, 1524947.6250, 1519979.1250, 1517052.3750, 1516701.0000,
         1514983.3750, 1514140.0000, 1513942.1250, 1513854.1250, 1512890.0000],
        [1343713.5000, 1303769.8750, 1250575.0000, 1163222.0000, 1158383.2500,
         1144626.7500, 1118521.1250, 1109916.1250, 1092121.0000, 1085411.2500],
        [1496007.3750, 1494601.3750, 1489258.6250, 1487721.2500, 1486867.3750,
         1485715.0000, 1485553.5000, 1485397.7500, 1484322.8750, 1483987.3750],
        [1462142.7500, 1447248.8750, 1432323.5000, 1426562.5000, 1424386.0000,
         1421742.2500, 1418535.2500, 1415236.8750, 1407539.1250, 1404585.0000],
        [1503938.0000, 1501726.5000, 1500111.8750, 1499764.3750, 1499764.3750,
         1499598.5000, 1497137.7500, 1496939.3750, 1495696.3750, 1493820.5000],
        [1314923.1250, 1314678.5000, 1298594.0000, 1282190.2500, 1270212.8750,
         1268582.2500, 1245972.7500, 1240523.5000, 1230282.7500, 1202830.2500],
        [1562126.5000, 1559552.7500, 1558152.3750, 1558107.7500, 1556391.0000,
         1556383.5000, 1555426.5000, 1555344.8750, 1555334.5000, 1555172.8750],
        [1557044.2500, 1556934.3750, 1554418.1250, 1551370.2500, 1546243.5000,
         1546146.2500, 1545849.8750, 1545728.8750, 1545556.5000, 1545472.5000],
        [1538707.5000, 1535768.1250, 1534054.0000, 1529837.6250, 1527899.8750,
         1524927.2500, 1524912.7500, 1524257.1250, 1523986.6250, 1523885.0000],
        [1390761.3750, 1379114.8750, 1371627.8750, 1346484.2500, 1329849.6250,
         1311125.1250, 1297449.0000, 1297211.5000, 1293723.7500, 1284057.5000],
        [1316987.5000, 1212604.1250, 1212170.5000, 1210106.5000, 1199813.7500,
         1199026.7500, 1190279.1250, 1187689.2500, 1183297.0000, 1175313.0000],
        [1362475.7500, 1339453.0000, 1152613.3750, 1092186.6250,  990943.3750,
          960840.0625,  956515.5625,  947934.8750,  935576.8125,  924751.0625],
        [1080362.2500, 1066456.7500, 1030396.4375,  995569.6875,  984754.8125,
          969476.5625,  965428.0625,  937369.2500,  908811.8750,  829709.5000],
        [1422326.8750, 1376059.0000, 1364153.0000, 1362938.3750, 1362174.3750,
         1353099.5000, 1329068.6250, 1322278.2500, 1322240.3750, 1319373.5000],
        [1467976.1250, 1465519.7500, 1464019.3750, 1462305.8750, 1457498.3750,
         1455834.1250, 1448008.1250, 1446455.3750, 1441508.8750, 1439710.5000],
        [1455251.1250, 1421852.1250, 1420049.8750, 1419604.3750, 1413278.6250,
         1413135.6250, 1404009.1250, 1403385.2500, 1398466.0000, 1391745.8750],
        [1396983.7500, 1396155.3750, 1395681.3750, 1387097.5000, 1379438.3750,
         1371714.2500, 1296187.5000, 1291805.3750, 1290420.1250, 1288359.3750],
        [1455022.2500, 1454846.0000, 1449772.6250, 1447026.6250, 1441023.7500,
         1422206.0000, 1408781.3750, 1404007.7500, 1386222.1250, 1376221.6250],
        [1401935.2500, 1341315.5000, 1335563.8750, 1331117.1250, 1316864.5000,
         1316500.3750, 1312391.1250, 1279393.0000, 1277930.8750, 1270496.3750],
        [1489534.2500, 1489507.2500, 1487437.5000, 1482659.1250, 1482086.5000,
         1482086.5000, 1481209.1250, 1475141.7500, 1474555.2500, 1469509.8750],
        [1509441.3750, 1493582.5000, 1487356.6250, 1485050.6250, 1475116.3750,
         1473038.7500, 1464536.1250, 1462950.2500, 1453642.2500, 1453642.2500],
        [1481323.5000, 1403016.0000, 1401174.7500, 1399980.6250, 1383430.2500,
         1373440.7500, 1367606.2500, 1361234.1250, 1346314.8750, 1343338.1250],
        [1432685.5000, 1431147.8750, 1409410.2500, 1378187.8750, 1366177.3750,
         1345901.3750, 1335929.3750, 1322207.6250, 1307489.0000, 1306073.2500],
        [1437005.5000, 1429553.2500, 1427910.0000, 1414179.1250, 1396496.2500,
         1368697.0000, 1361844.3750, 1358740.0000, 1358215.3750, 1309017.5000],
        [1528469.7500, 1474449.8750, 1464509.5000, 1437766.2500, 1436130.0000,
         1414917.1250, 1379445.0000, 1378019.7500, 1363093.1250, 1360116.8750],
        [1402387.2500, 1362928.0000, 1338630.6250, 1332134.3750, 1331154.0000,
         1329018.0000, 1324283.5000, 1318851.5000, 1314132.0000, 1314011.7500],
        [1440221.2500, 1426880.8750, 1352823.3750, 1324289.8750, 1295973.6250,
         1286744.5000, 1282286.8750, 1276488.7500, 1273623.8750, 1266326.7500],
        [1441836.1250, 1426129.8750, 1407298.8750, 1404053.3750, 1401090.5000,
         1374077.5000, 1318400.0000, 1283798.0000, 1271321.8750, 1267288.3750],
        [1447809.2500, 1440555.1250, 1437246.6250, 1427108.1250, 1423660.8750,
         1421886.1250, 1420834.1250, 1403135.0000, 1394473.3750, 1392640.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1523154.1250,       0.0000],
         [1521272.7500,       0.0000],
         [1499800.1250,       0.0000],
         ...,
         [1484402.1250,       0.0000],
         [1484358.2500,       0.0000],
         [1482865.6250,       0.0000]],

        [[1538384.7500,       0.0000],
         [1535059.3750,       0.0000],
         [1533461.6250,       0.0000],
         ...,
         [1527400.2500,       0.0000],
         [1527301.1250,       0.0000],
         [1527254.5000,       0.0000]],

        [[1159050.6250,       0.0000],
         [      0.0000, 1006550.4375],
         [ 991802.7500,       0.0000],
         ...,
         [ 948569.6875,       0.0000],
         [      0.0000,  943852.1250],
         [      0.0000,  921638.7500]],

        ...,

        [[1440221.2500,       0.0000],
         [1426880.8750,       0.0000],
         [1352823.3750,       0.0000],
         ...,
         [1276488.7500,       0.0000],
         [      0.0000, 1273623.8750],
         [1266326.7500,       0.0000]],

        [[1441836.1250,       0.0000],
         [1426129.8750,       0.0000],
         [1407298.8750,       0.0000],
         ...,
         [1283798.0000,       0.0000],
         [      0.0000, 1271321.8750],
         [      0.0000, 1267288.3750]],

        [[      0.0000, 1447809.2500],
         [      0.0000, 1440555.1250],
         [      0.0000, 1437246.6250],
         ...,
         [      0.0000, 1403135.0000],
         [      0.0000, 1394473.3750],
         [1392640.7500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14952908.0000,        0.0000],
        [15312434.0000,        0.0000],
        [ 4079245.7500,  5779160.5000],
        [12798436.0000,  1401301.7500],
        [ 9271377.0000,  3932885.0000],
        [10621409.0000,  1187367.6250],
        [ 3103087.0000,  7047270.5000],
        [ 7932164.5000,  1679392.0000],
        [13779444.0000,  1526661.7500],
        [12051572.0000,  1384129.7500],
        [15491078.0000,        0.0000],
        [14144900.0000,        0.0000],
        [13777726.0000,        0.0000],
        [15524566.0000,        0.0000],
        [15714564.0000,        0.0000],
        [15659545.0000,        0.0000],
        [13554418.0000,  1509169.3750],
        [11866758.0000,  2988356.2500],
        [14573356.0000,        0.0000],
        [15489720.0000,        0.0000],
        [15502292.0000,        0.0000],
        [11771144.0000,  2935223.7500],
        [15554645.0000,        0.0000],
        [15716404.0000,        0.0000],
        [11817366.0000,  2991151.0000],
        [15654602.0000,        0.0000],
        [15569198.0000,        0.0000],
        [15696070.0000,        0.0000],
        [15747035.0000,        0.0000],
        [15750174.0000,        0.0000],
        [15758848.0000,        0.0000],
        [15744256.0000,        0.0000],
        [ 3104288.5000,  8149090.5000],
        [12122690.0000,  3040014.0000],
        [12369342.0000,  3088521.5000],
        [13661838.0000,  1513942.1250],
        [ 3369025.5000,  8401234.0000],
        [10399566.0000,  4479867.5000],
        [12855718.0000,  1404585.0000],
        [14988498.0000,        0.0000],
        [10071676.0000,  2597113.5000],
        [15571992.0000,        0.0000],
        [15494764.0000,        0.0000],
        [12235423.0000,  3052812.5000],
        [ 2590935.2500, 10710470.0000],
        [       0.0000, 12087288.0000],
        [ 5716562.0000,  4946728.5000],
        [ 2675890.5000,  7092444.5000],
        [ 5379885.0000,  8153826.5000],
        [10159343.0000,  4389494.0000],
        [11272392.0000,  2868386.7500],
        [ 1288359.3750, 12205483.0000],
        [ 1376221.6250, 12868908.0000],
        [ 3925548.5000,  9257960.0000],
        [11834685.0000,  2979041.5000],
        [10286443.0000,  4471914.5000],
        [ 2744664.5000, 11116195.0000],
        [ 2724089.2500, 10911120.0000],
        [       0.0000, 13861659.0000],
        [ 2742538.0000, 11494380.0000],
        [11965144.0000,  1402387.2500],
        [10665292.0000,  2560368.5000],
        [ 9738284.0000,  3857010.2500],
        [ 1392640.7500, 12816709.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 331/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.46s/it]  7%|▋         | 2/29 [00:58<10:53, 24.21s/it] 10%|█         | 3/29 [01:00<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:01<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.05s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.895958662033081
Epoch 332/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:26, 56.65s/it]  7%|▋         | 2/29 [00:58<11:03, 24.57s/it] 10%|█         | 3/29 [00:59<05:58, 13.77s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.70s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.90s/it] 21%|██        | 6/29 [01:02<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 2.884009838104248
Epoch 333/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.80s/it]  7%|▋         | 2/29 [00:57<10:46, 23.94s/it] 10%|█         | 3/29 [01:01<06:21, 14.68s/it] 14%|█▍        | 4/29 [01:02<03:51,  9.25s/it] 17%|█▋        | 5/29 [01:03<02:29,  6.25s/it] 21%|██        | 6/29 [01:04<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:05<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:06<00:53,  2.53s/it] 31%|███       | 9/29 [01:06<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:07<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8915247917175293
Epoch 334/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.82s/it]  7%|▋         | 2/29 [00:57<10:46, 23.94s/it] 10%|█         | 3/29 [01:00<06:08, 14.17s/it] 14%|█▍        | 4/29 [01:01<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:02<02:27,  6.16s/it] 21%|██        | 6/29 [01:03<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.51s/it] 31%|███       | 9/29 [01:06<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.893960475921631
Epoch 335/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:12, 58.30s/it]  7%|▋         | 2/29 [01:00<11:21, 25.24s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8811864852905273
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0134, 0.0028,  ..., 0.0042, 0.0001, 0.0182],
        [0.0031, 0.0096, 0.0028,  ..., 0.0033, 0.0003, 0.0170],
        [0.0339, 0.0066, 0.0039,  ..., 0.0054, 0.0169, 0.0235],
        ...,
        [0.0068, 0.0085, 0.0212,  ..., 0.0045, 0.0015, 0.0200],
        [0.0050, 0.0090, 0.0155,  ..., 0.0052, 0.0047, 0.0193],
        [0.0092, 0.0053, 0.0056,  ..., 0.0023, 0.0030, 0.0212]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9964, 0.9954, 0.9951, 0.9947, 0.9947, 0.9946, 0.9946, 0.9946,
         0.9946],
        [0.9971, 0.9970, 0.9970, 0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9774, 0.9673, 0.9672, 0.9669, 0.9658, 0.9651, 0.9650, 0.9645, 0.9644,
         0.9625],
        [0.9927, 0.9922, 0.9921, 0.9917, 0.9915, 0.9915, 0.9910, 0.9905, 0.9904,
         0.9902],
        [0.9894, 0.9876, 0.9865, 0.9863, 0.9862, 0.9857, 0.9856, 0.9854, 0.9853,
         0.9852],
        [0.9855, 0.9852, 0.9800, 0.9775, 0.9773, 0.9754, 0.9741, 0.9741, 0.9736,
         0.9734],
        [0.9786, 0.9726, 0.9698, 0.9693, 0.9673, 0.9668, 0.9666, 0.9651, 0.9648,
         0.9634],
        [0.9767, 0.9732, 0.9730, 0.9686, 0.9582, 0.9563, 0.9562, 0.9542, 0.9536,
         0.9530],
        [0.9978, 0.9973, 0.9971, 0.9968, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9939, 0.9895, 0.9881, 0.9870, 0.9870, 0.9864, 0.9855, 0.9850, 0.9849,
         0.9846],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9941, 0.9930, 0.9917, 0.9909, 0.9904, 0.9903, 0.9902, 0.9902, 0.9896,
         0.9896],
        [0.9935, 0.9911, 0.9907, 0.9899, 0.9897, 0.9887, 0.9870, 0.9866, 0.9862,
         0.9859],
        [0.9985, 0.9983, 0.9982, 0.9981, 0.9978, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9961, 0.9961, 0.9960, 0.9959, 0.9958, 0.9957, 0.9955, 0.9955, 0.9955,
         0.9955],
        [0.9956, 0.9948, 0.9948, 0.9948, 0.9947, 0.9945, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9948, 0.9940, 0.9938, 0.9935, 0.9933, 0.9933, 0.9933, 0.9932, 0.9931,
         0.9930],
        [0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9982, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9952, 0.9947, 0.9947, 0.9942, 0.9941, 0.9941, 0.9937, 0.9936, 0.9931,
         0.9931],
        [0.9986, 0.9985, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9977, 0.9975,
         0.9975],
        [0.9990, 0.9989, 0.9989, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9953, 0.9951, 0.9950, 0.9946, 0.9943, 0.9943, 0.9941, 0.9941, 0.9941,
         0.9940],
        [0.9989, 0.9988, 0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9978],
        [0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984,
         0.9984],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9890, 0.9882, 0.9787, 0.9748, 0.9735, 0.9723, 0.9715, 0.9710, 0.9666,
         0.9635],
        [0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9959],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9966, 0.9965, 0.9963, 0.9963, 0.9961, 0.9961, 0.9961, 0.9960, 0.9959,
         0.9959],
        [0.9877, 0.9855, 0.9826, 0.9777, 0.9772, 0.9760, 0.9744, 0.9741, 0.9733,
         0.9726],
        [0.9953, 0.9951, 0.9949, 0.9948, 0.9948, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9946],
        [0.9933, 0.9923, 0.9921, 0.9917, 0.9917, 0.9912, 0.9911, 0.9908, 0.9907,
         0.9906],
        [0.9957, 0.9955, 0.9955, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952,
         0.9951],
        [0.9863, 0.9861, 0.9856, 0.9845, 0.9841, 0.9837, 0.9827, 0.9822, 0.9819,
         0.9809],
        [0.9983, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9972, 0.9971, 0.9970, 0.9968, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9900, 0.9893, 0.9890, 0.9875, 0.9867, 0.9856, 0.9852, 0.9852, 0.9851,
         0.9844],
        [0.9865, 0.9799, 0.9798, 0.9795, 0.9794, 0.9792, 0.9791, 0.9789, 0.9783,
         0.9778],
        [0.9888, 0.9876, 0.9766, 0.9729, 0.9659, 0.9632, 0.9628, 0.9625, 0.9617,
         0.9601],
        [0.9729, 0.9710, 0.9695, 0.9670, 0.9659, 0.9656, 0.9654, 0.9644, 0.9620,
         0.9554],
        [0.9914, 0.9892, 0.9887, 0.9886, 0.9885, 0.9884, 0.9867, 0.9866, 0.9865,
         0.9864],
        [0.9940, 0.9939, 0.9937, 0.9937, 0.9935, 0.9934, 0.9929, 0.9929, 0.9928,
         0.9926],
        [0.9934, 0.9918, 0.9918, 0.9917, 0.9914, 0.9912, 0.9911, 0.9910, 0.9905,
         0.9905],
        [0.9906, 0.9903, 0.9903, 0.9898, 0.9894, 0.9892, 0.9852, 0.9851, 0.9850,
         0.9849],
        [0.9933, 0.9932, 0.9930, 0.9928, 0.9925, 0.9917, 0.9911, 0.9907, 0.9897,
         0.9895],
        [0.9905, 0.9878, 0.9875, 0.9867, 0.9865, 0.9863, 0.9861, 0.9844, 0.9843,
         0.9837],
        [0.9950, 0.9949, 0.9949, 0.9947, 0.9947, 0.9947, 0.9944, 0.9943, 0.9942,
         0.9940],
        [0.9958, 0.9951, 0.9949, 0.9947, 0.9944, 0.9941, 0.9936, 0.9936, 0.9931,
         0.9930],
        [0.9946, 0.9907, 0.9905, 0.9905, 0.9897, 0.9892, 0.9891, 0.9888, 0.9876,
         0.9876],
        [0.9922, 0.9921, 0.9911, 0.9893, 0.9890, 0.9878, 0.9873, 0.9864, 0.9858,
         0.9857],
        [0.9922, 0.9921, 0.9919, 0.9915, 0.9902, 0.9889, 0.9886, 0.9884, 0.9880,
         0.9860],
        [0.9968, 0.9942, 0.9936, 0.9925, 0.9924, 0.9912, 0.9895, 0.9895, 0.9887,
         0.9886],
        [0.9907, 0.9886, 0.9875, 0.9872, 0.9871, 0.9869, 0.9866, 0.9865, 0.9862,
         0.9862],
        [0.9924, 0.9918, 0.9878, 0.9866, 0.9851, 0.9843, 0.9842, 0.9839, 0.9838,
         0.9833],
        [0.9925, 0.9918, 0.9908, 0.9908, 0.9905, 0.9891, 0.9861, 0.9846, 0.9838,
         0.9837],
        [0.9928, 0.9925, 0.9923, 0.9919, 0.9919, 0.9918, 0.9915, 0.9908, 0.9903,
         0.9901]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 0, 1, 1, 0, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1521473.0000, 1519019.8750, 1498403.2500, 1492045.0000, 1483526.1250,
         1483226.2500, 1482048.3750, 1482018.6250, 1481942.3750, 1481844.8750],
        [1536393.6250, 1533470.3750, 1532582.8750, 1532509.7500, 1531164.3750,
         1528952.2500, 1526350.2500, 1526324.0000, 1526050.3750, 1525721.5000],
        [1159392.3750, 1003230.7500, 1001831.0000,  996858.9375,  981619.3125,
          971855.6250,  970769.9375,  964001.9375,  962346.7500,  937131.5000],
        [1442750.8750, 1431491.8750, 1430101.3750, 1420865.3750, 1418271.5000,
         1417664.3750, 1407882.7500, 1397726.1250, 1394553.1250, 1391773.6250],
        [1374683.0000, 1340569.8750, 1318708.0000, 1315838.7500, 1314539.3750,
         1304581.8750, 1303654.1250, 1298610.1250, 1297248.5000, 1295202.6250],
        [1300783.0000, 1295748.7500, 1202774.1250, 1160268.3750, 1157878.5000,
         1126087.1250, 1105110.5000, 1104816.5000, 1096830.3750, 1094589.1250],
        [1178373.6250, 1081533.3750, 1039668.0625, 1031916.8125, 1002945.6875,
          995468.1250,  992712.1875,  972458.2500,  967488.9375,  948104.8750],
        [1147021.0000, 1091689.7500, 1087858.0000, 1021295.1875,  880732.2500,
          857059.3750,  855462.9375,  831401.3750,  824682.7500,  817167.8750],
        [1550531.6250, 1540291.6250, 1535634.8750, 1528861.8750, 1525730.2500,
         1525408.7500, 1524575.3750, 1524485.2500, 1524379.1250, 1521738.5000],
        [1465772.7500, 1377505.8750, 1350639.7500, 1329424.7500, 1329399.5000,
         1318203.8750, 1301153.8750, 1291674.7500, 1289566.3750, 1284034.2500],
        [1555236.7500, 1554412.1250, 1551006.3750, 1550200.5000, 1550179.7500,
         1549222.1250, 1548877.8750, 1548747.8750, 1548318.1250, 1548267.8750],
        [1469919.1250, 1447378.6250, 1422151.8750, 1406020.3750, 1395052.0000,
         1392408.2500, 1391861.2500, 1391572.0000, 1380288.5000, 1378462.6250],
        [1457663.8750, 1408640.2500, 1400665.7500, 1386158.7500, 1380599.2500,
         1361170.5000, 1328260.2500, 1322369.1250, 1313175.0000, 1307736.0000],
        [1567228.2500, 1561337.1250, 1560414.1250, 1558492.6250, 1551408.7500,
         1546787.7500, 1543781.3750, 1543771.1250, 1543573.8750, 1540908.7500],
        [1574860.3750, 1573339.6250, 1573314.1250, 1573279.7500, 1573069.6250,
         1572367.6250, 1571077.1250, 1570536.3750, 1570211.3750, 1570054.1250],
        [1571183.5000, 1568780.3750, 1568719.0000, 1567451.0000, 1566788.8750,
         1566352.6250, 1565083.5000, 1564925.1250, 1561605.1250, 1561535.1250],
        [1514307.5000, 1513272.3750, 1512467.2500, 1509863.2500, 1507861.5000,
         1505499.3750, 1501401.5000, 1500734.3750, 1500702.8750, 1500565.5000],
        [1501911.3750, 1486041.0000, 1485537.8750, 1485036.5000, 1483782.2500,
         1480116.1250, 1480059.6250, 1479359.7500, 1478101.7500, 1476407.0000],
        [1486218.1250, 1468511.0000, 1464316.8750, 1457640.1250, 1454023.5000,
         1453852.8750, 1453344.1250, 1453200.0000, 1449898.3750, 1448009.5000],
        [1553957.1250, 1553880.1250, 1549523.6250, 1549134.8750, 1545888.1250,
         1545745.1250, 1545529.8750, 1545347.2500, 1545288.2500, 1544698.8750],
        [1559572.0000, 1552584.0000, 1550760.8750, 1550391.2500, 1550117.6250,
         1549971.3750, 1547816.2500, 1546100.5000, 1546090.1250, 1545283.8750],
        [1494313.5000, 1483432.7500, 1482592.6250, 1474060.3750, 1471154.6250,
         1471101.2500, 1461975.5000, 1461403.8750, 1450027.1250, 1449609.5000],
        [1568677.1250, 1566204.7500, 1559151.2500, 1557632.3750, 1556661.1250,
         1554268.3750, 1552350.1250, 1549307.8750, 1544778.5000, 1544744.6250],
        [1577083.2500, 1574594.5000, 1574463.8750, 1571492.1250, 1571292.8750,
         1571026.2500, 1570862.8750, 1570528.8750, 1569539.1250, 1569232.2500],
        [1496459.7500, 1492752.3750, 1489199.0000, 1481830.7500, 1476102.8750,
         1474148.8750, 1471968.6250, 1471168.6250, 1470703.0000, 1468233.6250],
        [1575467.2500, 1572282.2500, 1564989.5000, 1564967.0000, 1564799.8750,
         1563457.3750, 1562871.5000, 1561654.2500, 1561116.7500, 1561009.6250],
        [1564126.8750, 1561821.1250, 1558773.6250, 1557214.8750, 1556117.8750,
         1555054.2500, 1554323.2500, 1553100.7500, 1552249.3750, 1550698.7500],
        [1572912.1250, 1572744.0000, 1572214.7500, 1571280.8750, 1570536.3750,
         1568994.3750, 1568517.1250, 1565510.5000, 1565128.2500, 1565046.1250],
        [1577394.6250, 1577086.2500, 1576913.3750, 1575845.8750, 1574974.5000,
         1573267.6250, 1573014.1250, 1572627.1250, 1572502.6250, 1572013.8750],
        [1579598.5000, 1579175.2500, 1576072.8750, 1575225.5000, 1575142.7500,
         1573836.5000, 1573525.7500, 1572976.6250, 1572015.2500, 1571968.7500],
        [1579872.6250, 1579199.2500, 1576328.3750, 1575812.8750, 1575477.8750,
         1575342.6250, 1574099.0000, 1574079.5000, 1573968.5000, 1573886.0000],
        [1578694.8750, 1577331.3750, 1576993.0000, 1574636.6250, 1574082.5000,
         1573158.1250, 1572750.1250, 1572489.1250, 1571631.6250, 1571492.1250],
        [1367535.7500, 1352622.2500, 1181278.8750, 1115875.6250, 1095977.2500,
         1076792.0000, 1064970.8750, 1057837.7500,  992901.5000,  949570.7500],
        [1521059.5000, 1520875.2500, 1518082.8750, 1518040.8750, 1518023.5000,
         1513224.7500, 1511863.0000, 1511335.5000, 1511061.6250, 1509100.2500],
        [1551697.3750, 1549996.5000, 1547724.6250, 1545529.8750, 1545118.7500,
         1544454.3750, 1544454.3750, 1544413.1250, 1544061.1250, 1543540.0000],
        [1524219.2500, 1521943.1250, 1518207.3750, 1517121.8750, 1514551.5000,
         1512853.8750, 1512607.2500, 1511342.7500, 1510040.2500, 1509825.7500],
        [1341631.5000, 1300894.6250, 1248970.6250, 1163826.7500, 1155909.1250,
         1136246.8750, 1110638.2500, 1105043.0000, 1092861.7500, 1081925.3750],
        [1495816.2500, 1492030.7500, 1487175.1250, 1486796.5000, 1486076.3750,
         1483499.2500, 1483151.2500, 1482209.5000, 1481374.3750, 1481089.0000],
        [1455030.5000, 1434553.1250, 1429431.8750, 1421524.0000, 1420415.5000,
         1411811.5000, 1410160.3750, 1404041.2500, 1401148.0000, 1399784.3750],
        [1505344.3750, 1501540.3750, 1501540.3750, 1500435.3750, 1500047.6250,
         1497587.6250, 1496221.5000, 1495539.6250, 1494919.2500, 1493040.0000],
        [1315442.3750, 1312412.5000, 1302912.1250, 1281824.6250, 1275946.0000,
         1267170.0000, 1249341.2500, 1241838.5000, 1236313.0000, 1217658.8750],
        [1562326.0000, 1558790.0000, 1557656.1250, 1557650.1250, 1556361.2500,
         1555972.5000, 1555843.3750, 1555196.6250, 1554843.6250, 1554680.5000],
        [1556484.5000, 1556201.1250, 1553634.1250, 1550573.0000, 1546668.2500,
         1546071.0000, 1545681.7500, 1545210.1250, 1545170.3750, 1545167.3750],
        [1538566.6250, 1535232.1250, 1532186.7500, 1529270.1250, 1527043.3750,
         1525772.5000, 1524196.0000, 1523299.3750, 1522282.8750, 1521818.2500],
        [1388017.2500, 1373544.2500, 1368250.6250, 1338052.5000, 1322550.7500,
         1302807.8750, 1295628.8750, 1294534.6250, 1292992.2500, 1281395.6250],
        [1318772.2500, 1200460.3750, 1198730.6250, 1194065.1250, 1191823.8750,
         1188916.5000, 1186582.0000, 1184448.6250, 1174299.0000, 1164992.7500],
        [1363139.8750, 1339782.6250, 1146300.3750, 1086296.6250,  982584.0000,
          946027.5000,  940181.3125,  937203.0000,  926018.3125,  904991.6875],
        [1086487.2500, 1057375.8750, 1034791.3750,  998225.0000,  982643.1250,
          978326.8750,  976059.5000,  962624.0000,  930307.8750,  846647.1250],
        [1415536.5000, 1370635.3750, 1362308.1250, 1359976.7500, 1358255.5000,
         1355622.1250, 1323710.2500, 1321174.0000, 1320170.2500, 1318449.1250],
        [1469434.2500, 1465948.8750, 1463129.0000, 1461764.8750, 1457684.7500,
         1456188.2500, 1446505.1250, 1445118.0000, 1443536.6250, 1439589.6250],
        [1456557.7500, 1423491.1250, 1422971.2500, 1420510.3750, 1415126.1250,
         1410550.5000, 1408718.1250, 1407582.0000, 1397468.7500, 1396405.7500],
        [1398946.2500, 1394058.5000, 1392709.7500, 1383991.1250, 1375275.7500,
         1372013.7500, 1295359.6250, 1293868.1250, 1291242.5000, 1289145.8750],
        [1454051.1250, 1452553.0000, 1447541.3750, 1444529.6250, 1437869.0000,
         1422265.7500, 1409638.7500, 1401555.6250, 1380649.2500, 1376458.0000],
        [1397628.7500, 1344369.8750, 1337913.3750, 1323929.8750, 1318923.1250,
         1316624.6250, 1311179.0000, 1279738.3750, 1278446.6250, 1267172.3750],
        [1490925.5000, 1488426.6250, 1487979.5000, 1482885.2500, 1482571.3750,
         1482571.3750, 1478321.7500, 1474438.5000, 1473146.8750, 1467960.6250],
        [1508119.0000, 1491106.1250, 1486844.7500, 1483280.0000, 1476370.3750,
         1470829.1250, 1460275.3750, 1459916.1250, 1449174.1250, 1448860.5000],
        [1480471.8750, 1400701.7500, 1397448.8750, 1397430.2500, 1381671.3750,
         1371487.8750, 1369225.7500, 1362863.0000, 1341337.2500, 1339689.3750],
        [1431045.5000, 1430329.2500, 1408304.3750, 1374285.8750, 1366741.7500,
         1344495.5000, 1334402.7500, 1318605.0000, 1306054.6250, 1304919.1250],
        [1432467.0000, 1430518.8750, 1425600.8750, 1417012.8750, 1390350.2500,
         1365155.0000, 1359195.0000, 1355058.6250, 1347830.7500, 1310678.8750],
        [1528822.5000, 1472337.8750, 1461514.1250, 1437056.1250, 1436162.8750,
         1411471.0000, 1376977.8750, 1376497.3750, 1362115.8750, 1359816.0000],
        [1401674.6250, 1359648.7500, 1338976.6250, 1332262.6250, 1331518.3750,
         1328068.8750, 1321204.2500, 1318772.2500, 1314430.3750, 1313707.2500],
        [1435486.3750, 1423965.0000, 1345113.6250, 1321098.5000, 1292832.0000,
         1278094.2500, 1276692.1250, 1272240.0000, 1269686.1250, 1261255.2500],
        [1437497.5000, 1423671.6250, 1403429.5000, 1402558.5000, 1397927.3750,
         1370385.7500, 1311486.6250, 1284220.3750, 1270446.7500, 1267988.3750],
        [1444514.5000, 1436997.2500, 1434476.5000, 1426192.5000, 1424588.5000,
         1422903.5000, 1418197.0000, 1403643.6250, 1392430.8750, 1389529.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1521473.0000,       0.0000],
         [1519019.8750,       0.0000],
         [1498403.2500,       0.0000],
         ...,
         [1482018.6250,       0.0000],
         [1481942.3750,       0.0000],
         [      0.0000, 1481844.8750]],

        [[1536393.6250,       0.0000],
         [1533470.3750,       0.0000],
         [1532582.8750,       0.0000],
         ...,
         [1526324.0000,       0.0000],
         [1526050.3750,       0.0000],
         [1525721.5000,       0.0000]],

        [[1159392.3750,       0.0000],
         [      0.0000, 1003230.7500],
         [      0.0000, 1001831.0000],
         ...,
         [      0.0000,  964001.9375],
         [      0.0000,  962346.7500],
         [      0.0000,  937131.5000]],

        ...,

        [[1435486.3750,       0.0000],
         [1423965.0000,       0.0000],
         [1345113.6250,       0.0000],
         ...,
         [      0.0000, 1272240.0000],
         [1269686.1250,       0.0000],
         [1261255.2500,       0.0000]],

        [[1437497.5000,       0.0000],
         [1423671.6250,       0.0000],
         [1403429.5000,       0.0000],
         ...,
         [1284220.3750,       0.0000],
         [      0.0000, 1270446.7500],
         [      0.0000, 1267988.3750]],

        [[      0.0000, 1444514.5000],
         [      0.0000, 1436997.2500],
         [      0.0000, 1434476.5000],
         ...,
         [      0.0000, 1403643.6250],
         [      0.0000, 1392430.8750],
         [      0.0000, 1389529.7500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13443702.0000,  1481844.8750],
        [15299519.0000,        0.0000],
        [ 4083637.5000,  5865401.0000],
        [12755355.0000,  1397726.1250],
        [ 9248941.0000,  3914695.5000],
        [ 9390178.0000,  2254709.0000],
        [ 3079947.2500,  7130723.0000],
        [ 8582969.0000,   831401.3750],
        [13775907.0000,  1525730.2500],
        [11959870.0000,  1377505.8750],
        [15504468.0000,        0.0000],
        [14075114.0000,        0.0000],
        [13666439.0000,        0.0000],
        [15517704.0000,        0.0000],
        [15722110.0000,        0.0000],
        [15662424.0000,        0.0000],
        [13554208.0000,  1512467.2500],
        [11855082.0000,  2981271.0000],
        [14589015.0000,        0.0000],
        [15478994.0000,        0.0000],
        [15498688.0000,        0.0000],
        [13217078.0000,  1482592.6250],
        [15553776.0000,        0.0000],
        [15720116.0000,        0.0000],
        [11803356.0000,  2989212.0000],
        [15652615.0000,        0.0000],
        [15563480.0000,        0.0000],
        [15692886.0000,        0.0000],
        [15745641.0000,        0.0000],
        [15749538.0000,        0.0000],
        [15758066.0000,        0.0000],
        [15743259.0000,        0.0000],
        [ 3091333.5000,  8164029.5000],
        [12113584.0000,  3039083.0000],
        [12372331.0000,  3088658.7500],
        [13640106.0000,  1512607.2500],
        [ 3353814.0000,  8384134.0000],
        [10385295.0000,  4473923.0000],
        [12786752.0000,  1401148.0000],
        [13493176.0000,  1493040.0000],
        [10112501.0000,  2588358.5000],
        [15569321.0000,        0.0000],
        [15490861.0000,        0.0000],
        [13752624.0000,  1527043.3750],
        [ 2588621.0000, 10669153.0000],
        [       0.0000, 12003092.0000],
        [ 5637006.0000,  4935519.5000],
        [ 2739579.0000,  7113909.0000],
        [ 2730612.0000, 10775226.0000],
        [10158651.0000,  4390248.0000],
        [11292274.0000,  2867108.2500],
        [ 1289145.8750, 12197465.0000],
        [ 1376458.0000, 12850653.0000],
        [ 3907727.0000,  9268199.0000],
        [11830323.0000,  2978905.0000],
        [10263442.0000,  4471334.0000],
        [ 2744534.5000, 11097792.0000],
        [ 2718781.5000, 10900403.0000],
        [       0.0000, 13833868.0000],
        [ 2738613.2500, 11484158.0000],
        [10644882.0000,  2715382.0000],
        [10627532.0000,  2548932.0000],
        [ 9719691.0000,  3849921.5000],
        [       0.0000, 14193474.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 336/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:03, 57.98s/it]  7%|▋         | 2/29 [01:01<11:37, 25.82s/it] 10%|█         | 3/29 [01:02<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.881798505783081
Epoch 337/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:59, 59.98s/it]  7%|▋         | 2/29 [01:01<11:36, 25.79s/it] 10%|█         | 3/29 [01:02<06:15, 14.43s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8752880096435547
Epoch 338/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:51, 57.57s/it]  7%|▋         | 2/29 [00:58<10:54, 24.25s/it] 10%|█         | 3/29 [00:59<05:53, 13.60s/it] 14%|█▍        | 4/29 [01:00<03:34,  8.59s/it] 17%|█▋        | 5/29 [01:01<02:19,  5.83s/it] 21%|██        | 6/29 [01:02<01:35,  4.16s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.10s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.06it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.8937833309173584
Epoch 339/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:43, 57.25s/it]  7%|▋         | 2/29 [00:58<10:51, 24.12s/it] 10%|█         | 3/29 [00:59<05:51, 13.53s/it] 14%|█▍        | 4/29 [01:00<03:33,  8.55s/it] 17%|█▋        | 5/29 [01:00<02:19,  5.80s/it] 21%|██        | 6/29 [01:01<01:35,  4.14s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.09s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.40s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.87s/it]
Epoch loss is 2.8935492038726807
Epoch 340/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:31, 56.84s/it]  7%|▋         | 2/29 [00:57<10:46, 23.95s/it] 10%|█         | 3/29 [00:58<05:49, 13.43s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.49s/it] 17%|█▋        | 5/29 [01:00<02:18,  5.76s/it] 21%|██        | 6/29 [01:01<01:34,  4.12s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.07s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.39s/it] 31%|███       | 9/29 [01:04<00:38,  1.93s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:07<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:08<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:09<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:18<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:19<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:20<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:21<00:00,  1.08it/s]100%|██████████| 29/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:22<00:00,  2.86s/it]
Epoch loss is 2.875617027282715
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0036, 0.0142, 0.0028,  ..., 0.0044, 0.0002, 0.0183],
        [0.0035, 0.0099, 0.0029,  ..., 0.0034, 0.0003, 0.0174],
        [0.0338, 0.0062, 0.0037,  ..., 0.0054, 0.0171, 0.0235],
        ...,
        [0.0069, 0.0088, 0.0215,  ..., 0.0046, 0.0016, 0.0200],
        [0.0048, 0.0091, 0.0148,  ..., 0.0052, 0.0048, 0.0195],
        [0.0098, 0.0053, 0.0055,  ..., 0.0024, 0.0032, 0.0215]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9959, 0.9952, 0.9946, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942,
         0.9941],
        [0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9779, 0.9681, 0.9666, 0.9661, 0.9660, 0.9651, 0.9643, 0.9641, 0.9632,
         0.9618],
        [0.9922, 0.9921, 0.9921, 0.9916, 0.9914, 0.9910, 0.9906, 0.9901, 0.9898,
         0.9896],
        [0.9887, 0.9868, 0.9865, 0.9851, 0.9850, 0.9849, 0.9848, 0.9845, 0.9844,
         0.9844],
        [0.9849, 0.9848, 0.9791, 0.9776, 0.9765, 0.9741, 0.9735, 0.9732, 0.9731,
         0.9729],
        [0.9792, 0.9722, 0.9686, 0.9683, 0.9680, 0.9671, 0.9661, 0.9646, 0.9636,
         0.9621],
        [0.9777, 0.9734, 0.9719, 0.9684, 0.9603, 0.9585, 0.9574, 0.9570, 0.9548,
         0.9541],
        [0.9977, 0.9972, 0.9970, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9939, 0.9894, 0.9881, 0.9869, 0.9869, 0.9862, 0.9845, 0.9844, 0.9842,
         0.9834],
        [0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9938, 0.9924, 0.9915, 0.9907, 0.9897, 0.9897, 0.9895, 0.9893, 0.9893,
         0.9892],
        [0.9931, 0.9910, 0.9902, 0.9896, 0.9889, 0.9882, 0.9860, 0.9857, 0.9855,
         0.9852],
        [0.9985, 0.9982, 0.9982, 0.9980, 0.9978, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9987, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984, 0.9982,
         0.9982],
        [0.9961, 0.9960, 0.9959, 0.9957, 0.9956, 0.9956, 0.9954, 0.9954, 0.9954,
         0.9952],
        [0.9954, 0.9947, 0.9946, 0.9946, 0.9945, 0.9943, 0.9943, 0.9943, 0.9942,
         0.9942],
        [0.9945, 0.9938, 0.9936, 0.9933, 0.9932, 0.9931, 0.9931, 0.9930, 0.9929,
         0.9927],
        [0.9978, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9981, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9951, 0.9944, 0.9944, 0.9940, 0.9936, 0.9936, 0.9935, 0.9934, 0.9928,
         0.9928],
        [0.9986, 0.9985, 0.9981, 0.9980, 0.9980, 0.9978, 0.9977, 0.9976, 0.9975,
         0.9974],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9951, 0.9950, 0.9946, 0.9945, 0.9943, 0.9940, 0.9940, 0.9939, 0.9938,
         0.9936],
        [0.9989, 0.9987, 0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9984, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9888, 0.9877, 0.9782, 0.9738, 0.9725, 0.9715, 0.9715, 0.9692, 0.9675,
         0.9652],
        [0.9963, 0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9964, 0.9963, 0.9961, 0.9961, 0.9959, 0.9959, 0.9958, 0.9958, 0.9958,
         0.9958],
        [0.9875, 0.9854, 0.9823, 0.9767, 0.9765, 0.9759, 0.9746, 0.9726, 0.9724,
         0.9717],
        [0.9951, 0.9949, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944,
         0.9944],
        [0.9933, 0.9924, 0.9919, 0.9914, 0.9911, 0.9911, 0.9910, 0.9908, 0.9906,
         0.9906],
        [0.9956, 0.9954, 0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9950, 0.9950,
         0.9950],
        [0.9865, 0.9858, 0.9854, 0.9846, 0.9836, 0.9835, 0.9824, 0.9823, 0.9814,
         0.9802],
        [0.9983, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,
         0.9974],
        [0.9971, 0.9969, 0.9968, 0.9966, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9897, 0.9887, 0.9886, 0.9871, 0.9861, 0.9851, 0.9849, 0.9849, 0.9846,
         0.9842],
        [0.9865, 0.9788, 0.9788, 0.9787, 0.9784, 0.9780, 0.9779, 0.9774, 0.9770,
         0.9769],
        [0.9889, 0.9878, 0.9757, 0.9723, 0.9650, 0.9620, 0.9620, 0.9619, 0.9610,
         0.9586],
        [0.9734, 0.9714, 0.9690, 0.9668, 0.9656, 0.9650, 0.9650, 0.9630, 0.9608,
         0.9552],
        [0.9913, 0.9889, 0.9886, 0.9883, 0.9883, 0.9882, 0.9868, 0.9868, 0.9862,
         0.9861],
        [0.9938, 0.9937, 0.9935, 0.9935, 0.9932, 0.9931, 0.9927, 0.9925, 0.9924,
         0.9920],
        [0.9928, 0.9915, 0.9914, 0.9912, 0.9911, 0.9906, 0.9906, 0.9906, 0.9903,
         0.9902],
        [0.9902, 0.9899, 0.9898, 0.9896, 0.9892, 0.9889, 0.9851, 0.9850, 0.9847,
         0.9846],
        [0.9934, 0.9930, 0.9929, 0.9927, 0.9925, 0.9916, 0.9910, 0.9904, 0.9896,
         0.9896],
        [0.9905, 0.9874, 0.9867, 0.9866, 0.9860, 0.9859, 0.9854, 0.9841, 0.9836,
         0.9833],
        [0.9948, 0.9948, 0.9947, 0.9945, 0.9944, 0.9944, 0.9943, 0.9941, 0.9939,
         0.9938],
        [0.9955, 0.9946, 0.9945, 0.9943, 0.9940, 0.9937, 0.9932, 0.9931, 0.9927,
         0.9925],
        [0.9944, 0.9904, 0.9903, 0.9902, 0.9897, 0.9890, 0.9889, 0.9889, 0.9875,
         0.9873],
        [0.9919, 0.9917, 0.9909, 0.9891, 0.9888, 0.9875, 0.9870, 0.9861, 0.9852,
         0.9852],
        [0.9920, 0.9919, 0.9919, 0.9912, 0.9896, 0.9887, 0.9885, 0.9882, 0.9879,
         0.9855],
        [0.9967, 0.9940, 0.9934, 0.9922, 0.9922, 0.9910, 0.9890, 0.9890, 0.9885,
         0.9882],
        [0.9906, 0.9887, 0.9872, 0.9870, 0.9867, 0.9864, 0.9862, 0.9862, 0.9861,
         0.9859],
        [0.9920, 0.9915, 0.9875, 0.9861, 0.9846, 0.9838, 0.9837, 0.9835, 0.9830,
         0.9829],
        [0.9923, 0.9917, 0.9908, 0.9908, 0.9904, 0.9890, 0.9857, 0.9843, 0.9839,
         0.9838],
        [0.9926, 0.9921, 0.9921, 0.9918, 0.9917, 0.9916, 0.9914, 0.9907, 0.9903,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 1, 0, 1, 1, 1, 1, 1, 0],
        [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 1, 0, 1, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515885.2500, 1508757.7500, 1494202.3750, 1481128.5000, 1479310.3750,
         1476279.0000, 1475979.0000, 1475438.6250, 1473638.6250, 1471957.3750],
        [1532280.3750, 1531177.5000, 1528813.7500, 1528357.3750, 1525742.0000,
         1524835.6250, 1523906.7500, 1522596.5000, 1522152.1250, 1522072.2500],
        [1166745.1250, 1015185.2500,  992404.5625,  986697.0000,  984448.7500,
          971581.2500,  961057.2500,  958055.7500,  945584.6250,  927607.5625],
        [1432058.5000, 1430059.1250, 1428513.3750, 1420300.3750, 1415350.2500,
         1408021.1250, 1398666.2500, 1389999.0000, 1383534.5000, 1378479.6250],
        [1362653.7500, 1325975.6250, 1320323.8750, 1294331.0000, 1291310.2500,
         1289771.7500, 1288167.6250, 1282931.3750, 1280993.6250, 1279867.7500],
        [1289041.3750, 1288751.2500, 1187299.7500, 1161431.8750, 1144330.0000,
         1104808.0000, 1095856.0000, 1091745.0000, 1089344.6250, 1086383.7500],
        [1189676.5000, 1076439.8750, 1021990.8750, 1017759.0000, 1013489.4375,
          999758.0000,  986601.0625,  964545.4375,  951700.3750,  930734.6875],
        [1164377.5000, 1093775.1250, 1071670.6250, 1019152.7500,  907466.8750,
          885006.9375,  870937.2500,  865846.5625,  838821.6250,  830930.5000],
        [1548328.5000, 1537273.0000, 1532350.5000, 1525113.5000, 1522441.1250,
         1522140.6250, 1521872.0000, 1521237.8750, 1520253.1250, 1519496.5000],
        [1465817.3750, 1376149.5000, 1350093.6250, 1327070.0000, 1326379.1250,
         1313992.8750, 1283261.7500, 1280197.3750, 1276997.7500, 1261696.6250],
        [1553203.1250, 1552130.8750, 1549505.7500, 1547764.6250, 1547375.0000,
         1547043.0000, 1546678.5000, 1545836.6250, 1545335.5000, 1544376.2500],
        [1465468.0000, 1435004.7500, 1417553.5000, 1401281.7500, 1381081.2500,
         1380824.3750, 1378202.3750, 1373857.3750, 1372681.2500, 1372139.3750],
        [1450850.1250, 1407192.8750, 1391509.6250, 1378554.6250, 1365750.2500,
         1351782.6250, 1310590.1250, 1304503.6250, 1301153.8750, 1295510.2500],
        [1565532.8750, 1559707.5000, 1559383.2500, 1556057.0000, 1549773.2500,
         1543002.7500, 1542293.6250, 1540735.3750, 1540441.6250, 1536952.0000],
        [1573366.6250, 1572660.1250, 1572103.7500, 1571468.2500, 1571239.0000,
         1571083.0000, 1569503.2500, 1569455.3750, 1568856.7500, 1568725.0000],
        [1570221.8750, 1566434.8750, 1566049.3750, 1565583.5000, 1565540.2500,
         1565320.7500, 1564107.5000, 1563321.6250, 1559392.1250, 1558940.1250],
        [1512718.3750, 1511050.1250, 1509556.5000, 1506004.8750, 1503292.7500,
         1502107.5000, 1499083.7500, 1498803.5000, 1498106.2500, 1494870.7500],
        [1497890.5000, 1482991.3750, 1481358.7500, 1481245.7500, 1479000.0000,
         1475575.1250, 1475257.1250, 1474364.0000, 1473432.0000, 1472045.7500],
        [1480339.1250, 1463671.7500, 1460496.8750, 1454619.8750, 1452065.3750,
         1451017.5000, 1450443.3750, 1448621.3750, 1446858.2500, 1442442.6250],
        [1551544.8750, 1551098.0000, 1546618.1250, 1546152.1250, 1544707.7500,
         1544067.0000, 1543494.3750, 1543189.7500, 1542462.7500, 1542354.0000],
        [1557106.6250, 1550576.0000, 1549244.2500, 1549012.2500, 1548539.6250,
         1548081.8750, 1545516.6250, 1544012.5000, 1543600.3750, 1543026.3750],
        [1491268.3750, 1477619.7500, 1476553.3750, 1468672.0000, 1460790.7500,
         1460120.8750, 1458608.0000, 1456111.8750, 1444130.2500, 1443900.1250],
        [1567525.6250, 1565759.7500, 1558006.7500, 1555769.2500, 1555738.1250,
         1551226.8750, 1548776.0000, 1547057.6250, 1543663.6250, 1542071.6250],
        [1575348.6250, 1573176.1250, 1572537.1250, 1570639.6250, 1570194.8750,
         1570106.5000, 1569516.6250, 1569429.7500, 1568409.3750, 1567785.7500],
        [1491862.8750, 1489498.6250, 1481818.0000, 1478424.6250, 1474213.6250,
         1468715.5000, 1468033.5000, 1466793.5000, 1463630.0000, 1460027.6250],
        [1574678.6250, 1570719.1250, 1563882.3750, 1563323.2500, 1562539.2500,
         1562008.7500, 1560442.3750, 1560369.6250, 1558911.8750, 1558895.5000],
        [1564064.3750, 1560308.5000, 1557755.7500, 1555873.1250, 1555227.7500,
         1553397.1250, 1551613.0000, 1550932.5000, 1550107.3750, 1549309.2500],
        [1572214.7500, 1571777.0000, 1571544.6250, 1571529.7500, 1569754.6250,
         1567842.6250, 1567285.0000, 1565625.3750, 1565046.1250, 1564637.2500],
        [1576133.0000, 1576038.3750, 1575474.8750, 1574836.2500, 1573339.6250,
         1572357.2500, 1571784.5000, 1571741.0000, 1570987.2500, 1570765.6250],
        [1578457.0000, 1577963.3750, 1574816.7500, 1573336.6250, 1573110.1250,
         1572252.2500, 1572181.7500, 1571297.3750, 1571152.0000, 1571063.6250],
        [1578321.6250, 1578122.8750, 1574901.0000, 1574723.7500, 1574238.7500,
         1573815.3750, 1573696.7500, 1572753.1250, 1572303.1250, 1572162.2500],
        [1576835.1250, 1576323.8750, 1575861.0000, 1573287.1250, 1572847.6250,
         1572306.1250, 1571313.8750, 1570238.2500, 1570112.5000, 1569578.0000],
        [1363968.2500, 1342165.1250, 1171883.6250, 1101417.3750, 1079719.5000,
         1065251.2500, 1064639.8750, 1031232.0625, 1006605.1250,  973829.8750],
        [1517289.7500, 1515513.8750, 1513432.6250, 1510963.7500, 1510890.1250,
         1509225.5000, 1505319.8750, 1504688.3750, 1503961.0000, 1501935.6250],
        [1550545.0000, 1548364.0000, 1545787.8750, 1543774.1250, 1542916.0000,
         1542567.3750, 1541955.3750, 1541923.0000, 1541742.2500, 1541742.2500],
        [1519758.7500, 1517865.7500, 1514550.1250, 1513354.6250, 1508675.7500,
         1508625.3750, 1508048.5000, 1507259.2500, 1506631.1250, 1506362.5000],
        [1337748.7500, 1298881.5000, 1243637.6250, 1146777.1250, 1144691.2500,
         1133478.3750, 1112963.5000, 1082384.6250, 1078523.7500, 1068418.3750],
        [1491473.1250, 1488134.2500, 1483424.2500, 1482625.2500, 1480984.5000,
         1480604.6250, 1478472.6250, 1478269.6250, 1476423.8750, 1476349.3750],
        [1453414.8750, 1436168.3750, 1426369.2500, 1415871.3750, 1410243.8750,
         1409773.1250, 1408027.8750, 1403280.8750, 1398616.8750, 1398519.3750],
        [1503646.8750, 1497890.5000, 1497217.7500, 1497217.7500, 1495760.6250,
         1494437.3750, 1493578.3750, 1490105.3750, 1489635.0000, 1489464.5000],
        [1319897.0000, 1306449.5000, 1299534.3750, 1284746.0000, 1265445.5000,
         1263845.0000, 1244307.8750, 1243478.7500, 1226899.0000, 1205621.0000],
        [1560917.2500, 1557106.6250, 1556123.7500, 1556083.7500, 1555456.2500,
         1553277.1250, 1552903.8750, 1552584.0000, 1552170.8750, 1552102.8750],
        [1554903.0000, 1552957.2500, 1550404.5000, 1547983.0000, 1543045.5000,
         1542871.8750, 1542346.6250, 1542209.8750, 1542033.3750, 1541555.5000],
        [1536340.8750, 1531136.6250, 1528767.0000, 1525080.0000, 1523353.1250,
         1522827.3750, 1519334.2500, 1518084.2500, 1516964.1250, 1516962.7500],
        [1381662.1250, 1361922.3750, 1360599.5000, 1330674.2500, 1312506.2500,
         1292581.7500, 1290430.0000, 1289410.2500, 1284774.1250, 1276203.8750],
        [1319595.0000, 1182737.3750, 1182672.0000, 1180074.0000, 1175582.0000,
         1169546.8750, 1166536.0000, 1158774.3750, 1152291.3750, 1150216.2500],
        [1364923.3750, 1344230.1250, 1131265.5000, 1076868.0000,  970589.3750,
          930437.4375,  929434.3750,  928206.6875,  916506.0625,  886378.6875],
        [1094169.5000, 1063084.3750, 1027984.8750,  996081.6250,  978595.5625,
          971107.9375,  970657.9375,  943058.5000,  914716.8750,  844407.8750],
        [1412350.1250, 1364790.6250, 1359398.5000, 1353987.7500, 1353417.0000,
         1352108.8750, 1326157.7500, 1325633.0000, 1313628.3750, 1312866.8750],
        [1465278.0000, 1462609.8750, 1458651.1250, 1457946.1250, 1452805.1250,
         1449565.2500, 1442697.1250, 1438641.2500, 1436587.5000, 1428262.7500],
        [1444719.6250, 1417787.3750, 1415571.6250, 1410729.3750, 1409184.3750,
         1399497.3750, 1399402.6250, 1398495.3750, 1392493.2500, 1391984.7500],
        [1391882.6250, 1384743.6250, 1383001.5000, 1378414.0000, 1371127.0000,
         1366163.1250, 1293526.3750, 1292128.1250, 1285926.3750, 1284024.5000],
        [1455371.8750, 1448175.2500, 1445251.6250, 1441030.5000, 1437067.0000,
         1419768.1250, 1406385.1250, 1395178.3750, 1379126.6250, 1379125.3750],
        [1396774.6250, 1336295.2500, 1323820.1250, 1321618.8750, 1311026.3750,
         1309084.8750, 1299400.5000, 1276050.5000, 1265520.3750, 1260513.1250],
        [1486280.5000, 1484757.5000, 1483881.3750, 1478719.3750, 1476725.2500,
         1476725.2500, 1474452.6250, 1471323.0000, 1466480.2500, 1465032.0000],
        [1501657.7500, 1481066.3750, 1479809.8750, 1475261.3750, 1468011.0000,
         1463081.5000, 1453049.0000, 1449312.3750, 1441595.5000, 1437697.7500],
        [1476766.1250, 1395758.6250, 1393683.6250, 1390269.3750, 1381892.7500,
         1368169.7500, 1364948.1250, 1364830.8750, 1339507.8750, 1334316.2500],
        [1424880.5000, 1420755.6250, 1404366.6250, 1369063.8750, 1363428.6250,
         1338334.5000, 1329192.7500, 1312108.3750, 1295190.3750, 1294633.3750],
        [1426936.6250, 1424894.2500, 1424564.0000, 1412243.8750, 1378818.8750,
         1361588.6250, 1357349.1250, 1352730.5000, 1346784.8750, 1300850.0000],
        [1525727.3750, 1468868.1250, 1456679.8750, 1431987.5000, 1431291.1250,
         1406634.6250, 1368356.2500, 1367388.3750, 1356906.5000, 1352484.2500],
        [1400018.0000, 1362618.6250, 1333535.1250, 1328873.5000, 1323760.7500,
         1318539.6250, 1314114.5000, 1313429.1250, 1312958.2500, 1307920.6250],
        [1427392.7500, 1417677.7500, 1338587.2500, 1312193.3750, 1284552.3750,
         1270249.3750, 1267039.5000, 1264194.6250, 1255504.2500, 1254038.5000],
        [1434506.6250, 1420622.8750, 1402748.5000, 1402349.7500, 1394763.3750,
         1367208.5000, 1304956.5000, 1279358.8750, 1270757.0000, 1268878.7500],
        [1439532.0000, 1428942.6250, 1428686.3750, 1422917.0000, 1420618.7500,
         1419210.5000, 1414990.0000, 1401214.7500, 1393015.3750, 1382277.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515885.2500,       0.0000],
         [1508757.7500,       0.0000],
         [1494202.3750,       0.0000],
         ...,
         [1475438.6250,       0.0000],
         [1473638.6250,       0.0000],
         [1471957.3750,       0.0000]],

        [[1532280.3750,       0.0000],
         [1531177.5000,       0.0000],
         [1528813.7500,       0.0000],
         ...,
         [1522596.5000,       0.0000],
         [1522152.1250,       0.0000],
         [1522072.2500,       0.0000]],

        [[1166745.1250,       0.0000],
         [      0.0000, 1015185.2500],
         [      0.0000,  992404.5625],
         ...,
         [      0.0000,  958055.7500],
         [ 945584.6250,       0.0000],
         [      0.0000,  927607.5625]],

        ...,

        [[1427392.7500,       0.0000],
         [1417677.7500,       0.0000],
         [1338587.2500,       0.0000],
         ...,
         [      0.0000, 1264194.6250],
         [1255504.2500,       0.0000],
         [1254038.5000,       0.0000]],

        [[1434506.6250,       0.0000],
         [1420622.8750,       0.0000],
         [1402748.5000,       0.0000],
         ...,
         [1279358.8750,       0.0000],
         [      0.0000, 1270757.0000],
         [      0.0000, 1268878.7500]],

        [[      0.0000, 1439532.0000],
         [      0.0000, 1428942.6250],
         [      0.0000, 1428686.3750],
         ...,
         [      0.0000, 1401214.7500],
         [      0.0000, 1393015.3750],
         [      0.0000, 1382277.6250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[14852577.0000,        0.0000],
        [15261934.0000,        0.0000],
        [ 4057835.7500,  5851531.0000],
        [12694982.0000,  1389999.0000],
        [10436850.0000,  2579478.0000],
        [ 9285815.0000,  2253177.0000],
        [ 4024691.5000,  6128004.0000],
        [ 8677048.0000,   870937.2500],
        [13748066.0000,  1522441.1250],
        [11885508.0000,  1376149.5000],
        [15479249.0000,        0.0000],
        [13978094.0000,        0.0000],
        [13557398.0000,        0.0000],
        [15493880.0000,        0.0000],
        [15708460.0000,        0.0000],
        [15644912.0000,        0.0000],
        [13526038.0000,  1509556.5000],
        [11820906.0000,  2972254.5000],
        [13108133.0000,  1442442.6250],
        [15455688.0000,        0.0000],
        [15478717.0000,        0.0000],
        [13161222.0000,  1476553.3750],
        [15535596.0000,        0.0000],
        [15707144.0000,        0.0000],
        [11761656.0000,  2981361.5000],
        [15635772.0000,        0.0000],
        [15548588.0000,        0.0000],
        [15687257.0000,        0.0000],
        [15733457.0000,        0.0000],
        [15735630.0000,        0.0000],
        [15745039.0000,        0.0000],
        [15728704.0000,        0.0000],
        [ 3118800.5000,  8081911.5000],
        [10564880.0000,  4528339.5000],
        [12356446.0000,  3084871.5000],
        [12095197.0000,  3015935.0000],
        [ 4374018.0000,  7273487.0000],
        [10356170.0000,  4460592.0000],
        [14160285.0000,        0.0000],
        [14948954.0000,        0.0000],
        [10088329.0000,  2571895.0000],
        [15548726.0000,        0.0000],
        [15460310.0000,        0.0000],
        [13715497.0000,  1523353.1250],
        [ 2579840.2500, 10600924.0000],
        [       0.0000, 11838026.0000],
        [ 5561552.5000,  4917287.0000],
        [ 2702183.2500,  7101681.5000],
        [ 4031645.2500,  9442694.0000],
        [10120254.0000,  4372789.5000],
        [11235744.0000,  2844122.2500],
        [ 1284024.5000, 12146913.0000],
        [ 1379125.3750, 12827355.0000],
        [ 3893418.0000,  9206687.0000],
        [11794216.0000,  2970162.0000],
        [10201064.0000,  4449478.5000],
        [ 2746723.5000, 11063420.0000],
        [ 2707398.5000, 10844556.0000],
        [       0.0000, 13786760.0000],
        [ 2719872.5000, 11446452.0000],
        [10601636.0000,  2714132.5000],
        [10556985.0000,  2534444.0000],
        [ 9701558.0000,  3844592.2500],
        [       0.0000, 14151404.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 341/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:11, 60.41s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:09, 14.23s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.882295608520508
Epoch 342/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:05, 60.21s/it]  7%|▋         | 2/29 [01:01<11:24, 25.34s/it] 10%|█         | 3/29 [01:02<06:09, 14.20s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.96s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.01it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.8890981674194336
Epoch 343/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:07, 60.27s/it]  7%|▋         | 2/29 [01:01<11:33, 25.67s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8791773319244385
Epoch 344/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.63s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8692593574523926
Epoch 345/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:46, 57.36s/it]  7%|▋         | 2/29 [01:01<11:40, 25.95s/it] 10%|█         | 3/29 [01:02<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.18s/it] 21%|██        | 6/29 [01:05<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.869863271713257
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0131, 0.0024,  ..., 0.0042, 0.0001, 0.0188],
        [0.0029, 0.0095, 0.0026,  ..., 0.0031, 0.0003, 0.0172],
        [0.0328, 0.0069, 0.0039,  ..., 0.0056, 0.0161, 0.0234],
        ...,
        [0.0068, 0.0087, 0.0208,  ..., 0.0045, 0.0016, 0.0203],
        [0.0045, 0.0085, 0.0138,  ..., 0.0049, 0.0046, 0.0195],
        [0.0090, 0.0052, 0.0052,  ..., 0.0023, 0.0029, 0.0214]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9963, 0.9955, 0.9951, 0.9950, 0.9950, 0.9949, 0.9948, 0.9947,
         0.9947],
        [0.9972, 0.9970, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9766, 0.9682, 0.9669, 0.9657, 0.9645, 0.9641, 0.9631, 0.9624, 0.9622,
         0.9621],
        [0.9927, 0.9925, 0.9923, 0.9922, 0.9921, 0.9913, 0.9912, 0.9911, 0.9905,
         0.9901],
        [0.9891, 0.9870, 0.9869, 0.9855, 0.9852, 0.9851, 0.9851, 0.9850, 0.9849,
         0.9849],
        [0.9852, 0.9844, 0.9800, 0.9776, 0.9770, 0.9751, 0.9738, 0.9737, 0.9730,
         0.9728],
        [0.9779, 0.9704, 0.9684, 0.9677, 0.9675, 0.9666, 0.9658, 0.9636, 0.9624,
         0.9609],
        [0.9770, 0.9728, 0.9725, 0.9686, 0.9598, 0.9583, 0.9581, 0.9558, 0.9555,
         0.9550],
        [0.9979, 0.9974, 0.9973, 0.9969, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9967],
        [0.9941, 0.9900, 0.9888, 0.9878, 0.9874, 0.9871, 0.9861, 0.9856, 0.9848,
         0.9847],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9944, 0.9932, 0.9919, 0.9910, 0.9909, 0.9907, 0.9905, 0.9900, 0.9900,
         0.9897],
        [0.9936, 0.9915, 0.9908, 0.9901, 0.9894, 0.9885, 0.9869, 0.9867, 0.9861,
         0.9856],
        [0.9986, 0.9984, 0.9983, 0.9982, 0.9980, 0.9977, 0.9977, 0.9975, 0.9975,
         0.9975],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9983],
        [0.9964, 0.9963, 0.9963, 0.9960, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9957, 0.9950, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9944, 0.9944,
         0.9943],
        [0.9946, 0.9941, 0.9937, 0.9935, 0.9935, 0.9934, 0.9934, 0.9934, 0.9933,
         0.9930],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9983, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977,
         0.9976],
        [0.9954, 0.9950, 0.9948, 0.9945, 0.9943, 0.9943, 0.9941, 0.9938, 0.9933,
         0.9932],
        [0.9986, 0.9986, 0.9981, 0.9981, 0.9981, 0.9979, 0.9979, 0.9976, 0.9975,
         0.9975],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9953, 0.9953, 0.9949, 0.9948, 0.9946, 0.9945, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9989, 0.9988, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9984, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9985, 0.9985,
         0.9985],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9886, 0.9875, 0.9780, 0.9743, 0.9708, 0.9708, 0.9700, 0.9688, 0.9657,
         0.9625],
        [0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961, 0.9960, 0.9959,
         0.9959],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9968, 0.9967, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962, 0.9961,
         0.9961],
        [0.9868, 0.9849, 0.9815, 0.9766, 0.9765, 0.9752, 0.9730, 0.9726, 0.9725,
         0.9713],
        [0.9955, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9949, 0.9948, 0.9948,
         0.9947],
        [0.9934, 0.9925, 0.9918, 0.9916, 0.9916, 0.9914, 0.9913, 0.9910, 0.9909,
         0.9908],
        [0.9959, 0.9957, 0.9957, 0.9957, 0.9957, 0.9955, 0.9953, 0.9953, 0.9953,
         0.9953],
        [0.9860, 0.9854, 0.9852, 0.9838, 0.9831, 0.9827, 0.9821, 0.9814, 0.9810,
         0.9795],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9973, 0.9971, 0.9971, 0.9971, 0.9970, 0.9968, 0.9968, 0.9966, 0.9966,
         0.9965],
        [0.9899, 0.9887, 0.9886, 0.9874, 0.9864, 0.9851, 0.9849, 0.9847, 0.9840,
         0.9837],
        [0.9862, 0.9794, 0.9792, 0.9789, 0.9783, 0.9782, 0.9781, 0.9779, 0.9774,
         0.9774],
        [0.9883, 0.9879, 0.9754, 0.9728, 0.9652, 0.9621, 0.9619, 0.9612, 0.9612,
         0.9589],
        [0.9727, 0.9715, 0.9677, 0.9662, 0.9656, 0.9649, 0.9648, 0.9623, 0.9604,
         0.9548],
        [0.9918, 0.9895, 0.9894, 0.9890, 0.9887, 0.9887, 0.9876, 0.9873, 0.9869,
         0.9869],
        [0.9943, 0.9943, 0.9941, 0.9940, 0.9937, 0.9936, 0.9936, 0.9935, 0.9931,
         0.9928],
        [0.9932, 0.9919, 0.9918, 0.9917, 0.9917, 0.9912, 0.9911, 0.9911, 0.9909,
         0.9909],
        [0.9907, 0.9905, 0.9898, 0.9897, 0.9896, 0.9895, 0.9856, 0.9854, 0.9854,
         0.9852],
        [0.9935, 0.9931, 0.9929, 0.9927, 0.9924, 0.9917, 0.9909, 0.9903, 0.9897,
         0.9896],
        [0.9905, 0.9877, 0.9871, 0.9867, 0.9862, 0.9860, 0.9860, 0.9845, 0.9843,
         0.9837],
        [0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949, 0.9946, 0.9946, 0.9944,
         0.9944],
        [0.9958, 0.9952, 0.9950, 0.9949, 0.9944, 0.9942, 0.9937, 0.9937, 0.9932,
         0.9932],
        [0.9945, 0.9906, 0.9905, 0.9901, 0.9896, 0.9892, 0.9891, 0.9887, 0.9877,
         0.9875],
        [0.9922, 0.9918, 0.9909, 0.9892, 0.9892, 0.9876, 0.9874, 0.9865, 0.9854,
         0.9854],
        [0.9921, 0.9920, 0.9920, 0.9910, 0.9898, 0.9889, 0.9886, 0.9882, 0.9878,
         0.9855],
        [0.9967, 0.9938, 0.9936, 0.9925, 0.9925, 0.9912, 0.9891, 0.9891, 0.9885,
         0.9883],
        [0.9905, 0.9887, 0.9874, 0.9873, 0.9870, 0.9868, 0.9865, 0.9862, 0.9861,
         0.9859],
        [0.9919, 0.9912, 0.9878, 0.9858, 0.9844, 0.9840, 0.9838, 0.9833, 0.9833,
         0.9825],
        [0.9928, 0.9921, 0.9915, 0.9912, 0.9911, 0.9899, 0.9866, 0.9848, 0.9846,
         0.9837],
        [0.9928, 0.9927, 0.9922, 0.9921, 0.9919, 0.9916, 0.9914, 0.9907, 0.9901,
         0.9900]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 0],
        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1523989.6250, 1517679.0000, 1500602.7500, 1491885.6250, 1491045.1250,
         1490369.6250, 1486921.2500, 1486351.3750, 1484658.3750, 1484423.3750],
        [1538120.6250, 1533098.8750, 1531956.0000, 1530773.0000, 1529782.1250,
         1529712.0000, 1527660.8750, 1527475.8750, 1527395.7500, 1526616.6250],
        [1146115.6250, 1015495.1250,  997566.5000,  979908.6875,  964207.0000,
          958796.0625,  944340.0625,  935452.8125,  932498.3125,  931754.3125],
        [1442589.8750, 1438649.5000, 1433948.6250, 1430955.3750, 1428727.2500,
         1412863.5000, 1411594.8750, 1408922.3750, 1397531.5000, 1389907.3750],
        [1369150.0000, 1329137.1250, 1326760.0000, 1300595.7500, 1294832.1250,
         1294248.1250, 1293472.1250, 1291694.5000, 1290394.3750, 1289368.3750],
        [1295013.6250, 1279753.1250, 1202464.3750, 1161651.2500, 1151351.0000,
         1121729.0000, 1101063.5000, 1099516.7500, 1088522.1250, 1084607.2500],
        [1167611.1250, 1048158.1875, 1018595.0000, 1008789.5000, 1005353.1250,
          992856.0625,  981288.0625,  952087.1250,  934641.3750,  915017.8750],
        [1151388.3750, 1085532.3750, 1080604.5000, 1021888.5000,  901561.5000,
          882129.3125,  880002.6875,  851558.3750,  846895.0625,  841520.2500],
        [1552695.0000, 1542021.6250, 1539036.2500, 1530787.7500, 1530686.8750,
         1529373.7500, 1526904.8750, 1526784.0000, 1526283.2500, 1526075.2500],
        [1470458.8750, 1388022.6250, 1363033.2500, 1344891.7500, 1335953.6250,
         1331145.1250, 1312211.0000, 1303657.8750, 1287088.2500, 1285960.6250],
        [1559224.1250, 1558177.6250, 1555598.6250, 1554108.2500, 1553180.7500,
         1552960.1250, 1552626.8750, 1551731.3750, 1550855.6250, 1550471.1250],
        [1476716.7500, 1452525.2500, 1425265.2500, 1407869.3750, 1405220.1250,
         1401490.1250, 1397714.1250, 1388178.7500, 1387752.5000, 1382116.7500],
        [1460854.8750, 1418195.7500, 1403298.2500, 1389111.0000, 1375459.2500,
         1358786.7500, 1327264.8750, 1322722.1250, 1312583.8750, 1303529.8750],
        [1568816.2500, 1563117.5000, 1562332.0000, 1560470.6250, 1554732.3750,
         1548898.6250, 1547532.8750, 1544754.8750, 1543489.8750, 1543169.0000],
        [1576348.0000, 1574867.8750, 1574866.3750, 1574828.8750, 1574364.7500,
         1574289.7500, 1572274.7500, 1572190.7500, 1571896.8750, 1571798.0000],
        [1572907.5000, 1571315.3750, 1570010.7500, 1569021.3750, 1568005.6250,
         1567563.1250, 1567056.3750, 1566439.2500, 1563362.0000, 1562650.8750],
        [1519124.1250, 1518617.2500, 1518294.2500, 1512507.7500, 1510665.3750,
         1508293.0000, 1507233.3750, 1506976.0000, 1505918.6250, 1504061.3750],
        [1505215.1250, 1490129.5000, 1486023.8750, 1484802.7500, 1484140.2500,
         1484090.7500, 1483091.8750, 1478022.8750, 1476387.2500, 1475983.2500],
        [1480881.3750, 1471017.1250, 1462929.3750, 1459390.0000, 1457809.7500,
         1456123.0000, 1455688.5000, 1455430.2500, 1454818.2500, 1448248.5000],
        [1556693.7500, 1556150.5000, 1553768.8750, 1551775.7500, 1549598.8750,
         1549272.3750, 1549146.7500, 1548439.2500, 1548408.2500, 1548207.3750],
        [1561219.5000, 1553847.5000, 1552924.6250, 1552624.0000, 1552582.5000,
         1551991.8750, 1550345.3750, 1549523.6250, 1549433.3750, 1547131.3750],
        [1498666.3750, 1490121.1250, 1485793.0000, 1479577.0000, 1475226.2500,
         1474629.7500, 1470770.2500, 1464184.2500, 1455177.6250, 1452188.7500],
        [1568936.0000, 1568740.0000, 1558443.6250, 1557522.5000, 1556906.1250,
         1553909.7500, 1553680.1250, 1547013.3750, 1544805.0000, 1543753.3750],
        [1578192.1250, 1575638.6250, 1575303.5000, 1574033.1250, 1573929.5000,
         1573374.2500, 1573024.6250, 1572384.1250, 1571272.0000, 1570178.3750],
        [1497247.7500, 1496918.0000, 1487646.1250, 1486140.2500, 1481199.1250,
         1479781.6250, 1474610.0000, 1473122.8750, 1472608.8750, 1471338.3750],
        [1575943.6250, 1573090.6250, 1565986.6250, 1565235.6250, 1563989.7500,
         1563256.0000, 1562461.7500, 1561186.7500, 1560964.8750, 1560887.5000],
        [1564209.0000, 1559717.8750, 1559410.0000, 1557638.3750, 1556076.3750,
         1554634.6250, 1553564.5000, 1553225.2500, 1551364.3750, 1550672.1250],
        [1574193.7500, 1573717.8750, 1573110.1250, 1573110.1250, 1572036.3750,
         1570946.7500, 1570570.7500, 1567117.6250, 1566918.8750, 1566376.6250],
        [1578383.2500, 1578162.0000, 1577739.1250, 1577724.1250, 1575704.6250,
         1575130.7500, 1575111.1250, 1573825.8750, 1573284.1250, 1573177.6250],
        [1580761.8750, 1580082.1250, 1576675.7500, 1575906.1250, 1575770.7500,
         1574235.7500, 1574223.6250, 1574001.5000, 1573614.3750, 1573437.2500],
        [1581089.1250, 1580083.6250, 1577560.1250, 1577517.8750, 1577060.7500,
         1576687.8750, 1575776.7500, 1575402.7500, 1575374.1250, 1575115.7500],
        [1579807.8750, 1578273.3750, 1578145.3750, 1576211.2500, 1575859.5000,
         1574253.7500, 1573977.6250, 1573321.6250, 1573237.7500, 1572954.1250],
        [1360622.8750, 1339120.8750, 1169474.3750, 1107993.3750, 1054714.0000,
         1054252.3750, 1043086.4375, 1025497.7500,  979766.6250,  936566.8125],
        [1524180.0000, 1523036.5000, 1519808.1250, 1518459.3750, 1517886.0000,
         1515366.3750, 1513439.7500, 1511623.8750, 1509929.5000, 1509645.7500],
        [1552982.3750, 1551318.5000, 1549146.7500, 1547987.3750, 1546296.6250,
         1546296.6250, 1545622.7500, 1544877.1250, 1544432.2500, 1544304.1250],
        [1528869.1250, 1526699.6250, 1521818.2500, 1521188.5000, 1519792.1250,
         1518313.1250, 1517456.1250, 1516256.8750, 1514203.5000, 1513683.7500],
        [1326124.8750, 1289798.8750, 1227875.2500, 1145811.7500, 1144372.5000,
         1123560.7500, 1088140.1250, 1082173.0000, 1080310.7500, 1061372.5000],
        [1499888.7500, 1496292.8750, 1494986.2500, 1492355.2500, 1490381.1250,
         1490132.3750, 1487850.5000, 1486578.1250, 1485603.1250, 1483994.5000],
        [1456093.8750, 1436738.1250, 1422902.0000, 1419921.1250, 1419045.3750,
         1414963.0000, 1412584.6250, 1407795.5000, 1406108.8750, 1403109.6250],
        [1509666.0000, 1505923.0000, 1504668.3750, 1504668.3750, 1504341.1250,
         1500778.7500, 1497170.6250, 1496074.5000, 1495866.2500, 1495822.0000],
        [1309766.7500, 1299921.1250, 1295753.7500, 1270101.5000, 1257155.3750,
         1249691.5000, 1238486.7500, 1226989.1250, 1220229.1250, 1194886.5000],
        [1564761.1250, 1560664.2500, 1560302.5000, 1559439.7500, 1559001.0000,
         1558136.0000, 1558072.1250, 1557430.3750, 1556888.2500, 1556857.1250],
        [1559126.0000, 1557580.3750, 1555786.8750, 1554536.7500, 1550364.6250,
         1549499.8750, 1549340.3750, 1549229.5000, 1549164.5000, 1548898.6250],
        [1540147.6250, 1536274.8750, 1534333.3750, 1534288.1250, 1533356.3750,
         1527920.2500, 1527895.5000, 1525269.1250, 1524659.7500, 1522497.7500],
        [1385603.5000, 1361770.5000, 1360053.2500, 1336524.5000, 1318198.8750,
         1293882.8750, 1290591.2500, 1286317.6250, 1274157.2500, 1267541.1250],
        [1313194.8750, 1192891.7500, 1189368.0000, 1184640.6250, 1174106.3750,
         1172276.0000, 1170500.8750, 1167233.6250, 1159427.7500, 1158028.6250],
        [1353049.2500, 1345897.6250, 1126556.5000, 1085353.2500,  973022.2500,
          931482.3750,  928349.1875,  919834.3125,  919333.5625,  889916.6250],
        [1083113.6250, 1065725.7500, 1009007.9375,  986871.0625,  978716.9375,
          968674.3750,  967437.2500,  934049.6875,  908887.3750,  839377.7500],
        [1423254.8750, 1377260.2500, 1374616.1250, 1367349.2500, 1362525.1250,
         1362512.1250, 1339998.5000, 1334943.7500, 1327594.1250, 1326442.3750],
        [1475728.5000, 1475578.0000, 1470642.6250, 1469067.1250, 1462854.1250,
         1460510.8750, 1459626.6250, 1458099.0000, 1450866.6250, 1443556.0000],
        [1452896.5000, 1425583.2500, 1424410.5000, 1422328.1250, 1421536.2500,
         1411320.1250, 1410026.0000, 1408871.3750, 1405134.3750, 1404689.5000],
        [1400243.7500, 1397586.1250, 1383752.2500, 1381240.5000, 1378896.5000,
         1377157.7500, 1302437.6250, 1299212.1250, 1299083.3750, 1296120.7500],
        [1458220.0000, 1450707.6250, 1445650.0000, 1440960.5000, 1435307.2500,
         1422336.2500, 1405678.5000, 1393900.2500, 1381264.2500, 1378529.7500],
        [1397074.3750, 1342606.7500, 1330552.3750, 1324154.7500, 1314568.2500,
         1309902.8750, 1309473.1250, 1282806.6250, 1278955.0000, 1268641.5000],
        [1494762.5000, 1491591.2500, 1490573.0000, 1490573.0000, 1490074.1250,
         1488730.3750, 1481760.1250, 1480813.6250, 1477216.8750, 1476916.8750],
        [1507943.5000, 1494934.8750, 1490602.8750, 1487240.3750, 1477927.0000,
         1473658.3750, 1462204.1250, 1461613.0000, 1452992.2500, 1452223.2500],
        [1480058.3750, 1399053.1250, 1397514.2500, 1389426.3750, 1379534.3750,
         1371225.1250, 1369645.0000, 1361322.5000, 1341948.8750, 1339301.1250],
        [1432595.3750, 1423310.5000, 1405570.0000, 1371307.5000, 1371259.1250,
         1341177.3750, 1336545.0000, 1318953.3750, 1299225.7500, 1298795.8750],
        [1429482.3750, 1427470.1250, 1427176.1250, 1407265.2500, 1382956.6250,
         1365445.3750, 1359184.6250, 1352841.5000, 1343464.8750, 1300061.1250],
        [1526964.7500, 1465634.2500, 1459689.2500, 1437657.8750, 1436960.2500,
         1410917.7500, 1370016.0000, 1369765.1250, 1357435.8750, 1354382.8750],
        [1397023.7500, 1361517.1250, 1336457.0000, 1335529.5000, 1329915.6250,
         1325165.3750, 1318791.1250, 1314186.0000, 1312510.1250, 1308146.3750],
        [1426153.0000, 1411566.5000, 1345016.1250, 1306637.7500, 1281137.8750,
         1274123.2500, 1270033.6250, 1260828.2500, 1260688.7500, 1246759.6250],
        [1442907.7500, 1429952.7500, 1416527.8750, 1410557.2500, 1409644.1250,
         1384387.0000, 1321970.5000, 1287196.2500, 1283995.1250, 1268749.2500],
        [1443797.0000, 1442331.2500, 1430749.3750, 1429036.6250, 1424570.7500,
         1419779.1250, 1414949.5000, 1401351.1250, 1389899.5000, 1387621.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1523989.6250,       0.0000],
         [1517679.0000,       0.0000],
         [1500602.7500,       0.0000],
         ...,
         [1486351.3750,       0.0000],
         [1484658.3750,       0.0000],
         [1484423.3750,       0.0000]],

        [[1538120.6250,       0.0000],
         [1533098.8750,       0.0000],
         [1531956.0000,       0.0000],
         ...,
         [1527475.8750,       0.0000],
         [1527395.7500,       0.0000],
         [1526616.6250,       0.0000]],

        [[1146115.6250,       0.0000],
         [      0.0000, 1015495.1250],
         [ 997566.5000,       0.0000],
         ...,
         [      0.0000,  935452.8125],
         [ 932498.3125,       0.0000],
         [ 931754.3125,       0.0000]],

        ...,

        [[1426153.0000,       0.0000],
         [1411566.5000,       0.0000],
         [1345016.1250,       0.0000],
         ...,
         [1260828.2500,       0.0000],
         [      0.0000, 1260688.7500],
         [1246759.6250,       0.0000]],

        [[1442907.7500,       0.0000],
         [1429952.7500,       0.0000],
         [1416527.8750,       0.0000],
         ...,
         [1287196.2500,       0.0000],
         [      0.0000, 1283995.1250],
         [      0.0000, 1268749.2500]],

        [[      0.0000, 1443797.0000],
         [      0.0000, 1442331.2500],
         [      0.0000, 1430749.3750],
         ...,
         [      0.0000, 1401351.1250],
         [      0.0000, 1389899.5000],
         [1387621.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13471005.0000,  1486921.2500],
        [15302592.0000,        0.0000],
        [ 4966731.0000,  4839404.0000],
        [12786767.0000,  1408922.3750],
        [ 9200178.0000,  3879474.5000],
        [ 9345799.0000,  2239873.0000],
        [ 3049803.7500,  6974593.5000],
        [ 8691522.0000,   851558.3750],
        [13803865.0000,  1526784.0000],
        [12034400.0000,  1388022.6250],
        [15538936.0000,        0.0000],
        [14124850.0000,        0.0000],
        [13671807.0000,        0.0000],
        [15537314.0000,        0.0000],
        [15737726.0000,        0.0000],
        [15678332.0000,        0.0000],
        [13593074.0000,  1518617.2500],
        [11866286.0000,  2981602.5000],
        [13154087.0000,  1448248.5000],
        [15511463.0000,        0.0000],
        [15521624.0000,        0.0000],
        [13260541.0000,  1485793.0000],
        [15553710.0000,        0.0000],
        [15737330.0000,        0.0000],
        [11826447.0000,  2994165.7500],
        [15653002.0000,        0.0000],
        [15560512.0000,        0.0000],
        [15708099.0000,        0.0000],
        [15758242.0000,        0.0000],
        [15758710.0000,        0.0000],
        [15771668.0000,        0.0000],
        [15756042.0000,        0.0000],
        [ 3033905.7500,  8037190.0000],
        [12120736.0000,  3042639.5000],
        [12383955.0000,  3089309.5000],
        [12160176.0000,  3038105.2500],
        [ 3293874.0000,  8275667.0000],
        [10425338.0000,  4482725.5000],
        [12796152.0000,  1403109.6250],
        [15014979.0000,        0.0000],
        [10005905.0000,  2557076.5000],
        [15591552.0000,        0.0000],
        [15523527.0000,        0.0000],
        [13773287.0000,  1533356.3750],
        [ 2561424.0000, 10613216.0000],
        [ 1159427.7500, 10722241.0000],
        [ 5561938.5000,  4910857.0000],
        [ 2682314.7500,  7059547.0000],
        [ 4068407.7500,  9528089.0000],
        [10220532.0000,  4405998.0000],
        [11329210.0000,  2857586.0000],
        [ 1296120.7500, 12219610.0000],
        [ 1378529.7500, 12834025.0000],
        [ 3902699.2500,  9256036.0000],
        [11882690.0000,  2980321.5000],
        [10284866.0000,  4476473.5000],
        [ 2740857.0000, 11088172.0000],
        [ 2712436.5000, 10886304.0000],
        [       0.0000, 13795348.0000],
        [ 2727452.0000, 11461972.0000],
        [10629708.0000,  2709534.0000],
        [10548133.0000,  2534812.0000],
        [ 9781174.0000,  3874715.0000],
        [ 1387621.5000, 12796464.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 346/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:34, 59.09s/it]  7%|▋         | 2/29 [01:00<11:11, 24.87s/it] 10%|█         | 3/29 [01:00<06:02, 13.94s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.8644189834594727
Epoch 347/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:01, 57.92s/it]  7%|▋         | 2/29 [01:00<11:21, 25.24s/it] 10%|█         | 3/29 [01:01<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.04s/it] 21%|██        | 6/29 [01:03<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.862290382385254
Epoch 348/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:10, 58.24s/it]  7%|▋         | 2/29 [00:59<11:02, 24.53s/it] 10%|█         | 3/29 [01:00<05:57, 13.75s/it] 14%|█▍        | 4/29 [01:01<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.06s/it] 21%|██        | 6/29 [01:03<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.861475944519043
Epoch 349/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:17, 56.32s/it]  7%|▋         | 2/29 [00:57<10:40, 23.73s/it] 10%|█         | 3/29 [00:59<06:07, 14.14s/it] 14%|█▍        | 4/29 [01:02<03:57,  9.49s/it] 17%|█▋        | 5/29 [01:03<02:33,  6.40s/it] 21%|██        | 6/29 [01:04<01:44,  4.54s/it] 24%|██▍       | 7/29 [01:05<01:13,  3.35s/it] 28%|██▊       | 8/29 [01:06<00:54,  2.58s/it] 31%|███       | 9/29 [01:06<00:41,  2.06s/it] 34%|███▍      | 10/29 [01:07<00:32,  1.71s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.47s/it] 41%|████▏     | 12/29 [01:09<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.19s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.11s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.869300127029419
Epoch 350/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:37, 61.34s/it]  7%|▋         | 2/29 [01:02<11:36, 25.80s/it] 10%|█         | 3/29 [01:03<06:15, 14.44s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.868013381958008
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0138, 0.0028,  ..., 0.0043, 0.0002, 0.0188],
        [0.0035, 0.0096, 0.0029,  ..., 0.0031, 0.0002, 0.0175],
        [0.0346, 0.0060, 0.0038,  ..., 0.0050, 0.0175, 0.0236],
        ...,
        [0.0070, 0.0082, 0.0210,  ..., 0.0045, 0.0017, 0.0198],
        [0.0047, 0.0086, 0.0143,  ..., 0.0051, 0.0049, 0.0195],
        [0.0096, 0.0048, 0.0053,  ..., 0.0023, 0.0030, 0.0217]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9960, 0.9951, 0.9948, 0.9946, 0.9944, 0.9944, 0.9944, 0.9943,
         0.9943],
        [0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9764, 0.9682, 0.9678, 0.9675, 0.9663, 0.9659, 0.9654, 0.9638, 0.9637,
         0.9623],
        [0.9925, 0.9922, 0.9920, 0.9918, 0.9918, 0.9911, 0.9909, 0.9905, 0.9900,
         0.9899],
        [0.9892, 0.9874, 0.9865, 0.9860, 0.9859, 0.9852, 0.9851, 0.9850, 0.9848,
         0.9846],
        [0.9854, 0.9849, 0.9806, 0.9782, 0.9782, 0.9750, 0.9749, 0.9746, 0.9742,
         0.9738],
        [0.9790, 0.9721, 0.9694, 0.9689, 0.9684, 0.9665, 0.9659, 0.9644, 0.9633,
         0.9626],
        [0.9767, 0.9725, 0.9705, 0.9673, 0.9585, 0.9572, 0.9554, 0.9549, 0.9533,
         0.9523],
        [0.9977, 0.9971, 0.9970, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9937, 0.9893, 0.9879, 0.9878, 0.9874, 0.9868, 0.9856, 0.9849, 0.9847,
         0.9845],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9975],
        [0.9939, 0.9931, 0.9912, 0.9908, 0.9903, 0.9902, 0.9901, 0.9900, 0.9896,
         0.9895],
        [0.9931, 0.9905, 0.9904, 0.9899, 0.9887, 0.9885, 0.9860, 0.9853, 0.9852,
         0.9851],
        [0.9985, 0.9982, 0.9982, 0.9981, 0.9978, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9972],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983,
         0.9983],
        [0.9961, 0.9961, 0.9960, 0.9956, 0.9956, 0.9956, 0.9956, 0.9955, 0.9954,
         0.9953],
        [0.9954, 0.9946, 0.9946, 0.9945, 0.9945, 0.9944, 0.9942, 0.9941, 0.9940,
         0.9940],
        [0.9945, 0.9938, 0.9937, 0.9933, 0.9933, 0.9933, 0.9932, 0.9930, 0.9930,
         0.9928],
        [0.9979, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9981, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9952, 0.9947, 0.9945, 0.9942, 0.9940, 0.9939, 0.9936, 0.9936, 0.9929,
         0.9928],
        [0.9987, 0.9986, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9976, 0.9976,
         0.9974],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9951, 0.9951, 0.9949, 0.9946, 0.9943, 0.9942, 0.9942, 0.9941, 0.9939,
         0.9939],
        [0.9989, 0.9988, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9984, 0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9893, 0.9880, 0.9784, 0.9739, 0.9718, 0.9709, 0.9699, 0.9694, 0.9659,
         0.9632],
        [0.9963, 0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9956,
         0.9956],
        [0.9978, 0.9978, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9966, 0.9965, 0.9963, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959,
         0.9959],
        [0.9875, 0.9851, 0.9820, 0.9770, 0.9767, 0.9759, 0.9749, 0.9731, 0.9724,
         0.9713],
        [0.9952, 0.9951, 0.9949, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945, 0.9944,
         0.9944],
        [0.9933, 0.9924, 0.9918, 0.9916, 0.9913, 0.9911, 0.9911, 0.9909, 0.9906,
         0.9905],
        [0.9957, 0.9954, 0.9954, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950,
         0.9949],
        [0.9864, 0.9859, 0.9858, 0.9853, 0.9837, 0.9836, 0.9823, 0.9822, 0.9820,
         0.9812],
        [0.9984, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9980, 0.9980, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9898, 0.9882, 0.9882, 0.9866, 0.9858, 0.9848, 0.9846, 0.9843, 0.9841,
         0.9841],
        [0.9860, 0.9789, 0.9789, 0.9785, 0.9785, 0.9784, 0.9780, 0.9777, 0.9772,
         0.9770],
        [0.9887, 0.9877, 0.9751, 0.9727, 0.9647, 0.9615, 0.9615, 0.9607, 0.9605,
         0.9582],
        [0.9733, 0.9694, 0.9692, 0.9662, 0.9657, 0.9654, 0.9650, 0.9631, 0.9624,
         0.9565],
        [0.9913, 0.9892, 0.9888, 0.9885, 0.9885, 0.9883, 0.9867, 0.9866, 0.9865,
         0.9862],
        [0.9940, 0.9939, 0.9938, 0.9936, 0.9935, 0.9930, 0.9929, 0.9928, 0.9926,
         0.9923],
        [0.9930, 0.9916, 0.9916, 0.9914, 0.9914, 0.9907, 0.9907, 0.9906, 0.9902,
         0.9902],
        [0.9909, 0.9903, 0.9897, 0.9895, 0.9895, 0.9894, 0.9861, 0.9859, 0.9858,
         0.9855],
        [0.9935, 0.9932, 0.9929, 0.9927, 0.9923, 0.9921, 0.9910, 0.9903, 0.9898,
         0.9895],
        [0.9906, 0.9880, 0.9870, 0.9868, 0.9863, 0.9863, 0.9856, 0.9849, 0.9844,
         0.9840],
        [0.9950, 0.9950, 0.9948, 0.9948, 0.9948, 0.9947, 0.9944, 0.9944, 0.9940,
         0.9939],
        [0.9957, 0.9949, 0.9948, 0.9944, 0.9943, 0.9938, 0.9936, 0.9933, 0.9929,
         0.9928],
        [0.9946, 0.9907, 0.9904, 0.9903, 0.9896, 0.9894, 0.9893, 0.9890, 0.9876,
         0.9873],
        [0.9921, 0.9919, 0.9911, 0.9895, 0.9890, 0.9875, 0.9873, 0.9861, 0.9855,
         0.9852],
        [0.9920, 0.9920, 0.9919, 0.9912, 0.9896, 0.9888, 0.9886, 0.9881, 0.9880,
         0.9859],
        [0.9968, 0.9939, 0.9933, 0.9925, 0.9924, 0.9912, 0.9890, 0.9889, 0.9885,
         0.9883],
        [0.9909, 0.9887, 0.9876, 0.9874, 0.9873, 0.9871, 0.9862, 0.9862, 0.9861,
         0.9861],
        [0.9920, 0.9915, 0.9875, 0.9859, 0.9846, 0.9839, 0.9837, 0.9832, 0.9830,
         0.9826],
        [0.9924, 0.9919, 0.9912, 0.9910, 0.9909, 0.9895, 0.9860, 0.9847, 0.9844,
         0.9837],
        [0.9927, 0.9924, 0.9921, 0.9921, 0.9920, 0.9919, 0.9916, 0.9909, 0.9902,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 0, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1516067.5000, 1511228.7500, 1492655.6250, 1485754.6250, 1482304.2500,
         1477898.7500, 1477521.1250, 1476932.3750, 1476153.5000, 1475590.6250],
        [1533065.2500, 1532001.3750, 1529376.6250, 1526826.3750, 1525996.5000,
         1524523.1250, 1524287.5000, 1523514.3750, 1523010.2500, 1522297.2500],
        [1141862.8750, 1015601.6875, 1010551.6250, 1005828.8125,  988770.3125,
          982741.5000,  975918.9375,  954488.0625,  953345.5000,  934325.0000],
        [1436868.3750, 1430874.8750, 1426489.0000, 1423364.8750, 1422767.7500,
         1410238.5000, 1406067.3750, 1397078.5000, 1387117.3750, 1384502.0000],
        [1372426.1250, 1336571.7500, 1318958.3750, 1310601.3750, 1308893.8750,
         1296056.5000, 1292892.3750, 1291820.1250, 1288446.5000, 1284372.3750],
        [1298393.3750, 1289266.3750, 1213105.0000, 1171847.8750, 1171303.7500,
         1118947.7500, 1118602.1250, 1112661.1250, 1106189.1250, 1100948.0000],
        [1185206.8750, 1074677.6250, 1034261.5625, 1026620.1250, 1019295.5625,
          991104.0625,  982990.8125,  962546.8125,  947464.8750,  938237.6875],
        [1146909.3750, 1079737.1250, 1049420.3750, 1002998.2500,  884460.1875,
          868493.8125,  846677.0000,  840520.8750,  821769.3125,  809940.6875],
        [1547618.3750, 1536061.0000, 1532416.2500, 1525765.1250, 1524287.5000,
         1523039.3750, 1522057.8750, 1521396.0000, 1521285.7500, 1520785.3750],
        [1463585.3750, 1374451.0000, 1346823.3750, 1344849.3750, 1336609.8750,
         1324507.1250, 1302501.0000, 1290522.2500, 1285640.6250, 1281715.8750],
        [1555029.0000, 1554320.2500, 1550485.7500, 1550074.8750, 1549966.8750,
         1548154.2500, 1548056.8750, 1547680.5000, 1547429.5000, 1545086.3750],
        [1466720.7500, 1450006.3750, 1411750.8750, 1403948.8750, 1392577.0000,
         1392049.7500, 1388452.8750, 1387244.3750, 1378713.6250, 1376987.1250],
        [1450230.3750, 1397688.7500, 1395795.8750, 1385542.7500, 1361636.6250,
         1358392.7500, 1309703.0000, 1297879.6250, 1295367.0000, 1294327.2500],
        [1566452.7500, 1560636.0000, 1560231.1250, 1557470.5000, 1551260.8750,
         1542296.6250, 1541711.2500, 1541039.5000, 1539567.6250, 1536509.3750],
        [1575350.1250, 1574514.8750, 1573892.0000, 1573618.7500, 1573372.6250,
         1572774.1250, 1571354.2500, 1571328.8750, 1570907.8750, 1570868.8750],
        [1571751.5000, 1568618.8750, 1567823.2500, 1567356.7500, 1566070.3750,
         1565976.2500, 1565631.2500, 1565196.8750, 1561209.0000, 1561015.5000],
        [1513797.7500, 1512888.5000, 1511752.1250, 1503661.2500, 1503332.8750,
         1503182.3750, 1502048.8750, 1501677.8750, 1498346.2500, 1497452.0000],
        [1497721.8750, 1481423.7500, 1480673.8750, 1480006.0000, 1479867.6250,
         1477198.5000, 1473654.1250, 1470673.3750, 1469686.3750, 1468471.7500],
        [1479774.6250, 1463729.1250, 1462057.7500, 1454316.1250, 1453973.5000,
         1453961.0000, 1453146.0000, 1448664.2500, 1447297.1250, 1444734.8750],
        [1552714.2500, 1552502.5000, 1547659.7500, 1546883.5000, 1546337.8750,
         1545695.1250, 1545065.7500, 1544174.5000, 1544017.0000, 1543354.5000],
        [1557172.0000, 1549678.7500, 1549194.0000, 1548417.1250, 1547324.7500,
         1546299.5000, 1544984.7500, 1544952.2500, 1542796.7500, 1542527.5000],
        [1495127.3750, 1483561.5000, 1478454.2500, 1472747.8750, 1468258.8750,
         1465920.8750, 1460389.7500, 1460118.1250, 1446897.0000, 1443587.6250],
        [1569986.7500, 1567966.7500, 1558975.7500, 1557620.3750, 1557318.8750,
         1552726.1250, 1552307.1250, 1546522.2500, 1545502.0000, 1542780.6250],
        [1576511.8750, 1574518.0000, 1572813.1250, 1572256.6250, 1571757.5000,
         1571310.8750, 1571286.8750, 1570693.6250, 1569849.0000, 1568315.2500],
        [1491508.6250, 1491134.6250, 1487783.7500, 1481606.0000, 1474823.8750,
         1473995.7500, 1472416.5000, 1469941.6250, 1466866.2500, 1466642.5000],
        [1575650.6250, 1572285.2500, 1566044.8750, 1564893.8750, 1563968.8750,
         1562640.5000, 1562239.7500, 1561418.8750, 1560522.7500, 1560176.0000],
        [1564273.2500, 1560305.5000, 1559994.5000, 1557105.0000, 1555830.0000,
         1553854.8750, 1552535.1250, 1551105.5000, 1550340.8750, 1550020.1250],
        [1573765.8750, 1572810.1250, 1572324.2500, 1572177.2500, 1570175.3750,
         1570094.5000, 1569682.8750, 1566585.6250, 1565955.3750, 1565364.0000],
        [1576862.1250, 1576781.0000, 1576731.3750, 1575763.2500, 1574232.7500,
         1573731.3750, 1573266.1250, 1572514.7500, 1572378.1250, 1571805.3750],
        [1579434.3750, 1579063.8750, 1575303.5000, 1574546.5000, 1574181.6250,
         1573543.7500, 1573047.1250, 1572828.1250, 1572702.1250, 1571838.3750],
        [1579473.5000, 1579389.1250, 1576495.2500, 1575822.0000, 1575402.7500,
         1574979.1250, 1574791.2500, 1574424.8750, 1573870.8750, 1573674.2500],
        [1578670.7500, 1577432.2500, 1576498.2500, 1574351.2500, 1574333.3750,
         1573495.7500, 1572841.6250, 1572630.1250, 1572030.3750, 1571768.0000],
        [1372829.2500, 1347920.7500, 1175068.6250, 1101541.3750, 1069637.7500,
         1056394.0000, 1040412.9375, 1033841.5625,  983315.3125,  946153.8125],
        [1517396.7500, 1515298.3750, 1512702.5000, 1512096.6250, 1510639.5000,
         1509926.6250, 1508359.2500, 1506158.5000, 1503060.5000, 1502639.1250],
        [1550317.3750, 1549977.2500, 1545734.8750, 1544840.3750, 1543507.6250,
         1543507.6250, 1543404.6250, 1542630.5000, 1542427.5000, 1541254.1250],
        [1523540.6250, 1521253.8750, 1517412.7500, 1514745.1250, 1512637.5000,
         1512321.7500, 1512039.0000, 1511300.8750, 1509765.2500, 1508681.5000],
        [1338303.8750, 1293822.5000, 1236827.2500, 1152305.6250, 1147010.0000,
         1133844.8750, 1118345.1250, 1090108.5000, 1079520.8750, 1062402.3750],
        [1493844.7500, 1491786.1250, 1487254.5000, 1484223.8750, 1483714.3750,
         1481853.3750, 1480983.0000, 1479182.0000, 1478035.6250, 1477577.5000],
        [1454481.1250, 1435075.8750, 1422423.1250, 1419879.2500, 1413479.3750,
         1409184.3750, 1408410.5000, 1404297.0000, 1398247.3750, 1398175.3750],
        [1504391.3750, 1497627.6250, 1497627.6250, 1497267.7500, 1494076.8750,
         1492785.1250, 1490089.7500, 1489275.6250, 1488984.5000, 1488570.0000],
        [1318132.2500, 1308923.7500, 1306120.6250, 1296649.8750, 1267319.8750,
         1266204.8750, 1242056.5000, 1241701.2500, 1238262.3750, 1223748.6250],
        [1563087.6250, 1559047.1250, 1558479.2500, 1557663.5000, 1556298.8750,
         1555711.3750, 1555212.8750, 1554630.1250, 1554336.6250, 1553409.0000],
        [1556282.6250, 1554960.7500, 1551836.5000, 1549598.8750, 1546921.8750,
         1544856.5000, 1544581.0000, 1544376.2500, 1543644.5000, 1543631.2500],
        [1537720.1250, 1532832.8750, 1529977.6250, 1529410.1250, 1525152.7500,
         1524502.6250, 1523276.1250, 1520356.1250, 1519225.5000, 1518815.6250],
        [1383641.2500, 1352364.2500, 1351919.3750, 1322214.0000, 1306433.3750,
         1288612.3750, 1283822.3750, 1278667.2500, 1275033.6250, 1275020.2500],
        [1310578.8750, 1184288.1250, 1183343.2500, 1177142.6250, 1177104.3750,
         1175971.1250, 1168484.5000, 1162910.3750, 1155301.8750, 1152549.6250],
        [1361327.6250, 1342962.7500, 1121904.3750, 1083766.6250,  966358.3750,
          923058.4375,  922875.4375,  912838.8750,  910850.1250,  881219.5625],
        [1092733.5000, 1033767.5625, 1030835.7500,  988052.0625,  979954.4375,
          975576.5000,  970841.2500,  944555.3750,  935770.4375,  859618.2500],
        [1412490.3750, 1371685.3750, 1363224.5000, 1358027.6250, 1357401.0000,
         1353650.6250, 1323871.8750, 1321486.5000, 1319944.8750, 1313890.2500],
        [1469048.8750, 1466566.8750, 1463817.0000, 1461080.6250, 1459067.1250,
         1448838.3750, 1445313.7500, 1444686.6250, 1440651.3750, 1432636.3750],
        [1447163.2500, 1419728.8750, 1419375.6250, 1416202.2500, 1414910.3750,
         1400987.6250, 1400764.6250, 1398410.1250, 1392175.8750, 1391842.6250],
        [1404377.3750, 1392642.0000, 1381472.5000, 1377461.2500, 1376950.3750,
         1375673.2500, 1311716.7500, 1309068.6250, 1306523.1250, 1301604.5000],
        [1457687.5000, 1451856.3750, 1446404.3750, 1442038.2500, 1432860.5000,
         1428546.1250, 1407261.2500, 1394081.1250, 1382902.6250, 1378019.7500],
        [1398754.1250, 1347951.6250, 1328257.7500, 1324359.3750, 1316524.1250,
         1315678.2500, 1303623.1250, 1289032.7500, 1280677.2500, 1272713.2500],
        [1490015.8750, 1489075.5000, 1484894.8750, 1484894.8750, 1484892.0000,
         1483945.0000, 1478137.1250, 1476511.2500, 1469376.6250, 1467070.5000],
        [1504471.6250, 1486836.2500, 1486561.1250, 1477242.2500, 1474468.1250,
         1464545.8750, 1459892.5000, 1454925.1250, 1446841.7500, 1444024.1250],
        [1480726.1250, 1400601.6250, 1395710.6250, 1392966.1250, 1380284.5000,
         1374588.6250, 1373578.2500, 1366830.3750, 1340137.8750, 1335497.6250],
        [1430278.7500, 1424513.7500, 1409357.7500, 1376964.7500, 1367432.7500,
         1338705.8750, 1334985.7500, 1312893.2500, 1300234.7500, 1294491.3750],
        [1428483.3750, 1428434.3750, 1426219.7500, 1410716.0000, 1379062.2500,
         1364518.5000, 1359690.1250, 1349694.5000, 1347533.8750, 1307780.8750],
        [1528009.1250, 1465837.0000, 1453657.5000, 1438032.2500, 1435044.3750,
         1410748.2500, 1367842.2500, 1366069.2500, 1358109.2500, 1354853.1250],
        [1404429.6250, 1362106.7500, 1341431.8750, 1337090.6250, 1335653.0000,
         1330568.8750, 1314667.3750, 1313372.7500, 1311801.7500, 1311261.3750],
        [1426863.2500, 1417694.1250, 1339504.1250, 1308792.7500, 1283774.6250,
         1270934.0000, 1268236.2500, 1257963.7500, 1254896.2500, 1248502.7500],
        [1435058.0000, 1424665.8750, 1411325.5000, 1408003.6250, 1404966.8750,
         1377499.3750, 1310057.7500, 1285610.0000, 1280610.1250, 1268432.2500],
        [1442654.5000, 1436651.8750, 1429939.1250, 1428870.3750, 1427120.3750,
         1425732.8750, 1419205.1250, 1405237.5000, 1390502.6250, 1384701.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1516067.5000,       0.0000],
         [1511228.7500,       0.0000],
         [1492655.6250,       0.0000],
         ...,
         [1476932.3750,       0.0000],
         [1476153.5000,       0.0000],
         [1475590.6250,       0.0000]],

        [[1533065.2500,       0.0000],
         [1532001.3750,       0.0000],
         [1529376.6250,       0.0000],
         ...,
         [1523514.3750,       0.0000],
         [1523010.2500,       0.0000],
         [1522297.2500,       0.0000]],

        [[1141862.8750,       0.0000],
         [      0.0000, 1015601.6875],
         [      0.0000, 1010551.6250],
         ...,
         [ 954488.0625,       0.0000],
         [ 953345.5000,       0.0000],
         [ 934325.0000,       0.0000]],

        ...,

        [[1426863.2500,       0.0000],
         [1417694.1250,       0.0000],
         [1339504.1250,       0.0000],
         ...,
         [1257963.7500,       0.0000],
         [      0.0000, 1254896.2500],
         [1248502.7500,       0.0000]],

        [[1435058.0000,       0.0000],
         [1424665.8750,       0.0000],
         [1411325.5000,       0.0000],
         ...,
         [1285610.0000,       0.0000],
         [      0.0000, 1280610.1250],
         [      0.0000, 1268432.2500]],

        [[      0.0000, 1442654.5000],
         [      0.0000, 1436651.8750],
         [      0.0000, 1429939.1250],
         ...,
         [      0.0000, 1405237.5000],
         [      0.0000, 1390502.6250],
         [      0.0000, 1384701.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13394586.0000,  1477521.1250],
        [15264899.0000,        0.0000],
        [ 4966763.0000,  4996671.5000],
        [12728291.0000,  1397078.5000],
        [ 9214881.0000,  3886158.5000],
        [ 9429012.0000,  2272251.7500],
        [ 3092402.0000,  7070004.5000],
        [ 8510406.0000,   840520.8750],
        [13753427.0000,  1521285.7500],
        [11976756.0000,  1374451.0000],
        [15496284.0000,        0.0000],
        [14048451.0000,        0.0000],
        [13546564.0000,        0.0000],
        [15497176.0000,        0.0000],
        [15727982.0000,        0.0000],
        [15660650.0000,        0.0000],
        [13534342.0000,  1513797.7500],
        [13281656.0000,  1497721.8750],
        [14561654.0000,        0.0000],
        [15468404.0000,        0.0000],
        [15473348.0000,        0.0000],
        [13196609.0000,  1478454.2500],
        [15551706.0000,        0.0000],
        [15719312.0000,        0.0000],
        [11794076.0000,  2982643.2500],
        [15649841.0000,        0.0000],
        [15555364.0000,        0.0000],
        [15698935.0000,        0.0000],
        [15744066.0000,        0.0000],
        [15746488.0000,        0.0000],
        [15758323.0000,        0.0000],
        [15744052.0000,        0.0000],
        [ 3036389.2500,  8090726.0000],
        [10567638.0000,  4530640.0000],
        [12362544.0000,  3085058.0000],
        [13628953.0000,  1514745.1250],
        [ 3321935.0000,  8330556.5000],
        [10368600.0000,  4469855.0000],
        [12765478.0000,  1398175.3750],
        [13451422.0000,  1489275.6250],
        [10133991.0000,  2575128.5000],
        [15567876.0000,        0.0000],
        [15480691.0000,        0.0000],
        [13736767.0000,  1524502.6250],
        [ 2567279.5000, 10550448.0000],
        [       0.0000, 11847675.0000],
        [ 5517201.0000,  4909961.5000],
        [ 2766230.0000,  7045475.5000],
        [ 2729086.5000, 10766586.0000],
        [10139774.0000,  4391933.0000],
        [11255987.0000,  2845573.5000],
        [ 1301604.5000, 12235885.0000],
        [ 1382902.6250, 12838756.0000],
        [ 2640883.5000, 10536689.0000],
        [11833906.0000,  2974908.0000],
        [10234033.0000,  4465776.0000],
        [ 2747115.0000, 11093807.0000],
        [ 4000630.0000,  9589229.0000],
        [       0.0000, 13802134.0000],
        [ 2720922.5000, 11457280.0000],
        [10644582.0000,  2717802.5000],
        [10551332.0000,  2525830.2500],
        [ 9747129.0000,  3859100.2500],
        [       0.0000, 14190616.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 351/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:10, 60.39s/it]  7%|▋         | 2/29 [01:01<11:26, 25.41s/it] 10%|█         | 3/29 [01:02<06:09, 14.23s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.878526210784912
Epoch 352/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:41, 57.19s/it]  7%|▋         | 2/29 [00:58<10:50, 24.09s/it] 10%|█         | 3/29 [00:59<05:51, 13.51s/it] 14%|█▍        | 4/29 [01:01<03:45,  9.00s/it] 17%|█▋        | 5/29 [01:02<02:26,  6.09s/it] 21%|██        | 6/29 [01:02<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.48s/it] 31%|███       | 9/29 [01:05<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 2.8518385887145996
Epoch 353/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:06, 58.11s/it]  7%|▋         | 2/29 [01:00<11:22, 25.28s/it] 10%|█         | 3/29 [01:01<06:08, 14.16s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8570659160614014
Epoch 354/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:26, 58.82s/it]  7%|▋         | 2/29 [00:59<11:08, 24.76s/it] 10%|█         | 3/29 [01:00<06:00, 13.87s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.76s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.8578062057495117
Epoch 355/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.66s/it]  7%|▋         | 2/29 [01:02<11:37, 25.82s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.8602874279022217
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0131, 0.0024,  ..., 0.0041, 0.0001, 0.0196],
        [0.0027, 0.0093, 0.0026,  ..., 0.0027, 0.0003, 0.0174],
        [0.0337, 0.0066, 0.0043,  ..., 0.0053, 0.0164, 0.0231],
        ...,
        [0.0070, 0.0083, 0.0209,  ..., 0.0045, 0.0016, 0.0207],
        [0.0044, 0.0081, 0.0139,  ..., 0.0048, 0.0046, 0.0197],
        [0.0087, 0.0049, 0.0050,  ..., 0.0023, 0.0027, 0.0216]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9964, 0.9954, 0.9954, 0.9952, 0.9950, 0.9950, 0.9950, 0.9947,
         0.9947],
        [0.9973, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968,
         0.9967],
        [0.9758, 0.9669, 0.9668, 0.9667, 0.9666, 0.9655, 0.9647, 0.9637, 0.9634,
         0.9629],
        [0.9927, 0.9926, 0.9923, 0.9923, 0.9919, 0.9915, 0.9913, 0.9912, 0.9907,
         0.9905],
        [0.9890, 0.9873, 0.9864, 0.9859, 0.9857, 0.9857, 0.9854, 0.9852, 0.9851,
         0.9848],
        [0.9855, 0.9842, 0.9807, 0.9789, 0.9789, 0.9755, 0.9755, 0.9755, 0.9748,
         0.9747],
        [0.9771, 0.9721, 0.9691, 0.9670, 0.9669, 0.9652, 0.9642, 0.9619, 0.9600,
         0.9593],
        [0.9760, 0.9727, 0.9724, 0.9656, 0.9592, 0.9582, 0.9568, 0.9545, 0.9534,
         0.9515],
        [0.9978, 0.9974, 0.9973, 0.9969, 0.9969, 0.9968, 0.9967, 0.9966, 0.9966,
         0.9965],
        [0.9939, 0.9901, 0.9886, 0.9880, 0.9876, 0.9874, 0.9864, 0.9852, 0.9848,
         0.9848],
        [0.9983, 0.9982, 0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9942, 0.9931, 0.9914, 0.9912, 0.9909, 0.9908, 0.9906, 0.9903, 0.9899,
         0.9898],
        [0.9933, 0.9912, 0.9910, 0.9904, 0.9889, 0.9881, 0.9863, 0.9860, 0.9854,
         0.9849],
        [0.9986, 0.9984, 0.9983, 0.9983, 0.9980, 0.9979, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9984],
        [0.9964, 0.9963, 0.9963, 0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9958,
         0.9957],
        [0.9957, 0.9951, 0.9947, 0.9947, 0.9946, 0.9946, 0.9945, 0.9944, 0.9942,
         0.9942],
        [0.9946, 0.9939, 0.9938, 0.9937, 0.9934, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9931],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9983, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9976],
        [0.9955, 0.9949, 0.9947, 0.9946, 0.9945, 0.9944, 0.9939, 0.9934, 0.9934,
         0.9933],
        [0.9987, 0.9987, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9976, 0.9976,
         0.9975],
        [0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9987,
         0.9987],
        [0.9953, 0.9952, 0.9950, 0.9948, 0.9946, 0.9945, 0.9943, 0.9941, 0.9941,
         0.9940],
        [0.9989, 0.9988, 0.9986, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983,
         0.9983],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9889, 0.9874, 0.9780, 0.9746, 0.9709, 0.9691, 0.9687, 0.9683, 0.9641,
         0.9597],
        [0.9966, 0.9966, 0.9963, 0.9963, 0.9963, 0.9962, 0.9960, 0.9960, 0.9960,
         0.9959],
        [0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9968, 0.9968, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9865, 0.9846, 0.9808, 0.9776, 0.9757, 0.9756, 0.9737, 0.9729, 0.9725,
         0.9723],
        [0.9956, 0.9953, 0.9953, 0.9953, 0.9951, 0.9951, 0.9951, 0.9950, 0.9950,
         0.9949],
        [0.9932, 0.9924, 0.9917, 0.9916, 0.9915, 0.9914, 0.9911, 0.9908, 0.9907,
         0.9907],
        [0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9956, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9855, 0.9853, 0.9850, 0.9838, 0.9831, 0.9823, 0.9814, 0.9810, 0.9806,
         0.9794],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981,
         0.9981],
        [0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9974, 0.9972, 0.9972, 0.9971, 0.9971, 0.9970, 0.9968, 0.9968, 0.9967,
         0.9966],
        [0.9900, 0.9883, 0.9881, 0.9870, 0.9862, 0.9849, 0.9847, 0.9839, 0.9837,
         0.9832],
        [0.9850, 0.9792, 0.9790, 0.9785, 0.9780, 0.9780, 0.9779, 0.9778, 0.9775,
         0.9772],
        [0.9878, 0.9870, 0.9745, 0.9730, 0.9650, 0.9611, 0.9608, 0.9607, 0.9607,
         0.9589],
        [0.9723, 0.9705, 0.9667, 0.9651, 0.9648, 0.9642, 0.9629, 0.9620, 0.9601,
         0.9533],
        [0.9918, 0.9899, 0.9897, 0.9892, 0.9891, 0.9887, 0.9879, 0.9872, 0.9871,
         0.9870],
        [0.9946, 0.9944, 0.9944, 0.9941, 0.9940, 0.9938, 0.9937, 0.9936, 0.9935,
         0.9930],
        [0.9930, 0.9923, 0.9919, 0.9919, 0.9917, 0.9916, 0.9913, 0.9911, 0.9911,
         0.9910],
        [0.9910, 0.9907, 0.9900, 0.9897, 0.9896, 0.9895, 0.9861, 0.9861, 0.9860,
         0.9860],
        [0.9934, 0.9930, 0.9928, 0.9925, 0.9921, 0.9919, 0.9908, 0.9901, 0.9897,
         0.9893],
        [0.9905, 0.9880, 0.9870, 0.9868, 0.9860, 0.9859, 0.9856, 0.9849, 0.9844,
         0.9839],
        [0.9953, 0.9953, 0.9953, 0.9952, 0.9951, 0.9949, 0.9947, 0.9946, 0.9946,
         0.9945],
        [0.9959, 0.9954, 0.9953, 0.9950, 0.9947, 0.9943, 0.9939, 0.9938, 0.9935,
         0.9935],
        [0.9946, 0.9906, 0.9903, 0.9901, 0.9893, 0.9893, 0.9891, 0.9885, 0.9876,
         0.9872],
        [0.9922, 0.9917, 0.9910, 0.9896, 0.9889, 0.9873, 0.9873, 0.9863, 0.9853,
         0.9851],
        [0.9920, 0.9918, 0.9917, 0.9904, 0.9894, 0.9886, 0.9883, 0.9878, 0.9878,
         0.9853],
        [0.9967, 0.9939, 0.9934, 0.9924, 0.9924, 0.9913, 0.9887, 0.9886, 0.9883,
         0.9878],
        [0.9905, 0.9884, 0.9877, 0.9876, 0.9875, 0.9872, 0.9870, 0.9863, 0.9860,
         0.9858],
        [0.9918, 0.9911, 0.9879, 0.9855, 0.9844, 0.9841, 0.9836, 0.9834, 0.9828,
         0.9823],
        [0.9929, 0.9923, 0.9919, 0.9915, 0.9913, 0.9902, 0.9869, 0.9853, 0.9850,
         0.9840],
        [0.9929, 0.9929, 0.9923, 0.9922, 0.9921, 0.9918, 0.9912, 0.9908, 0.9903,
         0.9901]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 0, 1, 0, 1, 1, 1, 0, 0, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1523534.7500, 1519470.5000, 1498780.6250, 1497559.0000, 1493827.5000,
         1489235.8750, 1489231.7500, 1489008.7500, 1483882.6250, 1483804.8750],
        [1540309.3750, 1532258.5000, 1531931.2500, 1530487.0000, 1530352.6250,
         1528602.2500, 1528235.0000, 1528124.2500, 1527805.1250, 1527585.1250],
        [1131853.6250,  996926.4375,  995510.8125,  993950.2500,  992736.8125,
          977817.5625,  966175.8750,  952995.5000,  948933.4375,  941597.2500],
        [1442606.3750, 1440248.7500, 1433617.7500, 1432811.2500, 1425171.3750,
         1417580.5000, 1413997.1250, 1410393.1250, 1401313.7500, 1396453.7500],
        [1368498.5000, 1334558.0000, 1317096.8750, 1308484.5000, 1305137.0000,
         1303726.2500, 1298134.6250, 1296230.8750, 1293092.2500, 1288119.6250],
        [1301233.3750, 1277767.6250, 1214868.1250, 1184488.1250, 1184445.2500,
         1128219.7500, 1127769.0000, 1127046.5000, 1116576.0000, 1114523.8750],
        [1154499.0000, 1073514.0000, 1028821.5000,  998681.1875,  996701.1250,
          973727.7500,  959223.1875,  928481.1250,  903220.6875,  895144.5625],
        [1135706.2500, 1083350.2500, 1078477.5000,  979085.6875,  894079.8125,
          881224.6250,  863395.1250,  835977.7500,  822787.9375,  800569.5000],
        [1551537.5000, 1541242.3750, 1539390.0000, 1532040.7500, 1530508.8750,
         1528911.3750, 1526526.5000, 1525061.1250, 1524989.8750, 1523117.7500],
        [1466452.2500, 1389219.6250, 1359945.6250, 1347630.2500, 1341075.0000,
         1337090.6250, 1318201.3750, 1295820.5000, 1288199.5000, 1288081.6250],
        [1560865.1250, 1559273.2500, 1558908.8750, 1555620.8750, 1555029.0000,
         1553380.8750, 1553259.2500, 1552410.7500, 1552202.0000, 1551654.3750],
        [1473273.2500, 1450519.3750, 1414326.1250, 1411511.2500, 1405115.6250,
         1402554.3750, 1400080.7500, 1392808.0000, 1385159.6250, 1383799.6250],
        [1454436.7500, 1412087.6250, 1407327.0000, 1394368.3750, 1364764.6250,
         1350617.8750, 1316215.3750, 1309565.6250, 1298729.0000, 1290620.8750],
        [1568511.1250, 1563640.7500, 1563004.2500, 1560900.8750, 1556158.0000,
         1552095.3750, 1547020.8750, 1545204.3750, 1544193.6250, 1544159.8750],
        [1577966.3750, 1577117.7500, 1576570.5000, 1576084.8750, 1575326.0000,
         1575308.0000, 1573928.0000, 1573552.7500, 1573414.6250, 1573345.7500],
        [1574457.8750, 1573651.7500, 1571006.7500, 1570808.8750, 1569622.8750,
         1569281.7500, 1569138.0000, 1568357.0000, 1565322.2500, 1564637.2500],
        [1521105.8750, 1518517.2500, 1517204.3750, 1511456.6250, 1510280.8750,
         1508130.5000, 1507746.5000, 1507635.7500, 1506603.8750, 1505121.7500],
        [1505539.5000, 1491666.5000, 1484320.1250, 1483397.5000, 1482018.6250,
         1481398.2500, 1478715.1250, 1476305.6250, 1474110.8750, 1473330.8750],
        [1481849.1250, 1466961.3750, 1464896.5000, 1462554.2500, 1456382.6250,
         1456031.2500, 1455284.5000, 1454933.3750, 1451144.8750, 1451121.2500],
        [1558790.0000, 1557428.7500, 1555795.8750, 1552909.7500, 1551126.2500,
         1550676.6250, 1550608.5000, 1550428.1250, 1549833.8750, 1549689.0000],
        [1561655.8750, 1552834.2500, 1552586.8750, 1552324.8750, 1551826.1250,
         1551678.1250, 1550528.7500, 1549334.3750, 1548714.0000, 1545677.2500],
        [1501211.0000, 1487961.1250, 1483595.3750, 1481606.0000, 1478496.6250,
         1476378.8750, 1466323.5000, 1456621.5000, 1456402.1250, 1453510.5000],
        [1570958.7500, 1570457.0000, 1559167.6250, 1558911.8750, 1558338.1250,
         1555779.6250, 1554644.8750, 1546950.0000, 1546119.6250, 1544377.8750],
        [1579184.2500, 1575963.2500, 1575213.3750, 1575141.2500, 1574979.1250,
         1574943.0000, 1574779.3750, 1573749.3750, 1571715.5000, 1571008.1250],
        [1496044.6250, 1495081.7500, 1489324.0000, 1484695.2500, 1481278.2500,
         1479804.2500, 1475258.5000, 1471143.3750, 1470509.3750, 1469173.5000],
        [1576334.3750, 1573231.6250, 1567773.8750, 1566070.3750, 1565010.2500,
         1562938.6250, 1562600.2500, 1562510.7500, 1562242.6250, 1561865.7500],
        [1564885.0000, 1561265.6250, 1558940.1250, 1558131.6250, 1557696.2500,
         1555431.0000, 1553374.7500, 1551330.2500, 1551294.7500, 1551203.1250],
        [1575656.6250, 1574205.7500, 1573947.5000, 1573856.0000, 1573786.8750,
         1572325.6250, 1571549.1250, 1569663.3750, 1568689.1250, 1567749.8750],
        [1579252.0000, 1579002.0000, 1578229.7500, 1578079.2500, 1576851.7500,
         1576421.6250, 1576268.2500, 1575931.6250, 1574873.8750, 1573854.3750],
        [1581239.8750, 1580927.7500, 1577262.2500, 1576193.1250, 1576151.0000,
         1575617.5000, 1575163.7500, 1575112.7500, 1575103.7500, 1574130.6250],
        [1582199.2500, 1580663.8750, 1578856.0000, 1578582.0000, 1578338.1250,
         1578089.7500, 1576242.7500, 1576208.2500, 1576193.1250, 1576060.8750],
        [1581206.7500, 1578869.6250, 1578559.3750, 1577072.7500, 1576800.5000,
         1575341.0000, 1574968.5000, 1574828.8750, 1574498.3750, 1573940.0000],
        [1366568.3750, 1336366.5000, 1168854.3750, 1113440.2500, 1055532.1250,
         1029862.0625, 1022886.9375, 1017592.0000,  957813.6250,  899727.7500],
        [1523677.1250, 1523572.5000, 1518987.8750, 1518718.6250, 1518717.1250,
         1516348.1250, 1512318.8750, 1511818.3750, 1511254.7500, 1510236.1250],
        [1552370.7500, 1552062.8750, 1549486.6250, 1548238.5000, 1547388.2500,
         1547388.2500, 1546240.5000, 1544746.0000, 1544628.2500, 1544408.7500],
        [1529389.7500, 1528478.3750, 1523722.1250, 1521808.2500, 1519721.1250,
         1518830.0000, 1518653.3750, 1517972.8750, 1517635.6250, 1516323.3750],
        [1319691.8750, 1283769.7500, 1215582.1250, 1162626.6250, 1130939.7500,
         1128934.3750, 1098700.1250, 1087097.7500, 1079926.5000, 1077418.6250],
        [1503057.6250, 1497366.2500, 1497356.2500, 1496706.7500, 1492454.8750,
         1491942.5000, 1491514.2500, 1490811.8750, 1489467.5000, 1487111.3750],
        [1451938.1250, 1436121.8750, 1421707.0000, 1420247.6250, 1417607.5000,
         1416223.8750, 1408499.2500, 1402478.1250, 1402181.2500, 1401297.6250],
        [1510442.1250, 1510177.1250, 1507692.0000, 1507692.0000, 1506091.0000,
         1502440.0000, 1498700.6250, 1497413.3750, 1496985.0000, 1496375.5000],
        [1300458.0000, 1296992.5000, 1291727.7500, 1270061.6250, 1256907.2500,
         1242951.1250, 1226360.8750, 1220595.7500, 1213306.2500, 1191694.3750],
        [1566485.6250, 1563698.8750, 1562402.1250, 1560813.0000, 1560722.2500,
         1560313.0000, 1559653.8750, 1559616.7500, 1558300.8750, 1557674.0000],
        [1560759.5000, 1559222.6250, 1557810.6250, 1556204.0000, 1553054.8750,
         1552727.6250, 1551262.3750, 1551007.8750, 1550953.1250, 1550769.7500],
        [1541337.8750, 1537934.3750, 1537507.6250, 1535894.1250, 1534759.2500,
         1532417.7500, 1529858.1250, 1527862.0000, 1527105.8750, 1525085.7500],
        [1387318.5000, 1353140.8750, 1349810.3750, 1328371.6250, 1313853.8750,
         1289422.5000, 1286218.2500, 1272365.0000, 1267850.5000, 1259734.3750],
        [1291109.5000, 1188195.6250, 1185408.0000, 1176876.5000, 1168833.2500,
         1168366.2500, 1166424.7500, 1165131.7500, 1160422.1250, 1156044.7500],
        [1343622.5000, 1328545.2500, 1111872.8750, 1087435.7500,  971232.0000,
          918638.6250,  913723.8125,  913215.9375,  913085.2500,  889953.9375],
        [1077234.6250, 1049367.3750,  994156.0625,  971434.8750,  967920.8125,
          959629.4375,  942156.8750,  929975.2500,  905046.9375,  821094.0625],
        [1422549.2500, 1384367.2500, 1382248.6250, 1370757.0000, 1369113.3750,
         1361157.5000, 1346230.1250, 1332070.8750, 1330900.0000, 1329897.7500],
        [1480911.1250, 1477822.7500, 1476236.6250, 1470039.7500, 1468719.6250,
         1464802.8750, 1461968.5000, 1460910.6250, 1459239.6250, 1447919.7500],
        [1448897.7500, 1433984.1250, 1426355.7500, 1426119.1250, 1421774.8750,
         1419586.8750, 1413257.0000, 1409917.0000, 1409891.5000, 1406366.3750],
        [1406268.5000, 1402131.8750, 1386855.5000, 1382031.1250, 1379320.0000,
         1376735.0000, 1311971.8750, 1311753.0000, 1309989.0000, 1309834.1250],
        [1457170.3750, 1448907.3750, 1443140.2500, 1437101.3750, 1429153.8750,
         1424471.6250, 1402341.7500, 1390221.6250, 1380437.2500, 1374211.1250],
        [1397419.5000, 1348393.8750, 1329138.3750, 1324978.3750, 1311130.2500,
         1307755.8750, 1302409.0000, 1290308.1250, 1280705.3750, 1270620.0000],
        [1496085.8750, 1495981.7500, 1495981.7500, 1493792.0000, 1492621.5000,
         1488730.3750, 1483991.6250, 1481999.0000, 1481989.0000, 1479951.0000],
        [1509093.0000, 1499195.1250, 1496635.3750, 1489669.1250, 1483066.3750,
         1474276.8750, 1465887.3750, 1465160.6250, 1458498.1250, 1458498.1250],
        [1481073.5000, 1399500.0000, 1392640.7500, 1388871.2500, 1374377.6250,
         1374327.7500, 1368618.6250, 1358401.8750, 1341306.5000, 1333364.7500],
        [1430992.3750, 1420739.2500, 1407403.5000, 1379268.7500, 1364694.3750,
         1335723.0000, 1334189.0000, 1315619.2500, 1296400.1250, 1294407.3750],
        [1427320.5000, 1424402.3750, 1421125.5000, 1394449.5000, 1376379.1250,
         1359668.1250, 1353933.5000, 1344709.6250, 1343923.6250, 1297268.3750],
        [1527621.6250, 1465733.6250, 1456066.1250, 1436504.0000, 1435730.1250,
         1413948.6250, 1361271.8750, 1360246.6250, 1354630.8750, 1344207.0000],
        [1396513.6250, 1356517.1250, 1343354.7500, 1340178.8750, 1338445.5000,
         1332806.6250, 1328386.8750, 1314923.1250, 1309664.2500, 1305615.0000],
        [1424186.3750, 1409408.8750, 1346506.1250, 1300124.5000, 1279744.5000,
         1274724.8750, 1266954.8750, 1261926.5000, 1251442.3750, 1243438.3750],
        [1445368.7500, 1434581.8750, 1425527.5000, 1418118.6250, 1413537.2500,
         1392230.3750, 1326939.6250, 1296813.1250, 1291328.7500, 1274131.7500],
        [1446270.6250, 1446070.6250, 1432968.3750, 1432039.3750, 1429252.0000,
         1424168.7500, 1411191.0000, 1402455.5000, 1393480.2500, 1389255.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1523534.7500,       0.0000],
         [1519470.5000,       0.0000],
         [1498780.6250,       0.0000],
         ...,
         [      0.0000, 1489008.7500],
         [1483882.6250,       0.0000],
         [1483804.8750,       0.0000]],

        [[1540309.3750,       0.0000],
         [1532258.5000,       0.0000],
         [1531931.2500,       0.0000],
         ...,
         [1528124.2500,       0.0000],
         [1527805.1250,       0.0000],
         [1527585.1250,       0.0000]],

        [[1131853.6250,       0.0000],
         [      0.0000,  996926.4375],
         [      0.0000,  995510.8125],
         ...,
         [      0.0000,  952995.5000],
         [ 948933.4375,       0.0000],
         [ 941597.2500,       0.0000]],

        ...,

        [[1424186.3750,       0.0000],
         [1409408.8750,       0.0000],
         [1346506.1250,       0.0000],
         ...,
         [1261926.5000,       0.0000],
         [      0.0000, 1251442.3750],
         [1243438.3750,       0.0000]],

        [[1445368.7500,       0.0000],
         [1434581.8750,       0.0000],
         [1425527.5000,       0.0000],
         ...,
         [      0.0000, 1296813.1250],
         [1291328.7500,       0.0000],
         [      0.0000, 1274131.7500]],

        [[      0.0000, 1446270.6250],
         [      0.0000, 1446070.6250],
         [      0.0000, 1432968.3750],
         ...,
         [      0.0000, 1402455.5000],
         [1393480.2500,       0.0000],
         [      0.0000, 1389255.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13479327.0000,  1489008.7500],
        [15305690.0000,        0.0000],
        [ 4994152.0000,  4904345.5000],
        [12796614.0000,  1417580.5000],
        [ 9211123.0000,  3901955.5000],
        [10592492.0000,  1184445.2500],
        [ 3971207.7500,  5940806.0000],
        [ 8538677.0000,   835977.7500],
        [13800208.0000,  1523117.7500],
        [12042497.0000,  1389219.6250],
        [15552604.0000,        0.0000],
        [14119148.0000,        0.0000],
        [13598734.0000,        0.0000],
        [15544888.0000,        0.0000],
        [15752614.0000,        0.0000],
        [15696285.0000,        0.0000],
        [13592698.0000,  1521105.8750],
        [13325263.0000,  1505539.5000],
        [14601158.0000,        0.0000],
        [15527286.0000,        0.0000],
        [15517161.0000,        0.0000],
        [13260500.0000,  1481606.0000],
        [15565706.0000,        0.0000],
        [15746678.0000,        0.0000],
        [10352013.0000,  4460300.0000],
        [15660578.0000,        0.0000],
        [15563553.0000,        0.0000],
        [15721430.0000,        0.0000],
        [15768765.0000,        0.0000],
        [15766903.0000,        0.0000],
        [15781434.0000,        0.0000],
        [15766086.0000,        0.0000],
        [ 2947181.7500,  8021462.0000],
        [10612748.0000,  4552901.0000],
        [13932550.0000,  1544408.7500],
        [12172073.0000,  3040461.5000],
        [ 3316737.7500,  8267949.5000],
        [10447908.0000,  4489881.0000],
        [12776121.0000,  1402181.2500],
        [15034008.0000,        0.0000],
        [ 9957156.0000,  2553899.7500],
        [15609681.0000,        0.0000],
        [15543773.0000,        0.0000],
        [13793869.0000,  1535894.1250],
        [ 2549157.0000, 10558929.0000],
        [ 1156044.7500, 10670768.0000],
        [ 5519849.5000,  4871476.0000],
        [ 2656116.2500,  6961900.0000],
        [ 5418095.0000,  8211197.0000],
        [10242704.0000,  4425867.5000],
        [11357361.0000,  2858789.2500],
        [ 1309989.0000, 12266901.0000],
        [ 1374211.1250, 12812945.0000],
        [ 2640268.5000, 10522590.0000],
        [11908601.0000,  2982522.5000],
        [10311185.0000,  4488795.0000],
        [ 2732729.5000, 11079753.0000],
        [ 3993290.7500,  9586146.0000],
        [ 1297268.3750, 12445911.0000],
        [ 2715902.7500, 11440058.0000],
        [10660228.0000,  2706178.0000],
        [10532290.0000,  2526167.2500],
        [ 9820693.0000,  3897884.5000],
        [ 1393480.2500, 12813672.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 356/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<28:59, 62.12s/it]  7%|▋         | 2/29 [01:03<11:45, 26.12s/it] 10%|█         | 3/29 [01:03<06:20, 14.62s/it] 14%|█▍        | 4/29 [01:04<03:50,  9.21s/it] 17%|█▋        | 5/29 [01:05<02:29,  6.22s/it] 21%|██        | 6/29 [01:06<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.53s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:32,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:28<00:00,  3.04s/it]
Epoch loss is 2.8416764736175537
Epoch 357/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:35, 61.27s/it]  7%|▋         | 2/29 [01:02<11:35, 25.77s/it] 10%|█         | 3/29 [01:03<06:15, 14.42s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.8524889945983887
Epoch 358/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:50, 61.80s/it]  7%|▋         | 2/29 [01:02<11:41, 25.99s/it] 10%|█         | 3/29 [01:03<06:18, 14.54s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.843973398208618
Epoch 359/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:14, 60.50s/it]  7%|▋         | 2/29 [01:01<11:27, 25.46s/it] 10%|█         | 3/29 [01:02<06:10, 14.25s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.8473594188690186
Epoch 360/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:55, 57.68s/it]  7%|▋         | 2/29 [00:58<10:55, 24.29s/it] 10%|█         | 3/29 [00:59<05:54, 13.62s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.61s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.84s/it] 21%|██        | 6/29 [01:02<01:35,  4.17s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.10s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.41s/it] 31%|███       | 9/29 [01:05<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 2.848991870880127
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.9887e-03, 1.2759e-02, 2.1930e-03,  ..., 3.9936e-03, 9.1822e-05,
         1.9663e-02],
        [2.4952e-03, 9.2260e-03, 2.3933e-03,  ..., 2.5840e-03, 2.6421e-04,
         1.7401e-02],
        [3.2414e-02, 6.7971e-03, 4.2640e-03,  ..., 5.4844e-03, 1.5595e-02,
         2.3481e-02],
        ...,
        [6.7204e-03, 8.2165e-03, 1.9929e-02,  ..., 4.4259e-03, 1.5967e-03,
         2.1028e-02],
        [4.0475e-03, 7.8368e-03, 1.2762e-02,  ..., 4.5087e-03, 4.4426e-03,
         1.9938e-02],
        [8.1844e-03, 4.7734e-03, 4.6072e-03,  ..., 2.1856e-03, 2.5745e-03,
         2.1593e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9966, 0.9964, 0.9955, 0.9953, 0.9952, 0.9951, 0.9951, 0.9949, 0.9949,
         0.9948],
        [0.9974, 0.9970, 0.9969, 0.9969, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968,
         0.9968],
        [0.9761, 0.9684, 0.9673, 0.9660, 0.9649, 0.9644, 0.9633, 0.9629, 0.9624,
         0.9623],
        [0.9927, 0.9926, 0.9923, 0.9922, 0.9920, 0.9915, 0.9912, 0.9910, 0.9906,
         0.9903],
        [0.9890, 0.9871, 0.9869, 0.9856, 0.9853, 0.9852, 0.9851, 0.9851, 0.9848,
         0.9845],
        [0.9850, 0.9843, 0.9806, 0.9781, 0.9769, 0.9746, 0.9742, 0.9736, 0.9728,
         0.9723],
        [0.9782, 0.9692, 0.9688, 0.9666, 0.9665, 0.9658, 0.9649, 0.9628, 0.9624,
         0.9599],
        [0.9769, 0.9723, 0.9718, 0.9688, 0.9603, 0.9596, 0.9578, 0.9574, 0.9572,
         0.9554],
        [0.9979, 0.9974, 0.9973, 0.9970, 0.9969, 0.9969, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9940, 0.9903, 0.9889, 0.9888, 0.9874, 0.9869, 0.9864, 0.9859, 0.9849,
         0.9842],
        [0.9983, 0.9982, 0.9982, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9944, 0.9935, 0.9919, 0.9913, 0.9912, 0.9909, 0.9907, 0.9901, 0.9900,
         0.9898],
        [0.9936, 0.9915, 0.9908, 0.9908, 0.9892, 0.9884, 0.9869, 0.9868, 0.9859,
         0.9852],
        [0.9986, 0.9984, 0.9984, 0.9983, 0.9981, 0.9980, 0.9978, 0.9976, 0.9976,
         0.9976],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9985,
         0.9985],
        [0.9965, 0.9964, 0.9963, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9957],
        [0.9957, 0.9951, 0.9948, 0.9948, 0.9946, 0.9945, 0.9945, 0.9944, 0.9943,
         0.9942],
        [0.9946, 0.9942, 0.9939, 0.9937, 0.9937, 0.9936, 0.9934, 0.9933, 0.9933,
         0.9933],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9983, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977,
         0.9976],
        [0.9955, 0.9951, 0.9947, 0.9947, 0.9946, 0.9945, 0.9941, 0.9936, 0.9934,
         0.9931],
        [0.9987, 0.9987, 0.9982, 0.9982, 0.9982, 0.9981, 0.9980, 0.9977, 0.9977,
         0.9976],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9953, 0.9952, 0.9950, 0.9948, 0.9947, 0.9945, 0.9945, 0.9944, 0.9942,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9989],
        [0.9992, 0.9992, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9889, 0.9873, 0.9783, 0.9744, 0.9701, 0.9699, 0.9685, 0.9679, 0.9641,
         0.9594],
        [0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9962, 0.9961, 0.9960, 0.9960,
         0.9960],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9970, 0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9863, 0.9843, 0.9805, 0.9776, 0.9760, 0.9752, 0.9735, 0.9728, 0.9724,
         0.9724],
        [0.9957, 0.9956, 0.9956, 0.9954, 0.9953, 0.9953, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9931, 0.9922, 0.9918, 0.9915, 0.9914, 0.9914, 0.9911, 0.9908, 0.9906,
         0.9906],
        [0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9957, 0.9955, 0.9955, 0.9955,
         0.9954],
        [0.9854, 0.9852, 0.9849, 0.9836, 0.9832, 0.9822, 0.9813, 0.9808, 0.9803,
         0.9793],
        [0.9986, 0.9985, 0.9984, 0.9983, 0.9983, 0.9983, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9983, 0.9982, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9974, 0.9973, 0.9973, 0.9973, 0.9972, 0.9971, 0.9969, 0.9969, 0.9968,
         0.9968],
        [0.9903, 0.9884, 0.9882, 0.9871, 0.9867, 0.9851, 0.9850, 0.9842, 0.9837,
         0.9836],
        [0.9860, 0.9798, 0.9793, 0.9790, 0.9788, 0.9786, 0.9779, 0.9779, 0.9778,
         0.9775],
        [0.9878, 0.9868, 0.9736, 0.9727, 0.9646, 0.9604, 0.9601, 0.9601, 0.9595,
         0.9573],
        [0.9722, 0.9700, 0.9666, 0.9660, 0.9650, 0.9643, 0.9621, 0.9616, 0.9601,
         0.9529],
        [0.9916, 0.9901, 0.9895, 0.9894, 0.9892, 0.9889, 0.9878, 0.9876, 0.9876,
         0.9872],
        [0.9946, 0.9946, 0.9945, 0.9943, 0.9940, 0.9940, 0.9939, 0.9939, 0.9936,
         0.9933],
        [0.9933, 0.9924, 0.9922, 0.9921, 0.9920, 0.9916, 0.9914, 0.9912, 0.9912,
         0.9910],
        [0.9912, 0.9909, 0.9901, 0.9899, 0.9897, 0.9897, 0.9864, 0.9863, 0.9861,
         0.9861],
        [0.9936, 0.9931, 0.9928, 0.9926, 0.9922, 0.9919, 0.9908, 0.9903, 0.9899,
         0.9896],
        [0.9907, 0.9883, 0.9873, 0.9869, 0.9864, 0.9860, 0.9858, 0.9854, 0.9849,
         0.9843],
        [0.9955, 0.9955, 0.9955, 0.9954, 0.9953, 0.9950, 0.9950, 0.9949, 0.9948,
         0.9948],
        [0.9959, 0.9956, 0.9955, 0.9952, 0.9949, 0.9944, 0.9941, 0.9940, 0.9937,
         0.9937],
        [0.9947, 0.9910, 0.9904, 0.9902, 0.9898, 0.9896, 0.9891, 0.9890, 0.9881,
         0.9875],
        [0.9922, 0.9917, 0.9911, 0.9898, 0.9888, 0.9875, 0.9874, 0.9865, 0.9856,
         0.9852],
        [0.9922, 0.9920, 0.9918, 0.9903, 0.9896, 0.9887, 0.9886, 0.9879, 0.9878,
         0.9857],
        [0.9968, 0.9939, 0.9935, 0.9926, 0.9926, 0.9915, 0.9890, 0.9889, 0.9885,
         0.9881],
        [0.9907, 0.9887, 0.9880, 0.9877, 0.9876, 0.9875, 0.9871, 0.9866, 0.9860,
         0.9860],
        [0.9919, 0.9912, 0.9883, 0.9856, 0.9845, 0.9842, 0.9838, 0.9835, 0.9831,
         0.9827],
        [0.9930, 0.9926, 0.9921, 0.9918, 0.9915, 0.9905, 0.9872, 0.9858, 0.9852,
         0.9845],
        [0.9932, 0.9930, 0.9925, 0.9925, 0.9922, 0.9921, 0.9910, 0.9908, 0.9907,
         0.9904]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1525275.0000, 1520521.3750, 1501162.3750, 1496726.6250, 1494360.5000,
         1492080.6250, 1491101.8750, 1488409.5000, 1487307.0000, 1485740.5000],
        [1542477.6250, 1532942.5000, 1531989.6250, 1530990.6250, 1530551.2500,
         1530431.5000, 1529907.6250, 1528796.2500, 1528571.7500, 1527982.8750],
        [1137669.5000, 1018416.2500, 1003335.0000,  983979.4375,  968840.6250,
          962646.0000,  947350.1250,  942221.5625,  935059.5000,  934422.1250],
        [1442395.8750, 1440199.3750, 1432614.5000, 1430780.7500, 1428251.8750,
         1416888.5000, 1412117.2500, 1406554.1250, 1399149.1250, 1393013.8750],
        [1368424.1250, 1331668.2500, 1327129.5000, 1302821.5000, 1296789.6250,
         1295295.3750, 1294409.8750, 1292797.3750, 1287668.8750, 1282751.6250],
        [1292568.2500, 1278914.7500, 1212666.5000, 1169787.8750, 1149935.5000,
         1113617.6250, 1106914.1250, 1097806.7500, 1084637.2500, 1077083.6250],
        [1172193.2500, 1031037.3125, 1024362.0000,  992746.2500,  991064.3750,
          982401.3750,  969322.1875,  940774.1875,  935674.0625,  901841.8125],
        [1151130.3750, 1077794.7500, 1069930.6250, 1025478.1875,  907369.1250,
          898548.6875,  875516.6250,  870331.1875,  868415.9375,  846288.6875],
        [1552282.0000, 1541580.3750, 1539520.6250, 1533856.5000, 1530940.8750,
         1530147.0000, 1526939.8750, 1526280.3750, 1525461.1250, 1524371.8750],
        [1468597.7500, 1392691.2500, 1365226.6250, 1363911.1250, 1335789.3750,
         1327934.7500, 1316889.6250, 1308641.7500, 1290421.3750, 1276497.2500],
        [1561082.5000, 1559764.0000, 1559325.1250, 1555632.6250, 1554867.3750,
         1554019.3750, 1553881.6250, 1553491.8750, 1552646.1250, 1551923.7500],
        [1477597.3750, 1459203.5000, 1424754.2500, 1414157.6250, 1410905.6250,
         1405583.3750, 1400239.6250, 1389548.3750, 1386736.5000, 1383741.7500],
        [1459483.2500, 1416516.8750, 1402767.1250, 1402763.1250, 1371106.0000,
         1355947.8750, 1327951.1250, 1325263.8750, 1307991.7500, 1294480.2500],
        [1568880.7500, 1565005.7500, 1563994.1250, 1562078.7500, 1557218.0000,
         1556198.1250, 1550230.1250, 1546858.5000, 1545879.3750, 1545839.5000],
        [1578494.7500, 1578211.6250, 1577015.6250, 1576546.5000, 1576190.1250,
         1575198.3750, 1574705.6250, 1574488.0000, 1574382.8750, 1573853.0000],
        [1575402.7500, 1575262.8750, 1572063.3750, 1571547.6250, 1570746.1250,
         1570421.0000, 1570401.5000, 1570013.7500, 1566509.5000, 1566490.1250],
        [1521784.8750, 1519089.3750, 1517428.6250, 1514274.2500, 1512326.0000,
         1510312.5000, 1509536.3750, 1508590.8750, 1508517.3750, 1505068.7500],
        [1505080.1250, 1491945.5000, 1485836.8750, 1485825.5000, 1481748.7500,
         1479088.8750, 1478495.1250, 1477528.2500, 1474171.3750, 1473825.5000],
        [1482186.8750, 1473343.5000, 1467102.7500, 1463595.1250, 1461873.6250,
         1460346.5000, 1457062.0000, 1455276.1250, 1454637.8750, 1454183.0000],
        [1559841.2500, 1558084.0000, 1556325.6250, 1553843.1250, 1553549.6250,
         1552863.8750, 1551707.7500, 1551382.1250, 1551379.1250, 1551030.1250],
        [1561687.0000, 1553898.0000, 1553671.2500, 1553454.8750, 1553240.0000,
         1552538.0000, 1551654.3750, 1550311.3750, 1549346.2500, 1545752.5000],
        [1501466.0000, 1492174.5000, 1484305.8750, 1483799.1250, 1480826.2500,
         1478830.7500, 1471421.2500, 1459573.7500, 1455873.1250, 1449769.8750],
        [1571920.8750, 1571222.5000, 1560280.2500, 1560137.3750, 1559604.7500,
         1556947.7500, 1556031.8750, 1548765.6250, 1547890.0000, 1545621.3750],
        [1579741.6250, 1576556.8750, 1576378.0000, 1576346.5000, 1575963.2500,
         1575856.5000, 1574815.3750, 1574624.6250, 1572667.6250, 1572546.1250],
        [1497053.5000, 1494550.0000, 1490371.1250, 1486566.8750, 1483710.0000,
         1479395.0000, 1478823.7500, 1477464.8750, 1473256.5000, 1467787.1250],
        [1577008.1250, 1573780.8750, 1568770.0000, 1567373.2500, 1565918.0000,
         1564170.2500, 1564104.5000, 1563912.1250, 1563596.1250, 1563415.6250],
        [1565488.0000, 1562563.0000, 1559570.6250, 1559350.5000, 1557969.6250,
         1556453.3750, 1554682.0000, 1553106.7500, 1552703.8750, 1552526.2500],
        [1576878.7500, 1576293.8750, 1574965.5000, 1574901.0000, 1574546.5000,
         1573632.2500, 1572676.6250, 1572001.7500, 1569928.3750, 1569823.5000],
        [1580065.6250, 1580055.0000, 1578913.2500, 1578280.8750, 1578271.8750,
         1577460.8750, 1577435.2500, 1576711.7500, 1576495.2500, 1574478.8750],
        [1581618.5000, 1581550.5000, 1577876.0000, 1576741.8750, 1576602.1250,
         1576567.5000, 1576415.7500, 1576233.7500, 1575755.7500, 1574528.5000],
        [1582937.2500, 1581208.1250, 1579809.5000, 1579654.2500, 1579101.3750,
         1578997.6250, 1577026.1250, 1576953.8750, 1576872.7500, 1576844.1250],
        [1582152.3750, 1579559.3750, 1578738.6250, 1577782.8750, 1577627.8750,
         1576265.2500, 1576002.2500, 1575769.3750, 1575411.7500, 1575084.2500],
        [1364857.0000, 1334082.0000, 1173067.8750, 1109667.5000, 1043267.5000,
         1041728.4375, 1020906.6250, 1012328.3750,  957656.5625,  896270.3750],
        [1526113.0000, 1525218.2500, 1521709.5000, 1520651.8750, 1518272.5000,
         1515471.8750, 1513405.1250, 1511930.8750, 1511821.2500, 1511471.0000],
        [1553422.2500, 1552256.8750, 1550468.1250, 1549414.2500, 1548640.1250,
         1548640.1250, 1547386.7500, 1547159.5000, 1546831.8750, 1545406.1250],
        [1533643.0000, 1531509.0000, 1527299.6250, 1525606.6250, 1523408.2500,
         1523053.8750, 1521682.0000, 1521634.0000, 1520018.2500, 1519587.8750],
        [1315520.1250, 1279385.7500, 1211656.2500, 1161704.3750, 1135527.6250,
         1123358.2500, 1095826.7500, 1084950.7500, 1079559.0000, 1078603.0000],
        [1504610.8750, 1503024.6250, 1502394.1250, 1497709.0000, 1496217.1250,
         1495571.0000, 1490447.8750, 1489818.3750, 1488040.5000, 1487175.1250],
        [1449335.8750, 1431778.6250, 1422824.6250, 1417917.1250, 1414560.8750,
         1414368.0000, 1409369.8750, 1402828.6250, 1399982.0000, 1398226.0000],
        [1512095.2500, 1511162.5000, 1509640.0000, 1509640.0000, 1509543.6250,
         1505499.3750, 1501266.8750, 1499770.1250, 1499680.0000, 1499345.3750],
        [1298952.0000, 1294623.5000, 1289785.3750, 1266435.5000, 1259007.8750,
         1240833.5000, 1224546.0000, 1216293.0000, 1207917.0000, 1189843.3750],
        [1567531.6250, 1566158.5000, 1563913.6250, 1562838.7500, 1562339.5000,
         1561730.2500, 1561018.5000, 1560997.6250, 1559670.2500, 1558980.2500],
        [1562138.3750, 1560089.7500, 1559839.8750, 1557962.2500, 1554680.5000,
         1554299.5000, 1552884.6250, 1552866.8750, 1552723.1250, 1552145.7500],
        [1542891.0000, 1540443.0000, 1538811.6250, 1538779.3750, 1536570.8750,
         1534756.3750, 1531834.7500, 1530762.7500, 1528596.5000, 1528077.6250],
        [1393049.8750, 1356650.2500, 1351669.2500, 1330813.7500, 1322803.0000,
         1293090.8750, 1291964.2500, 1277465.5000, 1267374.2500, 1266679.5000],
        [1309971.6250, 1198593.5000, 1190470.8750, 1184776.2500, 1181945.8750,
         1178456.7500, 1167759.2500, 1167661.1250, 1165547.3750, 1161044.2500],
        [1343946.7500, 1325288.0000, 1097305.3750, 1083546.5000,  964776.3750,
          909363.3125,  905242.8750,  904937.3125,  897454.1875,  869766.9375],
        [1075370.7500, 1042784.1250,  992377.0625,  984732.2500,  970250.6875,
          960705.3750,  931084.5625,  924468.0000,  904555.0625,  816822.6875],
        [1419389.1250, 1388941.5000, 1378178.6250, 1374609.6250, 1372250.6250,
         1364712.5000, 1343885.2500, 1341301.3750, 1339718.7500, 1332659.1250],
        [1482254.7500, 1481284.0000, 1478744.7500, 1475316.2500, 1468942.2500,
         1468020.8750, 1467802.5000, 1466918.0000, 1460717.0000, 1454975.0000],
        [1454352.1250, 1435393.3750, 1430821.7500, 1428963.0000, 1428014.8750,
         1419022.3750, 1415855.2500, 1411850.5000, 1410777.8750, 1407986.1250],
        [1410944.7500, 1405399.7500, 1389108.3750, 1386076.7500, 1382111.5000,
         1381145.6250, 1317858.2500, 1316256.7500, 1312965.7500, 1312799.2500],
        [1461040.1250, 1451077.0000, 1444391.8750, 1440334.0000, 1431546.5000,
         1424906.5000, 1403315.6250, 1393868.3750, 1384978.7500, 1379060.8750],
        [1400596.2500, 1353368.0000, 1334467.6250, 1327244.6250, 1317222.3750,
         1309767.8750, 1306470.7500, 1299663.2500, 1289827.1250, 1279552.8750],
        [1500791.7500, 1500455.2500, 1500455.2500, 1497789.0000, 1496957.8750,
         1490949.7500, 1489230.2500, 1486927.0000, 1486581.0000, 1485819.8750],
        [1509776.7500, 1503279.7500, 1499953.1250, 1493571.1250, 1487833.3750,
         1477009.8750, 1470752.0000, 1468603.3750, 1462693.6250, 1462693.6250],
        [1482761.0000, 1406362.3750, 1395222.3750, 1391568.0000, 1383464.6250,
         1379405.5000, 1369626.6250, 1367774.5000, 1349903.1250, 1338861.6250],
        [1432584.3750, 1420796.2500, 1409878.1250, 1383384.1250, 1364376.7500,
         1339276.7500, 1337251.3750, 1319230.1250, 1303230.3750, 1295255.7500],
        [1431237.8750, 1428404.3750, 1422959.1250, 1393343.3750, 1380041.0000,
         1361788.5000, 1359525.6250, 1346761.7500, 1344940.5000, 1305459.3750],
        [1528229.2500, 1465989.3750, 1459392.7500, 1440266.6250, 1440161.0000,
         1418221.3750, 1367149.7500, 1365295.7500, 1357751.7500, 1350183.7500],
        [1402095.6250, 1361436.6250, 1348366.8750, 1341997.5000, 1340959.8750,
         1339292.1250, 1331457.3750, 1320797.3750, 1311125.1250, 1310667.5000],
        [1425633.5000, 1410703.8750, 1353357.7500, 1302440.0000, 1282274.5000,
         1276822.3750, 1269809.6250, 1264122.2500, 1256637.5000, 1249978.8750],
        [1447842.3750, 1439871.1250, 1430206.5000, 1422641.5000, 1418003.7500,
         1397568.7500, 1331954.0000, 1305892.7500, 1295201.3750, 1283135.7500],
        [1451532.3750, 1448729.1250, 1438395.7500, 1438065.2500, 1430993.6250,
         1429106.1250, 1407237.1250, 1403675.7500, 1400839.3750, 1395366.0000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1525275.0000,       0.0000],
         [1520521.3750,       0.0000],
         [1501162.3750,       0.0000],
         ...,
         [1488409.5000,       0.0000],
         [1487307.0000,       0.0000],
         [1485740.5000,       0.0000]],

        [[1542477.6250,       0.0000],
         [1532942.5000,       0.0000],
         [1531989.6250,       0.0000],
         ...,
         [1528796.2500,       0.0000],
         [1528571.7500,       0.0000],
         [1527982.8750,       0.0000]],

        [[1137669.5000,       0.0000],
         [1018416.2500,       0.0000],
         [      0.0000, 1003335.0000],
         ...,
         [ 942221.5625,       0.0000],
         [      0.0000,  935059.5000],
         [      0.0000,  934422.1250]],

        ...,

        [[1425633.5000,       0.0000],
         [1410703.8750,       0.0000],
         [1353357.7500,       0.0000],
         ...,
         [1264122.2500,       0.0000],
         [      0.0000, 1256637.5000],
         [1249978.8750,       0.0000]],

        [[1447842.3750,       0.0000],
         [1439871.1250,       0.0000],
         [1430206.5000,       0.0000],
         ...,
         [      0.0000, 1305892.7500],
         [1295201.3750,       0.0000],
         [      0.0000, 1283135.7500]],

        [[      0.0000, 1451532.3750],
         [      0.0000, 1448729.1250],
         [      0.0000, 1438395.7500],
         ...,
         [      0.0000, 1403675.7500],
         [1400839.3750,       0.0000],
         [      0.0000, 1395366.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13491583.0000,  1491101.8750],
        [15314642.0000,        0.0000],
        [ 4060953.2500,  5772987.0000],
        [12785077.0000,  1416888.5000],
        [ 9209797.0000,  3869959.0000],
        [ 9356913.0000,  2227019.0000],
        [ 2984748.5000,  6956668.5000],
        [ 8722388.0000,   868415.9375],
        [12281548.0000,  3049833.0000],
        [12053910.0000,  1392691.2500],
        [15556634.0000,        0.0000],
        [14152468.0000,        0.0000],
        [13664271.0000,        0.0000],
        [15562183.0000,        0.0000],
        [15759086.0000,        0.0000],
        [15708858.0000,        0.0000],
        [13605145.0000,  1521784.8750],
        [11854295.0000,  2979251.5000],
        [14629608.0000,        0.0000],
        [15540007.0000,        0.0000],
        [15525554.0000,        0.0000],
        [11824472.0000,  2933569.0000],
        [15578422.0000,        0.0000],
        [15755497.0000,        0.0000],
        [11837376.0000,  2991603.5000],
        [15672048.0000,        0.0000],
        [15574413.0000,        0.0000],
        [15735648.0000,        0.0000],
        [15778168.0000,        0.0000],
        [15773890.0000,        0.0000],
        [15789404.0000,        0.0000],
        [15774394.0000,        0.0000],
        [ 2929505.5000,  8024327.0000],
        [ 9107927.0000,  6068138.0000],
        [15489627.0000,        0.0000],
        [12198428.0000,  3049015.0000],
        [ 3304135.7500,  8261956.5000],
        [10464648.0000,  4490360.5000],
        [12758363.0000,  1402828.6250],
        [15057643.0000,        0.0000],
        [ 9934606.0000,  2553631.5000],
        [15625178.0000,        0.0000],
        [15559631.0000,        0.0000],
        [13812713.0000,  1538811.6250],
        [ 1293090.8750, 11858469.0000],
        [ 1181945.8750, 10724281.0000],
        [ 5451541.0000,  4850086.5000],
        [ 2645845.7500,  6957305.0000],
        [ 4090148.0000,  9565498.0000],
        [10276926.0000,  4428050.0000],
        [11380700.0000,  2862338.2500],
        [ 1312799.2500, 12301868.0000],
        [ 1379060.8750, 12835458.0000],
        [ 2651690.0000, 10566491.0000],
        [11948050.0000,  2987907.5000],
        [10338603.0000,  4497563.0000],
        [ 2747180.0000, 11117770.0000],
        [ 4004858.5000,  9600405.0000],
        [ 1305459.3750, 12469002.0000],
        [ 2724901.5000, 11467740.0000],
        [10694975.0000,  2713220.7500],
        [10558321.0000,  2533460.0000],
        [ 9851336.0000,  3920982.5000],
        [ 1400839.3750, 12843101.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 361/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:16, 58.46s/it]  7%|▋         | 2/29 [00:59<11:04, 24.62s/it] 10%|█         | 3/29 [01:00<05:58, 13.80s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.72s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 2.853808879852295
Epoch 362/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.88s/it]  7%|▋         | 2/29 [00:58<10:58, 24.38s/it] 10%|█         | 3/29 [00:59<05:55, 13.67s/it] 14%|█▍        | 4/29 [01:01<03:47,  9.08s/it] 17%|█▋        | 5/29 [01:02<02:27,  6.14s/it] 21%|██        | 6/29 [01:03<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.50s/it] 31%|███       | 9/29 [01:06<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.8565444946289062
Epoch 363/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<29:11, 62.55s/it]  7%|▋         | 2/29 [01:03<11:50, 26.30s/it] 10%|█         | 3/29 [01:04<06:22, 14.71s/it] 14%|█▍        | 4/29 [01:05<03:51,  9.27s/it] 17%|█▋        | 5/29 [01:06<02:30,  6.26s/it] 21%|██        | 6/29 [01:07<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:08<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.54s/it] 31%|███       | 9/29 [01:09<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:10<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:16<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:17<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:18<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:19<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:20<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:28<00:00,  1.08it/s]100%|██████████| 29/29 [01:28<00:00,  3.05s/it]
Epoch loss is 2.8441720008850098
Epoch 364/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:44, 57.30s/it]  7%|▋         | 2/29 [00:58<10:51, 24.14s/it] 10%|█         | 3/29 [01:01<06:18, 14.57s/it] 14%|█▍        | 4/29 [01:02<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:03<02:28,  6.20s/it] 21%|██        | 6/29 [01:04<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:06<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:08<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8385813236236572
Epoch 365/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:38, 61.37s/it]  7%|▋         | 2/29 [01:02<11:36, 25.81s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.83882737159729
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0140, 0.0027,  ..., 0.0042, 0.0002, 0.0192],
        [0.0033, 0.0094, 0.0027,  ..., 0.0028, 0.0002, 0.0176],
        [0.0341, 0.0058, 0.0037,  ..., 0.0048, 0.0171, 0.0234],
        ...,
        [0.0071, 0.0079, 0.0205,  ..., 0.0045, 0.0016, 0.0205],
        [0.0046, 0.0081, 0.0142,  ..., 0.0051, 0.0050, 0.0195],
        [0.0092, 0.0045, 0.0049,  ..., 0.0023, 0.0028, 0.0219]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9959, 0.9951, 0.9947, 0.9946, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9971, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9965],
        [0.9759, 0.9684, 0.9682, 0.9680, 0.9672, 0.9664, 0.9661, 0.9636, 0.9631,
         0.9628],
        [0.9924, 0.9920, 0.9919, 0.9919, 0.9916, 0.9909, 0.9907, 0.9905, 0.9898,
         0.9893],
        [0.9891, 0.9871, 0.9868, 0.9857, 0.9853, 0.9850, 0.9849, 0.9844, 0.9843,
         0.9841],
        [0.9850, 0.9848, 0.9809, 0.9773, 0.9765, 0.9742, 0.9740, 0.9736, 0.9735,
         0.9731],
        [0.9804, 0.9701, 0.9699, 0.9685, 0.9675, 0.9671, 0.9671, 0.9651, 0.9642,
         0.9620],
        [0.9764, 0.9720, 0.9697, 0.9685, 0.9588, 0.9583, 0.9563, 0.9561, 0.9552,
         0.9547],
        [0.9976, 0.9971, 0.9969, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9937, 0.9896, 0.9884, 0.9881, 0.9872, 0.9862, 0.9854, 0.9850, 0.9846,
         0.9845],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9940, 0.9934, 0.9915, 0.9906, 0.9903, 0.9903, 0.9902, 0.9901, 0.9900,
         0.9894],
        [0.9926, 0.9903, 0.9900, 0.9895, 0.9883, 0.9880, 0.9864, 0.9859, 0.9850,
         0.9843],
        [0.9985, 0.9983, 0.9983, 0.9981, 0.9978, 0.9975, 0.9975, 0.9973, 0.9973,
         0.9972],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9988, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9983,
         0.9983],
        [0.9962, 0.9961, 0.9961, 0.9957, 0.9957, 0.9955, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9953, 0.9945, 0.9944, 0.9944, 0.9944, 0.9943, 0.9941, 0.9940, 0.9939,
         0.9938],
        [0.9944, 0.9938, 0.9936, 0.9934, 0.9933, 0.9933, 0.9932, 0.9931, 0.9929,
         0.9929],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9980, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9973],
        [0.9952, 0.9948, 0.9945, 0.9943, 0.9940, 0.9937, 0.9937, 0.9937, 0.9929,
         0.9928],
        [0.9987, 0.9986, 0.9982, 0.9982, 0.9982, 0.9979, 0.9979, 0.9977, 0.9976,
         0.9974],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9950, 0.9949, 0.9948, 0.9946, 0.9944, 0.9943, 0.9942, 0.9939, 0.9939,
         0.9938],
        [0.9989, 0.9988, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983, 0.9983,
         0.9982],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9889, 0.9875, 0.9779, 0.9734, 0.9702, 0.9701, 0.9696, 0.9693, 0.9659,
         0.9629],
        [0.9964, 0.9962, 0.9961, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9967, 0.9965, 0.9965, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9960],
        [0.9865, 0.9848, 0.9811, 0.9766, 0.9757, 0.9754, 0.9739, 0.9720, 0.9710,
         0.9705],
        [0.9952, 0.9951, 0.9950, 0.9949, 0.9948, 0.9946, 0.9946, 0.9946, 0.9945,
         0.9944],
        [0.9930, 0.9919, 0.9916, 0.9913, 0.9911, 0.9911, 0.9908, 0.9906, 0.9904,
         0.9903],
        [0.9957, 0.9955, 0.9955, 0.9955, 0.9953, 0.9952, 0.9950, 0.9950, 0.9950,
         0.9950],
        [0.9861, 0.9857, 0.9854, 0.9851, 0.9831, 0.9831, 0.9816, 0.9815, 0.9813,
         0.9806],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9979],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9972, 0.9970, 0.9970, 0.9968, 0.9967, 0.9967, 0.9967, 0.9965, 0.9965,
         0.9964],
        [0.9897, 0.9878, 0.9878, 0.9865, 0.9856, 0.9848, 0.9842, 0.9839, 0.9834,
         0.9833],
        [0.9867, 0.9797, 0.9779, 0.9778, 0.9778, 0.9777, 0.9776, 0.9774, 0.9771,
         0.9768],
        [0.9876, 0.9876, 0.9742, 0.9735, 0.9647, 0.9613, 0.9606, 0.9606, 0.9602,
         0.9589],
        [0.9732, 0.9693, 0.9684, 0.9659, 0.9657, 0.9651, 0.9640, 0.9622, 0.9620,
         0.9555],
        [0.9908, 0.9892, 0.9891, 0.9890, 0.9884, 0.9879, 0.9873, 0.9869, 0.9866,
         0.9865],
        [0.9941, 0.9940, 0.9939, 0.9938, 0.9936, 0.9931, 0.9931, 0.9930, 0.9929,
         0.9925],
        [0.9929, 0.9917, 0.9917, 0.9916, 0.9915, 0.9911, 0.9905, 0.9905, 0.9902,
         0.9902],
        [0.9909, 0.9903, 0.9895, 0.9895, 0.9894, 0.9894, 0.9863, 0.9862, 0.9858,
         0.9857],
        [0.9936, 0.9931, 0.9928, 0.9928, 0.9922, 0.9921, 0.9908, 0.9902, 0.9898,
         0.9897],
        [0.9906, 0.9881, 0.9868, 0.9865, 0.9864, 0.9860, 0.9852, 0.9849, 0.9848,
         0.9838],
        [0.9950, 0.9950, 0.9950, 0.9950, 0.9948, 0.9948, 0.9944, 0.9944, 0.9941,
         0.9941],
        [0.9956, 0.9950, 0.9950, 0.9945, 0.9944, 0.9937, 0.9936, 0.9933, 0.9932,
         0.9929],
        [0.9946, 0.9909, 0.9904, 0.9901, 0.9897, 0.9895, 0.9892, 0.9891, 0.9877,
         0.9874],
        [0.9921, 0.9915, 0.9911, 0.9899, 0.9886, 0.9874, 0.9872, 0.9860, 0.9853,
         0.9852],
        [0.9920, 0.9920, 0.9917, 0.9907, 0.9891, 0.9889, 0.9886, 0.9880, 0.9876,
         0.9854],
        [0.9967, 0.9940, 0.9932, 0.9924, 0.9923, 0.9913, 0.9888, 0.9887, 0.9882,
         0.9878],
        [0.9906, 0.9888, 0.9877, 0.9876, 0.9874, 0.9871, 0.9870, 0.9865, 0.9864,
         0.9861],
        [0.9919, 0.9915, 0.9878, 0.9858, 0.9846, 0.9839, 0.9836, 0.9835, 0.9829,
         0.9825],
        [0.9926, 0.9921, 0.9917, 0.9914, 0.9912, 0.9898, 0.9862, 0.9850, 0.9849,
         0.9836],
        [0.9928, 0.9926, 0.9924, 0.9922, 0.9920, 0.9917, 0.9913, 0.9908, 0.9899,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],
        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 1, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515758.1250, 1509589.6250, 1492843.5000, 1482892.3750, 1481567.8750,
         1477490.1250, 1477436.6250, 1476115.6250, 1476111.3750, 1474338.7500],
        [1535359.5000, 1529287.6250, 1528824.0000, 1525645.8750, 1524164.0000,
         1523972.2500, 1523270.3750, 1522114.3750, 1521478.7500, 1521239.2500],
        [1134042.7500, 1018676.5625, 1016323.4375, 1012572.6250, 1001557.7500,
          990139.5000,  986492.8750,  951533.3750,  944057.3125,  941251.6250],
        [1436320.3750, 1427369.5000, 1426030.6250, 1425159.1250, 1418792.3750,
         1404330.5000, 1402102.3750, 1396870.5000, 1382554.5000, 1372772.8750],
        [1369182.6250, 1330260.5000, 1325708.8750, 1304451.3750, 1296819.2500,
         1292048.1250, 1289014.2500, 1280273.0000, 1279408.8750, 1275542.0000],
        [1291275.7500, 1288218.0000, 1217395.3750, 1157874.1250, 1143361.2500,
         1106248.1250, 1104056.0000, 1097036.5000, 1096423.6250, 1089110.8750],
        [1208925.3750, 1043398.8125, 1040388.1250, 1020588.3125, 1005267.8125,
          999754.1875,  999578.7500,  972589.0000,  960135.6250,  930194.2500],
        [1142782.3750, 1072469.1250, 1037556.3750, 1020356.6875,  888050.5625,
          881465.8125,  857442.8125,  854711.8750,  843512.8750,  837650.4375],
        [1547037.1250, 1534646.5000, 1531441.7500, 1524896.7500, 1524825.5000,
         1522830.2500, 1521780.5000, 1521185.6250, 1520635.8750, 1519889.2500],
        [1462584.7500, 1378821.5000, 1355535.5000, 1350343.3750, 1333059.5000,
         1313793.7500, 1298559.3750, 1292343.8750, 1283966.8750, 1282940.0000],
        [1555858.1250, 1555628.2500, 1550929.5000, 1550054.1250, 1549177.7500,
         1548801.1250, 1548615.0000, 1548579.6250, 1547681.8750, 1545659.6250],
        [1468309.3750, 1456830.0000, 1416804.7500, 1398322.0000, 1393225.1250,
         1392393.6250, 1390646.0000, 1389349.5000, 1388174.7500, 1374968.8750],
        [1438854.0000, 1393961.5000, 1387669.1250, 1376728.3750, 1353344.7500,
         1347816.6250, 1317809.2500, 1308800.2500, 1292225.5000, 1279640.7500],
        [1566115.1250, 1561639.3750, 1560836.8750, 1557877.5000, 1551642.6250,
         1545090.7500, 1544491.1250, 1540672.2500, 1540039.0000, 1538390.5000],
        [1576106.0000, 1575858.0000, 1574722.1250, 1573958.0000, 1573540.7500,
         1573495.7500, 1572507.1250, 1572277.7500, 1572084.2500, 1572016.8750],
        [1573161.1250, 1569606.3750, 1569045.2500, 1568783.5000, 1566995.1250,
         1566791.8750, 1566397.3750, 1565819.5000, 1562437.8750, 1562396.1250],
        [1515596.2500, 1513692.3750, 1513320.0000, 1505130.3750, 1504675.3750,
         1501305.6250, 1500242.2500, 1499697.1250, 1499140.8750, 1497920.3750],
        [1495693.5000, 1480418.2500, 1477972.2500, 1477876.3750, 1476918.1250,
         1476083.1250, 1469968.1250, 1469608.0000, 1466007.6250, 1465574.2500],
        [1478004.6250, 1464487.2500, 1459803.5000, 1455749.3750, 1454961.1250,
         1453643.5000, 1451443.7500, 1450563.7500, 1446334.1250, 1445772.7500],
        [1553523.1250, 1552909.7500, 1549733.3750, 1547436.8750, 1547231.7500,
         1547197.8750, 1546795.1250, 1545846.8750, 1545757.0000, 1544128.8750],
        [1554980.1250, 1549495.3750, 1547986.0000, 1547038.5000, 1547007.5000,
         1546365.8750, 1543868.2500, 1543707.7500, 1543045.5000, 1540138.8750],
        [1494158.1250, 1485355.2500, 1478818.0000, 1474677.5000, 1468963.3750,
         1463081.5000, 1462630.8750, 1462582.0000, 1445636.3750, 1444321.6250],
        [1570749.1250, 1569168.0000, 1559645.0000, 1558978.7500, 1558821.2500,
         1553163.0000, 1552395.8750, 1548003.6250, 1545535.7500, 1542780.6250],
        [1577816.0000, 1574728.1250, 1574543.5000, 1572826.6250, 1572648.1250,
         1572453.1250, 1571901.3750, 1571790.5000, 1569935.8750, 1569867.0000],
        [1490608.5000, 1487715.6250, 1486300.3750, 1481603.2500, 1477787.5000,
         1475990.3750, 1472217.1250, 1467196.5000, 1466494.1250, 1465642.6250],
        [1576229.1250, 1572621.1250, 1567022.0000, 1565859.7500, 1564441.7500,
         1564228.3750, 1562928.1250, 1561836.0000, 1561095.8750, 1560214.7500],
        [1564482.0000, 1561943.2500, 1559283.5000, 1558262.2500, 1556771.1250,
         1553248.8750, 1553077.2500, 1552085.1250, 1551195.7500, 1550006.8750],
        [1575045.1250, 1573678.8750, 1573584.3750, 1572991.6250, 1572916.6250,
         1570849.3750, 1570804.5000, 1569432.8750, 1568535.1250, 1568206.0000],
        [1577913.7500, 1577519.5000, 1577275.7500, 1576106.0000, 1575456.7500,
         1574696.6250, 1574597.5000, 1574417.3750, 1573390.7500, 1572751.6250],
        [1579711.5000, 1579478.0000, 1575172.8750, 1574940.0000, 1574519.5000,
         1574021.0000, 1573750.8750, 1573461.1250, 1573189.6250, 1571612.1250],
        [1580059.6250, 1579601.5000, 1577272.7500, 1577057.7500, 1576893.8750,
         1576057.8750, 1575225.5000, 1574629.1250, 1574405.3750, 1574283.7500],
        [1579682.8750, 1578119.8750, 1575867.0000, 1575003.0000, 1574860.3750,
         1574249.2500, 1573887.3750, 1573597.8750, 1573096.6250, 1573002.1250],
        [1365613.5000, 1337858.5000, 1167807.1250, 1094680.8750, 1045816.6875,
         1044384.3750, 1036582.1250, 1032551.7500,  982611.2500,  941416.8125],
        [1519124.1250, 1516388.5000, 1512833.7500, 1510532.8750, 1509159.2500,
         1507679.0000, 1506126.8750, 1505701.7500, 1504997.0000, 1502010.2500],
        [1551515.2500, 1549068.5000, 1545733.3750, 1545583.0000, 1544781.3750,
         1543646.0000, 1543646.0000, 1543336.8750, 1543111.6250, 1542989.5000],
        [1526988.0000, 1523279.0000, 1521782.0000, 1518550.6250, 1515058.5000,
         1514834.7500, 1513672.2500, 1512926.1250, 1512790.5000, 1512070.6250],
        [1318855.2500, 1288238.8750, 1221309.5000, 1145422.8750, 1130553.7500,
         1125842.2500, 1102943.5000, 1073128.1250, 1057147.0000, 1050050.1250],
        [1494627.0000, 1491174.3750, 1491023.7500, 1486996.5000, 1485491.2500,
         1481247.2500, 1480969.0000, 1480508.5000, 1480229.0000, 1478275.2500],
        [1448987.5000, 1426451.0000, 1418678.6250, 1413158.5000, 1409306.6250,
         1409235.5000, 1402492.8750, 1399821.7500, 1395949.0000, 1393492.2500],
        [1505411.7500, 1501384.3750, 1501384.3750, 1500850.3750, 1496919.3750,
         1494943.3750, 1490600.0000, 1490465.0000, 1489826.8750, 1489564.0000],
        [1312856.8750, 1304322.0000, 1299276.6250, 1294098.8750, 1256755.0000,
         1256750.2500, 1230424.8750, 1228851.0000, 1224488.7500, 1212581.0000],
        [1563578.1250, 1560774.3750, 1559713.5000, 1558907.3750, 1558320.2500,
         1556760.6250, 1556475.6250, 1555181.8750, 1554391.5000, 1553086.0000],
        [1557014.5000, 1555543.7500, 1553291.8750, 1550080.7500, 1547444.2500,
         1546340.8750, 1546082.7500, 1545481.2500, 1545353.1250, 1544025.7500],
        [1537938.7500, 1533245.1250, 1532460.1250, 1529254.1250, 1527363.7500,
         1526204.7500, 1525670.6250, 1521562.8750, 1521332.2500, 1520531.5000],
        [1381924.3750, 1344677.6250, 1343791.6250, 1318963.3750, 1302903.3750,
         1287064.8750, 1276811.3750, 1270917.0000, 1262368.1250, 1260754.8750],
        [1322746.1250, 1196672.3750, 1166571.5000, 1165771.8750, 1164770.6250,
         1163008.0000, 1162109.8750, 1159554.8750, 1153604.1250, 1149653.7500],
        [1340578.8750, 1340043.2500, 1106274.6250, 1096343.1250,  966183.3125,
          920662.8125,  911578.3125,  911152.4375,  906587.2500,  889237.9375],
        [1091668.0000, 1031458.2500, 1019241.1875,  983742.0625,  981065.3125,
          972133.6875,  957344.2500,  933106.8125,  929620.5000,  847299.7500],
        [1404007.7500, 1371242.1250, 1369160.5000, 1368340.7500, 1356109.6250,
         1347178.0000, 1334133.0000, 1327951.1250, 1320919.6250, 1320468.6250],
        [1470628.6250, 1468721.0000, 1466681.6250, 1464414.6250, 1459675.3750,
         1450854.2500, 1449816.8750, 1447421.3750, 1446847.2500, 1437812.8750],
        [1446044.3750, 1422335.0000, 1421654.1250, 1419110.3750, 1417214.2500,
         1409083.6250, 1397339.6250, 1397307.6250, 1391449.8750, 1390913.8750],
        [1404598.3750, 1394027.8750, 1378369.2500, 1377982.7500, 1375424.0000,
         1375138.0000, 1315167.6250, 1313625.7500, 1307012.8750, 1305325.0000],
        [1460788.0000, 1450902.6250, 1444006.2500, 1443536.6250, 1432281.1250,
         1429483.7500, 1403843.1250, 1391680.7500, 1383867.0000, 1381402.6250],
        [1400102.1250, 1349435.8750, 1326041.3750, 1319184.8750, 1317330.5000,
         1310317.7500, 1294770.3750, 1290441.0000, 1288057.0000, 1270434.7500],
        [1491049.2500, 1490186.5000, 1490095.5000, 1490095.5000, 1486751.1250,
         1486063.6250, 1477187.2500, 1476711.2500, 1471234.6250, 1470139.2500],
        [1503788.8750, 1490740.7500, 1489777.2500, 1479300.5000, 1476588.7500,
         1462978.2500, 1460568.0000, 1454112.1250, 1452622.2500, 1446878.8750],
        [1481668.2500, 1405698.6250, 1394932.3750, 1388960.0000, 1381129.8750,
         1378198.3750, 1372410.2500, 1370529.5000, 1342761.7500, 1335975.3750],
        [1429186.6250, 1417919.8750, 1409457.2500, 1385402.7500, 1359617.6250,
         1336342.3750, 1333124.3750, 1310162.6250, 1297680.3750, 1294465.5000],
        [1428028.5000, 1427259.2500, 1420518.5000, 1401033.1250, 1370181.8750,
         1365457.1250, 1359762.8750, 1347625.1250, 1341431.8750, 1299726.5000],
        [1526389.6250, 1468673.5000, 1451290.1250, 1434665.3750, 1433595.7500,
         1413823.1250, 1362925.3750, 1360965.5000, 1352297.1250, 1345276.5000],
        [1399065.1250, 1363947.5000, 1341996.1250, 1339962.7500, 1337089.3750,
         1331860.0000, 1329246.0000, 1320118.6250, 1318088.2500, 1311267.7500],
        [1426399.2500, 1418272.8750, 1344346.7500, 1305793.0000, 1284217.8750,
         1272248.5000, 1265574.6250, 1263635.3750, 1253469.2500, 1245722.0000],
        [1439641.8750, 1430397.5000, 1420528.0000, 1414559.5000, 1411477.6250,
         1384022.7500, 1313236.2500, 1291851.0000, 1289972.2500, 1266358.1250],
        [1443677.1250, 1439580.1250, 1436134.1250, 1431887.8750, 1427116.3750,
         1422268.5000, 1413836.6250, 1402660.1250, 1386018.5000, 1385737.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515758.1250,       0.0000],
         [1509589.6250,       0.0000],
         [1492843.5000,       0.0000],
         ...,
         [1476115.6250,       0.0000],
         [1476111.3750,       0.0000],
         [1474338.7500,       0.0000]],

        [[1535359.5000,       0.0000],
         [1529287.6250,       0.0000],
         [1528824.0000,       0.0000],
         ...,
         [1522114.3750,       0.0000],
         [1521478.7500,       0.0000],
         [1521239.2500,       0.0000]],

        [[1134042.7500,       0.0000],
         [      0.0000, 1018676.5625],
         [      0.0000, 1016323.4375],
         ...,
         [ 951533.3750,       0.0000],
         [      0.0000,  944057.3125],
         [ 941251.6250,       0.0000]],

        ...,

        [[1426399.2500,       0.0000],
         [1418272.8750,       0.0000],
         [1344346.7500,       0.0000],
         ...,
         [1263635.3750,       0.0000],
         [      0.0000, 1253469.2500],
         [1245722.0000,       0.0000]],

        [[1439641.8750,       0.0000],
         [1430397.5000,       0.0000],
         [1420528.0000,       0.0000],
         ...,
         [      0.0000, 1291851.0000],
         [1289972.2500,       0.0000],
         [      0.0000, 1266358.1250]],

        [[      0.0000, 1443677.1250],
         [      0.0000, 1439580.1250],
         [      0.0000, 1436134.1250],
         ...,
         [      0.0000, 1402660.1250],
         [1386018.5000,       0.0000],
         [      0.0000, 1385737.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13386708.0000,  1477436.6250],
        [15255356.0000,        0.0000],
        [ 4028385.5000,  5968262.0000],
        [12695432.0000,  1396870.5000],
        [11745890.0000,  1296819.2500],
        [ 9351215.0000,  2239785.0000],
        [ 3975604.5000,  6205216.0000],
        [ 8578556.0000,   857442.8125],
        [13749280.0000,  1519889.2500],
        [11973127.0000,  1378821.5000],
        [15500986.0000,        0.0000],
        [14069024.0000,        0.0000],
        [13496850.0000,        0.0000],
        [15506796.0000,        0.0000],
        [15736567.0000,        0.0000],
        [15671433.0000,        0.0000],
        [13535124.0000,  1515596.2500],
        [13260426.0000,  1495693.5000],
        [14560764.0000,        0.0000],
        [15480560.0000,        0.0000],
        [15463633.0000,        0.0000],
        [13201406.0000,  1478818.0000],
        [15559242.0000,        0.0000],
        [15728510.0000,        0.0000],
        [11793232.0000,  2978324.0000],
        [15656477.0000,        0.0000],
        [15560356.0000,        0.0000],
        [15716044.0000,        0.0000],
        [15754124.0000,        0.0000],
        [15749857.0000,        0.0000],
        [15765487.0000,        0.0000],
        [15751367.0000,        0.0000],
        [ 3018353.0000,  8030970.0000],
        [10561930.0000,  4532623.0000],
        [13910422.0000,  1542989.5000],
        [12141331.0000,  3030621.2500],
        [ 3256117.5000,  8257374.0000],
        [10383644.0000,  4466898.0000],
        [12721624.0000,  1395949.0000],
        [13470884.0000,  1490465.0000],
        [10059334.0000,  2561072.2500],
        [15577189.0000,        0.0000],
        [15490658.0000,        0.0000],
        [13749359.0000,  1526204.7500],
        [ 2547819.7500, 10502357.0000],
        [ 1162109.8750, 10642353.0000],
        [ 5505402.0000,  4883239.5000],
        [ 2737750.7500,  7008929.0000],
        [ 4044919.0000,  9474592.0000],
        [10167796.0000,  4395078.0000],
        [11275494.0000,  2836958.2500],
        [ 1305325.0000, 12241346.0000],
        [ 1381402.6250, 12840390.0000],
        [ 2645226.2500, 10520889.0000],
        [11853264.0000,  2976250.0000],
        [10246236.0000,  4471118.0000],
        [ 2751659.5000, 11100605.0000],
        [ 3990422.5000,  9582938.0000],
        [       0.0000, 13761025.0000],
        [ 2708202.0000, 11441700.0000],
        [10675488.0000,  2717153.5000],
        [10553962.0000,  2525717.7500],
        [ 9790600.0000,  3871445.5000],
        [ 1386018.5000, 12802898.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 366/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:11, 60.41s/it]  7%|▋         | 2/29 [01:01<11:26, 25.42s/it] 10%|█         | 3/29 [01:02<06:10, 14.23s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.8479435443878174
Epoch 367/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:40, 59.30s/it]  7%|▋         | 2/29 [01:00<11:13, 24.96s/it] 10%|█         | 3/29 [01:01<06:08, 14.18s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.8487439155578613
Epoch 368/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:37, 61.35s/it]  7%|▋         | 2/29 [01:02<11:36, 25.80s/it] 10%|█         | 3/29 [01:03<06:15, 14.44s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.849762439727783
Epoch 369/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:30, 58.95s/it]  7%|▋         | 2/29 [01:00<11:19, 25.16s/it] 10%|█         | 3/29 [01:01<06:06, 14.09s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.847998857498169
Epoch 370/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:28, 58.89s/it]  7%|▋         | 2/29 [00:59<11:09, 24.79s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.84148907661438
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0135, 0.0023,  ..., 0.0040, 0.0001, 0.0193],
        [0.0029, 0.0093, 0.0025,  ..., 0.0027, 0.0002, 0.0175],
        [0.0334, 0.0059, 0.0039,  ..., 0.0050, 0.0165, 0.0234],
        ...,
        [0.0069, 0.0078, 0.0198,  ..., 0.0044, 0.0016, 0.0204],
        [0.0043, 0.0080, 0.0132,  ..., 0.0048, 0.0047, 0.0196],
        [0.0088, 0.0044, 0.0046,  ..., 0.0023, 0.0027, 0.0218]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9962, 0.9953, 0.9952, 0.9950, 0.9948, 0.9947, 0.9947, 0.9946,
         0.9945],
        [0.9972, 0.9969, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9965],
        [0.9756, 0.9682, 0.9672, 0.9671, 0.9668, 0.9659, 0.9650, 0.9632, 0.9632,
         0.9629],
        [0.9930, 0.9924, 0.9922, 0.9922, 0.9921, 0.9914, 0.9912, 0.9911, 0.9903,
         0.9900],
        [0.9890, 0.9869, 0.9868, 0.9856, 0.9853, 0.9852, 0.9849, 0.9846, 0.9845,
         0.9844],
        [0.9849, 0.9844, 0.9806, 0.9777, 0.9776, 0.9748, 0.9745, 0.9740, 0.9739,
         0.9729],
        [0.9788, 0.9711, 0.9693, 0.9675, 0.9675, 0.9663, 0.9650, 0.9633, 0.9613,
         0.9610],
        [0.9761, 0.9726, 0.9698, 0.9673, 0.9588, 0.9584, 0.9557, 0.9557, 0.9540,
         0.9534],
        [0.9977, 0.9971, 0.9971, 0.9968, 0.9967, 0.9967, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9938, 0.9899, 0.9888, 0.9880, 0.9874, 0.9867, 0.9867, 0.9855, 0.9846,
         0.9842],
        [0.9981, 0.9981, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9941, 0.9932, 0.9916, 0.9909, 0.9908, 0.9906, 0.9904, 0.9900, 0.9899,
         0.9897],
        [0.9928, 0.9909, 0.9905, 0.9897, 0.9884, 0.9879, 0.9860, 0.9854, 0.9854,
         0.9848],
        [0.9985, 0.9983, 0.9983, 0.9982, 0.9979, 0.9977, 0.9976, 0.9974, 0.9974,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9986, 0.9984,
         0.9984],
        [0.9963, 0.9962, 0.9961, 0.9958, 0.9958, 0.9956, 0.9956, 0.9956, 0.9956,
         0.9955],
        [0.9955, 0.9949, 0.9947, 0.9946, 0.9945, 0.9944, 0.9943, 0.9943, 0.9941,
         0.9941],
        [0.9946, 0.9939, 0.9937, 0.9937, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932,
         0.9931],
        [0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9974],
        [0.9953, 0.9948, 0.9944, 0.9944, 0.9943, 0.9942, 0.9938, 0.9935, 0.9931,
         0.9929],
        [0.9987, 0.9987, 0.9983, 0.9982, 0.9982, 0.9980, 0.9979, 0.9977, 0.9976,
         0.9975],
        [0.9991, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9953, 0.9952, 0.9949, 0.9947, 0.9945, 0.9943, 0.9942, 0.9942, 0.9941,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9983],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9888, 0.9872, 0.9781, 0.9735, 0.9695, 0.9689, 0.9684, 0.9684, 0.9659,
         0.9613],
        [0.9965, 0.9964, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9968, 0.9967, 0.9966, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9860, 0.9845, 0.9806, 0.9764, 0.9757, 0.9750, 0.9731, 0.9720, 0.9708,
         0.9707],
        [0.9955, 0.9953, 0.9952, 0.9951, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9932, 0.9924, 0.9918, 0.9915, 0.9915, 0.9914, 0.9912, 0.9907, 0.9906,
         0.9906],
        [0.9959, 0.9958, 0.9957, 0.9957, 0.9955, 0.9955, 0.9953, 0.9952, 0.9952,
         0.9952],
        [0.9857, 0.9855, 0.9851, 0.9847, 0.9831, 0.9829, 0.9814, 0.9811, 0.9809,
         0.9800],
        [0.9984, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9980],
        [0.9982, 0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9973, 0.9971, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9966, 0.9966,
         0.9966],
        [0.9900, 0.9879, 0.9879, 0.9865, 0.9859, 0.9849, 0.9845, 0.9839, 0.9836,
         0.9833],
        [0.9861, 0.9793, 0.9789, 0.9783, 0.9783, 0.9778, 0.9777, 0.9777, 0.9776,
         0.9775],
        [0.9876, 0.9872, 0.9736, 0.9729, 0.9640, 0.9602, 0.9595, 0.9594, 0.9589,
         0.9570],
        [0.9732, 0.9697, 0.9681, 0.9659, 0.9656, 0.9650, 0.9625, 0.9620, 0.9611,
         0.9540],
        [0.9913, 0.9895, 0.9895, 0.9888, 0.9888, 0.9885, 0.9875, 0.9871, 0.9868,
         0.9868],
        [0.9943, 0.9942, 0.9941, 0.9940, 0.9938, 0.9934, 0.9933, 0.9933, 0.9933,
         0.9928],
        [0.9926, 0.9919, 0.9918, 0.9917, 0.9915, 0.9909, 0.9909, 0.9908, 0.9906,
         0.9905],
        [0.9910, 0.9905, 0.9897, 0.9896, 0.9896, 0.9895, 0.9864, 0.9863, 0.9860,
         0.9859],
        [0.9935, 0.9931, 0.9928, 0.9927, 0.9921, 0.9920, 0.9909, 0.9903, 0.9900,
         0.9896],
        [0.9907, 0.9881, 0.9872, 0.9863, 0.9863, 0.9859, 0.9852, 0.9850, 0.9847,
         0.9839],
        [0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9949, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9957, 0.9952, 0.9952, 0.9948, 0.9946, 0.9939, 0.9938, 0.9936, 0.9933,
         0.9933],
        [0.9946, 0.9909, 0.9903, 0.9901, 0.9896, 0.9896, 0.9892, 0.9890, 0.9877,
         0.9875],
        [0.9920, 0.9915, 0.9910, 0.9899, 0.9885, 0.9874, 0.9870, 0.9860, 0.9852,
         0.9851],
        [0.9921, 0.9919, 0.9916, 0.9906, 0.9890, 0.9889, 0.9886, 0.9882, 0.9876,
         0.9854],
        [0.9967, 0.9941, 0.9933, 0.9924, 0.9924, 0.9914, 0.9887, 0.9886, 0.9881,
         0.9880],
        [0.9904, 0.9887, 0.9878, 0.9877, 0.9877, 0.9874, 0.9873, 0.9866, 0.9865,
         0.9859],
        [0.9921, 0.9916, 0.9882, 0.9859, 0.9848, 0.9840, 0.9838, 0.9837, 0.9832,
         0.9829],
        [0.9926, 0.9923, 0.9919, 0.9914, 0.9914, 0.9900, 0.9864, 0.9854, 0.9851,
         0.9840],
        [0.9929, 0.9927, 0.9924, 0.9923, 0.9921, 0.9918, 0.9912, 0.9908, 0.9901,
         0.9899]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 0, 1],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1519861.7500, 1515989.3750, 1496718.1250, 1493267.8750, 1489321.1250,
         1485283.0000, 1484263.3750, 1482725.5000, 1481211.8750, 1478775.7500],
        [1538588.6250, 1530355.6250, 1529785.1250, 1527446.7500, 1526874.3750,
         1525794.2500, 1525650.3750, 1525647.2500, 1524306.5000, 1523300.7500],
        [1129527.7500, 1016133.5000, 1002052.6875,  999863.8125,  996601.3125,
          982740.6250,  970757.9375,  945944.5000,  945433.1250,  942188.3125],
        [1447529.1250, 1435026.6250, 1431625.6250, 1431461.8750, 1428905.7500,
         1414799.6250, 1411940.8750, 1408542.1250, 1393775.3750, 1386833.0000],
        [1368527.2500, 1327587.7500, 1325344.8750, 1302986.7500, 1296725.3750,
         1295454.6250, 1290614.6250, 1283969.3750, 1282793.1250, 1281007.1250],
        [1289308.2500, 1280536.7500, 1212332.3750, 1164308.6250, 1162410.3750,
         1117278.0000, 1111874.0000, 1103669.6250, 1101710.5000, 1086231.3750],
        [1181588.7500, 1059006.6250, 1031851.8125, 1006556.1250, 1006346.9375,
          988489.3750,  970829.2500,  947043.9375,  920650.5000,  916362.6875],
        [1137506.7500, 1081402.3750, 1039439.0625, 1002456.0000,  888905.5625,
          883438.4375,  849866.8125,  849336.0625,  830047.4375,  822794.1875],
        [1547999.2500, 1535661.2500, 1534305.6250, 1527882.3750, 1526207.6250,
         1526198.8750, 1522505.0000, 1520914.3750, 1520897.0000, 1520863.6250],
        [1464691.2500, 1385520.3750, 1363260.8750, 1348013.3750, 1336903.1250,
         1323476.7500, 1322676.8750, 1301434.5000, 1284614.8750, 1276236.7500],
        [1557317.5000, 1557198.7500, 1554289.2500, 1552003.7500, 1551253.3750,
         1551034.5000, 1550746.1250, 1550336.5000, 1550252.2500, 1548330.0000],
        [1470467.3750, 1451280.5000, 1419705.8750, 1404385.3750, 1403153.8750,
         1399956.5000, 1395420.5000, 1388165.5000, 1385450.2500, 1380541.2500],
        [1443452.7500, 1405921.2500, 1397590.1250, 1382323.7500, 1356136.7500,
         1347148.3750, 1310800.1250, 1298826.8750, 1298451.6250, 1288621.0000],
        [1566452.7500, 1562363.3750, 1561553.0000, 1558923.7500, 1554101.0000,
         1548428.8750, 1546591.5000, 1541836.2500, 1541587.8750, 1540832.3750],
        [1577075.7500, 1576800.5000, 1575315.5000, 1575042.1250, 1574965.5000,
         1574418.8750, 1573540.7500, 1573348.7500, 1573305.1250, 1572984.1250],
        [1574584.0000, 1571366.3750, 1570539.3750, 1570454.0000, 1569175.3750,
         1568602.3750, 1568384.0000, 1568282.2500, 1564758.1250, 1564155.3750],
        [1517231.7500, 1515534.1250, 1513790.5000, 1507673.2500, 1506289.2500,
         1503715.7500, 1503619.7500, 1503033.2500, 1502990.2500, 1500954.7500],
        [1500924.7500, 1487010.6250, 1484011.5000, 1480560.7500, 1479383.7500,
         1478331.6250, 1476088.7500, 1476036.7500, 1471251.3750, 1471164.5000],
        [1481026.8750, 1465821.6250, 1462319.8750, 1461967.1250, 1455320.5000,
         1454916.6250, 1454181.5000, 1452868.8750, 1451634.8750, 1450209.6250],
        [1556586.8750, 1555825.6250, 1551485.6250, 1551003.5000, 1550789.0000,
         1550173.8750, 1549059.6250, 1548660.7500, 1548517.5000, 1548439.2500],
        [1557369.5000, 1551163.1250, 1550506.5000, 1550459.2500, 1550132.5000,
         1548838.0000, 1546541.3750, 1546205.1250, 1545765.8750, 1541815.7500],
        [1497436.2500, 1484843.8750, 1478293.5000, 1477021.0000, 1474849.1250,
         1473517.8750, 1464350.3750, 1458286.7500, 1449873.6250, 1444938.8750],
        [1571807.0000, 1571116.0000, 1560847.3750, 1560052.5000, 1560036.1250,
         1554926.6250, 1553918.6250, 1549662.5000, 1546658.0000, 1545062.8750],
        [1578859.0000, 1575646.0000, 1575105.1250, 1574169.6250, 1574136.6250,
         1574028.5000, 1573114.6250, 1572987.1250, 1571851.8750, 1570816.5000],
        [1495415.5000, 1493216.5000, 1486942.6250, 1484359.7500, 1478668.6250,
         1474995.5000, 1473943.7500, 1472884.1250, 1471645.7500, 1466007.6250],
        [1576982.5000, 1573255.6250, 1568050.5000, 1566696.2500, 1565616.3750,
         1565046.1250, 1564061.3750, 1562819.3750, 1562257.5000, 1561801.7500],
        [1565467.1250, 1563203.8750, 1560211.7500, 1558904.3750, 1558394.5000,
         1554458.1250, 1553794.2500, 1553726.0000, 1552535.1250, 1551963.6250],
        [1576310.5000, 1574908.3750, 1574890.5000, 1574375.3750, 1574124.6250,
         1572561.1250, 1572310.7500, 1571313.8750, 1570528.8750, 1570099.1250],
        [1578886.1250, 1578655.7500, 1578211.6250, 1576827.6250, 1576421.6250,
         1576217.2500, 1575599.3750, 1575440.2500, 1574328.7500, 1573909.8750],
        [1580691.1250, 1580312.7500, 1576550.8750, 1575918.0000, 1575262.8750,
         1575242.0000, 1574956.5000, 1574914.5000, 1574379.8750, 1572639.2500],
        [1581365.0000, 1580113.7500, 1578484.1250, 1578249.3750, 1578147.0000,
         1577349.5000, 1575948.1250, 1575408.7500, 1575205.8750, 1575168.2500],
        [1580561.3750, 1579039.7500, 1576884.7500, 1576104.3750, 1575764.7500,
         1575228.3750, 1574789.8750, 1574746.2500, 1574298.7500, 1573985.0000],
        [1364192.0000, 1332904.5000, 1170507.6250, 1096387.0000, 1035379.7500,
         1026569.2500, 1019586.2500, 1018727.0625,  983234.6250,  920470.5000],
        [1521979.5000, 1520770.7500, 1515675.7500, 1513200.1250, 1512826.5000,
         1511548.7500, 1508917.5000, 1507668.8750, 1507595.5000, 1505799.3750],
        [1551836.5000, 1550578.8750, 1548691.7500, 1547268.7500, 1546551.7500,
         1546292.1250, 1546292.1250, 1544338.0000, 1544033.1250, 1543918.3750],
        [1529582.2500, 1526414.3750, 1524316.6250, 1520972.5000, 1520287.8750,
         1517762.8750, 1517501.0000, 1517459.0000, 1515587.6250, 1515120.7500],
        [1310638.8750, 1282559.5000, 1213107.2500, 1141601.6250, 1130892.3750,
         1120288.8750, 1089067.2500, 1072055.0000, 1054965.5000, 1053044.6250],
        [1500936.1250, 1496446.8750, 1493772.0000, 1491951.1250, 1488949.1250,
         1488111.5000, 1487823.3750, 1487146.7500, 1486222.3750, 1485914.8750],
        [1452116.6250, 1435270.2500, 1423256.3750, 1417731.8750, 1417034.5000,
         1414323.5000, 1410834.3750, 1401686.6250, 1400098.1250, 1398771.5000],
        [1508890.1250, 1506483.1250, 1504831.8750, 1504831.8750, 1501500.3750,
         1501378.6250, 1496589.6250, 1494047.0000, 1493904.5000, 1493645.2500],
        [1305160.6250, 1301712.5000, 1294003.8750, 1285480.0000, 1257840.1250,
         1252923.1250, 1227116.6250, 1222027.2500, 1218165.3750, 1201998.8750],
        [1565123.6250, 1563212.8750, 1561801.7500, 1560911.2500, 1559746.1250,
         1559416.0000, 1558093.0000, 1556777.0000, 1556733.8750, 1555300.5000],
        [1559013.0000, 1557657.6250, 1555819.6250, 1552918.7500, 1549771.8750,
         1549621.0000, 1548641.5000, 1548640.1250, 1548272.3750, 1546849.6250],
        [1540115.3750, 1535328.7500, 1533751.1250, 1531386.3750, 1531360.0000,
         1530027.2500, 1529452.5000, 1524797.8750, 1523681.5000, 1523428.6250],
        [1386640.0000, 1347080.2500, 1345816.7500, 1320122.3750, 1308062.8750,
         1289706.6250, 1281558.1250, 1270921.7500, 1265475.7500, 1259858.2500],
        [1311258.8750, 1191250.1250, 1183350.0000, 1174046.0000, 1173178.5000,
         1165888.6250, 1163923.3750, 1162983.6250, 1162178.6250, 1160371.2500],
        [1339882.2500, 1333603.7500, 1097165.1250, 1087282.2500,  957344.2500,
          906572.5000,  897371.1250,  895417.7500,  889343.9375,  865687.2500],
        [1090998.7500, 1038765.1875, 1015022.6250,  982635.6250,  978725.3750,
          971082.8750,  936339.0625,  930179.1875,  917764.6875,  828971.5625],
        [1413723.3750, 1377947.3750, 1376573.5000, 1363993.0000, 1363831.6250,
         1358795.7500, 1339193.7500, 1331405.3750, 1326031.3750, 1325218.5000],
        [1474700.1250, 1473859.2500, 1471731.3750, 1468873.7500, 1465612.0000,
         1456709.1250, 1454976.3750, 1454840.5000, 1454736.3750, 1444181.1250],
        [1440637.6250, 1425350.8750, 1422976.7500, 1421269.1250, 1417745.5000,
         1405505.6250, 1404599.7500, 1402530.3750, 1399353.2500, 1398156.7500],
        [1407909.6250, 1396550.8750, 1382165.5000, 1380058.1250, 1379084.5000,
         1376715.2500, 1317515.1250, 1315044.7500, 1309751.6250, 1307748.3750],
        [1459221.6250, 1449438.1250, 1443900.1250, 1442372.5000, 1430216.0000,
         1427837.8750, 1404902.5000, 1392413.5000, 1387215.2500, 1378649.2500],
        [1401994.1250, 1350388.5000, 1333116.7500, 1316541.7500, 1316461.3750,
         1307684.7500, 1295930.3750, 1291450.6250, 1285807.3750, 1270680.6250],
        [1493508.5000, 1493508.5000, 1492835.0000, 1491540.0000, 1489905.0000,
         1487188.0000, 1479201.7500, 1478524.7500, 1476671.7500, 1476576.0000],
        [1505736.2500, 1494397.5000, 1494002.8750, 1484691.0000, 1480662.5000,
         1467410.6250, 1464142.3750, 1460094.5000, 1454320.2500, 1453450.8750],
        [1481625.8750, 1406064.7500, 1393597.2500, 1389887.5000, 1379477.8750,
         1379155.5000, 1370647.1250, 1368275.5000, 1342487.7500, 1338426.3750],
        [1428269.5000, 1416865.5000, 1407826.3750, 1386273.7500, 1357022.8750,
         1335812.2500, 1329706.3750, 1310192.6250, 1295944.0000, 1293594.1250],
        [1428537.8750, 1425353.6250, 1418516.2500, 1398380.7500, 1368255.8750,
         1364830.8750, 1359351.7500, 1351717.0000, 1339665.1250, 1298603.8750],
        [1526851.0000, 1471767.8750, 1453625.5000, 1435912.2500, 1434973.1250,
         1414896.7500, 1362387.3750, 1359954.7500, 1350105.2500, 1349114.1250],
        [1395465.8750, 1361573.0000, 1344296.7500, 1342405.7500, 1341591.8750,
         1337419.6250, 1335170.2500, 1322064.0000, 1318779.7500, 1308913.8750],
        [1429513.7500, 1418736.8750, 1352344.8750, 1307769.6250, 1288131.8750,
         1273045.8750, 1269402.7500, 1267363.3750, 1258047.7500, 1252782.1250],
        [1440706.3750, 1434439.5000, 1424728.3750, 1415389.3750, 1415324.6250,
         1387812.1250, 1317697.3750, 1299125.3750, 1293994.0000, 1273139.3750],
        [1445721.7500, 1442049.2500, 1435539.8750, 1434467.0000, 1429902.2500,
         1424136.1250, 1411321.5000, 1403310.3750, 1388598.3750, 1384643.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1519861.7500,       0.0000],
         [1515989.3750,       0.0000],
         [1496718.1250,       0.0000],
         ...,
         [      0.0000, 1482725.5000],
         [1481211.8750,       0.0000],
         [1478775.7500,       0.0000]],

        [[1538588.6250,       0.0000],
         [1530355.6250,       0.0000],
         [1529785.1250,       0.0000],
         ...,
         [1525647.2500,       0.0000],
         [1524306.5000,       0.0000],
         [1523300.7500,       0.0000]],

        [[1129527.7500,       0.0000],
         [      0.0000, 1016133.5000],
         [1002052.6875,       0.0000],
         ...,
         [ 945944.5000,       0.0000],
         [ 945433.1250,       0.0000],
         [ 942188.3125,       0.0000]],

        ...,

        [[1429513.7500,       0.0000],
         [1418736.8750,       0.0000],
         [1352344.8750,       0.0000],
         ...,
         [1267363.3750,       0.0000],
         [      0.0000, 1258047.7500],
         [1252782.1250,       0.0000]],

        [[1440706.3750,       0.0000],
         [1434439.5000,       0.0000],
         [1424728.3750,       0.0000],
         ...,
         [      0.0000, 1299125.3750],
         [1293994.0000,       0.0000],
         [1273139.3750,       0.0000]],

        [[      0.0000, 1445721.7500],
         [      0.0000, 1442049.2500],
         [      0.0000, 1435539.8750],
         ...,
         [      0.0000, 1403310.3750],
         [1388598.3750,       0.0000],
         [      0.0000, 1384643.2500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13444692.0000,  1482725.5000],
        [15277750.0000,        0.0000],
        [ 4965146.5000,  4966097.5000],
        [12778500.0000,  1411940.8750],
        [ 9192794.0000,  3862217.0000],
        [10465352.0000,  1164308.6250],
        [ 4916361.0000,  5112365.0000],
        [ 8535326.0000,   849866.8125],
        [13762520.0000,  1520914.3750],
        [12021309.0000,  1385520.3750],
        [15522762.0000,        0.0000],
        [14098527.0000,        0.0000],
        [13529272.0000,        0.0000],
        [15522670.0000,        0.0000],
        [15746797.0000,        0.0000],
        [15690302.0000,        0.0000],
        [13557602.0000,  1517231.7500],
        [13303840.0000,  1500924.7500],
        [14590268.0000,        0.0000],
        [15510541.0000,        0.0000],
        [15488798.0000,        0.0000],
        [13225118.0000,  1478293.5000],
        [15574087.0000,        0.0000],
        [15740715.0000,        0.0000],
        [11809448.0000,  2988632.0000],
        [15666588.0000,        0.0000],
        [15572658.0000,        0.0000],
        [15731422.0000,        0.0000],
        [15764499.0000,        0.0000],
        [15760868.0000,        0.0000],
        [15775440.0000,        0.0000],
        [15761402.0000,        0.0000],
        [ 2966626.0000,  8001332.5000],
        [ 9078917.0000,  6047065.5000],
        [13925464.0000,  1544338.0000],
        [12166269.0000,  3038735.5000],
        [ 3247309.5000,  8220911.0000],
        [10423669.0000,  4483605.5000],
        [12771026.0000,  1400098.1250],
        [13512056.0000,  1494047.0000],
        [10006876.0000,  2559552.5000],
        [15597116.0000,        0.0000],
        [15517206.0000,        0.0000],
        [13771944.0000,  1531386.3750],
        [ 2549565.0000, 10525678.0000],
        [ 1163923.3750, 10684506.0000],
        [ 5411737.0000,  4857933.0000],
        [ 2683075.2500,  7007409.0000],
        [ 4066598.0000,  9510115.0000],
        [10209018.0000,  4411202.5000],
        [12697488.0000,  1440637.6250],
        [ 1307748.3750, 12264795.0000],
        [ 1378649.2500, 12837518.0000],
        [ 2649578.0000, 10520478.0000],
        [11880731.0000,  2978728.0000],
        [10278112.0000,  4480796.0000],
        [ 2747753.5000, 11101892.0000],
        [ 5276267.5000,  8285240.0000],
        [ 1298603.8750, 12454610.0000],
        [ 2711501.5000, 11448086.0000],
        [10693435.0000,  2714245.5000],
        [10586045.0000,  2531093.5000],
        [11085533.0000,  2616822.7500],
        [ 1388598.3750, 12811092.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 371/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:49, 61.77s/it]  7%|▋         | 2/29 [01:02<11:41, 25.97s/it] 10%|█         | 3/29 [01:03<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.16s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.8328938484191895
Epoch 372/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.99s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8331313133239746
Epoch 373/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:08, 58.15s/it]  7%|▋         | 2/29 [01:01<11:37, 25.84s/it] 10%|█         | 3/29 [01:02<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.838937282562256
Epoch 374/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:48, 59.60s/it]  7%|▋         | 2/29 [01:00<11:17, 25.09s/it] 10%|█         | 3/29 [01:01<06:05, 14.05s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8293251991271973
Epoch 375/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:06, 58.10s/it]  7%|▋         | 2/29 [01:01<11:41, 25.96s/it] 10%|█         | 3/29 [01:02<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.16s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.19s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8311469554901123
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0136, 0.0024,  ..., 0.0041, 0.0001, 0.0196],
        [0.0031, 0.0094, 0.0025,  ..., 0.0028, 0.0002, 0.0179],
        [0.0327, 0.0061, 0.0038,  ..., 0.0051, 0.0162, 0.0236],
        ...,
        [0.0072, 0.0078, 0.0199,  ..., 0.0045, 0.0017, 0.0203],
        [0.0045, 0.0080, 0.0134,  ..., 0.0050, 0.0049, 0.0197],
        [0.0092, 0.0044, 0.0046,  ..., 0.0023, 0.0026, 0.0220]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9961, 0.9953, 0.9951, 0.9949, 0.9949, 0.9947, 0.9946, 0.9945,
         0.9944],
        [0.9972, 0.9968, 0.9968, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9753, 0.9687, 0.9673, 0.9659, 0.9649, 0.9647, 0.9646, 0.9634, 0.9627,
         0.9625],
        [0.9931, 0.9925, 0.9924, 0.9923, 0.9921, 0.9915, 0.9913, 0.9911, 0.9904,
         0.9900],
        [0.9892, 0.9872, 0.9871, 0.9860, 0.9852, 0.9851, 0.9849, 0.9848, 0.9847,
         0.9847],
        [0.9851, 0.9846, 0.9810, 0.9781, 0.9775, 0.9755, 0.9750, 0.9748, 0.9737,
         0.9734],
        [0.9785, 0.9704, 0.9698, 0.9685, 0.9673, 0.9659, 0.9646, 0.9639, 0.9628,
         0.9617],
        [0.9763, 0.9723, 0.9700, 0.9674, 0.9595, 0.9589, 0.9569, 0.9561, 0.9536,
         0.9534],
        [0.9976, 0.9971, 0.9969, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9939, 0.9901, 0.9891, 0.9883, 0.9878, 0.9870, 0.9869, 0.9862, 0.9847,
         0.9847],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9942, 0.9936, 0.9918, 0.9909, 0.9909, 0.9908, 0.9905, 0.9904, 0.9902,
         0.9902],
        [0.9929, 0.9911, 0.9906, 0.9903, 0.9889, 0.9883, 0.9870, 0.9860, 0.9855,
         0.9852],
        [0.9985, 0.9983, 0.9982, 0.9981, 0.9979, 0.9976, 0.9976, 0.9973, 0.9973,
         0.9973],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9962, 0.9962, 0.9960, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955,
         0.9955],
        [0.9955, 0.9949, 0.9946, 0.9945, 0.9945, 0.9944, 0.9944, 0.9943, 0.9941,
         0.9940],
        [0.9944, 0.9937, 0.9935, 0.9935, 0.9933, 0.9933, 0.9932, 0.9931, 0.9931,
         0.9930],
        [0.9980, 0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9973],
        [0.9954, 0.9948, 0.9945, 0.9943, 0.9942, 0.9940, 0.9938, 0.9936, 0.9930,
         0.9929],
        [0.9987, 0.9987, 0.9982, 0.9982, 0.9982, 0.9979, 0.9979, 0.9978, 0.9976,
         0.9975],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9953, 0.9951, 0.9949, 0.9948, 0.9946, 0.9944, 0.9943, 0.9943, 0.9942,
         0.9939],
        [0.9990, 0.9988, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983,
         0.9982],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9887, 0.9872, 0.9778, 0.9730, 0.9699, 0.9696, 0.9692, 0.9664, 0.9664,
         0.9633],
        [0.9964, 0.9964, 0.9961, 0.9960, 0.9959, 0.9958, 0.9958, 0.9958, 0.9957,
         0.9957],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9968, 0.9967, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9859, 0.9845, 0.9807, 0.9767, 0.9749, 0.9744, 0.9731, 0.9711, 0.9699,
         0.9696],
        [0.9954, 0.9953, 0.9952, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9934, 0.9927, 0.9921, 0.9919, 0.9917, 0.9913, 0.9913, 0.9911, 0.9909,
         0.9908],
        [0.9958, 0.9956, 0.9955, 0.9955, 0.9955, 0.9955, 0.9953, 0.9951, 0.9951,
         0.9950],
        [0.9857, 0.9854, 0.9850, 0.9849, 0.9828, 0.9826, 0.9814, 0.9811, 0.9809,
         0.9801],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9979],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9975],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9967, 0.9965, 0.9964,
         0.9964],
        [0.9898, 0.9876, 0.9874, 0.9863, 0.9857, 0.9847, 0.9843, 0.9838, 0.9830,
         0.9829],
        [0.9861, 0.9789, 0.9788, 0.9785, 0.9785, 0.9778, 0.9775, 0.9774, 0.9774,
         0.9773],
        [0.9877, 0.9877, 0.9739, 0.9739, 0.9640, 0.9602, 0.9596, 0.9595, 0.9594,
         0.9579],
        [0.9736, 0.9700, 0.9683, 0.9661, 0.9653, 0.9642, 0.9627, 0.9626, 0.9613,
         0.9547],
        [0.9914, 0.9893, 0.9892, 0.9887, 0.9887, 0.9884, 0.9875, 0.9869, 0.9866,
         0.9866],
        [0.9942, 0.9940, 0.9940, 0.9939, 0.9936, 0.9933, 0.9932, 0.9931, 0.9931,
         0.9927],
        [0.9925, 0.9918, 0.9915, 0.9915, 0.9913, 0.9906, 0.9905, 0.9904, 0.9904,
         0.9900],
        [0.9909, 0.9904, 0.9896, 0.9896, 0.9895, 0.9894, 0.9863, 0.9863, 0.9858,
         0.9857],
        [0.9937, 0.9931, 0.9930, 0.9927, 0.9921, 0.9920, 0.9909, 0.9902, 0.9898,
         0.9897],
        [0.9908, 0.9881, 0.9870, 0.9863, 0.9862, 0.9860, 0.9852, 0.9850, 0.9845,
         0.9838],
        [0.9950, 0.9950, 0.9950, 0.9950, 0.9949, 0.9947, 0.9943, 0.9943, 0.9942,
         0.9941],
        [0.9956, 0.9951, 0.9949, 0.9946, 0.9944, 0.9936, 0.9935, 0.9933, 0.9931,
         0.9929],
        [0.9946, 0.9910, 0.9904, 0.9900, 0.9897, 0.9894, 0.9892, 0.9892, 0.9878,
         0.9875],
        [0.9920, 0.9914, 0.9910, 0.9900, 0.9884, 0.9875, 0.9870, 0.9860, 0.9854,
         0.9853],
        [0.9920, 0.9920, 0.9917, 0.9909, 0.9890, 0.9888, 0.9885, 0.9881, 0.9874,
         0.9853],
        [0.9967, 0.9941, 0.9932, 0.9925, 0.9925, 0.9913, 0.9888, 0.9888, 0.9884,
         0.9878],
        [0.9902, 0.9889, 0.9878, 0.9877, 0.9875, 0.9873, 0.9873, 0.9866, 0.9865,
         0.9860],
        [0.9920, 0.9915, 0.9881, 0.9856, 0.9847, 0.9837, 0.9836, 0.9834, 0.9828,
         0.9826],
        [0.9925, 0.9922, 0.9917, 0.9913, 0.9912, 0.9898, 0.9858, 0.9852, 0.9850,
         0.9837],
        [0.9927, 0.9925, 0.9922, 0.9922, 0.9920, 0.9917, 0.9912, 0.9908, 0.9898,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1519279.1250, 1514014.3750, 1495658.0000, 1492324.0000, 1487897.2500,
         1487370.8750, 1484280.5000, 1482373.5000, 1479383.7500, 1477550.8750],
        [1537620.5000, 1529497.7500, 1529385.3750, 1525362.1250, 1524985.5000,
         1524257.1250, 1523813.7500, 1523280.5000, 1522464.2500, 1522436.6250],
        [1124168.6250, 1023868.7500, 1002664.4375,  983620.1250,  969334.1875,
          966839.5625,  964983.4375,  949062.8750,  939451.7500,  936738.3125],
        [1450014.6250, 1436799.8750, 1435664.5000, 1432809.8750, 1430086.3750,
         1416799.2500, 1413182.8750, 1409599.7500, 1395288.8750, 1387657.2500],
        [1372110.6250, 1332708.6250, 1331481.5000, 1309655.5000, 1294543.2500,
         1294328.5000, 1290548.2500, 1288182.3750, 1287008.5000, 1285328.0000],
        [1294358.1250, 1284668.7500, 1220727.3750, 1170217.3750, 1160200.7500,
         1127056.1250, 1119270.1250, 1116987.1250, 1098830.1250, 1093672.8750],
        [1177402.0000, 1048894.1250, 1039947.6875, 1020918.3750, 1002903.5625,
          983681.9375,  965754.9375,  954970.6250,  940006.5000,  925936.2500],
        [1140345.8750, 1076905.0000, 1041989.8125, 1005195.0000,  897318.9375,
          889105.6875,  864022.0000,  854884.6875,  824390.3125,  822714.1875],
        [1547442.8750, 1534779.8750, 1532052.5000, 1526760.8750, 1526321.1250,
         1524811.0000, 1521650.0000, 1521313.3750, 1521110.2500, 1520737.5000],
        [1467157.2500, 1390164.6250, 1368979.0000, 1354203.2500, 1344559.6250,
         1329416.0000, 1327180.1250, 1313315.1250, 1286982.7500, 1285621.0000],
        [1556330.1250, 1556261.8750, 1552775.0000, 1551456.2500, 1549956.5000,
         1549137.8750, 1549046.3750, 1549034.3750, 1548716.8750, 1547485.5000],
        [1472409.3750, 1460275.3750, 1423359.5000, 1405276.3750, 1405264.2500,
         1403224.6250, 1397808.6250, 1395300.8750, 1391787.0000, 1391771.0000],
        [1445317.7500, 1409919.7500, 1398756.7500, 1392417.6250, 1365593.8750,
         1354314.3750, 1329590.8750, 1310806.2500, 1301778.3750, 1295795.7500],
        [1565470.1250, 1560813.0000, 1559540.8750, 1557032.3750, 1552669.8750,
         1546831.8750, 1545925.0000, 1540344.6250, 1539577.8750, 1539388.5000],
        [1576193.1250, 1575841.5000, 1574941.5000, 1574276.2500, 1573707.3750,
         1573591.7500, 1572952.6250, 1572777.1250, 1572312.1250, 1572177.2500],
        [1574072.1250, 1570151.5000, 1570105.1250, 1569697.7500, 1568267.3750,
         1567276.1250, 1566950.3750, 1566325.7500, 1564070.2500, 1563071.2500],
        [1515996.6250, 1515029.7500, 1512473.1250, 1508124.8750, 1505065.8750,
         1504275.1250, 1503616.8750, 1501466.0000, 1500761.6250, 1500340.8750],
        [1500754.5000, 1487907.1250, 1481918.3750, 1480442.2500, 1478712.3750,
         1477016.7500, 1476632.3750, 1474476.5000, 1471623.2500, 1469403.3750],
        [1476871.7500, 1462485.8750, 1458663.6250, 1458396.6250, 1455201.1250,
         1454059.5000, 1452875.7500, 1450202.6250, 1449335.8750, 1447671.2500],
        [1555129.8750, 1553625.2500, 1549674.2500, 1549671.3750, 1549593.0000,
         1548926.6250, 1547594.7500, 1547487.1250, 1546972.1250, 1545733.3750],
        [1555698.0000, 1550589.3750, 1549897.5000, 1549601.7500, 1548787.7500,
         1547931.3750, 1545964.8750, 1544669.3750, 1543989.0000, 1540500.2500],
        [1498416.1250, 1486118.8750, 1479262.3750, 1474617.1250, 1473225.5000,
         1469598.1250, 1465677.6250, 1460606.8750, 1448249.7500, 1445401.8750],
        [1571027.6250, 1570530.3750, 1560302.5000, 1559764.0000, 1559384.7500,
         1554101.0000, 1552667.0000, 1549729.0000, 1546046.0000, 1543199.8750],
        [1578038.6250, 1575470.2500, 1574746.2500, 1573441.6250, 1573420.7500,
         1573179.1250, 1572196.7500, 1571952.2500, 1571408.2500, 1570131.8750],
        [1495622.2500, 1493024.3750, 1487083.0000, 1486572.5000, 1481170.8750,
         1476694.2500, 1474754.8750, 1474434.3750, 1472853.2500, 1466576.6250],
        [1576511.8750, 1573003.6250, 1567451.0000, 1566389.8750, 1564874.5000,
         1564534.2500, 1564191.1250, 1562060.8750, 1561590.2500, 1560403.7500],
        [1564728.2500, 1562880.5000, 1559380.3750, 1558091.5000, 1557469.0000,
         1553729.0000, 1552721.7500, 1552551.3750, 1552042.1250, 1550938.3750],
        [1575516.8750, 1574545.0000, 1573689.3750, 1573662.3750, 1573161.1250,
         1571988.2500, 1571658.5000, 1570844.8750, 1570087.0000, 1569648.5000],
        [1577873.0000, 1577833.8750, 1577682.0000, 1576005.2500, 1575553.0000,
         1575205.8750, 1574710.2500, 1573925.0000, 1573540.7500, 1573368.2500],
        [1580311.2500, 1579560.7500, 1575966.2500, 1575354.6250, 1574590.1250,
         1574573.6250, 1574123.1250, 1573949.0000, 1573573.7500, 1571929.8750],
        [1580415.1250, 1579530.7500, 1577683.5000, 1577614.2500, 1577396.2500,
         1576644.1250, 1575378.6250, 1574621.6250, 1574507.5000, 1574477.5000],
        [1579582.0000, 1578299.0000, 1576278.7500, 1575483.8750, 1574979.1250,
         1574696.6250, 1574202.7500, 1573931.0000, 1573817.0000, 1573177.6250],
        [1362241.8750, 1332741.8750, 1165910.8750, 1088597.8750, 1040840.6250,
         1036746.2500, 1030839.7500,  990034.6875,  989736.3750,  946823.6250],
        [1520012.5000, 1519615.3750, 1512732.7500, 1512347.5000, 1509393.7500,
         1507710.6250, 1507650.2500, 1506335.1250, 1504224.8750, 1504055.6250],
        [1551044.8750, 1550478.5000, 1548446.6250, 1546537.0000, 1545988.5000,
         1544993.5000, 1544993.5000, 1543853.5000, 1543830.0000, 1543182.2500],
        [1528533.8750, 1525689.5000, 1523287.7500, 1520218.3750, 1517171.1250,
         1517097.2500, 1516800.7500, 1515746.5000, 1514564.5000, 1514072.1250],
        [1308851.3750, 1281766.0000, 1214343.5000, 1146976.1250, 1117513.5000,
         1109759.5000, 1090107.5000, 1059439.0000, 1040556.8125, 1036908.4375],
        [1499329.6250, 1497172.0000, 1493242.2500, 1490216.2500, 1489762.8750,
         1488886.6250, 1488188.2500, 1487189.2500, 1485819.8750, 1485598.8750],
        [1456248.0000, 1441077.2500, 1429396.5000, 1424602.0000, 1421230.0000,
         1414194.0000, 1413332.3750, 1408692.6250, 1404516.6250, 1404179.2500],
        [1507571.1250, 1503860.6250, 1501563.3750, 1501563.3750, 1500353.7500,
         1499698.6250, 1497276.2500, 1492746.6250, 1492632.7500, 1491003.7500],
        [1305301.2500, 1299313.8750, 1291786.8750, 1289937.8750, 1250917.3750,
         1247578.0000, 1226419.3750, 1221130.2500, 1218207.1250, 1204950.8750],
        [1564031.5000, 1561877.6250, 1560420.1250, 1559542.3750, 1558391.6250,
         1558038.0000, 1556741.3750, 1555325.6250, 1554520.3750, 1553663.7500],
        [1558455.6250, 1555901.2500, 1554118.6250, 1551200.2500, 1548350.6250,
         1548019.8750, 1547695.1250, 1547600.7500, 1547456.1250, 1545267.6250],
        [1538233.6250, 1532292.0000, 1531462.2500, 1528551.2500, 1528029.5000,
         1527276.2500, 1527187.3750, 1521979.5000, 1520170.5000, 1520018.2500],
        [1384265.7500, 1341263.1250, 1336791.0000, 1315284.2500, 1303843.2500,
         1286898.0000, 1279518.7500, 1268788.0000, 1255299.6250, 1253127.3750],
        [1311850.6250, 1184393.2500, 1181924.5000, 1176865.3750, 1176415.3750,
         1165076.1250, 1160907.0000, 1159223.1250, 1158373.2500, 1157350.8750],
        [1343097.2500, 1342296.8750, 1102827.8750, 1101457.2500,  956392.4375,
          905841.3750,  898653.1875,  897668.1250,  895930.3125,  877076.1250],
        [1097869.6250, 1042310.8125, 1017925.9375,  986440.1250,  974606.6250,
          959111.5625,  939009.2500,  938480.1875,  920824.3750,  837954.1250],
        [1416113.1250, 1373210.2500, 1372047.7500, 1362577.1250, 1360864.2500,
         1355249.8750, 1337890.3750, 1328132.2500, 1322024.8750, 1321308.8750],
        [1472064.0000, 1469767.6250, 1468585.1250, 1467418.8750, 1460594.3750,
         1453816.8750, 1452916.0000, 1449938.6250, 1449500.2500, 1441592.7500],
        [1437934.8750, 1423060.8750, 1418258.0000, 1418060.5000, 1412811.0000,
         1398487.3750, 1397696.7500, 1395014.7500, 1394903.0000, 1387072.5000],
        [1405397.0000, 1395267.5000, 1379718.6250, 1378746.6250, 1377111.7500,
         1374647.6250, 1316035.8750, 1315589.1250, 1306670.1250, 1305220.3750],
        [1461737.0000, 1450093.5000, 1447132.8750, 1441907.6250, 1430480.6250,
         1427703.0000, 1404306.3750, 1392133.3750, 1384125.7500, 1380737.3750],
        [1403135.0000, 1349361.2500, 1328456.6250, 1316317.1250, 1314049.3750,
         1309404.5000, 1294870.3750, 1291709.2500, 1282214.6250, 1270336.5000],
        [1489845.3750, 1489551.3750, 1489551.3750, 1489447.6250, 1486871.6250,
         1484666.8750, 1476048.0000, 1475357.0000, 1473329.5000, 1471972.8750],
        [1503684.2500, 1491650.8750, 1487342.5000, 1481415.3750, 1477989.0000,
         1460556.8750, 1458752.7500, 1454156.6250, 1450635.6250, 1446938.3750],
        [1481549.5000, 1408031.7500, 1395588.3750, 1387878.2500, 1381018.0000,
         1375519.6250, 1372115.8750, 1371431.6250, 1344044.1250, 1338561.7500],
        [1426788.3750, 1415660.7500, 1407655.8750, 1387084.3750, 1355676.5000,
         1338080.5000, 1328701.0000, 1310630.1250, 1299295.1250, 1296966.5000],
        [1427211.6250, 1426622.3750, 1421173.0000, 1404865.0000, 1367620.5000,
         1363887.6250, 1358518.5000, 1350714.3750, 1336918.3750, 1297747.1250],
        [1526287.7500, 1470707.1250, 1453105.7500, 1437934.8750, 1437449.6250,
         1413840.6250, 1362859.1250, 1362770.7500, 1356303.6250, 1343996.7500],
        [1391897.1250, 1364962.3750, 1344158.2500, 1342489.0000, 1338727.6250,
         1335730.7500, 1334022.2500, 1321376.8750, 1319913.3750, 1310447.6250],
        [1428008.0000, 1417341.2500, 1349740.8750, 1303010.3750, 1286543.3750,
         1267937.6250, 1266198.7500, 1262595.7500, 1252297.1250, 1247462.5000],
        [1437771.7500, 1432300.3750, 1420904.7500, 1413819.1250, 1411352.5000,
         1383186.2500, 1306778.5000, 1294839.6250, 1291720.3750, 1268289.5000],
        [1442467.3750, 1437700.5000, 1432376.7500, 1431849.6250, 1426950.3750,
         1420881.6250, 1411924.6250, 1402896.8750, 1383446.0000, 1380083.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1519279.1250,       0.0000],
         [1514014.3750,       0.0000],
         [1495658.0000,       0.0000],
         ...,
         [1482373.5000,       0.0000],
         [      0.0000, 1479383.7500],
         [1477550.8750,       0.0000]],

        [[1537620.5000,       0.0000],
         [1529497.7500,       0.0000],
         [1529385.3750,       0.0000],
         ...,
         [1523280.5000,       0.0000],
         [1522464.2500,       0.0000],
         [1522436.6250,       0.0000]],

        [[1124168.6250,       0.0000],
         [      0.0000, 1023868.7500],
         [1002664.4375,       0.0000],
         ...,
         [      0.0000,  949062.8750],
         [ 939451.7500,       0.0000],
         [ 936738.3125,       0.0000]],

        ...,

        [[1428008.0000,       0.0000],
         [1417341.2500,       0.0000],
         [1349740.8750,       0.0000],
         ...,
         [1262595.7500,       0.0000],
         [      0.0000, 1252297.1250],
         [1247462.5000,       0.0000]],

        [[1437771.7500,       0.0000],
         [1432300.3750,       0.0000],
         [1420904.7500,       0.0000],
         ...,
         [      0.0000, 1294839.6250],
         [1291720.3750,       0.0000],
         [      0.0000, 1268289.5000]],

        [[      0.0000, 1442467.3750],
         [      0.0000, 1437700.5000],
         [      0.0000, 1432376.7500],
         ...,
         [      0.0000, 1402896.8750],
         [      0.0000, 1383446.0000],
         [1380083.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13440748.0000,  1479383.7500],
        [15263104.0000,        0.0000],
        [ 4003023.2500,  5857709.0000],
        [12798304.0000,  1409599.7500],
        [ 9215690.0000,  3870204.7500],
        [10515771.0000,  1170217.3750],
        [ 4957688.0000,  5102728.0000],
        [ 8561987.0000,   854884.6875],
        [13755869.0000,  1521110.2500],
        [12077414.0000,  1390164.6250],
        [15510200.0000,        0.0000],
        [14146477.0000,        0.0000],
        [13604292.0000,        0.0000],
        [15507595.0000,        0.0000],
        [15738770.0000,        0.0000],
        [15679988.0000,        0.0000],
        [13551155.0000,  1515996.6250],
        [13298133.0000,  1500754.5000],
        [14565765.0000,        0.0000],
        [15494408.0000,        0.0000],
        [15477629.0000,        0.0000],
        [13221912.0000,  1479262.3750],
        [15566753.0000,        0.0000],
        [15733987.0000,        0.0000],
        [11820140.0000,  2988646.5000],
        [15661012.0000,        0.0000],
        [15564533.0000,        0.0000],
        [15724802.0000,        0.0000],
        [15755697.0000,        0.0000],
        [15753934.0000,        0.0000],
        [15768270.0000,        0.0000],
        [15754447.0000,        0.0000],
        [ 3024410.5000,  7960103.0000],
        [ 9063194.0000,  6040884.0000],
        [12376313.0000,  3087035.7500],
        [12155866.0000,  3037315.5000],
        [ 3206107.0000,  8200115.0000],
        [10420018.0000,  4485388.0000],
        [14217468.0000,        0.0000],
        [13495638.0000,  1492632.7500],
        [10005312.0000,  2550231.2500],
        [15582552.0000,        0.0000],
        [15504066.0000,        0.0000],
        [13747171.0000,  1528029.5000],
        [ 2540025.5000, 10485053.0000],
        [ 1165076.1250, 10667303.0000],
        [ 5431561.5000,  4889679.0000],
        [ 2697787.7500,  7016745.0000],
        [ 4055933.5000,  9493485.0000],
        [10187248.0000,  4398947.0000],
        [11258292.0000,  2825007.5000],
        [ 1305220.3750, 12249184.0000],
        [ 1380737.3750, 12839620.0000],
        [ 2644773.7500, 10515080.0000],
        [11852128.0000,  2974512.2500],
        [10239798.0000,  4473324.0000],
        [ 2752449.5000, 11103289.0000],
        [ 5280639.0000,  8285900.0000],
        [       0.0000, 13755278.0000],
        [ 2706767.5000, 11458489.0000],
        [10691914.0000,  2711810.5000],
        [10560900.0000,  2520234.7500],
        [ 9791055.0000,  3869907.5000],
        [ 1380083.1250, 12790494.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 376/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:44, 59.46s/it]  7%|▋         | 2/29 [01:00<11:15, 25.03s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.831984519958496
Epoch 377/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:26, 56.68s/it]  7%|▋         | 2/29 [00:58<10:52, 24.15s/it] 10%|█         | 3/29 [00:58<05:52, 13.54s/it] 14%|█▍        | 4/29 [00:59<03:34,  8.56s/it] 17%|█▋        | 5/29 [01:01<02:25,  6.05s/it] 21%|██        | 6/29 [01:02<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.47s/it] 31%|███       | 9/29 [01:05<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 2.8402743339538574
Epoch 378/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.48s/it]  7%|▋         | 2/29 [01:00<11:15, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.830845832824707
Epoch 379/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:38, 57.10s/it]  7%|▋         | 2/29 [00:58<10:49, 24.06s/it] 10%|█         | 3/29 [00:59<05:55, 13.66s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.63s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.8264365196228027
Epoch 380/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:37, 57.07s/it]  7%|▋         | 2/29 [01:00<11:21, 25.23s/it] 10%|█         | 3/29 [01:00<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:01<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:02<02:24,  6.03s/it] 21%|██        | 6/29 [01:03<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.828240156173706
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0135, 0.0022,  ..., 0.0040, 0.0001, 0.0195],
        [0.0028, 0.0093, 0.0023,  ..., 0.0025, 0.0002, 0.0174],
        [0.0331, 0.0064, 0.0041,  ..., 0.0055, 0.0161, 0.0235],
        ...,
        [0.0070, 0.0079, 0.0198,  ..., 0.0045, 0.0017, 0.0203],
        [0.0042, 0.0080, 0.0131,  ..., 0.0047, 0.0048, 0.0199],
        [0.0089, 0.0044, 0.0045,  ..., 0.0025, 0.0025, 0.0220]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9963, 0.9953, 0.9953, 0.9950, 0.9949, 0.9948, 0.9948, 0.9947,
         0.9945],
        [0.9974, 0.9969, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9755, 0.9679, 0.9677, 0.9661, 0.9659, 0.9649, 0.9637, 0.9636, 0.9626,
         0.9621],
        [0.9929, 0.9922, 0.9921, 0.9919, 0.9917, 0.9912, 0.9910, 0.9905, 0.9900,
         0.9895],
        [0.9885, 0.9868, 0.9866, 0.9850, 0.9849, 0.9847, 0.9845, 0.9843, 0.9842,
         0.9837],
        [0.9844, 0.9837, 0.9800, 0.9772, 0.9767, 0.9741, 0.9739, 0.9729, 0.9724,
         0.9722],
        [0.9785, 0.9690, 0.9682, 0.9676, 0.9664, 0.9658, 0.9648, 0.9632, 0.9614,
         0.9600],
        [0.9759, 0.9726, 0.9693, 0.9684, 0.9599, 0.9580, 0.9570, 0.9557, 0.9554,
         0.9553],
        [0.9977, 0.9971, 0.9970, 0.9968, 0.9967, 0.9967, 0.9964, 0.9964, 0.9964,
         0.9964],
        [0.9937, 0.9898, 0.9884, 0.9881, 0.9865, 0.9860, 0.9859, 0.9848, 0.9837,
         0.9832],
        [0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9941, 0.9931, 0.9914, 0.9913, 0.9910, 0.9905, 0.9903, 0.9901, 0.9900,
         0.9894],
        [0.9926, 0.9908, 0.9902, 0.9893, 0.9875, 0.9874, 0.9854, 0.9853, 0.9851,
         0.9838],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9980, 0.9978, 0.9977, 0.9974, 0.9974,
         0.9974],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9985],
        [0.9964, 0.9963, 0.9962, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9954, 0.9948, 0.9947, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943, 0.9941,
         0.9941],
        [0.9946, 0.9940, 0.9939, 0.9937, 0.9935, 0.9933, 0.9933, 0.9932, 0.9932,
         0.9932],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9976],
        [0.9981, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9975,
         0.9974],
        [0.9953, 0.9948, 0.9946, 0.9944, 0.9942, 0.9942, 0.9940, 0.9934, 0.9930,
         0.9930],
        [0.9988, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9978, 0.9976,
         0.9976],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9952, 0.9951, 0.9947, 0.9945, 0.9943, 0.9942, 0.9941, 0.9940, 0.9939,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9983],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9986],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9884, 0.9870, 0.9778, 0.9737, 0.9704, 0.9677, 0.9668, 0.9664, 0.9641,
         0.9586],
        [0.9965, 0.9965, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9968, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9855, 0.9836, 0.9799, 0.9761, 0.9752, 0.9741, 0.9717, 0.9716, 0.9704,
         0.9702],
        [0.9956, 0.9955, 0.9953, 0.9952, 0.9951, 0.9951, 0.9950, 0.9949, 0.9948,
         0.9948],
        [0.9927, 0.9919, 0.9914, 0.9912, 0.9911, 0.9911, 0.9910, 0.9904, 0.9903,
         0.9901],
        [0.9960, 0.9959, 0.9959, 0.9959, 0.9957, 0.9956, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9850, 0.9848, 0.9846, 0.9846, 0.9828, 0.9819, 0.9810, 0.9802, 0.9797,
         0.9794],
        [0.9985, 0.9983, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9973, 0.9972, 0.9971, 0.9971, 0.9969, 0.9969, 0.9969, 0.9967, 0.9966,
         0.9966],
        [0.9901, 0.9879, 0.9876, 0.9864, 0.9861, 0.9846, 0.9845, 0.9836, 0.9832,
         0.9830],
        [0.9857, 0.9790, 0.9782, 0.9779, 0.9777, 0.9775, 0.9772, 0.9768, 0.9768,
         0.9767],
        [0.9879, 0.9874, 0.9739, 0.9735, 0.9638, 0.9602, 0.9595, 0.9591, 0.9582,
         0.9571],
        [0.9721, 0.9696, 0.9677, 0.9654, 0.9649, 0.9642, 0.9625, 0.9621, 0.9605,
         0.9528],
        [0.9912, 0.9898, 0.9892, 0.9890, 0.9889, 0.9884, 0.9878, 0.9873, 0.9872,
         0.9871],
        [0.9943, 0.9943, 0.9942, 0.9941, 0.9938, 0.9936, 0.9936, 0.9935, 0.9934,
         0.9929],
        [0.9927, 0.9919, 0.9918, 0.9917, 0.9916, 0.9912, 0.9910, 0.9908, 0.9906,
         0.9906],
        [0.9911, 0.9908, 0.9898, 0.9896, 0.9893, 0.9892, 0.9865, 0.9864, 0.9863,
         0.9861],
        [0.9934, 0.9929, 0.9927, 0.9923, 0.9917, 0.9917, 0.9908, 0.9900, 0.9896,
         0.9891],
        [0.9904, 0.9878, 0.9867, 0.9862, 0.9860, 0.9853, 0.9850, 0.9849, 0.9843,
         0.9837],
        [0.9952, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9947, 0.9947, 0.9946,
         0.9944],
        [0.9958, 0.9953, 0.9953, 0.9950, 0.9948, 0.9940, 0.9937, 0.9937, 0.9933,
         0.9933],
        [0.9945, 0.9910, 0.9900, 0.9899, 0.9895, 0.9892, 0.9888, 0.9887, 0.9877,
         0.9874],
        [0.9919, 0.9912, 0.9907, 0.9902, 0.9881, 0.9871, 0.9867, 0.9858, 0.9853,
         0.9853],
        [0.9918, 0.9917, 0.9913, 0.9905, 0.9888, 0.9884, 0.9884, 0.9883, 0.9871,
         0.9855],
        [0.9967, 0.9939, 0.9932, 0.9926, 0.9924, 0.9912, 0.9885, 0.9884, 0.9881,
         0.9880],
        [0.9902, 0.9883, 0.9879, 0.9877, 0.9875, 0.9874, 0.9871, 0.9864, 0.9862,
         0.9857],
        [0.9919, 0.9912, 0.9882, 0.9856, 0.9847, 0.9839, 0.9837, 0.9836, 0.9828,
         0.9828],
        [0.9926, 0.9924, 0.9919, 0.9915, 0.9914, 0.9900, 0.9864, 0.9857, 0.9851,
         0.9840],
        [0.9928, 0.9926, 0.9922, 0.9922, 0.9921, 0.9916, 0.9913, 0.9908, 0.9899,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 0, 1, 0, 1, 0, 1, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 0, 0, 1, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1519358.8750, 1516967.0000, 1496427.0000, 1495899.0000, 1490848.7500,
         1487041.8750, 1485584.6250, 1485256.1250, 1483618.1250, 1479603.8750],
        [1541005.6250, 1530028.7500, 1527687.1250, 1527272.0000, 1526993.7500,
         1526945.7500, 1526357.6250, 1525845.2500, 1525226.8750, 1524374.8750],
        [1127899.1250, 1011654.6875, 1009016.6250,  986688.5000,  983743.0000,
          969464.5000,  953399.1250,  951273.8125,  937442.5625,  931422.8750],
        [1445401.8750, 1431079.6250, 1430117.8750, 1425926.0000, 1420453.5000,
         1410854.6250, 1407706.8750, 1397054.3750, 1386904.5000, 1377345.6250],
        [1357771.1250, 1324421.2500, 1322294.6250, 1291210.5000, 1289299.5000,
         1287036.6250, 1282705.1250, 1277960.1250, 1277696.8750, 1268262.8750],
        [1280472.0000, 1267273.8750, 1201909.5000, 1154649.8750, 1147596.3750,
         1104657.3750, 1102794.2500, 1086526.6250, 1078630.6250, 1076051.8750],
        [1176360.3750, 1027003.0000, 1016703.4375, 1007588.5625,  990730.7500,
          981515.4375,  967813.7500,  945370.0000,  922632.5000,  904154.9375],
        [1134689.7500, 1082207.1250, 1031649.1250, 1019376.2500,  902243.5625,
          878547.8125,  865285.2500,  849864.3750,  845855.3750,  845361.8750],
        [1547594.7500, 1535618.7500, 1533659.0000, 1528430.2500, 1525899.0000,
         1525896.1250, 1520975.3750, 1520414.0000, 1520034.2500, 1519666.1250],
        [1462964.3750, 1383070.1250, 1356456.2500, 1350031.8750, 1319235.1250,
         1310233.8750, 1307717.2500, 1288069.3750, 1268160.1250, 1258977.7500],
        [1558462.8750, 1558406.5000, 1557131.8750, 1554695.3750, 1553034.2500,
         1552250.8750, 1551991.8750, 1550820.1250, 1550811.1250, 1549882.6250],
        [1470731.0000, 1450944.2500, 1416119.8750, 1413908.0000, 1406755.3750,
         1397171.7500, 1394186.2500, 1388352.2500, 1386821.1250, 1375138.0000],
        [1439926.1250, 1404036.0000, 1391720.6250, 1373328.1250, 1339267.7500,
         1336350.0000, 1299691.7500, 1297988.6250, 1293189.6250, 1269263.6250],
        [1566189.8750, 1562338.0000, 1560780.2500, 1559041.2500, 1555358.2500,
         1550882.1250, 1548832.1250, 1542949.7500, 1542876.1250, 1542552.5000],
        [1577928.7500, 1577785.8750, 1576402.1250, 1576354.0000, 1575963.2500,
         1574803.2500, 1574557.1250, 1574446.0000, 1574181.6250, 1573716.2500],
        [1575809.8750, 1572768.1250, 1572298.7500, 1571223.8750, 1571059.1250,
         1570549.8750, 1570494.5000, 1569694.7500, 1568164.1250, 1566648.3750],
        [1520443.1250, 1517036.5000, 1515534.1250, 1511419.1250, 1509175.0000,
         1508198.1250, 1506241.7500, 1505147.5000, 1504899.3750, 1503529.3750],
        [1499594.1250, 1486589.5000, 1483381.8750, 1478981.6250, 1478132.7500,
         1476861.8750, 1474524.2500, 1474382.3750, 1471831.0000, 1471219.1250],
        [1480894.1250, 1468575.3750, 1466305.3750, 1462828.8750, 1457702.7500,
         1454918.1250, 1454840.5000, 1452449.0000, 1452033.6250, 1451802.3750],
        [1557939.8750, 1554984.6250, 1554917.7500, 1552170.8750, 1551629.2500,
         1550196.0000, 1550147.2500, 1548929.6250, 1548488.0000, 1547481.2500],
        [1557926.5000, 1551903.0000, 1550882.1250, 1550689.8750, 1549380.1250,
         1549241.2500, 1549046.3750, 1548368.3750, 1544915.3750, 1542437.8750],
        [1496592.5000, 1485073.3750, 1480800.8750, 1476622.5000, 1472764.7500,
         1472287.2500, 1468660.8750, 1455362.1250, 1448513.6250, 1447170.1250],
        [1572964.6250, 1572100.7500, 1561743.7500, 1561067.6250, 1561034.8750,
         1557266.8750, 1554323.2500, 1551197.2500, 1546346.7500, 1545964.8750],
        [1579737.1250, 1576869.7500, 1575414.7500, 1575078.2500, 1574949.0000,
         1574860.3750, 1573399.7500, 1573383.1250, 1571868.3750, 1571280.8750],
        [1493933.1250, 1491116.1250, 1483090.3750, 1480357.5000, 1475599.0000,
         1474064.5000, 1471118.1250, 1468638.3750, 1467260.8750, 1466655.1250],
        [1577534.5000, 1573594.7500, 1568273.3750, 1567968.2500, 1566594.7500,
         1566115.1250, 1566103.2500, 1563800.3750, 1563707.8750, 1562913.2500],
        [1566254.0000, 1564652.1250, 1560753.5000, 1560673.1250, 1559378.7500,
         1554954.8750, 1554262.5000, 1554102.3750, 1553115.6250, 1552677.2500],
        [1576599.1250, 1574923.5000, 1574693.7500, 1574403.8750, 1574253.7500,
         1573711.8750, 1572057.2500, 1571559.7500, 1570197.8750, 1569428.3750],
        [1579380.0000, 1579184.2500, 1578913.2500, 1577206.6250, 1576809.5000,
         1576626.1250, 1576280.3750, 1575662.6250, 1574340.8750, 1574324.3750],
        [1581312.2500, 1580682.0000, 1576910.3750, 1576333.0000, 1575934.6250,
         1575845.8750, 1575596.5000, 1575315.5000, 1575061.7500, 1573290.2500],
        [1581683.2500, 1580427.2500, 1579392.1250, 1578797.3750, 1578553.3750,
         1578369.7500, 1576606.5000, 1576519.3750, 1576194.6250, 1576065.3750],
        [1581324.2500, 1578890.6250, 1577469.8750, 1577173.5000, 1576501.2500,
         1575779.7500, 1575629.5000, 1575324.5000, 1575225.5000, 1575075.1250],
        [1355252.3750, 1328471.7500, 1164891.7500, 1099118.2500, 1048758.1250,
         1008153.8125,  996220.3125,  989892.1250,  958084.9375,  886325.4375],
        [1522767.8750, 1522509.2500, 1515873.7500, 1513055.8750, 1512985.2500,
         1511486.7500, 1509733.6250, 1509588.1250, 1508926.0000, 1507346.8750],
        [1553238.6250, 1552815.0000, 1550784.6250, 1549675.6250, 1547550.5000,
         1546777.3750, 1546777.3750, 1545419.5000, 1545002.3750, 1544990.6250],
        [1529443.7500, 1527095.7500, 1523861.6250, 1521465.7500, 1520380.7500,
         1520011.1250, 1519653.0000, 1517124.7500, 1516754.5000, 1516634.3750],
        [1301417.0000, 1266174.6250, 1200308.1250, 1136800.7500, 1123255.5000,
         1104879.6250, 1068377.7500, 1066313.3750, 1047749.3750, 1045653.1250],
        [1503208.1250, 1501457.2500, 1497197.7500, 1494417.5000, 1492093.3750,
         1491944.0000, 1490429.3750, 1488101.6250, 1485311.2500, 1485025.1250],
        [1442800.2500, 1426185.6250, 1415440.7500, 1411196.3750, 1408984.1250,
         1408651.0000, 1407721.6250, 1396170.0000, 1392842.5000, 1388979.8750],
        [1512028.8750, 1508756.2500, 1508363.5000, 1508363.5000, 1504615.2500,
         1503850.5000, 1498929.3750, 1498007.5000, 1496672.5000, 1495894.7500],
        [1291959.3750, 1287843.2500, 1284531.5000, 1283521.2500, 1251596.2500,
         1235985.2500, 1219383.3750, 1206299.5000, 1196892.5000, 1192613.0000],
        [1566328.7500, 1562245.6250, 1562135.3750, 1561556.0000, 1560255.0000,
         1559859.2500, 1559304.3750, 1557898.3750, 1557495.7500, 1556845.2500],
        [1560292.2500, 1558521.0000, 1556866.0000, 1553554.1250, 1552721.7500,
         1551796.5000, 1550972.3750, 1550367.5000, 1550222.6250, 1549046.3750],
        [1540512.1250, 1537234.8750, 1535071.0000, 1534744.7500, 1531710.6250,
         1530867.8750, 1530505.8750, 1526888.8750, 1524875.0000, 1524546.3750],
        [1389854.5000, 1345516.5000, 1339706.0000, 1317546.6250, 1311870.6250,
         1283980.3750, 1283286.2500, 1266363.0000, 1258165.2500, 1255622.8750],
        [1304840.7500, 1184979.6250, 1171658.0000, 1167607.7500, 1163387.3750,
         1161161.6250, 1156145.1250, 1149270.0000, 1149081.5000, 1147139.1250],
        [1345388.1250, 1336935.0000, 1101767.1250, 1095370.1250,  954787.5625,
          905886.2500,  896689.3750,  892333.5625,  881403.6250,  866674.3750],
        [1074427.5000, 1036681.0000, 1009363.1250,  976860.3750,  969774.2500,
          959795.1250,  937013.5000,  930852.8125,  910667.6875,  814826.2500],
        [1410710.6250, 1384157.3750, 1371715.5000, 1367354.5000, 1366404.2500,
         1356001.0000, 1344445.5000, 1335025.2500, 1333437.2500, 1330518.1250],
        [1476125.5000, 1475939.6250, 1472274.6250, 1471299.1250, 1463641.1250,
         1460749.0000, 1459469.3750, 1459376.0000, 1455348.3750, 1446851.3750],
        [1441120.0000, 1425707.1250, 1422724.2500, 1421853.5000, 1420140.6250,
         1410460.3750, 1408198.3750, 1403614.2500, 1399772.3750, 1398390.0000],
        [1408440.1250, 1403179.2500, 1382569.0000, 1380148.8750, 1373541.6250,
         1371195.0000, 1318794.8750, 1318361.0000, 1315535.1250, 1312979.5000],
        [1457050.8750, 1445472.2500, 1441596.8750, 1434412.1250, 1421852.1250,
         1421583.7500, 1402929.0000, 1386649.2500, 1379192.5000, 1369656.7500],
        [1394900.3750, 1344335.1250, 1324340.3750, 1314584.6250, 1310686.2500,
         1297764.5000, 1291955.7500, 1290044.8750, 1278296.6250, 1267137.3750],
        [1494625.6250, 1494625.6250, 1494531.5000, 1492621.5000, 1491689.3750,
         1489709.0000, 1484140.2500, 1483354.8750, 1481570.7500, 1477111.2500],
        [1507210.2500, 1497290.5000, 1496659.6250, 1490492.0000, 1486324.3750,
         1468074.1250, 1462166.5000, 1461859.7500, 1455274.7500, 1455274.7500],
        [1479057.8750, 1407267.8750, 1387436.2500, 1385410.6250, 1376737.6250,
         1371443.5000, 1364348.1250, 1361149.7500, 1341721.1250, 1337026.7500],
        [1425837.6250, 1411561.1250, 1401446.0000, 1391593.2500, 1349859.3750,
         1330783.2500, 1322495.1250, 1306326.1250, 1297975.0000, 1296379.1250],
        [1424430.8750, 1421915.8750, 1414136.0000, 1396963.8750, 1362827.8750,
         1356398.0000, 1356025.5000, 1353534.5000, 1330225.0000, 1301811.7500],
        [1527183.1250, 1466529.1250, 1451338.6250, 1439043.3750, 1435185.2500,
         1411659.5000, 1358365.6250, 1355115.5000, 1350945.0000, 1348815.7500],
        [1390664.6250, 1353930.8750, 1346173.6250, 1342659.3750, 1339124.7500,
         1336634.2500, 1331343.1250, 1316821.7500, 1313112.2500, 1304929.1250],
        [1424502.8750, 1411425.1250, 1351634.5000, 1303276.2500, 1285244.6250,
         1270983.6250, 1268336.7500, 1265823.3750, 1251615.3750, 1250837.5000],
        [1440119.6250, 1434966.3750, 1425527.5000, 1416406.2500, 1415003.3750,
         1386982.5000, 1317247.5000, 1303892.8750, 1294327.2500, 1274050.2500],
        [1443609.6250, 1440654.0000, 1431268.0000, 1430701.6250, 1428523.0000,
         1420239.5000, 1413292.0000, 1403385.2500, 1386097.8750, 1380991.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1519358.8750,       0.0000],
         [1516967.0000,       0.0000],
         [1496427.0000,       0.0000],
         ...,
         [      0.0000, 1485256.1250],
         [1483618.1250,       0.0000],
         [1479603.8750,       0.0000]],

        [[1541005.6250,       0.0000],
         [1530028.7500,       0.0000],
         [1527687.1250,       0.0000],
         ...,
         [1525845.2500,       0.0000],
         [1525226.8750,       0.0000],
         [1524374.8750,       0.0000]],

        [[1127899.1250,       0.0000],
         [1011654.6875,       0.0000],
         [      0.0000, 1009016.6250],
         ...,
         [ 951273.8125,       0.0000],
         [ 937442.5625,       0.0000],
         [ 931422.8750,       0.0000]],

        ...,

        [[1424502.8750,       0.0000],
         [1411425.1250,       0.0000],
         [1351634.5000,       0.0000],
         ...,
         [1265823.3750,       0.0000],
         [1251615.3750,       0.0000],
         [      0.0000, 1250837.5000]],

        [[1440119.6250,       0.0000],
         [1434966.3750,       0.0000],
         [1425527.5000,       0.0000],
         ...,
         [      0.0000, 1303892.8750],
         [1294327.2500,       0.0000],
         [1274050.2500,       0.0000]],

        [[      0.0000, 1443609.6250],
         [      0.0000, 1440654.0000],
         [      0.0000, 1431268.0000],
         ...,
         [      0.0000, 1403385.2500],
         [      0.0000, 1386097.8750],
         [1380991.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13455349.0000,  1485256.1250],
        [15281738.0000,        0.0000],
        [ 4959693.0000,  4902312.0000],
        [12721990.0000,  1410854.6250],
        [ 9149730.0000,  3828928.0000],
        [ 9276914.0000,  2223648.2500],
        [ 3920262.0000,  6019611.0000],
        [ 8589795.0000,   865285.2500],
        [12238108.0000,  3040080.0000],
        [11921845.0000,  1383070.1250],
        [15537488.0000,        0.0000],
        [14100128.0000,        0.0000],
        [13444763.0000,        0.0000],
        [15531799.0000,        0.0000],
        [15756137.0000,        0.0000],
        [15708712.0000,        0.0000],
        [13581180.0000,  1520443.1250],
        [11824073.0000,  2971425.0000],
        [14602350.0000,        0.0000],
        [15516884.0000,        0.0000],
        [15494790.0000,        0.0000],
        [11780055.0000,  2923792.5000],
        [15584010.0000,        0.0000],
        [15746842.0000,        0.0000],
        [11786784.0000,  2985049.2500],
        [15676604.0000,        0.0000],
        [15580824.0000,        0.0000],
        [15731830.0000,        0.0000],
        [15768729.0000,        0.0000],
        [15766282.0000,        0.0000],
        [15782609.0000,        0.0000],
        [15768394.0000,        0.0000],
        [ 2872438.0000,  7962731.0000],
        [ 9079790.0000,  6054483.5000],
        [13938041.0000,  1544990.6250],
        [12170949.0000,  3041477.0000],
        [ 3218942.5000,  8141987.0000],
        [11933311.0000,  2995874.7500],
        [12702802.0000,  1396170.0000],
        [15035482.0000,        0.0000],
        [ 9907070.0000,  2543555.5000],
        [15603924.0000,        0.0000],
        [15534360.0000,        0.0000],
        [13782213.0000,  1534744.7500],
        [ 2542145.5000, 10509766.0000],
        [ 1167607.7500, 10587663.0000],
        [ 5397775.0000,  4879460.0000],
        [ 2656346.7500,  6963915.0000],
        [ 5402075.0000,  8197694.0000],
        [10229033.0000,  4412041.0000],
        [12710861.0000,  1441120.0000],
        [ 1315535.1250, 12269210.0000],
        [ 1369656.7500, 12790740.0000],
        [ 2638925.0000, 10475121.0000],
        [11901650.0000,  2982330.5000],
        [10289802.0000,  4490825.0000],
        [ 2732593.2500, 11079007.0000],
        [ 5266708.5000,  8267547.5000],
        [ 1301811.7500, 12416458.0000],
        [ 2709310.5000, 11434870.0000],
        [10667907.0000,  2707486.5000],
        [10561858.0000,  2521821.0000],
        [11087383.0000,  2621140.5000],
        [ 1380991.6250, 12797771.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 381/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:34, 56.95s/it]  7%|▋         | 2/29 [00:58<11:00, 24.47s/it] 10%|█         | 3/29 [00:59<05:56, 13.72s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.67s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.87s/it] 21%|██        | 6/29 [01:02<01:36,  4.19s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.06it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.89s/it]
Epoch loss is 2.8363988399505615
Epoch 382/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:01, 57.92s/it]  7%|▋         | 2/29 [00:59<11:16, 25.04s/it] 10%|█         | 3/29 [01:00<06:04, 14.03s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.99s/it] 21%|██        | 6/29 [01:03<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.828801393508911
Epoch 383/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.40s/it]  7%|▋         | 2/29 [01:00<11:17, 25.10s/it] 10%|█         | 3/29 [01:01<06:05, 14.06s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.8285744190216064
Epoch 384/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:05, 58.06s/it]  7%|▋         | 2/29 [00:59<11:11, 24.86s/it] 10%|█         | 3/29 [01:00<06:02, 13.93s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.8134264945983887
Epoch 385/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:51, 59.70s/it]  7%|▋         | 2/29 [01:00<11:18, 25.12s/it] 10%|█         | 3/29 [01:01<06:05, 14.07s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.822990655899048
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0146, 0.0027,  ..., 0.0041, 0.0002, 0.0191],
        [0.0037, 0.0098, 0.0026,  ..., 0.0028, 0.0002, 0.0179],
        [0.0336, 0.0058, 0.0036,  ..., 0.0049, 0.0164, 0.0238],
        ...,
        [0.0074, 0.0079, 0.0200,  ..., 0.0045, 0.0018, 0.0199],
        [0.0046, 0.0084, 0.0136,  ..., 0.0052, 0.0052, 0.0194],
        [0.0101, 0.0045, 0.0047,  ..., 0.0026, 0.0027, 0.0224]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9959, 0.9956, 0.9949, 0.9946, 0.9944, 0.9943, 0.9942, 0.9940, 0.9940,
         0.9939],
        [0.9970, 0.9966, 0.9966, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9758, 0.9695, 0.9673, 0.9666, 0.9665, 0.9664, 0.9661, 0.9658, 0.9634,
         0.9630],
        [0.9926, 0.9921, 0.9918, 0.9918, 0.9914, 0.9907, 0.9907, 0.9901, 0.9893,
         0.9889],
        [0.9887, 0.9872, 0.9865, 0.9850, 0.9843, 0.9843, 0.9842, 0.9839, 0.9838,
         0.9838],
        [0.9844, 0.9843, 0.9806, 0.9771, 0.9763, 0.9740, 0.9738, 0.9735, 0.9729,
         0.9728],
        [0.9807, 0.9692, 0.9685, 0.9681, 0.9677, 0.9673, 0.9655, 0.9650, 0.9631,
         0.9626],
        [0.9772, 0.9728, 0.9692, 0.9676, 0.9608, 0.9587, 0.9582, 0.9558, 0.9556,
         0.9556],
        [0.9974, 0.9969, 0.9967, 0.9965, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9962],
        [0.9937, 0.9892, 0.9881, 0.9879, 0.9869, 0.9853, 0.9850, 0.9845, 0.9844,
         0.9828],
        [0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9938, 0.9933, 0.9913, 0.9905, 0.9905, 0.9905, 0.9902, 0.9900, 0.9897,
         0.9895],
        [0.9918, 0.9903, 0.9893, 0.9892, 0.9872, 0.9872, 0.9863, 0.9854, 0.9842,
         0.9836],
        [0.9983, 0.9981, 0.9980, 0.9979, 0.9978, 0.9974, 0.9971, 0.9971, 0.9970,
         0.9969],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9988, 0.9987, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9961, 0.9961, 0.9961, 0.9957, 0.9956, 0.9954, 0.9954, 0.9954, 0.9952,
         0.9952],
        [0.9951, 0.9945, 0.9944, 0.9944, 0.9943, 0.9941, 0.9940, 0.9939, 0.9939,
         0.9939],
        [0.9943, 0.9937, 0.9934, 0.9933, 0.9933, 0.9932, 0.9931, 0.9931, 0.9929,
         0.9929],
        [0.9978, 0.9977, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9951, 0.9946, 0.9942, 0.9941, 0.9938, 0.9936, 0.9936, 0.9932, 0.9928,
         0.9925],
        [0.9987, 0.9986, 0.9982, 0.9982, 0.9981, 0.9978, 0.9977, 0.9976, 0.9974,
         0.9974],
        [0.9990, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9951, 0.9948, 0.9947, 0.9946, 0.9943, 0.9941, 0.9939, 0.9938, 0.9937,
         0.9937],
        [0.9989, 0.9987, 0.9985, 0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982,
         0.9982],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977,
         0.9977],
        [0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9889, 0.9872, 0.9777, 0.9723, 0.9699, 0.9695, 0.9688, 0.9664, 0.9659,
         0.9637],
        [0.9961, 0.9960, 0.9958, 0.9957, 0.9956, 0.9955, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9978, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9965, 0.9963, 0.9963, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960, 0.9958,
         0.9958],
        [0.9864, 0.9843, 0.9808, 0.9766, 0.9751, 0.9748, 0.9734, 0.9701, 0.9688,
         0.9685],
        [0.9952, 0.9950, 0.9950, 0.9948, 0.9946, 0.9946, 0.9945, 0.9945, 0.9945,
         0.9944],
        [0.9928, 0.9921, 0.9916, 0.9915, 0.9910, 0.9908, 0.9907, 0.9906, 0.9903,
         0.9902],
        [0.9957, 0.9953, 0.9953, 0.9953, 0.9952, 0.9950, 0.9950, 0.9948, 0.9948,
         0.9946],
        [0.9862, 0.9857, 0.9857, 0.9853, 0.9831, 0.9826, 0.9815, 0.9809, 0.9807,
         0.9805],
        [0.9982, 0.9981, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9979, 0.9978, 0.9976, 0.9975, 0.9974, 0.9974, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9971, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9894, 0.9872, 0.9866, 0.9856, 0.9847, 0.9842, 0.9839, 0.9835, 0.9826,
         0.9826],
        [0.9865, 0.9792, 0.9784, 0.9770, 0.9770, 0.9767, 0.9766, 0.9765, 0.9764,
         0.9763],
        [0.9879, 0.9871, 0.9737, 0.9727, 0.9626, 0.9591, 0.9588, 0.9585, 0.9584,
         0.9581],
        [0.9736, 0.9696, 0.9687, 0.9660, 0.9656, 0.9642, 0.9635, 0.9624, 0.9622,
         0.9556],
        [0.9908, 0.9893, 0.9887, 0.9885, 0.9882, 0.9876, 0.9872, 0.9869, 0.9868,
         0.9866],
        [0.9938, 0.9937, 0.9936, 0.9935, 0.9932, 0.9928, 0.9927, 0.9927, 0.9926,
         0.9922],
        [0.9916, 0.9915, 0.9911, 0.9908, 0.9907, 0.9903, 0.9899, 0.9896, 0.9895,
         0.9894],
        [0.9906, 0.9900, 0.9892, 0.9892, 0.9890, 0.9888, 0.9867, 0.9862, 0.9859,
         0.9857],
        [0.9937, 0.9931, 0.9930, 0.9925, 0.9920, 0.9920, 0.9908, 0.9900, 0.9897,
         0.9896],
        [0.9905, 0.9875, 0.9866, 0.9863, 0.9857, 0.9856, 0.9846, 0.9846, 0.9841,
         0.9833],
        [0.9948, 0.9947, 0.9946, 0.9945, 0.9945, 0.9945, 0.9940, 0.9938, 0.9937,
         0.9937],
        [0.9954, 0.9946, 0.9942, 0.9941, 0.9939, 0.9931, 0.9930, 0.9928, 0.9926,
         0.9923],
        [0.9945, 0.9912, 0.9902, 0.9899, 0.9897, 0.9894, 0.9892, 0.9891, 0.9879,
         0.9876],
        [0.9916, 0.9910, 0.9908, 0.9904, 0.9878, 0.9869, 0.9865, 0.9856, 0.9855,
         0.9854],
        [0.9920, 0.9917, 0.9913, 0.9911, 0.9890, 0.9889, 0.9889, 0.9883, 0.9870,
         0.9853],
        [0.9966, 0.9940, 0.9927, 0.9922, 0.9921, 0.9909, 0.9885, 0.9884, 0.9882,
         0.9875],
        [0.9904, 0.9888, 0.9875, 0.9874, 0.9874, 0.9874, 0.9866, 0.9865, 0.9862,
         0.9862],
        [0.9917, 0.9914, 0.9873, 0.9856, 0.9843, 0.9834, 0.9832, 0.9830, 0.9822,
         0.9821],
        [0.9921, 0.9919, 0.9914, 0.9912, 0.9909, 0.9893, 0.9850, 0.9850, 0.9848,
         0.9846],
        [0.9924, 0.9918, 0.9918, 0.9918, 0.9918, 0.9917, 0.9912, 0.9908, 0.9900,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1509634.2500, 1502569.0000, 1487514.1250, 1480751.3750, 1477690.2500,
         1474833.6250, 1472181.8750, 1468757.5000, 1468466.1250, 1465979.6250],
        [1534206.1250, 1525133.7500, 1524156.7500, 1518766.2500, 1518657.7500,
         1517401.1250, 1517324.3750, 1517239.0000, 1517116.1250, 1516161.5000],
        [1133242.7500, 1035784.6875, 1003529.3125,  993368.5000,  991475.6250,
          990491.7500,  986596.3125,  982114.6875,  949298.2500,  942979.3750],
        [1439570.5000, 1428589.7500, 1424217.6250, 1424118.3750, 1415259.8750,
         1401908.6250, 1400792.6250, 1388304.5000, 1372566.1250, 1364763.2500],
        [1362134.0000, 1333809.7500, 1319508.2500, 1290807.8750, 1279233.2500,
         1278189.2500, 1276668.8750, 1271690.5000, 1270371.6250, 1269970.6250],
        [1279782.3750, 1278688.0000, 1212524.3750, 1153961.8750, 1141155.2500,
         1104606.7500, 1100438.7500, 1096633.7500, 1086976.3750, 1084979.6250],
        [1214198.7500, 1030635.2500, 1019781.7500, 1014965.5000, 1009422.7500,
         1002608.0625,  977051.3750,  970009.2500,  945029.2500,  937385.3750],
        [1155381.2500, 1085219.7500, 1030617.5625, 1007603.0000,  913867.6250,
          886982.4375,  880312.4375,  851339.1250,  849012.1875,  848121.9375],
        [1542885.1250, 1530457.7500, 1526589.0000, 1521970.6250, 1519929.8750,
         1516847.0000, 1515944.5000, 1515788.5000, 1514817.3750, 1514752.3750],
        [1462792.6250, 1371887.0000, 1349433.2500, 1346867.1250, 1326334.8750,
         1297946.5000, 1292416.5000, 1283230.0000, 1280301.1250, 1251078.3750],
        [1550981.2500, 1550910.2500, 1548307.8750, 1546709.5000, 1546013.5000,
         1544603.2500, 1544501.5000, 1544212.8750, 1543635.6250, 1542505.5000],
        [1463815.6250, 1453495.2500, 1413368.8750, 1397830.0000, 1396967.8750,
         1396500.3750, 1391070.3750, 1386630.7500, 1381144.3750, 1378160.2500],
        [1423705.6250, 1392255.6250, 1374049.8750, 1370876.0000, 1333158.7500,
         1332182.6250, 1315384.6250, 1299237.0000, 1277642.1250, 1265986.2500],
        [1562659.8750, 1558410.8750, 1555337.5000, 1553822.3750, 1550055.6250,
         1541221.7500, 1536012.7500, 1535998.0000, 1533473.2500, 1531773.3750],
        [1574337.8750, 1573997.1250, 1573165.7500, 1572771.1250, 1571831.0000,
         1571664.5000, 1571628.5000, 1571340.8750, 1571090.6250, 1570355.1250],
        [1572298.7500, 1569789.0000, 1568321.1250, 1566476.6250, 1566191.2500,
         1564116.6250, 1563634.8750, 1563367.8750, 1563208.3750, 1561633.3750],
        [1514599.1250, 1513516.2500, 1513295.3750, 1505077.2500, 1502371.2500,
         1499293.8750, 1498837.8750, 1497599.0000, 1493383.1250, 1493331.8750],
        [1492042.1250, 1478651.7500, 1477639.6250, 1477608.5000, 1475948.0000,
         1471090.1250, 1469779.0000, 1467742.2500, 1467084.5000, 1466934.7500],
        [1475099.6250, 1462398.0000, 1456541.0000, 1455255.3750, 1454665.6250,
         1452148.5000, 1450808.6250, 1450226.2500, 1446916.2500, 1445046.3750],
        [1550636.6250, 1548183.8750, 1544855.0000, 1544751.8750, 1544280.6250,
         1542614.3750, 1542506.8750, 1541533.3750, 1540291.6250, 1539278.5000],
        [1550037.8750, 1546958.8750, 1546267.1250, 1546035.6250, 1544981.7500,
         1544246.7500, 1540247.6250, 1540081.6250, 1537702.6250, 1536499.1250],
        [1491194.3750, 1480452.1250, 1473252.2500, 1470533.2500, 1464998.5000,
         1461114.0000, 1460399.3750, 1452494.7500, 1443454.1250, 1438239.3750],
        [1570939.2500, 1567794.8750, 1560656.7500, 1559166.1250, 1558418.3750,
         1551374.7500, 1548364.0000, 1546919.0000, 1542282.0000, 1541751.0000],
        [1576584.0000, 1573414.6250, 1572711.0000, 1571102.5000, 1570603.7500,
         1570184.3750, 1570128.8750, 1569209.8750, 1569009.2500, 1567754.5000],
        [1491579.7500, 1486609.3750, 1484294.6250, 1481635.6250, 1474276.8750,
         1470701.5000, 1467525.2500, 1465427.5000, 1462626.7500, 1462513.7500],
        [1575028.6250, 1571574.6250, 1566771.0000, 1565659.7500, 1565356.6250,
         1564262.7500, 1561384.7500, 1561222.3750, 1560534.7500, 1560439.5000],
        [1564149.3750, 1561777.8750, 1559520.0000, 1558853.8750, 1554938.6250,
         1554741.3750, 1550091.1250, 1549766.0000, 1549591.5000, 1549513.2500],
        [1573810.8750, 1573467.1250, 1572540.1250, 1571486.2500, 1570218.8750,
         1570135.0000, 1568759.5000, 1568636.7500, 1567827.6250, 1567193.8750],
        [1576647.1250, 1575912.0000, 1575006.1250, 1573750.8750, 1573290.2500,
         1572963.0000, 1572592.6250, 1572414.1250, 1571032.1250, 1570850.8750],
        [1578896.7500, 1577621.8750, 1573850.0000, 1573219.6250, 1572942.1250,
         1572747.0000, 1571642.0000, 1571532.7500, 1571456.2500, 1570548.2500],
        [1578130.5000, 1577704.6250, 1576143.6250, 1575510.8750, 1575010.6250,
         1574304.8750, 1574075.1250, 1573895.0000, 1572652.6250, 1572484.7500],
        [1577313.3750, 1576317.8750, 1574049.6250, 1573164.1250, 1573003.6250,
         1572901.6250, 1572568.6250, 1572021.2500, 1571829.5000, 1571385.8750],
        [1364773.7500, 1332725.2500, 1163987.7500, 1077101.1250, 1040921.0625,
         1034739.1875, 1025054.8750,  990420.0000,  983588.1875,  952291.4375],
        [1513888.7500, 1510895.8750, 1506253.2500, 1505337.1250, 1503172.3750,
         1499815.7500, 1499452.6250, 1499269.5000, 1497050.6250, 1495629.3750],
        [1551661.8750, 1549457.0000, 1546463.2500, 1544657.7500, 1544531.0000,
         1543350.1250, 1543026.3750, 1542309.8750, 1541627.6250, 1540725.0000],
        [1522401.8750, 1517470.6250, 1516958.3750, 1514811.6250, 1513807.8750,
         1511067.5000, 1510835.3750, 1510826.7500, 1508134.7500, 1506899.8750],
        [1317992.6250, 1278725.8750, 1216402.0000, 1145916.7500, 1121347.1250,
         1116144.8750, 1094199.7500, 1043789.9375, 1024898.4375, 1021022.5625],
        [1493695.1250, 1490520.3750, 1489912.1250, 1485137.0000, 1482291.5000,
         1480791.0000, 1480367.3750, 1479788.7500, 1479529.0000, 1477855.2500],
        [1444314.7500, 1428627.8750, 1419781.7500, 1417007.3750, 1407663.8750,
         1403671.7500, 1402107.7500, 1399669.6250, 1392550.3750, 1392150.7500],
        [1505598.3750, 1495747.7500, 1495491.0000, 1495491.0000, 1493974.2500,
         1490487.6250, 1490314.2500, 1486566.8750, 1485547.8750, 1481885.7500],
        [1313620.7500, 1304105.5000, 1303720.0000, 1296506.3750, 1257191.3750,
         1248582.5000, 1228825.2500, 1218416.3750, 1214103.7500, 1211627.3750],
        [1560534.7500, 1556909.1250, 1555898.2500, 1555239.6250, 1552683.1250,
         1552462.6250, 1552132.5000, 1551647.0000, 1550652.8750, 1549309.2500],
        [1553137.8750, 1551324.3750, 1547329.2500, 1543386.8750, 1542764.3750,
         1542545.1250, 1541093.8750, 1539975.8750, 1539633.7500, 1538189.6250],
        [1535125.2500, 1527004.0000, 1525980.5000, 1525293.8750, 1522827.3750,
         1519954.6250, 1518970.6250, 1517176.8750, 1515856.3750, 1513857.0000],
        [1374749.8750, 1333121.7500, 1321228.1250, 1303400.6250, 1286165.5000,
         1276985.5000, 1270685.5000, 1264006.6250, 1248989.7500, 1247406.6250],
        [1320143.7500, 1189695.8750, 1175641.5000, 1152751.8750, 1152144.0000,
         1146474.1250, 1145464.2500, 1143633.8750, 1142769.2500, 1141263.1250],
        [1346079.8750, 1331080.2500, 1099661.5000, 1083152.8750,  937653.5625,
          892749.7500,  888405.5000,  884209.6875,  883272.5625,  879982.5625],
        [1096934.0000, 1035939.7500, 1023078.1875,  984196.1875,  978898.9375,
          959505.0000,  949580.7500,  935395.7500,  932151.5625,  848210.1250],
        [1402423.3750, 1373376.6250, 1362097.7500, 1358247.7500, 1352330.6250,
         1340059.8750, 1333745.0000, 1327556.1250, 1325344.8750, 1322017.1250],
        [1465684.6250, 1461604.6250, 1460934.2500, 1457706.8750, 1452715.0000,
         1444402.8750, 1441498.0000, 1441066.3750, 1439155.8750, 1430883.1250],
        [1418851.8750, 1416445.3750, 1409359.1250, 1403726.6250, 1401845.7500,
         1393675.7500, 1385532.2500, 1379659.3750, 1378321.8750, 1375864.7500],
        [1399975.2500, 1388076.8750, 1371323.1250, 1370891.6250, 1367897.1250,
         1363630.1250, 1324153.3750, 1313213.6250, 1308837.7500, 1305173.1250],
        [1462619.7500, 1449232.1250, 1448711.1250, 1437818.3750, 1426566.6250,
         1426542.1250, 1402713.6250, 1387896.7500, 1382028.5000, 1379383.1250],
        [1397640.7500, 1339507.8750, 1321753.7500, 1316114.8750, 1303924.0000,
         1301890.0000, 1283802.8750, 1283477.2500, 1275320.6250, 1260233.1250],
        [1485192.2500, 1482775.0000, 1481866.1250, 1480145.7500, 1480145.7500,
         1479905.8750, 1468604.7500, 1465530.8750, 1463470.7500, 1461681.3750],
        [1498413.3750, 1482137.5000, 1474103.8750, 1471800.1250, 1467687.6250,
         1449273.6250, 1448606.2500, 1444357.3750, 1440346.3750, 1433683.3750],
        [1479345.6250, 1410872.1250, 1391081.1250, 1385202.0000, 1380994.2500,
         1374971.5000, 1371870.0000, 1369889.2500, 1346038.7500, 1341296.3750],
        [1419949.6250, 1408021.1250, 1403117.6250, 1395368.6250, 1343790.3750,
         1327240.8750, 1320094.7500, 1303442.7500, 1300768.1250, 1299603.7500],
        [1427908.6250, 1420681.0000, 1413606.1250, 1408501.8750, 1367363.6250,
         1365669.3750, 1364892.1250, 1353075.1250, 1329632.7500, 1297515.7500],
        [1525445.1250, 1467970.5000, 1441999.7500, 1432214.2500, 1429478.2500,
         1405371.6250, 1357880.0000, 1355076.6250, 1352813.1250, 1338920.3750],
        [1395544.3750, 1363004.7500, 1338873.2500, 1337162.0000, 1336729.7500,
         1335842.7500, 1321300.0000, 1318934.5000, 1314559.5000, 1313152.3750],
        [1421181.1250, 1415623.0000, 1335551.1250, 1302005.5000, 1278931.8750,
         1262454.8750, 1259272.0000, 1255179.8750, 1241491.6250, 1239832.7500],
        [1429102.0000, 1424960.7500, 1414864.3750, 1411680.8750, 1404982.8750,
         1373288.8750, 1292182.3750, 1291168.6250, 1287169.2500, 1284383.2500],
        [1435471.5000, 1424107.6250, 1423549.5000, 1423392.0000, 1422642.8750,
         1421936.2500, 1410339.2500, 1403975.6250, 1387128.0000, 1378795.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1509634.2500,       0.0000],
         [1502569.0000,       0.0000],
         [1487514.1250,       0.0000],
         ...,
         [1468757.5000,       0.0000],
         [      0.0000, 1468466.1250],
         [1465979.6250,       0.0000]],

        [[1534206.1250,       0.0000],
         [1525133.7500,       0.0000],
         [1524156.7500,       0.0000],
         ...,
         [1517239.0000,       0.0000],
         [1517116.1250,       0.0000],
         [1516161.5000,       0.0000]],

        [[1133242.7500,       0.0000],
         [      0.0000, 1035784.6875],
         [1003529.3125,       0.0000],
         ...,
         [      0.0000,  982114.6875],
         [ 949298.2500,       0.0000],
         [ 942979.3750,       0.0000]],

        ...,

        [[1421181.1250,       0.0000],
         [1415623.0000,       0.0000],
         [1335551.1250,       0.0000],
         ...,
         [1255179.8750,       0.0000],
         [1241491.6250,       0.0000],
         [      0.0000, 1239832.7500]],

        [[1429102.0000,       0.0000],
         [1424960.7500,       0.0000],
         [1414864.3750,       0.0000],
         ...,
         [      0.0000, 1291168.6250],
         [1287169.2500,       0.0000],
         [      0.0000, 1284383.2500]],

        [[      0.0000, 1435471.5000],
         [      0.0000, 1424107.6250],
         [      0.0000, 1423549.5000],
         ...,
         [      0.0000, 1403975.6250],
         [      0.0000, 1387128.0000],
         [      0.0000, 1378795.2500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13339911.0000,  1468466.1250],
        [15206162.0000,        0.0000],
        [ 4029049.7500,  5979831.5000],
        [12671786.0000,  1388304.5000],
        [10403180.0000,  2549204.0000],
        [ 9285347.0000,  2254400.5000],
        [ 4942254.0000,  5178833.0000],
        [ 8621475.0000,   886982.4375],
        [13704195.0000,  1515788.5000],
        [11890400.0000,  1371887.0000],
        [15462382.0000,        0.0000],
        [14058984.0000,        0.0000],
        [13384479.0000,        0.0000],
        [15458766.0000,        0.0000],
        [15722182.0000,        0.0000],
        [15659038.0000,        0.0000],
        [13516706.0000,  1514599.1250],
        [13252479.0000,  1492042.1250],
        [14549106.0000,        0.0000],
        [15438933.0000,        0.0000],
        [15433058.0000,        0.0000],
        [13162879.0000,  1473252.2500],
        [15547666.0000,        0.0000],
        [15710702.0000,        0.0000],
        [11769002.0000,  2978189.0000],
        [15652235.0000,        0.0000],
        [15552943.0000,        0.0000],
        [15704077.0000,        0.0000],
        [15734460.0000,        0.0000],
        [15734456.0000,        0.0000],
        [15749913.0000,        0.0000],
        [15734556.0000,        0.0000],
        [ 3012085.5000,  7953517.0000],
        [ 9017975.0000,  6012790.5000],
        [12361434.0000,  3086376.5000],
        [12107576.0000,  3025638.5000],
        [ 2165137.0000,  9215303.0000],
        [11856281.0000,  2983607.2500],
        [12715395.0000,  1392150.7500],
        [13435557.0000,  1485547.8750],
        [10044397.0000,  2552302.5000],
        [15537470.0000,        0.0000],
        [15439381.0000,        0.0000],
        [13702092.0000,  1519954.6250],
        [ 2525975.2500, 10400765.0000],
        [ 1142769.2500, 10567213.0000],
        [ 5366273.5000,  4859974.5000],
        [ 2743111.0000,  7000779.0000],
        [ 4036445.5000,  9460754.0000],
        [10124295.0000,  4371356.0000],
        [12544430.0000,  1418851.8750],
        [ 1305173.1250, 12207999.0000],
        [ 1382028.5000, 12821484.0000],
        [ 2637868.5000, 10445796.0000],
        [11781352.0000,  2967967.2500],
        [10162171.0000,  4448238.5000],
        [ 2755965.7500, 11095595.0000],
        [ 5264257.0000,  8257140.5000],
        [       0.0000, 13748846.0000],
        [ 2693997.0000, 11413172.0000],
        [10658258.0000,  2716844.5000],
        [10509236.0000,  2502287.5000],
        [ 9746049.0000,  3867734.0000],
        [       0.0000, 14131338.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 386/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:21, 60.75s/it]  7%|▋         | 2/29 [01:01<11:30, 25.56s/it] 10%|█         | 3/29 [01:02<06:11, 14.31s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8293447494506836
Epoch 387/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:22, 60.81s/it]  7%|▋         | 2/29 [01:01<11:30, 25.58s/it] 10%|█         | 3/29 [01:02<06:12, 14.32s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.03s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8257222175598145
Epoch 388/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:52, 59.72s/it]  7%|▋         | 2/29 [01:00<11:18, 25.13s/it] 10%|█         | 3/29 [01:01<06:06, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.83349347114563
Epoch 389/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:31, 61.14s/it]  7%|▋         | 2/29 [01:02<11:34, 25.72s/it] 10%|█         | 3/29 [01:02<06:14, 14.39s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.07s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.815408945083618
Epoch 390/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:34, 59.07s/it]  7%|▋         | 2/29 [00:59<11:11, 24.87s/it] 10%|█         | 3/29 [01:02<06:16, 14.47s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.12s/it] 17%|█▋        | 5/29 [01:03<02:28,  6.17s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.8099775314331055
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0138, 0.0023,  ..., 0.0040, 0.0001, 0.0192],
        [0.0031, 0.0094, 0.0023,  ..., 0.0025, 0.0002, 0.0177],
        [0.0332, 0.0062, 0.0037,  ..., 0.0054, 0.0162, 0.0239],
        ...,
        [0.0070, 0.0078, 0.0193,  ..., 0.0044, 0.0018, 0.0201],
        [0.0042, 0.0082, 0.0124,  ..., 0.0048, 0.0048, 0.0199],
        [0.0094, 0.0045, 0.0044,  ..., 0.0025, 0.0025, 0.0223]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9961, 0.9951, 0.9951, 0.9948, 0.9947, 0.9947, 0.9945, 0.9945,
         0.9943],
        [0.9973, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9964],
        [0.9761, 0.9681, 0.9675, 0.9663, 0.9659, 0.9656, 0.9648, 0.9636, 0.9630,
         0.9625],
        [0.9930, 0.9921, 0.9921, 0.9920, 0.9916, 0.9909, 0.9909, 0.9902, 0.9896,
         0.9893],
        [0.9883, 0.9870, 0.9863, 0.9845, 0.9845, 0.9844, 0.9843, 0.9839, 0.9836,
         0.9835],
        [0.9844, 0.9836, 0.9797, 0.9769, 0.9764, 0.9742, 0.9733, 0.9732, 0.9728,
         0.9723],
        [0.9795, 0.9696, 0.9683, 0.9677, 0.9674, 0.9672, 0.9649, 0.9641, 0.9615,
         0.9614],
        [0.9764, 0.9732, 0.9687, 0.9685, 0.9604, 0.9575, 0.9568, 0.9560, 0.9554,
         0.9546],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9966, 0.9965, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9937, 0.9894, 0.9881, 0.9880, 0.9862, 0.9859, 0.9849, 0.9841, 0.9838,
         0.9825],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9939, 0.9931, 0.9913, 0.9912, 0.9904, 0.9903, 0.9901, 0.9900, 0.9898,
         0.9892],
        [0.9923, 0.9903, 0.9898, 0.9888, 0.9874, 0.9866, 0.9854, 0.9849, 0.9842,
         0.9831],
        [0.9984, 0.9982, 0.9981, 0.9981, 0.9979, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9964, 0.9962, 0.9962, 0.9960, 0.9958, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9955],
        [0.9953, 0.9947, 0.9946, 0.9945, 0.9945, 0.9943, 0.9943, 0.9942, 0.9942,
         0.9942],
        [0.9944, 0.9938, 0.9937, 0.9935, 0.9933, 0.9933, 0.9932, 0.9931, 0.9931,
         0.9931],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9952, 0.9946, 0.9943, 0.9943, 0.9940, 0.9938, 0.9937, 0.9935, 0.9927,
         0.9927],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9978, 0.9976,
         0.9976],
        [0.9991, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9951, 0.9950, 0.9946, 0.9945, 0.9942, 0.9940, 0.9939, 0.9939, 0.9939,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9883, 0.9870, 0.9777, 0.9728, 0.9699, 0.9670, 0.9665, 0.9664, 0.9649,
         0.9600],
        [0.9964, 0.9963, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957,
         0.9956],
        [0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9967, 0.9965, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9856, 0.9835, 0.9799, 0.9762, 0.9745, 0.9737, 0.9722, 0.9707, 0.9695,
         0.9687],
        [0.9956, 0.9954, 0.9952, 0.9951, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948,
         0.9947],
        [0.9926, 0.9918, 0.9914, 0.9911, 0.9910, 0.9908, 0.9908, 0.9903, 0.9901,
         0.9901],
        [0.9960, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954, 0.9953, 0.9951, 0.9951,
         0.9951],
        [0.9851, 0.9850, 0.9849, 0.9847, 0.9828, 0.9821, 0.9810, 0.9799, 0.9799,
         0.9795],
        [0.9984, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9970, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968, 0.9965, 0.9965,
         0.9965],
        [0.9898, 0.9875, 0.9870, 0.9859, 0.9854, 0.9843, 0.9840, 0.9836, 0.9829,
         0.9822],
        [0.9859, 0.9790, 0.9782, 0.9777, 0.9774, 0.9773, 0.9768, 0.9767, 0.9766,
         0.9763],
        [0.9878, 0.9877, 0.9734, 0.9728, 0.9624, 0.9584, 0.9580, 0.9577, 0.9562,
         0.9561],
        [0.9724, 0.9691, 0.9687, 0.9658, 0.9654, 0.9636, 0.9629, 0.9623, 0.9612,
         0.9536],
        [0.9910, 0.9897, 0.9890, 0.9887, 0.9887, 0.9881, 0.9877, 0.9872, 0.9871,
         0.9870],
        [0.9941, 0.9941, 0.9940, 0.9939, 0.9936, 0.9933, 0.9932, 0.9932, 0.9931,
         0.9927],
        [0.9920, 0.9916, 0.9915, 0.9914, 0.9912, 0.9908, 0.9907, 0.9903, 0.9903,
         0.9901],
        [0.9910, 0.9907, 0.9896, 0.9895, 0.9891, 0.9888, 0.9867, 0.9865, 0.9863,
         0.9861],
        [0.9935, 0.9929, 0.9928, 0.9922, 0.9917, 0.9917, 0.9908, 0.9900, 0.9895,
         0.9893],
        [0.9903, 0.9874, 0.9865, 0.9863, 0.9858, 0.9853, 0.9848, 0.9847, 0.9840,
         0.9833],
        [0.9950, 0.9950, 0.9950, 0.9950, 0.9949, 0.9949, 0.9945, 0.9944, 0.9943,
         0.9941],
        [0.9957, 0.9950, 0.9949, 0.9949, 0.9946, 0.9937, 0.9935, 0.9934, 0.9930,
         0.9930],
        [0.9944, 0.9911, 0.9900, 0.9899, 0.9894, 0.9893, 0.9889, 0.9888, 0.9878,
         0.9877],
        [0.9917, 0.9910, 0.9906, 0.9905, 0.9877, 0.9868, 0.9864, 0.9856, 0.9856,
         0.9854],
        [0.9918, 0.9917, 0.9911, 0.9908, 0.9890, 0.9889, 0.9885, 0.9884, 0.9868,
         0.9855],
        [0.9967, 0.9939, 0.9930, 0.9925, 0.9922, 0.9909, 0.9885, 0.9883, 0.9881,
         0.9880],
        [0.9900, 0.9885, 0.9879, 0.9877, 0.9875, 0.9872, 0.9867, 0.9867, 0.9862,
         0.9859],
        [0.9918, 0.9912, 0.9879, 0.9857, 0.9844, 0.9837, 0.9836, 0.9832, 0.9826,
         0.9825],
        [0.9924, 0.9922, 0.9917, 0.9915, 0.9912, 0.9897, 0.9860, 0.9858, 0.9851,
         0.9839],
        [0.9926, 0.9923, 0.9920, 0.9920, 0.9918, 0.9916, 0.9914, 0.9908, 0.9900,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515117.8750, 1513517.7500, 1493095.5000, 1492946.0000, 1486382.5000,
         1483413.0000, 1483231.8750, 1480380.1250, 1479430.3750, 1475160.0000],
        [1539137.5000, 1527660.8750, 1525491.7500, 1524949.2500, 1524476.6250,
         1523696.1250, 1523530.3750, 1523422.8750, 1521480.1250, 1520973.8750],
        [1138097.0000, 1014445.8125, 1005228.5000,  989412.6875,  983210.2500,
          979358.3750,  967213.0625,  951438.0625,  943112.4375,  936240.0000],
        [1447738.8750, 1430378.2500, 1429098.0000, 1427870.6250, 1418493.3750,
         1405488.2500, 1404263.6250, 1392201.2500, 1379322.6250, 1373146.1250],
        [1354663.1250, 1328815.1250, 1315919.1250, 1282634.2500, 1282510.6250,
         1281427.3750, 1278301.5000, 1270668.5000, 1265907.7500, 1264377.8750],
        [1280396.3750, 1266078.0000, 1197503.3750, 1150243.6250, 1142409.6250,
         1106558.3750, 1092772.1250, 1091596.1250, 1085317.1250, 1077718.6250],
        [1193289.8750, 1036977.6875, 1017397.0000, 1008899.1250, 1004413.0000,
         1001405.0000,  969066.1250,  958174.5000,  923263.6250,  922083.6250],
        [1142490.2500, 1090946.7500, 1022949.3750, 1020490.0000,  908701.0000,
          872144.9375,  863954.3750,  853503.9375,  846832.8125,  836618.1875],
        [1544644.3750, 1531690.1250, 1530459.2500, 1523701.8750, 1523530.3750,
         1522782.2500, 1517621.1250, 1517412.7500, 1516645.8750, 1516559.2500],
        [1462446.7500, 1376255.7500, 1349307.1250, 1347530.0000, 1313716.0000,
         1307742.1250, 1290684.7500, 1275285.3750, 1269658.2500, 1245979.8750],
        [1555573.3750, 1555365.7500, 1553982.2500, 1553443.0000, 1550537.5000,
         1550414.8750, 1549683.1250, 1549071.3750, 1548563.3750, 1547473.7500],
        [1466186.5000, 1451014.7500, 1413552.1250, 1410865.2500, 1395588.3750,
         1393844.5000, 1388534.8750, 1388218.5000, 1382525.5000, 1371248.5000],
        [1432650.0000, 1393404.5000, 1383352.3750, 1363500.0000, 1336146.0000,
         1322297.2500, 1298379.7500, 1289175.3750, 1276641.0000, 1257948.1250],
        [1565146.0000, 1560686.5000, 1558034.8750, 1557299.6250, 1553875.6250,
         1546228.7500, 1542839.5000, 1539911.2500, 1539738.0000, 1539431.1250],
        [1576999.1250, 1576941.8750, 1575688.1250, 1575342.6250, 1575025.6250,
         1574003.0000, 1573998.5000, 1573834.8750, 1573776.3750, 1572757.6250],
        [1575268.8750, 1571600.1250, 1570993.2500, 1570832.8750, 1570115.6250,
         1569855.0000, 1569160.5000, 1568252.3750, 1567663.2500, 1566422.7500],
        [1519205.3750, 1516044.3750, 1516017.0000, 1510855.6250, 1507739.2500,
         1504523.3750, 1504240.6250, 1503312.8750, 1501848.2500, 1501022.1250],
        [1496860.7500, 1484314.5000, 1482502.1250, 1478701.1250, 1478691.2500,
         1474961.7500, 1474791.5000, 1472909.3750, 1472837.7500, 1472472.7500],
        [1477824.2500, 1465634.2500, 1462985.2500, 1459135.3750, 1454538.0000,
         1454176.0000, 1452806.5000, 1451125.5000, 1450626.0000, 1449841.7500],
        [1555389.3750, 1552375.2500, 1552128.0000, 1549724.5000, 1548273.8750,
         1547652.5000, 1547200.8750, 1546846.7500, 1544865.3750, 1544827.1250],
        [1555118.0000, 1550398.5000, 1550376.3750, 1549859.0000, 1549576.7500,
         1548031.7500, 1546078.3750, 1545280.8750, 1542031.7500, 1541470.2500],
        [1493594.0000, 1481649.8750, 1476223.8750, 1474714.1250, 1468533.2500,
         1464910.5000, 1462702.0000, 1457495.6250, 1442833.3750, 1442145.6250],
        [1573252.6250, 1570895.8750, 1561877.6250, 1561401.1250, 1561204.5000,
         1556860.1250, 1553401.5000, 1551379.1250, 1545885.2500, 1545603.6250],
        [1579026.1250, 1575590.5000, 1574663.6250, 1574042.1250, 1573777.8750,
         1573455.2500, 1572558.1250, 1572015.2500, 1571174.5000, 1570245.8750],
        [1493115.5000, 1490081.2500, 1480586.2500, 1479546.0000, 1472439.0000,
         1469228.1250, 1467504.2500, 1467314.0000, 1466284.3750, 1466059.3750],
        [1577138.8750, 1573027.6250, 1568767.0000, 1567152.0000, 1566645.3750,
         1566584.2500, 1565392.3750, 1563549.8750, 1563488.7500, 1563473.7500],
        [1566054.0000, 1564359.7500, 1561399.6250, 1560841.2500, 1558691.8750,
         1556500.8750, 1553583.7500, 1553491.8750, 1552030.3750, 1551922.2500],
        [1575667.1250, 1574740.2500, 1573758.3750, 1573366.6250, 1573158.1250,
         1572352.6250, 1571526.7500, 1569452.3750, 1569401.3750, 1569374.3750],
        [1578544.3750, 1578309.5000, 1577978.3750, 1576254.8750, 1575850.5000,
         1575404.1250, 1574674.1250, 1574415.8750, 1574154.6250, 1574057.0000],
        [1580900.6250, 1579676.8750, 1576032.2500, 1575268.8750, 1574907.0000,
         1574833.3750, 1574821.3750, 1574444.3750, 1574246.2500, 1573126.7500],
        [1580463.5000, 1579719.0000, 1578901.1250, 1577927.2500, 1577794.8750,
         1576744.8750, 1576077.5000, 1575912.0000, 1575392.1250, 1575112.7500],
        [1580243.3750, 1578125.8750, 1576707.3750, 1576140.5000, 1575453.7500,
         1575398.1250, 1575003.0000, 1574904.0000, 1574477.5000, 1574459.3750],
        [1353157.7500, 1328270.2500, 1163501.6250, 1085001.3750, 1041510.9375,
          999404.3125,  991562.6250,  990184.8125,  968736.2500,  903743.7500],
        [1519187.8750, 1517764.3750, 1512064.8750, 1510028.7500, 1507690.5000,
         1506981.7500, 1505757.8750, 1505743.3750, 1505410.3750, 1503168.0000],
        [1553923.1250, 1552156.1250, 1550048.2500, 1548579.6250, 1547184.6250,
         1545479.8750, 1545173.2500, 1544908.1250, 1544908.1250, 1544382.1250],
        [1526511.8750, 1521896.7500, 1519576.2500, 1518248.0000, 1518240.7500,
         1516988.7500, 1515889.6250, 1514060.5000, 1513695.2500, 1513400.8750],
        [1302257.5000, 1264345.3750, 1200705.3750, 1138327.1250, 1111362.0000,
         1099691.8750, 1076357.7500, 1053416.2500, 1034707.5000, 1023779.8750],
        [1502868.5000, 1499338.1250, 1493219.3750, 1491601.1250, 1490287.2500,
         1488737.5000, 1488239.2500, 1486161.5000, 1485142.6250, 1484552.2500],
        [1439015.8750, 1423468.0000, 1415651.2500, 1408813.6250, 1408109.7500,
         1402950.3750, 1402677.5000, 1392383.1250, 1389341.5000, 1388674.0000],
        [1511240.2500, 1504632.3750, 1503532.2500, 1503532.2500, 1500579.7500,
         1498683.3750, 1495620.8750, 1492409.3750, 1492161.7500, 1492084.8750],
        [1293782.8750, 1292512.6250, 1289327.7500, 1285840.5000, 1251442.3750,
         1240032.6250, 1220310.7500, 1201636.7500, 1200210.7500, 1193662.1250],
        [1564179.1250, 1560723.7500, 1559225.6250, 1558681.5000, 1557240.2500,
         1557232.8750, 1556880.8750, 1556598.8750, 1555358.2500, 1554910.3750],
        [1557266.8750, 1556800.6250, 1553883.0000, 1549984.6250, 1549801.3750,
         1548836.5000, 1547605.1250, 1547495.8750, 1546402.7500, 1545320.6250],
        [1539535.2500, 1533600.5000, 1532917.6250, 1532298.0000, 1530313.3750,
         1528178.2500, 1527993.1250, 1522929.0000, 1522870.8750, 1522686.3750],
        [1383514.6250, 1338939.6250, 1329030.6250, 1309018.6250, 1299768.6250,
         1278317.3750, 1274201.0000, 1266439.1250, 1253034.2500, 1241839.7500],
        [1308413.3750, 1186207.5000, 1171401.0000, 1163166.6250, 1159218.7500,
         1157796.8750, 1149203.1250, 1147457.5000, 1145237.1250, 1140155.6250],
        [1344233.8750, 1342825.7500, 1094290.5000, 1085522.0000,  935390.3750,
          883008.0625,  878258.0000,  874235.1250,  855643.2500,  855293.3125],
        [1078463.0000, 1028663.4375, 1023091.7500,  982486.6250,  975615.6250,
          951185.8750,  942140.6875,  933676.5000,  919694.0000,  824764.6250],
        [1406653.3750, 1381531.7500, 1367530.6250, 1361692.5000, 1361317.2500,
         1349412.7500, 1342194.6250, 1333592.3750, 1331780.0000, 1329525.0000],
        [1471142.0000, 1470278.0000, 1467847.2500, 1466848.0000, 1460505.1250,
         1454966.7500, 1452224.7500, 1451619.6250, 1449445.0000, 1441016.8750],
        [1428266.8750, 1420309.8750, 1417283.1250, 1415972.6250, 1411829.0000,
         1403244.8750, 1400769.8750, 1393569.3750, 1392685.7500, 1390173.8750],
        [1406453.6250, 1400585.5000, 1380247.7500, 1378093.2500, 1370430.1250,
         1364666.8750, 1322961.8750, 1320502.7500, 1316056.0000, 1312977.0000],
        [1459103.2500, 1445895.3750, 1443363.2500, 1432251.1250, 1420738.0000,
         1420704.0000, 1402749.7500, 1387765.7500, 1377327.2500, 1373205.0000],
        [1392715.0000, 1337576.5000, 1320302.3750, 1315029.6250, 1307202.2500,
         1296621.5000, 1288337.1250, 1286694.2500, 1272757.0000, 1260526.3750],
        [1490204.8750, 1489447.6250, 1489075.5000, 1489075.5000, 1488578.6250,
         1488545.8750, 1480419.6250, 1477188.6250, 1476025.5000, 1471292.1250],
        [1504984.0000, 1491052.1250, 1488869.6250, 1486946.8750, 1480800.8750,
         1461770.5000, 1458040.5000, 1455648.1250, 1448900.5000, 1448517.7500],
        [1477185.8750, 1409544.6250, 1388144.3750, 1385043.5000, 1376347.6250,
         1374042.1250, 1365001.3750, 1363446.7500, 1345084.1250, 1343117.8750],
        [1420881.6250, 1406763.5000, 1398410.1250, 1398212.6250, 1342367.3750,
         1325023.7500, 1316887.1250, 1303630.5000, 1302353.1250, 1298930.8750],
        [1424119.7500, 1421754.5000, 1409387.3750, 1402591.8750, 1366747.0000,
         1365651.2500, 1357173.0000, 1355552.3750, 1325170.3750, 1300698.6250],
        [1526741.8750, 1467039.8750, 1447552.5000, 1436726.0000, 1431420.8750,
         1405754.8750, 1357483.7500, 1353284.1250, 1350418.1250, 1348863.3750],
        [1387379.3750, 1357072.1250, 1346185.1250, 1341501.0000, 1338471.1250,
         1333687.6250, 1324308.7500, 1324302.5000, 1313579.3750, 1308056.5000],
        [1422910.2500, 1410667.5000, 1345395.8750, 1304312.0000, 1281310.1250,
         1267822.7500, 1266115.5000, 1259729.6250, 1247667.1250, 1246012.0000],
        [1435111.3750, 1431826.3750, 1422145.1250, 1417872.5000, 1410960.7500,
         1381270.8750, 1309484.3750, 1305774.3750, 1292634.7500, 1270964.2500],
        [1439624.0000, 1433386.6250, 1427566.8750, 1427052.3750, 1424322.2500,
         1418678.6250, 1415650.0000, 1404120.2500, 1386585.7500, 1377688.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515117.8750,       0.0000],
         [1513517.7500,       0.0000],
         [1493095.5000,       0.0000],
         ...,
         [      0.0000, 1480380.1250],
         [1479430.3750,       0.0000],
         [1475160.0000,       0.0000]],

        [[1539137.5000,       0.0000],
         [1527660.8750,       0.0000],
         [1525491.7500,       0.0000],
         ...,
         [1523422.8750,       0.0000],
         [1521480.1250,       0.0000],
         [1520973.8750,       0.0000]],

        [[1138097.0000,       0.0000],
         [      0.0000, 1014445.8125],
         [1005228.5000,       0.0000],
         ...,
         [ 951438.0625,       0.0000],
         [ 943112.4375,       0.0000],
         [ 936240.0000,       0.0000]],

        ...,

        [[1422910.2500,       0.0000],
         [1410667.5000,       0.0000],
         [1345395.8750,       0.0000],
         ...,
         [1259729.6250,       0.0000],
         [1247667.1250,       0.0000],
         [      0.0000, 1246012.0000]],

        [[1435111.3750,       0.0000],
         [1431826.3750,       0.0000],
         [1422145.1250,       0.0000],
         ...,
         [      0.0000, 1305774.3750],
         [1292634.7500,       0.0000],
         [1270964.2500,       0.0000]],

        [[      0.0000, 1439624.0000],
         [      0.0000, 1433386.6250],
         [      0.0000, 1427566.8750],
         ...,
         [      0.0000, 1404120.2500],
         [      0.0000, 1386585.7500],
         [      0.0000, 1377688.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13422296.0000,  1480380.1250],
        [15254819.0000,        0.0000],
        [ 4974116.0000,  4933640.0000],
        [12703738.0000,  1404263.6250],
        [ 9116638.0000,  3808587.0000],
        [ 9248754.0000,  2241839.7500],
        [ 4901127.0000,  5133842.5000],
        [ 8586487.0000,   872144.9375],
        [12210866.0000,  3034180.5000],
        [11862350.0000,  1376255.7500],
        [15514108.0000,        0.0000],
        [12690331.0000,  1371248.5000],
        [13353494.0000,        0.0000],
        [15503191.0000,        0.0000],
        [15748368.0000,        0.0000],
        [15700165.0000,        0.0000],
        [13565604.0000,  1519205.3750],
        [13292182.0000,  1496860.7500],
        [14578693.0000,        0.0000],
        [15489284.0000,        0.0000],
        [15478222.0000,        0.0000],
        [11747943.0000,  2916859.7500],
        [15581761.0000,        0.0000],
        [15736550.0000,        0.0000],
        [10302677.0000,  4449481.0000],
        [15675220.0000,        0.0000],
        [15578877.0000,        0.0000],
        [15722798.0000,        0.0000],
        [15759643.0000,        0.0000],
        [15758257.0000,        0.0000],
        [15774045.0000,        0.0000],
        [15760912.0000,        0.0000],
        [ 2893332.7500,  7931740.5000],
        [ 9055951.0000,  6037847.0000],
        [12386090.0000,  3090653.0000],
        [12144378.0000,  3034130.5000],
        [ 3199485.7500,  8105464.5000],
        [11919208.0000,  2990939.2500],
        [12678703.0000,  1392383.1250],
        [13502392.0000,  1492084.8750],
        [ 9923534.0000,  2545225.2500],
        [15581032.0000,        0.0000],
        [15503396.0000,        0.0000],
        [13761024.0000,  1532298.0000],
        [ 2531351.5000, 10442752.0000],
        [ 1157796.8750, 10570460.0000],
        [ 5281828.0000,  4866872.0000],
        [ 2686599.2500,  6973183.0000],
        [ 4061003.0000,  9504227.0000],
        [10188262.0000,  4397631.0000],
        [12645838.0000,  1428266.8750],
        [ 1312977.0000, 12259998.0000],
        [ 1373205.0000, 12789898.0000],
        [ 2635332.0000, 10442430.0000],
        [11861070.0000,  2978783.5000],
        [10248694.0000,  4476837.0000],
        [ 2739043.5000, 11087915.0000],
        [ 5261816.0000,  8251644.5000],
        [ 1300698.6250, 12428148.0000],
        [ 2706347.0000, 11418938.0000],
        [10662862.0000,  2711682.0000],
        [10538108.0000,  2513834.7500],
        [11062786.0000,  2615258.7500],
        [       0.0000, 14154676.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 391/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:46, 61.66s/it]  7%|▋         | 2/29 [01:02<11:40, 25.93s/it] 10%|█         | 3/29 [01:03<06:17, 14.51s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.8263046741485596
Epoch 392/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:14, 58.38s/it]  7%|▋         | 2/29 [00:59<11:05, 24.66s/it] 10%|█         | 3/29 [01:01<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7999370098114014
Epoch 393/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.22s/it]  7%|▋         | 2/29 [01:01<11:24, 25.34s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.8070015907287598
Epoch 394/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:18, 60.66s/it]  7%|▋         | 2/29 [01:01<11:29, 25.52s/it] 10%|█         | 3/29 [01:02<06:11, 14.29s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8248796463012695
Epoch 395/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:34, 59.11s/it]  7%|▋         | 2/29 [01:00<11:11, 24.88s/it] 10%|█         | 3/29 [01:00<06:02, 13.94s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.8189892768859863
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.8388e-03, 1.3108e-02, 2.0293e-03,  ..., 3.9943e-03, 9.1197e-05,
         1.9675e-02],
        [2.6317e-03, 9.1788e-03, 2.1064e-03,  ..., 2.2362e-03, 1.9878e-04,
         1.7901e-02],
        [3.2111e-02, 6.4759e-03, 3.8468e-03,  ..., 5.3871e-03, 1.5356e-02,
         2.4188e-02],
        ...,
        [7.1056e-03, 7.8326e-03, 1.8870e-02,  ..., 4.1912e-03, 1.6645e-03,
         2.0603e-02],
        [4.2239e-03, 7.8216e-03, 1.2296e-02,  ..., 4.6529e-03, 4.7692e-03,
         2.0009e-02],
        [8.7172e-03, 4.3968e-03, 4.0755e-03,  ..., 2.3622e-03, 2.2175e-03,
         2.2288e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9964, 0.9964, 0.9954, 0.9953, 0.9952, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9946],
        [0.9974, 0.9969, 0.9968, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967,
         0.9966],
        [0.9763, 0.9689, 0.9687, 0.9659, 0.9654, 0.9652, 0.9639, 0.9639, 0.9637,
         0.9633],
        [0.9932, 0.9926, 0.9923, 0.9923, 0.9917, 0.9913, 0.9911, 0.9906, 0.9900,
         0.9897],
        [0.9885, 0.9873, 0.9867, 0.9852, 0.9850, 0.9849, 0.9848, 0.9846, 0.9844,
         0.9841],
        [0.9850, 0.9841, 0.9810, 0.9776, 0.9772, 0.9754, 0.9740, 0.9739, 0.9734,
         0.9727],
        [0.9794, 0.9689, 0.9686, 0.9682, 0.9681, 0.9680, 0.9661, 0.9653, 0.9632,
         0.9623],
        [0.9762, 0.9731, 0.9699, 0.9697, 0.9607, 0.9575, 0.9568, 0.9566, 0.9557,
         0.9556],
        [0.9977, 0.9971, 0.9970, 0.9968, 0.9967, 0.9967, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9939, 0.9902, 0.9887, 0.9884, 0.9868, 0.9862, 0.9860, 0.9851, 0.9840,
         0.9835],
        [0.9982, 0.9981, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9941, 0.9936, 0.9917, 0.9914, 0.9908, 0.9907, 0.9907, 0.9905, 0.9904,
         0.9896],
        [0.9927, 0.9909, 0.9902, 0.9895, 0.9877, 0.9874, 0.9859, 0.9857, 0.9852,
         0.9835],
        [0.9985, 0.9983, 0.9982, 0.9982, 0.9980, 0.9978, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9990, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9966, 0.9963, 0.9963, 0.9962, 0.9960, 0.9960, 0.9959, 0.9958, 0.9958,
         0.9957],
        [0.9956, 0.9951, 0.9948, 0.9947, 0.9947, 0.9946, 0.9945, 0.9945, 0.9945,
         0.9944],
        [0.9945, 0.9941, 0.9940, 0.9937, 0.9936, 0.9934, 0.9934, 0.9933, 0.9933,
         0.9932],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9977],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9954, 0.9949, 0.9946, 0.9945, 0.9943, 0.9941, 0.9941, 0.9938, 0.9931,
         0.9930],
        [0.9988, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9978, 0.9976,
         0.9976],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9953, 0.9953, 0.9947, 0.9947, 0.9946, 0.9943, 0.9942, 0.9942, 0.9940,
         0.9940],
        [0.9990, 0.9988, 0.9986, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9978],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9992, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9884, 0.9871, 0.9782, 0.9726, 0.9692, 0.9681, 0.9680, 0.9673, 0.9650,
         0.9602],
        [0.9966, 0.9965, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960, 0.9959,
         0.9958],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9969, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963,
         0.9962],
        [0.9856, 0.9837, 0.9800, 0.9761, 0.9752, 0.9743, 0.9724, 0.9721, 0.9705,
         0.9703],
        [0.9960, 0.9957, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952, 0.9951, 0.9950,
         0.9949],
        [0.9928, 0.9920, 0.9917, 0.9913, 0.9913, 0.9912, 0.9910, 0.9906, 0.9904,
         0.9902],
        [0.9961, 0.9959, 0.9958, 0.9958, 0.9958, 0.9955, 0.9955, 0.9954, 0.9954,
         0.9954],
        [0.9850, 0.9848, 0.9847, 0.9843, 0.9827, 0.9818, 0.9812, 0.9803, 0.9796,
         0.9792],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9981],
        [0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9974, 0.9972, 0.9972, 0.9972, 0.9970, 0.9970, 0.9970, 0.9967, 0.9967,
         0.9967],
        [0.9901, 0.9875, 0.9873, 0.9861, 0.9859, 0.9846, 0.9845, 0.9834, 0.9829,
         0.9825],
        [0.9861, 0.9793, 0.9786, 0.9786, 0.9784, 0.9780, 0.9776, 0.9773, 0.9771,
         0.9763],
        [0.9876, 0.9865, 0.9738, 0.9730, 0.9627, 0.9581, 0.9577, 0.9574, 0.9573,
         0.9572],
        [0.9730, 0.9695, 0.9681, 0.9666, 0.9656, 0.9648, 0.9629, 0.9624, 0.9618,
         0.9534],
        [0.9912, 0.9902, 0.9893, 0.9893, 0.9891, 0.9884, 0.9881, 0.9879, 0.9875,
         0.9874],
        [0.9945, 0.9943, 0.9943, 0.9943, 0.9940, 0.9938, 0.9937, 0.9937, 0.9935,
         0.9932],
        [0.9927, 0.9921, 0.9919, 0.9919, 0.9916, 0.9915, 0.9910, 0.9908, 0.9905,
         0.9904],
        [0.9912, 0.9910, 0.9898, 0.9898, 0.9895, 0.9894, 0.9869, 0.9867, 0.9866,
         0.9864],
        [0.9938, 0.9931, 0.9929, 0.9925, 0.9919, 0.9918, 0.9907, 0.9902, 0.9899,
         0.9897],
        [0.9906, 0.9880, 0.9871, 0.9867, 0.9863, 0.9858, 0.9853, 0.9852, 0.9846,
         0.9837],
        [0.9953, 0.9953, 0.9953, 0.9952, 0.9952, 0.9951, 0.9950, 0.9948, 0.9947,
         0.9944],
        [0.9959, 0.9953, 0.9953, 0.9953, 0.9949, 0.9940, 0.9938, 0.9938, 0.9935,
         0.9935],
        [0.9946, 0.9915, 0.9903, 0.9903, 0.9897, 0.9895, 0.9892, 0.9891, 0.9882,
         0.9880],
        [0.9921, 0.9914, 0.9909, 0.9906, 0.9881, 0.9875, 0.9868, 0.9862, 0.9861,
         0.9861],
        [0.9921, 0.9921, 0.9912, 0.9903, 0.9892, 0.9891, 0.9887, 0.9886, 0.9870,
         0.9861],
        [0.9968, 0.9940, 0.9934, 0.9927, 0.9923, 0.9913, 0.9887, 0.9885, 0.9882,
         0.9878],
        [0.9902, 0.9888, 0.9882, 0.9882, 0.9878, 0.9877, 0.9874, 0.9868, 0.9867,
         0.9861],
        [0.9917, 0.9909, 0.9880, 0.9854, 0.9843, 0.9838, 0.9835, 0.9835, 0.9827,
         0.9822],
        [0.9927, 0.9925, 0.9922, 0.9918, 0.9916, 0.9902, 0.9867, 0.9863, 0.9854,
         0.9845],
        [0.9929, 0.9926, 0.9922, 0.9922, 0.9921, 0.9918, 0.9914, 0.9910, 0.9900,
         0.9900]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1520721.5000, 1520203.8750, 1498326.1250, 1497160.6250, 1494494.5000,
         1491056.3750, 1489900.7500, 1489592.5000, 1488501.8750, 1481322.0000],
        [1541082.2500, 1530946.8750, 1529194.2500, 1528485.7500, 1528321.0000,
         1528070.3750, 1527324.3750, 1526289.1250, 1525841.0000, 1523930.0000],
        [1140946.3750, 1026738.6250, 1022633.3750,  982970.1875,  976060.3750,
          973803.8750,  955522.6875,  955325.8750,  952130.6875,  947990.9375],
        [1451633.3750, 1438800.5000, 1433224.0000, 1432846.7500, 1422020.2500,
         1414005.1250, 1408982.8750, 1398774.1250, 1387825.3750, 1381660.7500],
        [1358249.0000, 1335122.0000, 1322642.7500, 1296082.5000, 1291375.5000,
         1290025.1250, 1287148.3750, 1283970.6250, 1281005.8750, 1275240.3750],
        [1290985.1250, 1274447.6250, 1219844.0000, 1162798.3750, 1155360.2500,
         1125548.1250, 1103114.0000, 1102433.6250, 1094731.0000, 1084046.7500],
        [1192820.0000, 1026734.7500, 1022141.9375, 1016157.6875, 1015057.4375,
         1013758.2500,  986383.7500,  974151.3125,  946226.0000,  933916.9375],
        [1138630.0000, 1089017.5000, 1041365.9375, 1037473.2500,  913343.9375,
          872532.6250,  863765.7500,  861181.3750,  849874.9375,  848993.5000],
        [1548120.2500, 1535561.6250, 1533643.0000, 1529089.2500, 1527462.7500,
         1527241.3750, 1522226.2500, 1521666.0000, 1521439.5000, 1520965.1250],
        [1467707.2500, 1391146.0000, 1361766.5000, 1356097.8750, 1324599.3750,
         1313382.7500, 1310470.1250, 1292691.5000, 1273010.7500, 1264275.3750],
        [1559069.3750, 1558217.7500, 1557477.8750, 1557382.8750, 1552831.3750,
         1552754.2500, 1552572.1250, 1552378.2500, 1551894.1250, 1550956.0000],
        [1469961.1250, 1459884.1250, 1421967.3750, 1415578.3750, 1402888.8750,
         1401570.2500, 1401389.8750, 1397337.0000, 1395934.3750, 1379901.5000],
        [1441609.2500, 1405820.6250, 1391106.2500, 1378151.1250, 1343124.1250,
         1336578.1250, 1309079.8750, 1303970.0000, 1294554.3750, 1263506.3750],
        [1567244.6250, 1562776.1250, 1560576.3750, 1560228.1250, 1556161.0000,
         1551055.2500, 1547273.0000, 1544277.6250, 1544152.5000, 1541920.1250],
        [1578243.3750, 1578240.2500, 1576747.8750, 1576505.8750, 1575590.5000,
         1575285.5000, 1575254.0000, 1575103.7500, 1574632.1250, 1573702.7500],
        [1576677.2500, 1573853.0000, 1573707.3750, 1573110.1250, 1572112.7500,
         1571971.8750, 1571328.8750, 1569887.8750, 1569572.1250, 1569073.7500],
        [1524230.8750, 1519003.8750, 1518911.2500, 1515470.5000, 1511286.5000,
         1510965.1250, 1508506.0000, 1507086.7500, 1506994.7500, 1505960.2500],
        [1502794.0000, 1491855.7500, 1486496.0000, 1482974.5000, 1482811.7500,
         1482294.3750, 1479474.0000, 1479362.6250, 1478414.8750, 1478311.8750],
        [1480064.0000, 1469926.1250, 1469420.1250, 1463384.3750, 1461313.3750,
         1456448.0000, 1455569.0000, 1454460.2500, 1454056.7500, 1451722.0000],
        [1558058.7500, 1555522.8750, 1554692.3750, 1552564.7500, 1551547.8750,
         1550626.3750, 1550414.8750, 1549403.8750, 1549384.6250, 1548461.3750],
        [1558182.1250, 1554314.3750, 1553294.8750, 1551935.6250, 1551152.7500,
         1550617.3750, 1549449.7500, 1549103.8750, 1545771.7500, 1545387.0000],
        [1498553.3750, 1487352.5000, 1481347.5000, 1479593.8750, 1474785.8750,
         1471713.1250, 1470355.1250, 1464300.1250, 1449963.5000, 1446999.1250],
        [1573138.6250, 1572018.2500, 1561679.5000, 1561532.2500, 1561133.0000,
         1557730.3750, 1554633.1250, 1551870.5000, 1545706.8750, 1545529.8750],
        [1580350.3750, 1576623.1250, 1575731.7500, 1575722.7500, 1575573.8750,
         1575091.6250, 1573878.5000, 1573450.6250, 1572882.1250, 1571679.6250],
        [1496222.8750, 1495482.5000, 1484390.8750, 1484099.2500, 1480771.2500,
         1475240.2500, 1472250.7500, 1472135.7500, 1469466.3750, 1469002.6250],
        [1577465.3750, 1573809.3750, 1569614.0000, 1568858.2500, 1568283.8750,
         1567646.7500, 1566160.0000, 1565413.2500, 1564795.3750, 1564419.3750],
        [1566502.0000, 1564865.6250, 1560973.8750, 1560051.1250, 1559874.0000,
         1555422.0000, 1555241.0000, 1554659.7500, 1553875.6250, 1551238.6250],
        [1576660.7500, 1574986.6250, 1574849.8750, 1574830.3750, 1574638.1250,
         1573952.0000, 1572022.8750, 1571310.8750, 1570100.5000, 1569816.0000],
        [1579969.1250, 1579954.1250, 1579588.0000, 1577621.8750, 1577305.8750,
         1576851.7500, 1576731.3750, 1576226.1250, 1575410.1250, 1575024.1250],
        [1582104.1250, 1581161.5000, 1577018.6250, 1576743.5000, 1576424.6250,
         1576190.1250, 1575981.2500, 1575885.0000, 1575748.2500, 1574578.0000],
        [1582303.2500, 1580763.5000, 1580353.3750, 1579465.8750, 1579265.6250,
         1578729.5000, 1577727.1250, 1577140.5000, 1576869.7500, 1576827.6250],
        [1581835.6250, 1578901.1250, 1578588.1250, 1578034.1250, 1577038.2500,
         1576788.5000, 1576322.3750, 1576113.5000, 1576081.8750, 1575973.6250],
        [1356804.2500, 1330242.8750, 1172321.7500, 1082061.6250, 1029999.5625,
         1014644.1875, 1013206.3750, 1002543.0625,  970501.5000,  906246.6250],
        [1523587.0000, 1522900.0000, 1516783.3750, 1514173.1250, 1513509.0000,
         1511755.0000, 1511563.2500, 1510870.0000, 1509483.1250, 1506789.1250],
        [1555528.8750, 1553994.2500, 1552376.6250, 1551018.2500, 1549105.3750,
         1547715.8750, 1547715.8750, 1547193.3750, 1547053.2500, 1546578.2500],
        [1530783.2500, 1527290.8750, 1523704.7500, 1523113.5000, 1522733.0000,
         1522551.3750, 1521017.5000, 1519463.2500, 1517917.8750, 1516783.3750],
        [1302236.3750, 1268198.7500, 1202423.1250, 1136629.3750, 1122848.5000,
         1107897.2500, 1078886.8750, 1074001.3750, 1049471.5000, 1046509.0625],
        [1511687.1250, 1504286.6250, 1500375.2500, 1497503.3750, 1497030.7500,
         1495538.1250, 1494544.3750, 1492892.0000, 1490938.3750, 1488239.2500],
        [1444124.6250, 1426523.1250, 1421964.7500, 1414187.2500, 1412491.6250,
         1411662.1250, 1407311.0000, 1399179.7500, 1395509.7500, 1391013.3750],
        [1514323.3750, 1509658.7500, 1507841.5000, 1507841.5000, 1507250.5000,
         1501268.3750, 1500558.3750, 1498846.3750, 1497954.7500, 1497940.5000],
        [1292130.6250, 1288108.6250, 1286680.7500, 1279707.8750, 1250318.6250,
         1233261.8750, 1224049.7500, 1207824.8750, 1195058.6250, 1188822.5000],
        [1566228.6250, 1563214.3750, 1561255.2500, 1560626.8750, 1560030.2500,
         1560013.8750, 1560008.0000, 1559753.5000, 1558596.7500, 1558072.1250],
        [1559756.6250, 1559436.7500, 1557417.0000, 1554210.6250, 1553192.7500,
         1552169.5000, 1551991.8750, 1551769.7500, 1550416.3750, 1549403.8750],
        [1542165.7500, 1538254.1250, 1538089.8750, 1537325.7500, 1534135.8750,
         1533287.5000, 1532442.6250, 1527628.8750, 1527508.0000, 1527442.3750],
        [1389067.3750, 1338785.1250, 1333860.7500, 1312432.3750, 1307875.6250,
         1283941.2500, 1281741.5000, 1262601.8750, 1252902.7500, 1246029.8750],
        [1312085.7500, 1190316.6250, 1179553.0000, 1178737.7500, 1176168.6250,
         1169036.1250, 1162367.1250, 1157496.5000, 1153994.8750, 1140759.2500],
        [1341416.6250, 1319736.0000, 1101335.5000, 1088058.1250,  939133.8125,
          879133.6875,  874517.0000,  870996.2500,  869693.1250,  868670.1875],
        [1087891.1250, 1034392.7500, 1015264.6250,  993624.2500,  979465.7500,
          967755.5625,  942397.6875,  934794.6875,  927095.5625,  822619.3125],
        [1410401.1250, 1392033.8750, 1373713.2500, 1372682.6250, 1368601.6250,
         1356765.5000, 1349452.6250, 1346771.8750, 1338337.1250, 1336803.7500],
        [1479356.8750, 1476223.8750, 1475569.5000, 1475144.5000, 1468190.2500,
         1463854.6250, 1463250.3750, 1461663.2500, 1457691.6250, 1451594.6250],
        [1441720.6250, 1429062.6250, 1426331.2500, 1424864.2500, 1418759.8750,
         1416818.2500, 1407764.6250, 1404022.5000, 1398162.0000, 1396062.1250],
        [1410873.3750, 1407170.0000, 1384107.2500, 1383929.0000, 1376738.8750,
         1375001.6250, 1327553.6250, 1323197.7500, 1322406.8750, 1318078.1250],
        [1464576.6250, 1450473.8750, 1445574.2500, 1436932.7500, 1426259.1250,
         1424045.1250, 1401296.2500, 1391034.6250, 1385823.0000, 1380417.5000],
        [1398907.6250, 1347674.0000, 1330914.0000, 1323348.0000, 1316322.1250,
         1305896.3750, 1296515.1250, 1296097.2500, 1284061.2500, 1268530.2500],
        [1496768.0000, 1496768.0000, 1495465.3750, 1494736.7500, 1494491.6250,
         1492659.7500, 1489277.1250, 1486583.8750, 1483145.6250, 1478228.7500],
        [1509529.1250, 1497400.5000, 1496133.0000, 1495416.8750, 1488059.0000,
         1467976.1250, 1464948.1250, 1463663.5000, 1459103.2500, 1459103.2500],
        [1481276.8750, 1416716.8750, 1393742.1250, 1392494.6250, 1380657.1250,
         1378113.0000, 1370836.7500, 1369345.8750, 1351813.6250, 1348935.3750],
        [1428629.1250, 1415807.8750, 1404447.0000, 1400102.1250, 1350325.5000,
         1338377.8750, 1325381.5000, 1313308.8750, 1312478.7500, 1311247.7500],
        [1429572.3750, 1429442.8750, 1410457.6250, 1394090.5000, 1371747.0000,
         1370048.6250, 1362614.8750, 1360215.5000, 1329059.7500, 1312647.8750],
        [1528497.3750, 1467819.2500, 1455594.0000, 1441146.0000, 1434190.6250,
         1413323.0000, 1360899.2500, 1357987.5000, 1351102.1250, 1344931.5000],
        [1390895.3750, 1364431.3750, 1352908.6250, 1352885.3750, 1344035.1250,
         1342028.2500, 1335877.2500, 1325157.7500, 1323778.3750, 1311933.1250],
        [1422032.5000, 1404863.6250, 1349016.3750, 1299010.2500, 1279079.5000,
         1270111.2500, 1264761.3750, 1264756.6250, 1249837.0000, 1241737.8750],
        [1442722.0000, 1438627.6250, 1431307.6250, 1423192.5000, 1419014.2500,
         1391976.7500, 1323972.8750, 1315405.8750, 1298635.0000, 1282284.3750],
        [1444930.5000, 1440795.6250, 1432359.0000, 1432185.5000, 1430488.8750,
         1422830.2500, 1414941.3750, 1407017.0000, 1387356.8750, 1386867.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1520721.5000,       0.0000],
         [1520203.8750,       0.0000],
         [1498326.1250,       0.0000],
         ...,
         [1489592.5000,       0.0000],
         [1488501.8750,       0.0000],
         [1481322.0000,       0.0000]],

        [[1541082.2500,       0.0000],
         [1530946.8750,       0.0000],
         [1529194.2500,       0.0000],
         ...,
         [1526289.1250,       0.0000],
         [1525841.0000,       0.0000],
         [1523930.0000,       0.0000]],

        [[1140946.3750,       0.0000],
         [1026738.6250,       0.0000],
         [      0.0000, 1022633.3750],
         ...,
         [ 955325.8750,       0.0000],
         [ 952130.6875,       0.0000],
         [      0.0000,  947990.9375]],

        ...,

        [[1422032.5000,       0.0000],
         [1404863.6250,       0.0000],
         [1349016.3750,       0.0000],
         ...,
         [1264756.6250,       0.0000],
         [1249837.0000,       0.0000],
         [      0.0000, 1241737.8750]],

        [[1442722.0000,       0.0000],
         [1438627.6250,       0.0000],
         [1431307.6250,       0.0000],
         ...,
         [      0.0000, 1315405.8750],
         [1298635.0000,       0.0000],
         [      0.0000, 1282284.3750]],

        [[      0.0000, 1444930.5000],
         [      0.0000, 1440795.6250],
         [      0.0000, 1432359.0000],
         ...,
         [      0.0000, 1407017.0000],
         [1387356.8750,       0.0000],
         [      0.0000, 1386867.3750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13481379.0000,  1489900.7500],
        [15289485.0000,        0.0000],
        [ 4075141.5000,  5858981.0000],
        [12755768.0000,  1414005.1250],
        [10455886.0000,  2564976.5000],
        [ 9363218.0000,  2250091.2500],
        [ 4944077.0000,  5183271.0000],
        [ 8654997.0000,   861181.3750],
        [13765748.0000,  1521666.0000],
        [11964002.0000,  1391146.0000],
        [15545534.0000,        0.0000],
        [12766512.0000,  1379901.5000],
        [13467500.0000,        0.0000],
        [15535666.0000,        0.0000],
        [15759306.0000,        0.0000],
        [15721295.0000,        0.0000],
        [13604184.0000,  1524230.8750],
        [11862521.0000,  2982268.0000],
        [14616364.0000,        0.0000],
        [15520678.0000,        0.0000],
        [15509210.0000,        0.0000],
        [13245370.0000,  1479593.8750],
        [15584973.0000,        0.0000],
        [15750984.0000,        0.0000],
        [10338354.0000,  4460708.0000],
        [15686466.0000,        0.0000],
        [15582704.0000,        0.0000],
        [15733168.0000,        0.0000],
        [15774682.0000,        0.0000],
        [15771834.0000,        0.0000],
        [15789446.0000,        0.0000],
        [15775678.0000,        0.0000],
        [ 2934097.0000,  7944475.0000],
        [ 9084325.0000,  6057088.0000],
        [12404032.0000,  3094246.5000],
        [12181608.0000,  3043750.5000],
        [ 3236255.5000,  8152847.0000],
        [11971718.0000,  3001317.5000],
        [12724787.0000,  1399179.7500],
        [13545530.0000,  1497954.7500],
        [ 9903515.0000,  2542449.2500],
        [15607800.0000,        0.0000],
        [15539766.0000,        0.0000],
        [13800026.0000,  1538254.1250],
        [ 2534644.2500, 10474594.0000],
        [ 1179553.0000, 10640963.0000],
        [ 5302144.0000,  4850546.0000],
        [ 2692112.5000,  7013188.5000],
        [ 5417456.0000,  8228107.5000],
        [10252556.0000,  4419983.5000],
        [12721848.0000,  1441720.6250],
        [ 1318078.1250, 12310979.0000],
        [ 1380417.5000, 12826016.0000],
        [ 2654262.0000, 10514004.0000],
        [11920728.0000,  2987396.5000],
        [10307612.0000,  4493721.0000],
        [ 2747459.0000, 11136474.0000],
        [ 5299433.5000,  8300673.0000],
        [ 1312647.8750, 12457250.0000],
        [ 2712001.5000, 11443490.0000],
        [10727877.0000,  2716053.0000],
        [10533357.0000,  2511849.0000],
        [ 9845476.0000,  3921663.0000],
        [ 1387356.8750, 12812416.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 396/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:15, 60.55s/it]  7%|▋         | 2/29 [01:01<11:27, 25.48s/it] 10%|█         | 3/29 [01:02<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:03<03:44,  9.00s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8052337169647217
Epoch 397/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:31, 56.86s/it]  7%|▋         | 2/29 [00:57<10:46, 23.96s/it] 10%|█         | 3/29 [00:58<05:49, 13.44s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.50s/it] 17%|█▋        | 5/29 [01:01<02:25,  6.05s/it] 21%|██        | 6/29 [01:02<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:03<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.47s/it] 31%|███       | 9/29 [01:05<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:05<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.8084540367126465
Epoch 398/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:27, 60.99s/it]  7%|▋         | 2/29 [01:01<11:32, 25.66s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.8058910369873047
Epoch 399/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:39, 61.42s/it]  7%|▋         | 2/29 [01:02<11:37, 25.83s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.829550266265869
Epoch 400/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:52, 59.71s/it]  7%|▋         | 2/29 [01:00<11:18, 25.13s/it] 10%|█         | 3/29 [01:01<06:06, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.810844898223877
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0029, 0.0135, 0.0021,  ..., 0.0040, 0.0001, 0.0192],
        [0.0028, 0.0093, 0.0022,  ..., 0.0024, 0.0002, 0.0179],
        [0.0326, 0.0062, 0.0037,  ..., 0.0054, 0.0157, 0.0239],
        ...,
        [0.0073, 0.0080, 0.0193,  ..., 0.0043, 0.0017, 0.0204],
        [0.0043, 0.0081, 0.0127,  ..., 0.0049, 0.0049, 0.0198],
        [0.0092, 0.0045, 0.0043,  ..., 0.0026, 0.0023, 0.0223]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9954, 0.9953, 0.9950, 0.9949, 0.9949, 0.9948, 0.9947,
         0.9945],
        [0.9973, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9767, 0.9687, 0.9683, 0.9659, 0.9658, 0.9654, 0.9643, 0.9642, 0.9636,
         0.9631],
        [0.9933, 0.9925, 0.9922, 0.9922, 0.9917, 0.9912, 0.9911, 0.9902, 0.9898,
         0.9896],
        [0.9882, 0.9873, 0.9862, 0.9848, 0.9847, 0.9843, 0.9841, 0.9841, 0.9839,
         0.9838],
        [0.9846, 0.9835, 0.9803, 0.9773, 0.9767, 0.9749, 0.9737, 0.9736, 0.9732,
         0.9720],
        [0.9795, 0.9701, 0.9692, 0.9682, 0.9673, 0.9669, 0.9651, 0.9645, 0.9628,
         0.9622],
        [0.9765, 0.9739, 0.9694, 0.9691, 0.9614, 0.9576, 0.9572, 0.9570, 0.9560,
         0.9548],
        [0.9976, 0.9969, 0.9969, 0.9968, 0.9966, 0.9966, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9938, 0.9899, 0.9882, 0.9881, 0.9863, 0.9862, 0.9852, 0.9843, 0.9837,
         0.9830],
        [0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9939, 0.9932, 0.9916, 0.9913, 0.9905, 0.9905, 0.9904, 0.9902, 0.9902,
         0.9894],
        [0.9922, 0.9905, 0.9898, 0.9885, 0.9874, 0.9863, 0.9854, 0.9848, 0.9842,
         0.9829],
        [0.9985, 0.9983, 0.9982, 0.9981, 0.9980, 0.9977, 0.9974, 0.9974, 0.9974,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9960, 0.9958, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9955, 0.9949, 0.9949, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9944,
         0.9944],
        [0.9945, 0.9939, 0.9938, 0.9936, 0.9935, 0.9933, 0.9933, 0.9932, 0.9932,
         0.9932],
        [0.9981, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9981, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975,
         0.9975],
        [0.9953, 0.9947, 0.9945, 0.9943, 0.9942, 0.9940, 0.9939, 0.9936, 0.9929,
         0.9929],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9982, 0.9981, 0.9979, 0.9978, 0.9975,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9952, 0.9952, 0.9946, 0.9945, 0.9943, 0.9942, 0.9941, 0.9941, 0.9940,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9992, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9882, 0.9867, 0.9777, 0.9725, 0.9691, 0.9675, 0.9674, 0.9653, 0.9647,
         0.9598],
        [0.9965, 0.9964, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9957],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9968, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9854, 0.9834, 0.9797, 0.9758, 0.9743, 0.9740, 0.9719, 0.9713, 0.9695,
         0.9693],
        [0.9959, 0.9956, 0.9953, 0.9952, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950,
         0.9949],
        [0.9925, 0.9917, 0.9915, 0.9911, 0.9910, 0.9910, 0.9909, 0.9903, 0.9901,
         0.9901],
        [0.9961, 0.9958, 0.9958, 0.9958, 0.9957, 0.9954, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9849, 0.9846, 0.9845, 0.9844, 0.9825, 0.9814, 0.9809, 0.9796, 0.9795,
         0.9786],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977,
         0.9977],
        [0.9973, 0.9971, 0.9971, 0.9971, 0.9969, 0.9969, 0.9968, 0.9966, 0.9966,
         0.9966],
        [0.9898, 0.9871, 0.9866, 0.9859, 0.9853, 0.9841, 0.9840, 0.9835, 0.9827,
         0.9825],
        [0.9859, 0.9790, 0.9780, 0.9777, 0.9776, 0.9773, 0.9769, 0.9766, 0.9765,
         0.9759],
        [0.9874, 0.9864, 0.9738, 0.9725, 0.9624, 0.9586, 0.9575, 0.9572, 0.9569,
         0.9567],
        [0.9727, 0.9698, 0.9681, 0.9660, 0.9654, 0.9635, 0.9629, 0.9624, 0.9613,
         0.9531],
        [0.9911, 0.9901, 0.9893, 0.9890, 0.9889, 0.9884, 0.9882, 0.9877, 0.9876,
         0.9875],
        [0.9944, 0.9942, 0.9942, 0.9941, 0.9938, 0.9936, 0.9936, 0.9935, 0.9933,
         0.9930],
        [0.9921, 0.9919, 0.9917, 0.9916, 0.9914, 0.9911, 0.9909, 0.9907, 0.9905,
         0.9905],
        [0.9909, 0.9908, 0.9895, 0.9895, 0.9891, 0.9889, 0.9866, 0.9865, 0.9863,
         0.9862],
        [0.9936, 0.9929, 0.9927, 0.9923, 0.9918, 0.9917, 0.9906, 0.9899, 0.9897,
         0.9894],
        [0.9903, 0.9875, 0.9866, 0.9863, 0.9858, 0.9852, 0.9849, 0.9848, 0.9840,
         0.9832],
        [0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9950, 0.9949, 0.9947, 0.9946,
         0.9943],
        [0.9958, 0.9952, 0.9952, 0.9951, 0.9947, 0.9938, 0.9937, 0.9934, 0.9933,
         0.9933],
        [0.9945, 0.9912, 0.9901, 0.9900, 0.9894, 0.9892, 0.9889, 0.9889, 0.9880,
         0.9879],
        [0.9918, 0.9911, 0.9906, 0.9905, 0.9877, 0.9870, 0.9864, 0.9861, 0.9859,
         0.9858],
        [0.9918, 0.9918, 0.9911, 0.9906, 0.9888, 0.9887, 0.9887, 0.9880, 0.9867,
         0.9857],
        [0.9967, 0.9939, 0.9930, 0.9925, 0.9921, 0.9910, 0.9883, 0.9882, 0.9879,
         0.9877],
        [0.9900, 0.9886, 0.9880, 0.9880, 0.9877, 0.9871, 0.9870, 0.9867, 0.9863,
         0.9859],
        [0.9915, 0.9907, 0.9876, 0.9852, 0.9839, 0.9837, 0.9833, 0.9832, 0.9824,
         0.9820],
        [0.9925, 0.9923, 0.9920, 0.9916, 0.9914, 0.9900, 0.9862, 0.9861, 0.9852,
         0.9841],
        [0.9926, 0.9924, 0.9921, 0.9920, 0.9918, 0.9915, 0.9913, 0.9909, 0.9898,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1517181.1250, 1516776.1250, 1497786.1250, 1495531.0000, 1490477.8750,
         1488560.1250, 1487521.2500, 1486354.1250, 1483169.6250, 1478438.7500],
        [1540683.8750, 1528592.2500, 1527006.8750, 1526746.2500, 1526449.2500,
         1525167.3750, 1524773.1250, 1524765.8750, 1522990.0000, 1521383.0000],
        [1147428.0000, 1023781.8125, 1016898.3750,  983416.5625,  981524.8125,
          976531.5000,  961634.0000,  959580.9375,  950765.9375,  945108.6250],
        [1454217.5000, 1436847.8750, 1432512.1250, 1432313.8750, 1421994.5000,
         1411260.8750, 1409680.3750, 1391035.8750, 1383293.0000, 1378903.0000],
        [1352495.8750, 1334530.0000, 1314559.5000, 1287644.3750, 1285241.0000,
         1279158.7500, 1274989.8750, 1274441.6250, 1270818.7500, 1269723.6250],
        [1284347.8750, 1263946.2500, 1207166.1250, 1156749.5000, 1147260.5000,
         1118053.8750, 1098665.6250, 1098267.6250, 1091412.8750, 1073457.6250],
        [1193622.3750, 1044150.3750, 1030186.1250, 1015572.5625, 1003693.8750,
          996780.9375,  971888.9375,  963524.9375,  941017.3750,  932212.0000],
        [1144299.3750, 1101617.0000, 1034091.0000, 1029545.8125,  921782.9375,
          873545.0625,  868479.7500,  865346.3125,  853354.2500,  839374.5625],
        [1545709.7500, 1531665.2500, 1531392.2500, 1527856.1250, 1525242.8750,
         1524098.6250, 1520125.5000, 1518957.5000, 1518449.2500, 1517925.1250],
        [1465125.6250, 1384688.1250, 1352547.3750, 1349795.0000, 1316056.0000,
         1313614.6250, 1295080.3750, 1278178.3750, 1268075.5000, 1254854.2500],
        [1557264.0000, 1556604.7500, 1556530.5000, 1556217.3750, 1552434.3750,
         1551997.7500, 1551883.7500, 1551392.5000, 1550993.1250, 1548296.0000],
        [1466808.8750, 1451673.6250, 1419502.8750, 1413081.7500, 1397682.1250,
         1396963.8750, 1395883.7500, 1390992.1250, 1390262.6250, 1376209.8750],
        [1431440.0000, 1397443.5000, 1384205.0000, 1358676.6250, 1336366.5000,
         1316141.3750, 1298885.1250, 1287983.3750, 1277153.6250, 1253446.6250],
        [1565906.0000, 1561307.3750, 1558639.8750, 1558561.0000, 1555104.6250,
         1547934.2500, 1542977.7500, 1542081.8750, 1541455.5000, 1539210.8750],
        [1577590.1250, 1577423.1250, 1576438.2500, 1576241.2500, 1575054.1250,
         1574804.8750, 1574719.2500, 1574483.5000, 1573914.5000, 1573174.6250],
        [1576054.8750, 1572874.6250, 1572415.7500, 1571997.3750, 1571289.8750,
         1571242.0000, 1570299.6250, 1569155.8750, 1568551.6250, 1568238.8750],
        [1522670.3750, 1518136.5000, 1518075.6250, 1514040.3750, 1510914.6250,
         1507119.7500, 1506866.8750, 1504925.2500, 1504707.0000, 1502804.0000],
        [1500352.2500, 1488510.3750, 1487073.0000, 1482743.8750, 1481214.7500,
         1480470.5000, 1478959.1250, 1478560.0000, 1477339.3750, 1477318.2500],
        [1479901.5000, 1466297.0000, 1465539.2500, 1459907.7500, 1458973.8750,
         1454285.5000, 1454108.1250, 1453019.8750, 1452361.7500, 1451493.6250],
        [1556797.7500, 1555350.7500, 1553020.8750, 1551592.2500, 1550987.2500,
         1549101.0000, 1548377.1250, 1548016.8750, 1547650.8750, 1546947.1250],
        [1556843.7500, 1553263.7500, 1552459.6250, 1551712.1250, 1551346.6250,
         1550629.2500, 1548696.1250, 1546562.0000, 1545155.6250, 1543191.1250],
        [1495414.0000, 1482882.5000, 1479428.8750, 1476073.3750, 1472767.5000,
         1467917.2500, 1466376.7500, 1460485.7500, 1446972.7500, 1446608.5000],
        [1573038.1250, 1571233.0000, 1561228.3750, 1560967.7500, 1560725.2500,
         1556909.1250, 1553346.7500, 1550537.5000, 1545121.7500, 1544168.6250],
        [1580139.3750, 1576534.3750, 1575425.2500, 1575336.6250, 1574916.0000,
         1574552.5000, 1573549.7500, 1573327.6250, 1571702.0000, 1570895.8750],
        [1494550.0000, 1494057.0000, 1480848.8750, 1480100.6250, 1474251.5000,
         1473541.7500, 1471616.2500, 1471022.7500, 1469746.6250, 1465783.8750],
        [1577233.6250, 1573377.2500, 1568969.0000, 1567922.0000, 1567736.3750,
         1566334.6250, 1565922.5000, 1564042.0000, 1564031.5000, 1563889.7500],
        [1565806.0000, 1564276.2500, 1560252.0000, 1560243.1250, 1559207.7500,
         1555389.3750, 1553998.6250, 1553761.6250, 1552883.1250, 1550851.1250],
        [1575793.2500, 1574542.0000, 1573979.0000, 1573962.5000, 1573137.1250,
         1572727.5000, 1571074.1250, 1569889.5000, 1569581.0000, 1569096.1250],
        [1579256.6250, 1579115.0000, 1578889.1250, 1576830.6250, 1576686.2500,
         1576275.7500, 1575556.0000, 1575207.3750, 1574959.5000, 1574439.8750],
        [1581696.8750, 1580528.2500, 1576609.5000, 1576244.2500, 1575955.6250,
         1575437.2500, 1575366.6250, 1575042.1250, 1574863.3750, 1573843.8750],
        [1581517.2500, 1579982.7500, 1579765.7500, 1578907.1250, 1578478.1250,
         1577709.0000, 1577014.1250, 1576674.2500, 1576327.0000, 1576005.2500],
        [1581036.3750, 1578410.3750, 1577573.7500, 1576720.7500, 1576527.0000,
         1576033.7500, 1575501.7500, 1575441.7500, 1575423.6250, 1575178.8750],
        [1351857.5000, 1323668.6250, 1163933.3750, 1080254.1250, 1028508.5000,
         1005297.5625, 1004824.0000,  975344.8750,  966478.1875,  901749.8125],
        [1521442.5000, 1520151.6250, 1514096.6250, 1511788.1250, 1510677.0000,
         1509939.3750, 1509196.6250, 1508298.7500, 1507007.6250, 1504435.8750],
        [1555201.1250, 1553182.2500, 1551950.3750, 1550400.1250, 1548904.5000,
         1547192.0000, 1547172.8750, 1546776.0000, 1546776.0000, 1546169.7500],
        [1528032.5000, 1522339.5000, 1520611.2500, 1520364.7500, 1520029.8750,
         1519877.7500, 1518502.7500, 1516682.1250, 1516108.0000, 1515659.8750],
        [1298252.2500, 1262480.2500, 1196881.1250, 1132430.2500, 1109032.6250,
         1103172.8750, 1071424.5000, 1061298.6250, 1034928.6250, 1032638.4375],
        [1510198.7500, 1501808.2500, 1496856.6250, 1494517.3750, 1494446.0000,
         1493591.1250, 1491889.8750, 1491119.0000, 1489527.1250, 1488817.1250],
        [1437270.0000, 1421483.3750, 1416657.5000, 1409941.2500, 1408041.2500,
         1407723.0000, 1405646.3750, 1393566.6250, 1388769.2500, 1388495.1250],
        [1514079.2500, 1507828.5000, 1506484.6250, 1506484.6250, 1504460.2500,
         1498630.5000, 1498277.6250, 1496315.6250, 1496170.0000, 1495726.3750],
        [1288966.3750, 1284075.8750, 1281638.8750, 1281399.3750, 1245476.1250,
         1227709.0000, 1219035.7500, 1196546.7500, 1193659.7500, 1179304.5000],
        [1565250.5000, 1562260.5000, 1559665.8750, 1559508.1250, 1558743.8750,
         1558471.8750, 1558044.0000, 1557237.3750, 1556895.7500, 1556434.1250],
        [1558183.6250, 1557733.3750, 1555662.3750, 1552351.5000, 1552113.2500,
         1550806.7500, 1550091.1250, 1550067.3750, 1548244.3750, 1547869.3750],
        [1540422.3750, 1536187.0000, 1536153.3750, 1534390.5000, 1531547.0000,
         1530154.2500, 1528684.0000, 1524940.3750, 1524851.6250, 1524411.1250],
        [1382969.8750, 1331525.8750, 1320700.3750, 1307546.3750, 1297357.5000,
         1274730.8750, 1273435.6250, 1263512.3750, 1249384.1250, 1245941.8750],
        [1308473.2500, 1185000.0000, 1169085.1250, 1163431.7500, 1162402.5000,
         1157397.2500, 1150332.5000, 1145473.1250, 1143463.7500, 1134226.6250],
        [1337417.1250, 1318618.8750, 1100517.5000, 1081008.5000,  935457.2500,
          886153.8125,  872178.2500,  868850.8125,  864885.9375,  862585.2500],
        [1083450.3750, 1039327.0625, 1014300.7500,  984540.7500,  976283.8125,
          950547.5000,  941910.6875,  935499.2500,  920530.2500,  819472.3750],
        [1409089.0000, 1389119.0000, 1372555.6250, 1366720.8750, 1365747.6250,
         1355238.2500, 1351352.1250, 1342468.5000, 1339998.5000, 1337730.8750],
        [1476578.7500, 1473187.5000, 1472239.6250, 1472003.7500, 1465037.6250,
         1461128.0000, 1459562.6250, 1458018.3750, 1453886.1250, 1447229.5000],
        [1430074.1250, 1425043.6250, 1420780.0000, 1419922.6250, 1416049.6250,
         1409474.7500, 1404812.7500, 1400635.0000, 1397155.6250, 1396483.0000],
        [1404842.2500, 1402452.7500, 1377873.7500, 1377517.7500, 1370268.1250,
         1366500.6250, 1321228.1250, 1319493.0000, 1315201.5000, 1313883.8750],
        [1460739.2500, 1446299.5000, 1441983.2500, 1432983.3750, 1423123.3750,
         1422067.7500, 1398515.3750, 1386153.3750, 1382086.5000, 1375948.6250],
        [1392995.3750, 1339399.3750, 1321965.5000, 1315933.0000, 1307174.8750,
         1295295.3750, 1288959.0000, 1287718.0000, 1274084.3750, 1258881.7500],
        [1493262.0000, 1492906.1250, 1492621.5000, 1492621.5000, 1491756.1250,
         1490156.5000, 1487136.8750, 1483758.2500, 1482113.3750, 1474663.5000],
        [1506953.0000, 1494541.5000, 1494487.3750, 1492581.6250, 1484524.0000,
         1465300.3750, 1463101.0000, 1457077.2500, 1454933.3750, 1454933.3750],
        [1478694.0000, 1411252.8750, 1389267.3750, 1388199.8750, 1375475.1250,
         1372057.0000, 1366590.5000, 1366121.3750, 1347608.3750, 1345652.5000],
        [1422666.0000, 1409016.3750, 1399865.7500, 1398156.7500, 1342856.5000,
         1329105.3750, 1317899.6250, 1312744.1250, 1307455.3750, 1305968.7500],
        [1423640.5000, 1422450.2500, 1409508.3750, 1399868.5000, 1362740.8750,
         1362722.7500, 1361741.8750, 1348167.6250, 1323485.6250, 1305473.1250],
        [1527098.6250, 1466671.7500, 1448705.6250, 1438068.0000, 1429864.1250,
         1407199.6250, 1354491.3750, 1351475.8750, 1345765.3750, 1342235.5000],
        [1386811.8750, 1360006.6250, 1348962.3750, 1348175.2500, 1342222.7500,
         1331827.0000, 1328936.7500, 1323226.8750, 1316440.1250, 1308353.5000],
        [1418211.8750, 1401690.6250, 1339651.0000, 1294544.3750, 1271884.5000,
         1267523.0000, 1259961.6250, 1259690.0000, 1243941.2500, 1237261.2500],
        [1438399.8750, 1434049.7500, 1426491.7500, 1419215.8750, 1415523.1250,
         1387126.6250, 1314353.8750, 1311334.0000, 1295376.7500, 1274918.1250],
        [1439835.3750, 1435527.5000, 1429117.0000, 1427513.8750, 1424113.0000,
         1416862.8750, 1414169.6250, 1404824.8750, 1382770.7500, 1381981.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1517181.1250,       0.0000],
         [1516776.1250,       0.0000],
         [1497786.1250,       0.0000],
         ...,
         [      0.0000, 1486354.1250],
         [1483169.6250,       0.0000],
         [1478438.7500,       0.0000]],

        [[1540683.8750,       0.0000],
         [1528592.2500,       0.0000],
         [1527006.8750,       0.0000],
         ...,
         [1524765.8750,       0.0000],
         [1522990.0000,       0.0000],
         [1521383.0000,       0.0000]],

        [[1147428.0000,       0.0000],
         [      0.0000, 1023781.8125],
         [1016898.3750,       0.0000],
         ...,
         [ 959580.9375,       0.0000],
         [ 950765.9375,       0.0000],
         [ 945108.6250,       0.0000]],

        ...,

        [[1418211.8750,       0.0000],
         [1401690.6250,       0.0000],
         [1339651.0000,       0.0000],
         ...,
         [1259690.0000,       0.0000],
         [1243941.2500,       0.0000],
         [1237261.2500,       0.0000]],

        [[1438399.8750,       0.0000],
         [1434049.7500,       0.0000],
         [1426491.7500,       0.0000],
         ...,
         [      0.0000, 1311334.0000],
         [1295376.7500,       0.0000],
         [1274918.1250,       0.0000]],

        [[      0.0000, 1439835.3750],
         [      0.0000, 1435527.5000],
         [      0.0000, 1429117.0000],
         ...,
         [      0.0000, 1404824.8750],
         [1382770.7500,       0.0000],
         [      0.0000, 1381981.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13455443.0000,  1486354.1250],
        [15268558.0000,        0.0000],
        [ 5019782.0000,  4926888.5000],
        [12740798.0000,  1411260.8750],
        [ 9128620.0000,  3814984.0000],
        [ 9291166.0000,  2248162.5000],
        [ 4963138.5000,  5129511.0000],
        [ 8657891.0000,   873545.0625],
        [12222848.0000,  3038574.7500],
        [11893328.0000,  1384688.1250],
        [15533614.0000,        0.0000],
        [12722852.0000,  1376209.8750],
        [13341742.0000,        0.0000],
        [15513179.0000,        0.0000],
        [15753845.0000,        0.0000],
        [15712121.0000,        0.0000],
        [13587590.0000,  1522670.3750],
        [11851718.0000,  2980822.7500],
        [14595888.0000,        0.0000],
        [15507842.0000,        0.0000],
        [15499860.0000,        0.0000],
        [11772246.0000,  2922682.0000],
        [15577276.0000,        0.0000],
        [15746379.0000,        0.0000],
        [10315889.0000,  4459630.0000],
        [15679460.0000,        0.0000],
        [15576669.0000,        0.0000],
        [15723782.0000,        0.0000],
        [15767216.0000,        0.0000],
        [15765588.0000,        0.0000],
        [15782382.0000,        0.0000],
        [15767848.0000,        0.0000],
        [ 2911871.5000,  7890045.5000],
        [ 9069448.0000,  6047586.0000],
        [12399360.0000,  3094365.0000],
        [12159676.0000,  3038532.5000],
        [ 3199400.0000,  8103140.0000],
        [11957372.0000,  2995399.5000],
        [12684027.0000,  1393566.6250],
        [15024457.0000,        0.0000],
        [ 9863370.0000,  2534442.5000],
        [15592512.0000,        0.0000],
        [15523123.0000,        0.0000],
        [13775555.0000,  1536187.0000],
        [ 2519377.5000, 10427727.0000],
        [ 1162402.5000, 10556884.0000],
        [ 5290111.5000,  4837562.0000],
        [ 2675502.0000,  6990361.0000],
        [ 4078301.5000,  9551718.0000],
        [10228643.0000,  4410229.0000],
        [12690358.0000,  1430074.1250],
        [ 1313883.8750, 12255379.0000],
        [ 1375948.6250, 12793951.0000],
        [ 2637898.5000, 10444508.0000],
        [11897934.0000,  2983062.5000],
        [10282469.0000,  4485964.5000],
        [ 2741596.5000, 11099323.0000],
        [ 5279469.0000,  8266266.0000],
        [ 1305473.1250, 12414326.0000],
        [ 2700256.7500, 11411320.0000],
        [10684924.0000,  2710038.7500],
        [11726836.0000,  1267523.0000],
        [11091102.0000,  2625688.0000],
        [ 1382770.7500, 12773945.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 401/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:03, 57.98s/it]  7%|▋         | 2/29 [01:00<11:29, 25.54s/it] 10%|█         | 3/29 [01:01<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:02<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.10s/it] 21%|██        | 6/29 [01:04<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.787353515625
Epoch 402/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:24, 60.89s/it]  7%|▋         | 2/29 [01:01<11:31, 25.61s/it] 10%|█         | 3/29 [01:02<06:12, 14.34s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.04s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.825150966644287
Epoch 403/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:27, 58.84s/it]  7%|▋         | 2/29 [01:01<11:37, 25.83s/it] 10%|█         | 3/29 [01:02<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.814177989959717
Epoch 404/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:14, 58.38s/it]  7%|▋         | 2/29 [01:01<11:41, 26.00s/it] 10%|█         | 3/29 [01:02<06:18, 14.55s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.19s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8022890090942383
Epoch 405/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:48, 61.75s/it]  7%|▋         | 2/29 [01:02<11:41, 25.97s/it] 10%|█         | 3/29 [01:03<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.16s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.8162741661071777
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0136, 0.0022,  ..., 0.0040, 0.0001, 0.0194],
        [0.0029, 0.0093, 0.0022,  ..., 0.0023, 0.0002, 0.0182],
        [0.0334, 0.0060, 0.0035,  ..., 0.0050, 0.0161, 0.0243],
        ...,
        [0.0072, 0.0077, 0.0184,  ..., 0.0040, 0.0017, 0.0205],
        [0.0043, 0.0080, 0.0123,  ..., 0.0048, 0.0050, 0.0198],
        [0.0091, 0.0044, 0.0041,  ..., 0.0025, 0.0023, 0.0224]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9962, 0.9953, 0.9952, 0.9949, 0.9948, 0.9947, 0.9946, 0.9946,
         0.9943],
        [0.9973, 0.9968, 0.9967, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9766, 0.9692, 0.9677, 0.9676, 0.9675, 0.9674, 0.9671, 0.9647, 0.9647,
         0.9644],
        [0.9934, 0.9924, 0.9923, 0.9923, 0.9919, 0.9913, 0.9911, 0.9903, 0.9897,
         0.9897],
        [0.9884, 0.9873, 0.9863, 0.9849, 0.9848, 0.9846, 0.9845, 0.9841, 0.9841,
         0.9838],
        [0.9848, 0.9836, 0.9801, 0.9778, 0.9762, 0.9746, 0.9745, 0.9742, 0.9735,
         0.9733],
        [0.9801, 0.9721, 0.9707, 0.9684, 0.9679, 0.9667, 0.9653, 0.9651, 0.9638,
         0.9632],
        [0.9760, 0.9740, 0.9687, 0.9678, 0.9600, 0.9561, 0.9559, 0.9557, 0.9548,
         0.9523],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9937, 0.9899, 0.9882, 0.9878, 0.9868, 0.9866, 0.9852, 0.9841, 0.9837,
         0.9832],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9976],
        [0.9937, 0.9928, 0.9912, 0.9908, 0.9906, 0.9903, 0.9901, 0.9901, 0.9900,
         0.9891],
        [0.9918, 0.9907, 0.9892, 0.9882, 0.9870, 0.9860, 0.9853, 0.9840, 0.9836,
         0.9824],
        [0.9985, 0.9983, 0.9982, 0.9981, 0.9980, 0.9977, 0.9975, 0.9974, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986,
         0.9986],
        [0.9965, 0.9963, 0.9963, 0.9960, 0.9960, 0.9957, 0.9956, 0.9956, 0.9955,
         0.9955],
        [0.9954, 0.9949, 0.9948, 0.9946, 0.9945, 0.9945, 0.9944, 0.9944, 0.9943,
         0.9943],
        [0.9946, 0.9938, 0.9938, 0.9937, 0.9934, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9932],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9952, 0.9944, 0.9942, 0.9941, 0.9939, 0.9939, 0.9937, 0.9933, 0.9929,
         0.9928],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9979, 0.9976,
         0.9975],
        [0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9952, 0.9951, 0.9946, 0.9945, 0.9942, 0.9942, 0.9940, 0.9940, 0.9940,
         0.9938],
        [0.9990, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9978],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9885, 0.9870, 0.9779, 0.9720, 0.9694, 0.9683, 0.9681, 0.9657, 0.9651,
         0.9611],
        [0.9964, 0.9963, 0.9961, 0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957,
         0.9956],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9967, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9962,
         0.9961],
        [0.9857, 0.9837, 0.9802, 0.9764, 0.9746, 0.9742, 0.9725, 0.9715, 0.9696,
         0.9696],
        [0.9957, 0.9955, 0.9952, 0.9952, 0.9952, 0.9950, 0.9950, 0.9949, 0.9949,
         0.9949],
        [0.9927, 0.9921, 0.9916, 0.9913, 0.9912, 0.9910, 0.9907, 0.9904, 0.9902,
         0.9902],
        [0.9961, 0.9959, 0.9958, 0.9958, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9853, 0.9851, 0.9849, 0.9849, 0.9831, 0.9822, 0.9815, 0.9801, 0.9798,
         0.9793],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968, 0.9968, 0.9966, 0.9966,
         0.9965],
        [0.9899, 0.9874, 0.9866, 0.9859, 0.9853, 0.9844, 0.9842, 0.9838, 0.9830,
         0.9829],
        [0.9860, 0.9793, 0.9784, 0.9777, 0.9776, 0.9774, 0.9773, 0.9767, 0.9766,
         0.9763],
        [0.9872, 0.9865, 0.9739, 0.9723, 0.9623, 0.9588, 0.9574, 0.9572, 0.9569,
         0.9562],
        [0.9733, 0.9692, 0.9690, 0.9667, 0.9658, 0.9637, 0.9633, 0.9629, 0.9621,
         0.9538],
        [0.9910, 0.9898, 0.9895, 0.9889, 0.9887, 0.9883, 0.9881, 0.9876, 0.9875,
         0.9874],
        [0.9942, 0.9942, 0.9941, 0.9940, 0.9939, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9928],
        [0.9919, 0.9918, 0.9917, 0.9916, 0.9912, 0.9908, 0.9907, 0.9906, 0.9906,
         0.9905],
        [0.9911, 0.9909, 0.9898, 0.9897, 0.9891, 0.9891, 0.9872, 0.9872, 0.9869,
         0.9866],
        [0.9938, 0.9931, 0.9929, 0.9924, 0.9919, 0.9919, 0.9908, 0.9901, 0.9900,
         0.9896],
        [0.9906, 0.9878, 0.9869, 0.9868, 0.9860, 0.9857, 0.9850, 0.9850, 0.9844,
         0.9834],
        [0.9952, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9946, 0.9946, 0.9943,
         0.9943],
        [0.9958, 0.9951, 0.9950, 0.9950, 0.9946, 0.9936, 0.9934, 0.9934, 0.9932,
         0.9932],
        [0.9945, 0.9914, 0.9902, 0.9902, 0.9895, 0.9895, 0.9892, 0.9891, 0.9883,
         0.9882],
        [0.9918, 0.9912, 0.9908, 0.9908, 0.9876, 0.9872, 0.9864, 0.9863, 0.9859,
         0.9859],
        [0.9920, 0.9919, 0.9911, 0.9907, 0.9892, 0.9890, 0.9889, 0.9882, 0.9867,
         0.9860],
        [0.9968, 0.9941, 0.9930, 0.9924, 0.9921, 0.9912, 0.9886, 0.9883, 0.9879,
         0.9879],
        [0.9899, 0.9888, 0.9883, 0.9881, 0.9879, 0.9875, 0.9875, 0.9871, 0.9868,
         0.9862],
        [0.9919, 0.9914, 0.9879, 0.9857, 0.9846, 0.9839, 0.9838, 0.9836, 0.9829,
         0.9825],
        [0.9925, 0.9924, 0.9921, 0.9917, 0.9915, 0.9899, 0.9864, 0.9862, 0.9854,
         0.9843],
        [0.9927, 0.9924, 0.9921, 0.9921, 0.9921, 0.9916, 0.9915, 0.9909, 0.9898,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1516060.2500, 1515357.7500, 1496625.3750, 1494010.0000, 1488534.5000,
         1485689.5000, 1482884.0000, 1482106.3750, 1481799.6250, 1475048.8750],
        [1539964.1250, 1528969.7500, 1526545.3750, 1526018.5000, 1525759.3750,
         1525609.5000, 1524949.2500, 1524236.6250, 1523254.3750, 1522968.1250],
        [1146132.0000, 1030584.1875, 1009420.8125, 1006848.0625, 1005812.4375,
         1004362.2500, 1000625.0000,  966992.6250,  966886.5625,  961906.3125],
        [1456216.0000, 1436680.7500, 1433222.6250, 1432636.3750, 1425881.1250,
         1413141.0000, 1408910.3750, 1392484.0000, 1381642.3750, 1380831.0000],
        [1355234.2500, 1334139.3750, 1316688.6250, 1289945.2500, 1288519.0000,
         1283600.7500, 1283007.2500, 1275404.6250, 1274649.3750, 1269727.2500],
        [1288431.8750, 1265892.0000, 1204105.3750, 1165731.8750, 1139865.3750,
         1113793.8750, 1110997.5000, 1107353.2500, 1096488.5000, 1093569.6250],
        [1203625.5000, 1074436.7500, 1052327.7500, 1018546.4375, 1011532.2500,
          994614.1250,  974768.3125,  971484.0000,  954457.1875,  945785.7500],
        [1135674.7500, 1103469.6250, 1024018.1250, 1010677.8750,  904073.0625,
          855005.3750,  851930.3750,  849426.0000,  838942.3750,  809132.3750],
        [1544919.8750, 1531533.7500, 1531361.5000, 1523761.3750, 1523046.6250,
         1522777.8750, 1519192.2500, 1517813.6250, 1517731.1250, 1517621.1250],
        [1463243.3750, 1385459.5000, 1352651.8750, 1343409.8750, 1325217.1250,
         1320903.2500, 1294926.0000, 1275778.0000, 1268133.5000, 1259580.7500],
        [1556070.3750, 1556061.5000, 1554986.0000, 1554757.6250, 1552031.7500,
         1551107.0000, 1550505.0000, 1549430.5000, 1548700.6250, 1547333.6250],
        [1462604.3750, 1443138.8750, 1412123.8750, 1402929.0000, 1399860.3750,
         1393887.0000, 1389699.3750, 1388908.3750, 1387986.7500, 1370320.5000],
        [1423932.3750, 1401062.5000, 1372276.8750, 1352210.7500, 1328589.6250,
         1309413.1250, 1296861.3750, 1273540.1250, 1265694.1250, 1243700.5000],
        [1565649.2500, 1561472.6250, 1558775.1250, 1557972.6250, 1554812.5000,
         1547890.0000, 1543203.0000, 1541402.6250, 1540495.8750, 1540378.2500],
        [1577549.6250, 1577308.8750, 1576260.8750, 1575924.0000, 1575136.7500,
         1574935.5000, 1574867.8750, 1574824.3750, 1574346.8750, 1573275.1250],
        [1575764.7500, 1572814.6250, 1571970.3750, 1571552.1250, 1571083.0000,
         1570615.6250, 1570054.1250, 1569055.7500, 1568630.7500, 1567648.2500],
        [1522018.6250, 1517916.3750, 1517162.3750, 1511975.6250, 1511842.8750,
         1505065.8750, 1503188.1250, 1502968.7500, 1500844.6250, 1500277.8750],
        [1498893.5000, 1486911.3750, 1484894.8750, 1480518.5000, 1480127.3750,
         1479014.1250, 1477436.6250, 1476423.8750, 1475841.1250, 1474331.6250],
        [1482069.6250, 1465008.3750, 1464305.6250, 1461898.7500, 1457306.5000,
         1455512.1250, 1454954.2500, 1454339.6250, 1452292.5000, 1451830.0000],
        [1556143.1250, 1553266.7500, 1552995.7500, 1551220.8750, 1549570.7500,
         1548787.7500, 1548234.0000, 1548213.2500, 1546538.5000, 1546460.2500],
        [1556049.6250, 1552162.1250, 1551792.0000, 1550617.3750, 1550070.3750,
         1549222.1250, 1547068.0000, 1546532.5000, 1543320.6250, 1542464.3750],
        [1494577.1250, 1476340.7500, 1473453.2500, 1471979.8750, 1467045.3750,
         1466021.5000, 1463258.7500, 1455179.0000, 1445458.5000, 1444108.1250],
        [1574052.6250, 1571727.5000, 1562576.3750, 1562178.6250, 1561678.1250,
         1556919.5000, 1553657.8750, 1552603.2500, 1545904.3750, 1545085.0000],
        [1579924.0000, 1576372.0000, 1574800.2500, 1574728.1250, 1574414.3750,
         1573937.0000, 1573707.3750, 1572402.1250, 1572292.6250, 1571051.6250],
        [1493494.2500, 1492620.0000, 1481654.0000, 1478667.2500, 1473235.3750,
         1472731.0000, 1469319.2500, 1468722.3750, 1468368.0000, 1464449.5000],
        [1577321.0000, 1573372.6250, 1569877.3750, 1568203.0000, 1568108.7500,
         1567165.5000, 1565747.8750, 1564158.3750, 1564053.8750, 1564052.3750],
        [1566735.1250, 1565071.5000, 1561891.1250, 1561749.6250, 1559374.2500,
         1556503.7500, 1554286.1250, 1554149.8750, 1553142.2500, 1551772.7500],
        [1576499.8750, 1575099.2500, 1574108.1250, 1574078.1250, 1573940.0000,
         1573578.3750, 1571974.8750, 1570722.1250, 1570217.2500, 1570131.8750],
        [1579298.7500, 1578961.3750, 1578825.8750, 1576451.7500, 1576387.0000,
         1576284.7500, 1575416.1250, 1575234.3750, 1574965.5000, 1574923.5000],
        [1581137.3750, 1580213.2500, 1576382.6250, 1575782.8750, 1575643.0000,
         1575638.6250, 1575611.5000, 1575144.2500, 1574267.2500, 1573083.1250],
        [1581191.5000, 1580062.6250, 1579688.8750, 1578538.3750, 1578225.2500,
         1577921.2500, 1577141.8750, 1576166.1250, 1576059.3750, 1575685.1250],
        [1580929.2500, 1578815.3750, 1576814.1250, 1576744.8750, 1576305.8750,
         1576003.7500, 1575912.0000, 1575829.3750, 1575129.2500, 1575003.0000],
        [1357595.1250, 1328974.7500, 1167420.6250, 1071994.7500, 1033174.2500,
         1017223.3125, 1014224.3125,  980027.3750,  971751.7500,  918134.9375],
        [1520238.6250, 1517919.3750, 1513086.2500, 1511909.2500, 1509103.1250,
         1508881.3750, 1507080.8750, 1505966.0000, 1505156.2500, 1501911.3750],
        [1555057.1250, 1553560.0000, 1551756.5000, 1549365.5000, 1548331.5000,
         1547063.5000, 1546967.6250, 1546758.1250, 1546019.3750, 1546012.0000],
        [1526134.8750, 1521027.5000, 1519742.8750, 1519169.0000, 1519115.5000,
         1518743.2500, 1515127.8750, 1515073.0000, 1514860.6250, 1514644.0000],
        [1305433.2500, 1267375.3750, 1206015.3750, 1141529.7500, 1113878.8750,
         1107581.3750, 1081083.7500, 1065698.3750, 1037020.1875, 1036802.6250],
        [1505370.1250, 1500727.2500, 1494487.3750, 1493908.7500, 1493839.0000,
         1490293.0000, 1489451.8750, 1488727.5000, 1488723.3750, 1488306.0000],
        [1440992.0000, 1428693.2500, 1419358.0000, 1414029.3750, 1410764.3750,
         1407582.0000, 1400930.2500, 1394421.6250, 1390915.2500, 1390444.3750],
        [1512885.6250, 1508280.1250, 1506050.7500, 1506050.7500, 1501484.6250,
         1500639.8750, 1499293.8750, 1496417.0000, 1495994.6250, 1495970.2500],
        [1297410.6250, 1293797.7500, 1290008.0000, 1289664.7500, 1256532.1250,
         1240535.2500, 1228559.2500, 1204863.5000, 1198849.5000, 1190491.3750],
        [1564917.7500, 1562928.1250, 1559935.1250, 1559642.0000, 1558706.7500,
         1557996.2500, 1557816.6250, 1557632.3750, 1556153.5000, 1556114.8750],
        [1557693.2500, 1557503.2500, 1555385.0000, 1550737.1250, 1550636.6250,
         1549882.6250, 1548734.6250, 1548489.5000, 1546402.7500, 1546395.3750],
        [1540585.5000, 1535368.2500, 1533736.5000, 1533685.2500, 1531399.3750,
         1528980.0000, 1528847.2500, 1525421.8750, 1523902.5000, 1523312.5000],
        [1384560.0000, 1335776.5000, 1321747.5000, 1308494.5000, 1297811.6250,
         1280468.3750, 1276390.1250, 1270269.8750, 1254826.8750, 1254149.6250],
        [1310075.2500, 1190275.7500, 1174830.0000, 1164330.7500, 1162368.1250,
         1159007.6250, 1157233.7500, 1146956.5000, 1145489.5000, 1140896.2500],
        [1332429.1250, 1319372.2500, 1101656.8750, 1077789.6250,  933684.5000,
          888388.5625,  870539.5000,  868238.7500,  864539.6250,  856367.3125],
        [1092958.6250, 1030705.0000, 1027467.3750,  994061.2500,  981791.6250,
          952544.8125,  947651.9375,  941484.1250,  931866.2500,  826797.1875],
        [1407657.2500, 1383432.8750, 1376728.3750, 1366482.3750, 1361358.7500,
         1353484.2500, 1349797.6250, 1340641.6250, 1338436.6250, 1336856.0000],
        [1473298.6250, 1472176.3750, 1470416.7500, 1469421.6250, 1466835.3750,
         1457021.6250, 1453918.0000, 1453376.1250, 1453044.7500, 1443246.2500],
        [1424570.7500, 1422591.3750, 1420817.8750, 1419033.1250, 1411678.2500,
         1402864.8750, 1401230.8750, 1399604.1250, 1398519.3750, 1397398.2500],
        [1408935.8750, 1405490.8750, 1384025.3750, 1382177.3750, 1370498.1250,
         1370027.7500, 1333078.6250, 1332746.8750, 1326770.0000, 1321560.8750],
        [1465108.8750, 1449360.7500, 1446736.8750, 1434852.7500, 1426325.7500,
         1425902.8750, 1402406.0000, 1389173.2500, 1386349.1250, 1380191.1250],
        [1398475.3750, 1345158.5000, 1327271.2500, 1325463.6250, 1310870.1250,
         1304746.2500, 1292404.2500, 1291719.1250, 1281398.0000, 1262919.6250],
        [1494903.5000, 1494054.1250, 1494054.1250, 1492361.0000, 1491255.5000,
         1490310.1250, 1481809.5000, 1481278.2500, 1475331.6250, 1475153.0000],
        [1506421.3750, 1491292.5000, 1489997.5000, 1489488.7500, 1481777.1250,
         1460122.2500, 1457100.8750, 1456049.3750, 1452191.5000, 1451197.5000],
        [1479658.8750, 1415963.1250, 1392084.3750, 1391889.1250, 1378312.7500,
         1377980.2500, 1371094.2500, 1369161.7500, 1353791.3750, 1352284.2500],
        [1422598.1250, 1411652.6250, 1402759.1250, 1402237.5000, 1341361.6250,
         1332101.3750, 1317354.3750, 1316250.5000, 1308620.5000, 1308258.6250],
        [1427573.7500, 1425970.8750, 1408613.3750, 1400550.7500, 1370636.7500,
         1368385.0000, 1365487.1250, 1352324.2500, 1324325.2500, 1309744.2500],
        [1527803.7500, 1470071.8750, 1447930.7500, 1436525.8750, 1428716.3750,
         1411683.6250, 1359074.3750, 1353140.8750, 1346743.7500, 1345403.5000],
        [1385729.1250, 1362817.5000, 1353745.0000, 1350106.5000, 1346878.5000,
         1339174.6250, 1338037.1250, 1331909.5000, 1325505.3750, 1313871.3750],
        [1425931.3750, 1414863.1250, 1346103.0000, 1304476.1250, 1283609.3750,
         1270955.7500, 1269571.0000, 1265968.1250, 1253071.2500, 1246725.1250],
        [1438273.6250, 1435127.8750, 1428840.3750, 1422320.0000, 1416666.8750,
         1385726.5000, 1317349.3750, 1313927.7500, 1298643.6250, 1279239.3750],
        [1442384.8750, 1434880.2500, 1430517.3750, 1430300.5000, 1430083.6250,
         1419730.2500, 1417426.3750, 1405732.1250, 1383587.2500, 1380412.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1516060.2500,       0.0000],
         [1515357.7500,       0.0000],
         [1496625.3750,       0.0000],
         ...,
         [1482106.3750,       0.0000],
         [      0.0000, 1481799.6250],
         [1475048.8750,       0.0000]],

        [[1539964.1250,       0.0000],
         [1528969.7500,       0.0000],
         [1526545.3750,       0.0000],
         ...,
         [1524236.6250,       0.0000],
         [1523254.3750,       0.0000],
         [1522968.1250,       0.0000]],

        [[1146132.0000,       0.0000],
         [      0.0000, 1030584.1875],
         [      0.0000, 1009420.8125],
         ...,
         [ 966992.6250,       0.0000],
         [ 966886.5625,       0.0000],
         [ 961906.3125,       0.0000]],

        ...,

        [[1425931.3750,       0.0000],
         [1414863.1250,       0.0000],
         [1346103.0000,       0.0000],
         ...,
         [1265968.1250,       0.0000],
         [1253071.2500,       0.0000],
         [      0.0000, 1246725.1250]],

        [[1438273.6250,       0.0000],
         [1435127.8750,       0.0000],
         [1428840.3750,       0.0000],
         ...,
         [      0.0000, 1313927.7500],
         [1298643.6250,       0.0000],
         [1279239.3750,       0.0000]],

        [[      0.0000, 1442384.8750],
         [      0.0000, 1434880.2500],
         [      0.0000, 1430517.3750],
         ...,
         [      0.0000, 1405732.1250],
         [      0.0000, 1383587.2500],
         [1380412.2500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13436316.0000,  1481799.6250],
        [15268275.0000,        0.0000],
        [ 5048765.5000,  5050805.0000],
        [12748504.0000,  1413141.0000],
        [ 9137854.0000,  3833061.0000],
        [ 9324009.0000,  2262220.5000],
        [ 5045554.0000,  5156024.0000],
        [ 8527344.0000,   855005.3750],
        [13732138.0000,  1517621.1250],
        [11903844.0000,  1385459.5000],
        [15520983.0000,        0.0000],
        [14051458.0000,        0.0000],
        [13267281.0000,        0.0000],
        [15512051.0000,        0.0000],
        [15754430.0000,        0.0000],
        [15709190.0000,        0.0000],
        [13571242.0000,  1522018.6250],
        [11841168.0000,  2973225.0000],
        [14599518.0000,        0.0000],
        [15501432.0000,        0.0000],
        [15489299.0000,        0.0000],
        [13185443.0000,  1471979.8750],
        [15586383.0000,        0.0000],
        [15743630.0000,        0.0000],
        [10307828.0000,  4455433.5000],
        [15682060.0000,        0.0000],
        [15584676.0000,        0.0000],
        [15730349.0000,        0.0000],
        [15766748.0000,        0.0000],
        [15762904.0000,        0.0000],
        [15780680.0000,        0.0000],
        [15767486.0000,        0.0000],
        [ 2949582.5000,  7910938.5000],
        [ 9059383.0000,  6041870.0000],
        [12396860.0000,  3094031.0000],
        [12150251.0000,  3033387.2500],
        [ 3216380.0000,  8146039.0000],
        [11939268.0000,  2994566.2500],
        [12703709.0000,  1394421.6250],
        [15023068.0000,        0.0000],
        [ 9936769.0000,  2553942.7500],
        [15591844.0000,        0.0000],
        [15511860.0000,        0.0000],
        [13771502.0000,  1533736.5000],
        [ 2534618.0000, 10449877.0000],
        [ 1162368.1250, 10589095.0000],
        [ 5281758.0000,  4831248.0000],
        [ 2706315.5000,  7021013.0000],
        [ 4076524.0000,  9538352.0000],
        [10203327.0000,  4409428.5000],
        [12675717.0000,  1422591.3750],
        [ 1321560.8750, 12313750.0000],
        [ 1380191.1250, 12826216.0000],
        [ 2652735.0000, 10487691.0000],
        [11885297.0000,  2985213.5000],
        [10256148.0000,  4479491.0000],
        [ 2747474.5000, 11134745.0000],
        [ 5283587.0000,  8279607.0000],
        [ 1309744.2500, 12443867.0000],
        [ 2704478.0000, 11422617.0000],
        [10730136.0000,  2717638.5000],
        [10563593.0000,  2517681.0000],
        [11104838.0000,  2631277.0000],
        [ 1380412.2500, 12794642.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 406/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:25, 60.90s/it]  7%|▋         | 2/29 [01:01<11:31, 25.62s/it] 10%|█         | 3/29 [01:02<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.812042713165283
Epoch 407/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:53, 61.92s/it]  7%|▋         | 2/29 [01:02<11:42, 26.04s/it] 10%|█         | 3/29 [01:03<06:18, 14.57s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.20s/it] 21%|██        | 6/29 [01:06<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.8146800994873047
Epoch 408/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:05, 58.04s/it]  7%|▋         | 2/29 [00:58<10:59, 24.44s/it] 10%|█         | 3/29 [00:59<05:56, 13.70s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.66s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.87s/it] 21%|██        | 6/29 [01:02<01:36,  4.19s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.63s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 2.801985263824463
Epoch 409/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:14, 58.36s/it]  7%|▋         | 2/29 [00:59<11:05, 24.66s/it] 10%|█         | 3/29 [01:00<05:59, 13.82s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.73s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.22s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.807340621948242
Epoch 410/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:50, 59.65s/it]  7%|▋         | 2/29 [01:01<11:36, 25.78s/it] 10%|█         | 3/29 [01:02<06:15, 14.43s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.10s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.15s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8031065464019775
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0029, 0.0136, 0.0022,  ..., 0.0040, 0.0001, 0.0194],
        [0.0030, 0.0094, 0.0022,  ..., 0.0024, 0.0002, 0.0183],
        [0.0336, 0.0060, 0.0036,  ..., 0.0051, 0.0160, 0.0241],
        ...,
        [0.0076, 0.0080, 0.0194,  ..., 0.0042, 0.0018, 0.0205],
        [0.0045, 0.0082, 0.0127,  ..., 0.0050, 0.0050, 0.0200],
        [0.0095, 0.0044, 0.0042,  ..., 0.0027, 0.0023, 0.0226]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9953, 0.9952, 0.9950, 0.9949, 0.9947, 0.9947, 0.9947,
         0.9943],
        [0.9972, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9966, 0.9965,
         0.9964],
        [0.9761, 0.9694, 0.9674, 0.9671, 0.9670, 0.9669, 0.9668, 0.9649, 0.9647,
         0.9646],
        [0.9936, 0.9925, 0.9923, 0.9923, 0.9921, 0.9915, 0.9913, 0.9904, 0.9898,
         0.9898],
        [0.9886, 0.9870, 0.9866, 0.9851, 0.9849, 0.9849, 0.9846, 0.9846, 0.9845,
         0.9841],
        [0.9849, 0.9835, 0.9804, 0.9785, 0.9767, 0.9755, 0.9754, 0.9744, 0.9740,
         0.9738],
        [0.9791, 0.9725, 0.9715, 0.9683, 0.9682, 0.9648, 0.9644, 0.9641, 0.9640,
         0.9628],
        [0.9753, 0.9739, 0.9693, 0.9661, 0.9594, 0.9561, 0.9549, 0.9548, 0.9537,
         0.9507],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9938, 0.9899, 0.9886, 0.9876, 0.9872, 0.9868, 0.9855, 0.9844, 0.9840,
         0.9840],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9937, 0.9928, 0.9911, 0.9908, 0.9907, 0.9904, 0.9902, 0.9901, 0.9901,
         0.9891],
        [0.9919, 0.9912, 0.9892, 0.9885, 0.9870, 0.9863, 0.9858, 0.9843, 0.9841,
         0.9826],
        [0.9984, 0.9982, 0.9981, 0.9981, 0.9979, 0.9976, 0.9973, 0.9973, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9965, 0.9962, 0.9962, 0.9960, 0.9960, 0.9956, 0.9956, 0.9956, 0.9955,
         0.9954],
        [0.9955, 0.9949, 0.9947, 0.9946, 0.9946, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9946, 0.9937, 0.9936, 0.9935, 0.9934, 0.9933, 0.9932, 0.9932, 0.9932,
         0.9931],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9974,
         0.9974],
        [0.9952, 0.9943, 0.9941, 0.9941, 0.9940, 0.9938, 0.9937, 0.9934, 0.9929,
         0.9928],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9982, 0.9980, 0.9979, 0.9978, 0.9975,
         0.9974],
        [0.9991, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9952, 0.9951, 0.9947, 0.9944, 0.9942, 0.9942, 0.9940, 0.9940, 0.9940,
         0.9937],
        [0.9990, 0.9988, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9885, 0.9871, 0.9779, 0.9716, 0.9692, 0.9688, 0.9687, 0.9655, 0.9641,
         0.9619],
        [0.9964, 0.9963, 0.9960, 0.9960, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957,
         0.9955],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9966, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9856, 0.9835, 0.9802, 0.9759, 0.9743, 0.9742, 0.9722, 0.9712, 0.9692,
         0.9691],
        [0.9957, 0.9955, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9927, 0.9920, 0.9917, 0.9915, 0.9911, 0.9910, 0.9906, 0.9904, 0.9904,
         0.9903],
        [0.9961, 0.9958, 0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9953, 0.9953,
         0.9952],
        [0.9851, 0.9850, 0.9847, 0.9847, 0.9827, 0.9819, 0.9813, 0.9798, 0.9795,
         0.9791],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9970, 0.9969, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965,
         0.9965],
        [0.9895, 0.9868, 0.9860, 0.9854, 0.9849, 0.9839, 0.9839, 0.9834, 0.9828,
         0.9824],
        [0.9853, 0.9787, 0.9784, 0.9776, 0.9775, 0.9774, 0.9773, 0.9765, 0.9763,
         0.9760],
        [0.9874, 0.9864, 0.9738, 0.9717, 0.9620, 0.9598, 0.9565, 0.9561, 0.9560,
         0.9558],
        [0.9734, 0.9695, 0.9686, 0.9666, 0.9657, 0.9635, 0.9633, 0.9628, 0.9619,
         0.9536],
        [0.9911, 0.9897, 0.9895, 0.9887, 0.9885, 0.9882, 0.9881, 0.9874, 0.9873,
         0.9871],
        [0.9941, 0.9941, 0.9940, 0.9939, 0.9938, 0.9932, 0.9932, 0.9931, 0.9931,
         0.9926],
        [0.9917, 0.9915, 0.9915, 0.9915, 0.9910, 0.9906, 0.9904, 0.9904, 0.9903,
         0.9903],
        [0.9909, 0.9907, 0.9895, 0.9895, 0.9889, 0.9888, 0.9868, 0.9868, 0.9864,
         0.9863],
        [0.9937, 0.9929, 0.9928, 0.9922, 0.9918, 0.9918, 0.9907, 0.9899, 0.9897,
         0.9895],
        [0.9905, 0.9876, 0.9868, 0.9865, 0.9857, 0.9854, 0.9848, 0.9848, 0.9840,
         0.9832],
        [0.9952, 0.9951, 0.9951, 0.9950, 0.9949, 0.9949, 0.9945, 0.9945, 0.9943,
         0.9941],
        [0.9957, 0.9950, 0.9949, 0.9949, 0.9946, 0.9934, 0.9933, 0.9933, 0.9931,
         0.9931],
        [0.9945, 0.9912, 0.9901, 0.9900, 0.9894, 0.9892, 0.9890, 0.9890, 0.9882,
         0.9880],
        [0.9916, 0.9911, 0.9907, 0.9905, 0.9873, 0.9869, 0.9860, 0.9860, 0.9857,
         0.9856],
        [0.9919, 0.9917, 0.9910, 0.9905, 0.9889, 0.9888, 0.9888, 0.9877, 0.9865,
         0.9857],
        [0.9967, 0.9940, 0.9929, 0.9924, 0.9920, 0.9909, 0.9882, 0.9880, 0.9877,
         0.9875],
        [0.9897, 0.9887, 0.9883, 0.9882, 0.9879, 0.9876, 0.9875, 0.9870, 0.9867,
         0.9860],
        [0.9915, 0.9908, 0.9874, 0.9850, 0.9840, 0.9836, 0.9830, 0.9830, 0.9822,
         0.9820],
        [0.9924, 0.9922, 0.9919, 0.9916, 0.9913, 0.9898, 0.9860, 0.9860, 0.9851,
         0.9840],
        [0.9926, 0.9921, 0.9920, 0.9920, 0.9919, 0.9914, 0.9914, 0.9908, 0.9896,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1516977.1250, 1516339.2500, 1497466.2500, 1494283.6250, 1490437.8750,
         1487257.3750, 1484199.7500, 1484088.0000, 1483807.7500, 1475558.2500],
        [1538449.2500, 1528410.0000, 1525958.7500, 1525798.7500, 1525210.8750,
         1524187.2500, 1524076.8750, 1523760.0000, 1522198.6250, 1520976.7500],
        [1137397.1250, 1033447.1875, 1005004.1875, 1000181.3750,  998651.6250,
          996824.6875,  996026.4375,  968986.6250,  966220.1250,  964687.1250],
        [1460212.7500, 1437908.8750, 1433904.7500, 1433210.2500, 1429605.0000,
         1416438.6250, 1412739.5000, 1394541.1250, 1383644.0000, 1383562.2500],
        [1359710.8750, 1329815.3750, 1321232.0000, 1293037.8750, 1290666.3750,
         1290129.7500, 1285139.3750, 1284611.1250, 1282969.3750, 1275245.2500],
        [1289910.7500, 1264596.1250, 1210006.1250, 1176366.0000, 1147405.0000,
         1128028.2500, 1126812.1250, 1110029.5000, 1104475.1250, 1101368.0000],
        [1188024.6250, 1079655.7500, 1065353.7500, 1018137.5625, 1016480.5000,
          968062.9375,  962122.8125,  958686.3125,  956973.6250,  940926.6875],
        [1125015.7500, 1102460.8750, 1031477.9375,  986474.9375,  895856.7500,
          854627.9375,  839792.5000,  838845.6250,  825429.5000,  790857.8125],
        [1544554.6250, 1531278.2500, 1530882.6250, 1523605.8750, 1523343.0000,
         1522169.6250, 1519490.7500, 1518457.8750, 1517282.3750, 1517094.3750],
        [1464720.5000, 1385042.1250, 1359476.2500, 1340699.1250, 1332351.6250,
         1325768.2500, 1300897.1250, 1279803.1250, 1274150.0000, 1272838.2500],
        [1556316.7500, 1555956.1250, 1555893.7500, 1555112.0000, 1551707.7500,
         1550117.6250, 1549652.1250, 1549573.7500, 1549214.7500, 1546476.5000],
        [1461896.0000, 1443818.8750, 1408348.7500, 1402969.1250, 1401990.1250,
         1395830.5000, 1391179.2500, 1389036.8750, 1388593.1250, 1370298.2500],
        [1424615.6250, 1411699.7500, 1371038.0000, 1357788.0000, 1328283.0000,
         1315965.6250, 1306611.5000, 1279307.6250, 1275511.5000, 1248359.8750],
        [1564973.0000, 1560393.2500, 1557507.6250, 1556598.8750, 1553942.3750,
         1546500.1250, 1540648.6250, 1540228.5000, 1538911.5000, 1538904.2500],
        [1576970.3750, 1576731.3750, 1575703.2500, 1575604.0000, 1574794.2500,
         1574549.5000, 1574351.2500, 1574291.2500, 1573843.8750, 1572813.1250],
        [1575483.8750, 1572585.1250, 1571640.6250, 1570734.0000, 1570665.1250,
         1570543.7500, 1569323.6250, 1568864.2500, 1567806.7500, 1567312.0000],
        [1522065.1250, 1516502.7500, 1516479.6250, 1512072.1250, 1511303.7500,
         1502864.1250, 1501944.3750, 1501791.1250, 1499999.0000, 1499266.6250],
        [1499807.2500, 1487128.3750, 1483943.6250, 1481062.2500, 1480519.8750,
         1478166.6250, 1476461.8750, 1475859.3750, 1475502.0000, 1475410.3750],
        [1480617.3750, 1462756.3750, 1461454.0000, 1459260.5000, 1456718.7500,
         1453516.0000, 1452307.7500, 1452210.8750, 1451387.1250, 1449966.2500],
        [1555675.7500, 1552795.7500, 1552560.3750, 1550805.2500, 1548755.2500,
         1548220.7500, 1547935.8750, 1547246.6250, 1546624.0000, 1546259.6250],
        [1555466.6250, 1552316.0000, 1551001.8750, 1550200.5000, 1549986.1250,
         1548954.6250, 1546550.2500, 1545649.3750, 1542839.5000, 1541586.2500],
        [1493823.3750, 1476180.3750, 1471389.0000, 1470409.8750, 1469741.0000,
         1465089.3750, 1463324.3750, 1455967.3750, 1446346.3750, 1443765.2500],
        [1573066.6250, 1571633.1250, 1561137.5000, 1561103.3750, 1560543.6250,
         1556204.0000, 1552782.5000, 1551584.8750, 1544644.3750, 1542386.3750],
        [1579699.3750, 1576378.0000, 1574453.3750, 1574382.8750, 1573952.0000,
         1573737.3750, 1573506.2500, 1572178.7500, 1572054.2500, 1570527.2500],
        [1494538.7500, 1491601.1250, 1483016.8750, 1477600.1250, 1473807.2500,
         1472728.2500, 1469912.0000, 1468728.1250, 1468202.8750, 1462400.7500],
        [1576578.0000, 1572664.6250, 1569275.7500, 1568080.3750, 1567675.1250,
         1566714.1250, 1565149.0000, 1564122.5000, 1562896.8750, 1562576.3750],
        [1565952.3750, 1564253.8750, 1560436.5000, 1560360.5000, 1558397.6250,
         1554763.6250, 1553034.2500, 1552595.8750, 1552067.2500, 1550091.1250],
        [1575706.2500, 1574177.2500, 1573902.3750, 1573372.6250, 1573366.6250,
         1573092.1250, 1571277.8750, 1570454.0000, 1569724.7500, 1569155.8750],
        [1578920.7500, 1578466.1250, 1578442.0000, 1576014.2500, 1575825.0000,
         1575772.3750, 1574905.3750, 1574740.2500, 1574463.8750, 1574189.1250],
        [1581098.1250, 1580103.2500, 1576256.2500, 1575348.6250, 1575018.1250,
         1574967.0000, 1574959.5000, 1574908.3750, 1574078.1250, 1572942.1250],
        [1580724.1250, 1579687.3750, 1579471.8750, 1578136.5000, 1577897.1250,
         1577324.0000, 1576869.7500, 1575909.0000, 1575604.0000, 1575279.5000],
        [1580279.6250, 1578363.7500, 1576811.1250, 1576561.5000, 1575979.6250,
         1575616.0000, 1575166.7500, 1575117.2500, 1574863.3750, 1574830.3750],
        [1357991.2500, 1330528.3750, 1167787.1250, 1067095.6250, 1029973.0000,
         1024791.8750, 1023468.5000,  977327.1875,  957879.3750,  927954.3750],
        [1519282.0000, 1517509.6250, 1511267.7500, 1511018.3750, 1508283.0000,
         1507861.5000, 1505384.5000, 1504827.6250, 1504331.0000, 1501002.0000],
        [1554373.6250, 1552892.0000, 1550905.8750, 1548476.2500, 1548095.2500,
         1547013.3750, 1546677.1250, 1546588.6250, 1545874.8750, 1545698.0000],
        [1524209.1250, 1519708.0000, 1518107.5000, 1518019.1250, 1517499.6250,
         1517234.7500, 1515152.5000, 1513725.6250, 1513369.1250, 1512627.3750],
        [1302795.3750, 1264642.0000, 1205446.2500, 1134812.0000, 1107780.0000,
         1107036.6250, 1075216.7500, 1060999.0000, 1030283.4375, 1029594.8750],
        [1504732.8750, 1500152.1250, 1495366.8750, 1493249.3750, 1493064.1250,
         1490618.5000, 1489457.5000, 1489118.0000, 1488043.3750, 1487074.3750],
        [1441642.2500, 1428211.0000, 1422194.0000, 1417554.7500, 1409043.2500,
         1408018.3750, 1399733.6250, 1395504.3750, 1395476.5000, 1393152.1250],
        [1513041.5000, 1507582.6250, 1504708.5000, 1504708.5000, 1500369.5000,
         1499943.1250, 1498887.8750, 1496862.2500, 1496738.1250, 1494715.3750],
        [1292881.2500, 1291621.8750, 1286786.3750, 1285744.8750, 1249502.1250,
         1236112.6250, 1225176.7500, 1198799.1250, 1194787.3750, 1187752.6250],
        [1564374.5000, 1562102.6250, 1558793.0000, 1558781.0000, 1557723.0000,
         1557552.1250, 1556597.2500, 1555968.1250, 1555597.1250, 1555499.1250],
        [1557166.0000, 1556894.2500, 1554425.5000, 1550318.7500, 1550184.2500,
         1549748.1250, 1548835.0000, 1548694.7500, 1546507.5000, 1546150.6250],
        [1539544.2500, 1534797.3750, 1532191.2500, 1532083.1250, 1529912.0000,
         1528684.0000, 1526343.0000, 1523976.5000, 1522429.3750, 1522384.5000],
        [1377674.0000, 1325583.7500, 1310948.8750, 1298711.6250, 1289015.6250,
         1271352.2500, 1271064.8750, 1263041.3750, 1251008.0000, 1243675.6250],
        [1297612.2500, 1180151.7500, 1174781.8750, 1161800.7500, 1160372.3750,
         1158341.3750, 1156749.5000, 1143220.5000, 1141392.5000, 1136120.1250],
        [1336088.7500, 1316889.6250, 1100996.2500, 1068284.0000,  930400.1250,
          900644.5625,  859137.9375,  854513.8750,  853414.4375,  851098.0000],
        [1094770.7500, 1034548.6875, 1021865.1250,  992748.1250,  980385.3750,
          950065.3750,  946679.1250,  940524.7500,  928392.5625,  824411.4375],
        [1409950.6250, 1380915.1250, 1377446.7500, 1360922.6250, 1358303.5000,
         1351897.3750, 1349869.6250, 1336319.3750, 1335684.8750, 1330258.0000],
        [1471056.3750, 1469994.7500, 1468274.2500, 1466940.3750, 1465040.3750,
         1453195.8750, 1451437.0000, 1450294.0000, 1449510.0000, 1439795.6250],
        [1421437.2500, 1417767.0000, 1417549.3750, 1416787.2500, 1407175.3750,
         1398786.1250, 1395886.5000, 1395348.7500, 1393250.5000, 1392553.0000],
        [1404854.2500, 1400464.0000, 1377188.0000, 1376553.7500, 1366297.3750,
         1362977.5000, 1326126.2500, 1324835.6250, 1318129.6250, 1315955.6250],
        [1462866.6250, 1446543.7500, 1444706.0000, 1432365.8750, 1423690.7500,
         1423322.7500, 1400237.0000, 1384834.7500, 1380771.6250, 1377297.1250],
        [1396644.1250, 1341316.8750, 1325425.7500, 1320480.0000, 1304675.2500,
         1298287.0000, 1288825.0000, 1288171.3750, 1273917.8750, 1259099.1250],
        [1493779.1250, 1491151.6250, 1491151.6250, 1489116.6250, 1488388.2500,
         1488381.1250, 1479438.7500, 1478400.6250, 1475759.5000, 1471279.5000],
        [1504714.2500, 1490868.7500, 1487749.6250, 1487132.6250, 1480991.5000,
         1456027.2500, 1453460.6250, 1453428.6250, 1449123.0000, 1449123.0000],
        [1478761.7500, 1411660.7500, 1389091.2500, 1388011.8750, 1376076.0000,
         1371779.6250, 1366975.1250, 1366831.6250, 1351680.7500, 1348977.8750],
        [1418740.8750, 1408363.5000, 1401058.5000, 1398163.3750, 1334924.6250,
         1327294.1250, 1310935.1250, 1309486.8750, 1304786.0000, 1303183.0000],
        [1424704.0000, 1421046.8750, 1406941.8750, 1396962.3750, 1365959.8750,
         1363861.6250, 1363770.5000, 1343225.3750, 1319649.1250, 1304756.1250],
        [1526974.8750, 1468012.5000, 1445182.7500, 1435237.3750, 1427444.3750,
         1405607.5000, 1351830.3750, 1348885.2500, 1343357.3750, 1339292.1250],
        [1380663.7500, 1361853.5000, 1354053.5000, 1351684.7500, 1346981.3750,
         1340989.3750, 1338334.5000, 1329512.3750, 1324020.8750, 1310632.6250],
        [1417656.2500, 1403239.3750, 1336046.6250, 1291676.1250, 1273843.7500,
         1265852.2500, 1255561.7500, 1255300.7500, 1240626.3750, 1236602.0000],
        [1435801.3750, 1432178.6250, 1425272.0000, 1419312.0000, 1412528.0000,
         1382732.5000, 1310232.7500, 1309824.1250, 1293368.3750, 1273156.3750],
        [1438891.0000, 1430139.6250, 1426887.7500, 1426836.0000, 1424717.5000,
         1415713.3750, 1415246.3750, 1403503.1250, 1379372.6250, 1377490.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1516977.1250,       0.0000],
         [1516339.2500,       0.0000],
         [1497466.2500,       0.0000],
         ...,
         [1484088.0000,       0.0000],
         [1483807.7500,       0.0000],
         [1475558.2500,       0.0000]],

        [[1538449.2500,       0.0000],
         [1528410.0000,       0.0000],
         [1525958.7500,       0.0000],
         ...,
         [1523760.0000,       0.0000],
         [1522198.6250,       0.0000],
         [1520976.7500,       0.0000]],

        [[1137397.1250,       0.0000],
         [      0.0000, 1033447.1875],
         [1005004.1875,       0.0000],
         ...,
         [ 968986.6250,       0.0000],
         [ 966220.1250,       0.0000],
         [ 964687.1250,       0.0000]],

        ...,

        [[1417656.2500,       0.0000],
         [1403239.3750,       0.0000],
         [1336046.6250,       0.0000],
         ...,
         [1255300.7500,       0.0000],
         [1240626.3750,       0.0000],
         [1236602.0000,       0.0000]],

        [[1435801.3750,       0.0000],
         [1432178.6250,       0.0000],
         [1425272.0000,       0.0000],
         ...,
         [      0.0000, 1309824.1250],
         [1293368.3750,       0.0000],
         [1273156.3750,       0.0000]],

        [[      0.0000, 1438891.0000],
         [      0.0000, 1430139.6250],
         [      0.0000, 1426887.7500],
         ...,
         [      0.0000, 1403503.1250],
         [      0.0000, 1379372.6250],
         [1377490.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13446216.0000,  1484199.7500],
        [15259027.0000,        0.0000],
        [ 5042295.5000,  5025131.5000],
        [12769328.0000,  1416438.6250],
        [ 9159837.0000,  3852720.0000],
        [ 9381264.0000,  2277734.0000],
        [ 5059390.0000,  5095034.0000],
        [ 7661136.5000,  1629703.5000],
        [13731066.0000,  1517094.3750],
        [11950704.0000,  1385042.1250],
        [15520021.0000,        0.0000],
        [14053961.0000,        0.0000],
        [13319180.0000,        0.0000],
        [15498608.0000,        0.0000],
        [15749651.0000,        0.0000],
        [15704959.0000,        0.0000],
        [13562223.0000,  1522065.1250],
        [13314054.0000,  1499807.2500],
        [14580196.0000,        0.0000],
        [15496879.0000,        0.0000],
        [15484551.0000,        0.0000],
        [13185627.0000,  1470409.8750],
        [15575086.0000,        0.0000],
        [15740870.0000,        0.0000],
        [10306484.0000,  4456052.0000],
        [15675733.0000,        0.0000],
        [15571954.0000,        0.0000],
        [15724230.0000,        0.0000],
        [15761738.0000,        0.0000],
        [15759680.0000,        0.0000],
        [15776904.0000,        0.0000],
        [15763589.0000,        0.0000],
        [ 2976214.7500,  7888582.0000],
        [ 9052782.0000,  6037985.0000],
        [12392905.0000,  3093690.5000],
        [12139526.0000,  3030127.0000],
        [ 3197630.5000,  8120976.0000],
        [11937662.0000,  2993216.2500],
        [12715027.0000,  1395504.3750],
        [15017557.0000,        0.0000],
        [ 9908041.0000,  2541124.0000],
        [15582987.0000,        0.0000],
        [15508926.0000,        0.0000],
        [13760262.0000,  1532083.1250],
        [ 2515028.0000, 10387048.0000],
        [ 1160372.3750, 10550171.0000],
        [ 5249209.0000,  4822259.0000],
        [ 2693328.7500,  7021062.0000],
        [ 5404312.5000,  8187255.5000],
        [10181168.0000,  4404371.0000],
        [12638774.0000,  1417767.0000],
        [ 1315955.6250, 12257426.0000],
        [ 1377297.1250, 12799338.0000],
        [ 2645905.7500, 10450937.0000],
        [11864687.0000,  2982160.2500],
        [10236044.0000,  4476574.5000],
        [ 2742907.5000, 11106940.0000],
        [ 5260132.5000,  8256803.5000],
        [ 1304756.1250, 12406122.0000],
        [ 2691122.5000, 11400702.0000],
        [10728551.0000,  2710176.0000],
        [11710553.0000,  1265852.2500],
        [11074350.0000,  2620057.0000],
        [ 1377490.1250, 12761307.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 411/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:11, 56.12s/it]  7%|▋         | 2/29 [00:57<10:38, 23.66s/it] 10%|█         | 3/29 [00:57<05:45, 13.28s/it] 14%|█▍        | 4/29 [00:58<03:30,  8.40s/it] 17%|█▋        | 5/29 [00:59<02:16,  5.71s/it] 21%|██        | 6/29 [01:00<01:33,  4.08s/it] 24%|██▍       | 7/29 [01:01<01:07,  3.05s/it] 28%|██▊       | 8/29 [01:02<00:49,  2.37s/it] 31%|███       | 9/29 [01:03<00:38,  1.92s/it] 34%|███▍      | 10/29 [01:04<00:30,  1.61s/it] 38%|███▊      | 11/29 [01:05<00:25,  1.40s/it] 41%|████▏     | 12/29 [01:06<00:21,  1.25s/it] 45%|████▍     | 13/29 [01:07<00:18,  1.15s/it] 48%|████▊     | 14/29 [01:08<00:16,  1.08s/it] 52%|█████▏    | 15/29 [01:09<00:14,  1.03s/it] 55%|█████▌    | 16/29 [01:09<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:10<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:11<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:12<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:13<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:14<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:15<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:16<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:17<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:18<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:19<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:20<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:21<00:00,  1.09it/s]100%|██████████| 29/29 [01:21<00:00,  1.09it/s]100%|██████████| 29/29 [01:22<00:00,  2.83s/it]
Epoch loss is 2.8027939796447754
Epoch 412/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:10, 58.23s/it]  7%|▋         | 2/29 [00:59<11:15, 25.01s/it] 10%|█         | 3/29 [01:00<06:04, 14.01s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.84s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.99s/it] 21%|██        | 6/29 [01:03<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.784874200820923
Epoch 413/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:35, 59.13s/it]  7%|▋         | 2/29 [01:00<11:12, 24.89s/it] 10%|█         | 3/29 [01:00<06:02, 13.95s/it] 14%|█▍        | 4/29 [01:01<03:40,  8.81s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.97s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7885382175445557
Epoch 414/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:12, 60.46s/it]  7%|▋         | 2/29 [01:01<11:26, 25.44s/it] 10%|█         | 3/29 [01:02<06:10, 14.24s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.98s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.801795244216919
Epoch 415/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:49, 57.50s/it]  7%|▋         | 2/29 [00:58<10:54, 24.23s/it] 10%|█         | 3/29 [01:00<06:01, 13.92s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.79s/it] 17%|█▋        | 5/29 [01:01<02:22,  5.95s/it] 21%|██        | 6/29 [01:02<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:03<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.45s/it] 31%|███       | 9/29 [01:05<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 2.7920126914978027
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0139, 0.0021,  ..., 0.0041, 0.0001, 0.0195],
        [0.0030, 0.0095, 0.0021,  ..., 0.0025, 0.0002, 0.0182],
        [0.0324, 0.0063, 0.0037,  ..., 0.0056, 0.0153, 0.0239],
        ...,
        [0.0073, 0.0082, 0.0187,  ..., 0.0044, 0.0019, 0.0204],
        [0.0042, 0.0084, 0.0117,  ..., 0.0048, 0.0047, 0.0203],
        [0.0096, 0.0045, 0.0042,  ..., 0.0027, 0.0022, 0.0226]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9953, 0.9952, 0.9950, 0.9948, 0.9948, 0.9948, 0.9947,
         0.9944],
        [0.9973, 0.9968, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965,
         0.9965],
        [0.9755, 0.9693, 0.9683, 0.9657, 0.9649, 0.9644, 0.9644, 0.9640, 0.9639,
         0.9631],
        [0.9935, 0.9926, 0.9925, 0.9924, 0.9920, 0.9913, 0.9912, 0.9899, 0.9899,
         0.9897],
        [0.9884, 0.9872, 0.9865, 0.9847, 0.9846, 0.9845, 0.9842, 0.9841, 0.9839,
         0.9838],
        [0.9845, 0.9828, 0.9802, 0.9768, 0.9758, 0.9749, 0.9747, 0.9735, 0.9732,
         0.9723],
        [0.9786, 0.9705, 0.9696, 0.9678, 0.9676, 0.9651, 0.9641, 0.9639, 0.9633,
         0.9617],
        [0.9764, 0.9729, 0.9690, 0.9678, 0.9606, 0.9572, 0.9568, 0.9560, 0.9555,
         0.9545],
        [0.9975, 0.9969, 0.9969, 0.9967, 0.9966, 0.9965, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9940, 0.9900, 0.9890, 0.9885, 0.9867, 0.9865, 0.9859, 0.9848, 0.9842,
         0.9833],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9941, 0.9935, 0.9915, 0.9914, 0.9909, 0.9904, 0.9902, 0.9900, 0.9899,
         0.9894],
        [0.9927, 0.9904, 0.9902, 0.9894, 0.9878, 0.9874, 0.9861, 0.9855, 0.9852,
         0.9839],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9980, 0.9977, 0.9975, 0.9974, 0.9974,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9960, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9954, 0.9949, 0.9947, 0.9945, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9944, 0.9938, 0.9936, 0.9935, 0.9935, 0.9933, 0.9932, 0.9932, 0.9931,
         0.9930],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9975],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9952, 0.9947, 0.9944, 0.9943, 0.9940, 0.9939, 0.9938, 0.9935, 0.9929,
         0.9928],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9976,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9952, 0.9951, 0.9946, 0.9945, 0.9943, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9990, 0.9988, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9881, 0.9868, 0.9778, 0.9712, 0.9690, 0.9674, 0.9671, 0.9646, 0.9627,
         0.9612],
        [0.9963, 0.9963, 0.9959, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957,
         0.9954],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9967, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9854, 0.9829, 0.9796, 0.9762, 0.9735, 0.9733, 0.9714, 0.9705, 0.9685,
         0.9683],
        [0.9958, 0.9955, 0.9952, 0.9951, 0.9951, 0.9950, 0.9949, 0.9949, 0.9949,
         0.9949],
        [0.9925, 0.9919, 0.9916, 0.9913, 0.9913, 0.9911, 0.9904, 0.9904, 0.9904,
         0.9902],
        [0.9961, 0.9957, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9954, 0.9952,
         0.9952],
        [0.9847, 0.9844, 0.9844, 0.9842, 0.9824, 0.9813, 0.9808, 0.9795, 0.9792,
         0.9785],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9972, 0.9971, 0.9970, 0.9969, 0.9968, 0.9968, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9897, 0.9869, 0.9862, 0.9853, 0.9850, 0.9840, 0.9836, 0.9834, 0.9827,
         0.9825],
        [0.9859, 0.9788, 0.9786, 0.9785, 0.9784, 0.9780, 0.9769, 0.9768, 0.9766,
         0.9759],
        [0.9876, 0.9871, 0.9734, 0.9711, 0.9611, 0.9569, 0.9554, 0.9550, 0.9550,
         0.9531],
        [0.9727, 0.9692, 0.9684, 0.9663, 0.9656, 0.9635, 0.9621, 0.9618, 0.9609,
         0.9530],
        [0.9912, 0.9897, 0.9890, 0.9886, 0.9886, 0.9880, 0.9880, 0.9873, 0.9872,
         0.9871],
        [0.9941, 0.9941, 0.9940, 0.9940, 0.9937, 0.9933, 0.9933, 0.9933, 0.9931,
         0.9928],
        [0.9917, 0.9914, 0.9912, 0.9912, 0.9908, 0.9905, 0.9902, 0.9901, 0.9898,
         0.9898],
        [0.9910, 0.9906, 0.9895, 0.9894, 0.9890, 0.9886, 0.9868, 0.9868, 0.9864,
         0.9862],
        [0.9936, 0.9929, 0.9928, 0.9921, 0.9917, 0.9916, 0.9907, 0.9899, 0.9895,
         0.9893],
        [0.9904, 0.9877, 0.9867, 0.9866, 0.9857, 0.9853, 0.9850, 0.9850, 0.9841,
         0.9835],
        [0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949, 0.9947, 0.9946, 0.9945,
         0.9941],
        [0.9956, 0.9951, 0.9949, 0.9949, 0.9947, 0.9934, 0.9934, 0.9932, 0.9930,
         0.9930],
        [0.9944, 0.9912, 0.9901, 0.9899, 0.9893, 0.9893, 0.9889, 0.9887, 0.9885,
         0.9880],
        [0.9915, 0.9909, 0.9908, 0.9904, 0.9869, 0.9867, 0.9861, 0.9858, 0.9857,
         0.9855],
        [0.9918, 0.9916, 0.9911, 0.9908, 0.9889, 0.9887, 0.9887, 0.9877, 0.9864,
         0.9859],
        [0.9967, 0.9939, 0.9929, 0.9925, 0.9923, 0.9909, 0.9884, 0.9883, 0.9881,
         0.9875],
        [0.9900, 0.9887, 0.9883, 0.9881, 0.9877, 0.9875, 0.9873, 0.9868, 0.9865,
         0.9862],
        [0.9916, 0.9908, 0.9875, 0.9851, 0.9840, 0.9834, 0.9832, 0.9828, 0.9822,
         0.9818],
        [0.9923, 0.9923, 0.9917, 0.9916, 0.9912, 0.9897, 0.9860, 0.9858, 0.9849,
         0.9840],
        [0.9924, 0.9922, 0.9920, 0.9920, 0.9918, 0.9914, 0.9913, 0.9907, 0.9899,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 0, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1517253.6250, 1515928.6250, 1496304.2500, 1493796.2500, 1490287.2500,
         1486569.7500, 1485913.3750, 1485848.2500, 1482606.8750, 1476611.1250],
        [1540328.3750, 1527864.8750, 1526341.5000, 1525855.5000, 1524075.3750,
         1523329.8750, 1523299.3750, 1522574.6250, 1522533.8750, 1522223.3750],
        [1128530.7500, 1031663.8750, 1018133.6875,  980939.9375,  969244.5000,
          962720.3750,  962587.2500,  956385.1250,  955686.7500,  944366.1875],
        [1459115.8750, 1438815.6250, 1437328.8750, 1435502.8750, 1427034.6250,
         1412485.0000, 1411672.8750, 1385750.2500, 1385164.8750, 1381551.5000],
        [1355039.2500, 1333774.1250, 1319646.5000, 1285217.7500, 1284395.6250,
         1282662.2500, 1276451.0000, 1275529.7500, 1272208.5000, 1270011.8750],
        [1281828.3750, 1252559.8750, 1206658.5000, 1149001.5000, 1133293.5000,
         1118042.2500, 1115138.3750, 1096562.7500, 1091274.5000, 1077481.2500],
        [1178236.5000, 1049622.5000, 1036407.1875, 1010748.1875, 1007513.6250,
          972543.5625,  957906.7500,  955610.1875,  947037.6250,  926056.3750],
        [1142198.3750, 1086157.8750, 1027600.6250, 1010030.3750,  911033.4375,
          868200.6250,  863724.5625,  854067.3750,  847283.5625,  835755.3750],
        [1544292.3750, 1531046.0000, 1529963.1250, 1525957.3750, 1524260.0000,
         1521854.6250, 1518770.7500, 1518414.5000, 1517503.8750, 1516896.2500],
        [1469046.1250, 1387731.3750, 1366881.2500, 1358329.3750, 1323137.2500,
         1319493.0000, 1307852.0000, 1288399.7500, 1277223.1250, 1260853.5000],
        [1555445.7500, 1555417.6250, 1555293.0000, 1555202.5000, 1550922.1250,
         1549836.8750, 1549272.3750, 1549220.6250, 1548530.8750, 1546475.0000],
        [1470083.1250, 1459051.8750, 1417996.8750, 1416249.5000, 1404480.5000,
         1394287.2500, 1391390.1250, 1387026.1250, 1385641.8750, 1374963.6250],
        [1441931.0000, 1396078.1250, 1391967.5000, 1374549.3750, 1344751.8750,
         1337026.7500, 1312754.2500, 1301579.6250, 1296197.3750, 1270887.8750],
        [1564426.7500, 1560040.7500, 1556183.2500, 1556166.8750, 1554301.0000,
         1547692.2500, 1543541.3750, 1542026.0000, 1541901.0000, 1539987.6250],
        [1576919.3750, 1576746.5000, 1575808.3750, 1575751.2500, 1575193.8750,
         1574270.2500, 1574190.6250, 1573914.5000, 1573882.8750, 1572829.6250],
        [1575570.8750, 1572439.6250, 1571417.2500, 1571414.2500, 1570677.1250,
         1570491.3750, 1569305.7500, 1568753.5000, 1567599.0000, 1567370.2500],
        [1521499.0000, 1518521.6250, 1517124.7500, 1513462.8750, 1510885.8750,
         1506828.0000, 1505941.6250, 1504628.0000, 1503275.6250, 1500996.3750],
        [1498797.8750, 1487836.2500, 1484104.8750, 1479671.5000, 1479119.8750,
         1478001.7500, 1477364.7500, 1476091.7500, 1476062.1250, 1476052.2500],
        [1477145.0000, 1464268.0000, 1461213.0000, 1459104.7500, 1457505.3750,
         1453737.8750, 1452888.2500, 1452040.6250, 1449138.1250, 1448222.1250],
        [1555196.6250, 1554259.5000, 1551302.2500, 1550698.7500, 1549718.6250,
         1548016.8750, 1547949.0000, 1547289.2500, 1547161.0000, 1545030.3750],
        [1554435.8750, 1552409.2500, 1551695.7500, 1551386.6250, 1549768.8750,
         1549033.0000, 1545846.8750, 1543721.0000, 1542952.7500, 1542464.3750],
        [1494102.6250, 1483016.8750, 1477841.0000, 1474711.2500, 1469462.1250,
         1467150.2500, 1465529.5000, 1457652.6250, 1445734.1250, 1444171.5000],
        [1573402.6250, 1571914.8750, 1561146.5000, 1560990.1250, 1560979.7500,
         1557526.8750, 1554403.2500, 1552754.2500, 1545964.8750, 1544433.7500],
        [1579303.2500, 1576519.3750, 1574378.3750, 1574109.6250, 1574069.1250,
         1573344.1250, 1573234.7500, 1572409.7500, 1571048.6250, 1570296.7500],
        [1493730.7500, 1492856.2500, 1480959.1250, 1479309.0000, 1475351.3750,
         1471780.5000, 1470961.0000, 1468501.1250, 1468180.5000, 1466224.3750],
        [1576826.0000, 1572807.1250, 1569283.1250, 1567791.7500, 1567107.1250,
         1566850.1250, 1565483.5000, 1564429.7500, 1563703.5000, 1563130.8750],
        [1565886.6250, 1564446.1250, 1561390.6250, 1560473.7500, 1558914.8750,
         1556815.6250, 1553281.5000, 1552915.6250, 1552045.1250, 1551231.2500],
        [1575819.0000, 1574436.8750, 1574054.0000, 1573390.7500, 1573222.6250,
         1573053.1250, 1571068.1250, 1570443.5000, 1570160.5000, 1569635.0000],
        [1578550.3750, 1578344.1250, 1578174.1250, 1575851.8750, 1575380.1250,
         1575229.8750, 1575115.7500, 1574862.0000, 1574485.0000, 1573976.0000],
        [1581144.8750, 1579810.8750, 1576519.3750, 1575470.2500, 1575120.2500,
         1574989.6250, 1574937.0000, 1574127.6250, 1573902.3750, 1573002.1250],
        [1580841.8750, 1579743.1250, 1579687.3750, 1578288.5000, 1577787.2500,
         1577551.0000, 1576800.5000, 1576253.2500, 1575817.3750, 1575306.5000],
        [1580131.8750, 1578246.3750, 1576181.1250, 1576075.8750, 1575960.1250,
         1575686.6250, 1575069.1250, 1575025.6250, 1574243.1250, 1574115.5000],
        [1349703.5000, 1326131.2500, 1164651.7500, 1060944.3750, 1027078.4375,
         1004649.6875, 1000650.8125,  964904.2500,  938923.3125,  919135.4375],
        [1518950.2500, 1518938.7500, 1510193.0000, 1508888.6250, 1506697.2500,
         1506402.7500, 1505777.8750, 1505032.7500, 1504655.3750, 1499424.0000],
        [1554916.3750, 1552165.0000, 1551876.3750, 1549157.0000, 1547962.3750,
         1547227.3750, 1546193.3750, 1546162.5000, 1546009.0000, 1545873.3750],
        [1525851.0000, 1520728.7500, 1519512.3750, 1518834.5000, 1518708.5000,
         1517977.1250, 1516802.2500, 1515282.5000, 1514512.6250, 1513357.6250],
        [1298513.6250, 1252605.3750, 1195602.3750, 1138424.8750, 1095185.2500,
         1093335.0000, 1063321.7500, 1049271.2500, 1019946.1250, 1017262.0625],
        [1508179.3750, 1500140.5000, 1495136.0000, 1493141.0000, 1492325.3750,
         1490583.0000, 1488697.7500, 1488066.1250, 1487446.0000, 1487376.6250],
        [1438564.5000, 1424595.2500, 1419697.7500, 1413666.7500, 1412331.3750,
         1408523.3750, 1395937.0000, 1395387.3750, 1395001.5000, 1391034.6250],
        [1512601.5000, 1505934.3750, 1503218.2500, 1503218.2500, 1501276.8750,
         1501215.3750, 1499525.5000, 1499488.2500, 1495232.8750, 1494193.7500],
        [1286723.7500, 1281533.7500, 1281498.2500, 1277206.0000, 1245137.7500,
         1225340.3750, 1216324.2500, 1193903.3750, 1189475.6250, 1177707.3750],
        [1564568.6250, 1561669.1250, 1558596.7500, 1558584.8750, 1558023.1250,
         1557901.2500, 1556463.6250, 1555922.0000, 1555586.6250, 1555576.3750],
        [1558000.7500, 1556561.6250, 1555092.7500, 1551004.8750, 1550716.5000,
         1550274.3750, 1549083.1250, 1548832.1250, 1547345.3750, 1546143.2500],
        [1538587.2500, 1534400.7500, 1532575.5000, 1531214.0000, 1529201.6250,
         1529035.3750, 1524658.2500, 1523449.0000, 1521506.2500, 1521438.1250],
        [1380579.3750, 1326928.2500, 1314374.0000, 1296365.6250, 1291934.7500,
         1273177.0000, 1266428.2500, 1262804.1250, 1249197.0000, 1246847.6250],
        [1308243.6250, 1181967.2500, 1178344.3750, 1177069.6250, 1175934.1250,
         1168212.5000, 1151177.6250, 1148742.8750, 1146160.3750, 1134963.5000],
        [1340970.1250, 1330061.3750, 1094257.1250, 1058433.1250,  918635.0625,
          864241.1875,  846783.5625,  842018.7500,  840870.4375,  819053.5625],
        [1083160.1250, 1030166.5625, 1019545.4375,  988156.6875,  978915.7500,
          949635.9375,  931183.9375,  926946.1250,  915069.3750,  817829.7500],
        [1411631.1250, 1381286.6250, 1367850.1250, 1360406.1250, 1359175.5000,
         1349002.2500, 1348765.5000, 1335376.6250, 1333119.2500, 1331632.6250],
        [1471593.8750, 1470667.8750, 1469438.3750, 1469145.5000, 1462176.2500,
         1455059.6250, 1453977.7500, 1453826.6250, 1449544.6250, 1444554.3750],
        [1421213.6250, 1415087.1250, 1412086.2500, 1410269.3750, 1402657.5000,
         1396297.8750, 1391142.1250, 1389694.0000, 1384049.1250, 1383984.5000],
        [1406682.8750, 1399121.0000, 1376591.8750, 1376043.1250, 1367710.5000,
         1359042.0000, 1325416.8750, 1325284.1250, 1317520.1250, 1314797.7500],
        [1461128.0000, 1445275.1250, 1444671.5000, 1430276.1250, 1421896.8750,
         1419470.3750, 1400453.3750, 1384727.7500, 1376938.5000, 1372716.6250],
        [1395275.5000, 1342879.6250, 1322979.6250, 1320648.7500, 1304541.0000,
         1296322.2500, 1291194.5000, 1290967.8750, 1275956.8750, 1264897.6250],
        [1493988.6250, 1491468.8750, 1490780.5000, 1489930.6250, 1489930.6250,
         1487614.8750, 1482749.5000, 1481601.7500, 1479517.7500, 1471701.8750],
        [1503572.3750, 1492070.6250, 1488517.3750, 1487046.1250, 1482789.1250,
         1457228.7500, 1456063.2500, 1451514.3750, 1447950.1250, 1447944.6250],
        [1477774.8750, 1411888.2500, 1388831.6250, 1385364.3750, 1374440.5000,
         1374323.7500, 1365875.2500, 1361386.0000, 1357024.2500, 1349011.2500],
        [1417102.0000, 1406167.8750, 1404109.5000, 1394720.7500, 1327421.8750,
         1323844.1250, 1312542.6250, 1307045.2500, 1305185.5000, 1300472.8750],
        [1423834.6250, 1419853.5000, 1409152.1250, 1404084.1250, 1364816.6250,
         1362334.1250, 1361645.7500, 1342918.0000, 1318019.0000, 1308110.1250],
        [1527190.5000, 1466322.2500, 1446091.2500, 1438476.6250, 1433945.8750,
         1404444.3750, 1356656.7500, 1353728.1250, 1350845.8750, 1339205.2500],
        [1386817.1250, 1362578.3750, 1353821.1250, 1350760.7500, 1342573.5000,
         1339386.6250, 1334522.3750, 1325768.2500, 1320179.0000, 1314170.8750],
        [1418925.0000, 1403790.8750, 1338791.3750, 1293996.5000, 1273309.3750,
         1263124.5000, 1259136.3750, 1252536.0000, 1241831.3750, 1234795.3750],
        [1432890.5000, 1432609.0000, 1422385.1250, 1420273.2500, 1410995.8750,
         1381828.2500, 1310547.6250, 1306322.5000, 1290297.1250, 1273978.6250],
        [1436512.1250, 1432353.6250, 1427321.7500, 1427187.1250, 1423591.5000,
         1415025.0000, 1413354.0000, 1401643.7500, 1384315.7500, 1377931.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1517253.6250,       0.0000],
         [1515928.6250,       0.0000],
         [1496304.2500,       0.0000],
         ...,
         [1485848.2500,       0.0000],
         [      0.0000, 1482606.8750],
         [1476611.1250,       0.0000]],

        [[1540328.3750,       0.0000],
         [1527864.8750,       0.0000],
         [1526341.5000,       0.0000],
         ...,
         [1522574.6250,       0.0000],
         [1522533.8750,       0.0000],
         [1522223.3750,       0.0000]],

        [[1128530.7500,       0.0000],
         [      0.0000, 1031663.8750],
         [1018133.6875,       0.0000],
         ...,
         [ 956385.1250,       0.0000],
         [ 955686.7500,       0.0000],
         [      0.0000,  944366.1875]],

        ...,

        [[1418925.0000,       0.0000],
         [1403790.8750,       0.0000],
         [1338791.3750,       0.0000],
         ...,
         [1252536.0000,       0.0000],
         [1241831.3750,       0.0000],
         [1234795.3750,       0.0000]],

        [[1432890.5000,       0.0000],
         [1432609.0000,       0.0000],
         [1422385.1250,       0.0000],
         ...,
         [      0.0000, 1306322.5000],
         [1290297.1250,       0.0000],
         [1273978.6250,       0.0000]],

        [[      0.0000, 1436512.1250],
         [      0.0000, 1432353.6250],
         [      0.0000, 1427321.7500],
         ...,
         [      0.0000, 1401643.7500],
         [      0.0000, 1384315.7500],
         [1377931.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13448512.0000,  1482606.8750],
        [15258427.0000,        0.0000],
        [ 4058736.5000,  5851522.0000],
        [12762750.0000,  1411672.8750],
        [ 9132944.0000,  3821992.7500],
        [ 9276277.0000,  2245564.2500],
        [ 4966637.0000,  5075045.0000],
        [ 8582327.0000,   863724.5625],
        [12212685.0000,  3036274.5000],
        [11971215.0000,  1387731.3750],
        [15515617.0000,        0.0000],
        [12726208.0000,  1374963.6250],
        [13467724.0000,        0.0000],
        [15506267.0000,        0.0000],
        [15749507.0000,        0.0000],
        [15705039.0000,        0.0000],
        [13581665.0000,  1521499.0000],
        [11838253.0000,  2974850.0000],
        [14575262.0000,        0.0000],
        [15496622.0000,        0.0000],
        [15483714.0000,        0.0000],
        [11758927.0000,  2920445.5000],
        [15583518.0000,        0.0000],
        [15738714.0000,        0.0000],
        [10315042.0000,  4452811.0000],
        [15677412.0000,        0.0000],
        [15577402.0000,        0.0000],
        [15725283.0000,        0.0000],
        [15759970.0000,        0.0000],
        [15759024.0000,        0.0000],
        [15778077.0000,        0.0000],
        [15760736.0000,        0.0000],
        [ 2924436.0000,  7832336.5000],
        [ 9048503.0000,  6036458.0000],
        [12394153.0000,  3093390.0000],
        [12144756.0000,  3036811.5000],
        [ 3161718.5000,  8061749.0000],
        [11938626.0000,  2992466.0000],
        [12699738.0000,  1395001.5000],
        [15015906.0000,        0.0000],
        [ 9848179.0000,  2526671.5000],
        [15582893.0000,        0.0000],
        [15513055.0000,        0.0000],
        [13753490.0000,  1532575.5000],
        [ 2515625.2500, 10393011.0000],
        [ 1177069.6250, 10593746.0000],
        [ 5131603.0000,  4823721.5000],
        [ 2664083.0000,  6976527.0000],
        [ 4059889.0000,  9518357.0000],
        [10199225.0000,  4400760.0000],
        [12596212.0000,  1410269.3750],
        [ 1314797.7500, 12253412.0000],
        [ 1372716.6250, 12784838.0000],
        [ 2643628.5000, 10462036.0000],
        [11877682.0000,  2981603.5000],
        [10236264.0000,  4478432.0000],
        [ 2740315.7500, 11105604.0000],
        [ 5252195.0000,  8246417.0000],
        [ 1308110.1250, 12406658.0000],
        [ 2695862.0000, 11421045.0000],
        [10717993.0000,  2712585.5000],
        [11717112.0000,  1263124.5000],
        [11065258.0000,  2616870.0000],
        [ 1377931.6250, 12761304.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 416/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:45, 61.61s/it]  7%|▋         | 2/29 [01:02<11:39, 25.92s/it] 10%|█         | 3/29 [01:03<06:17, 14.50s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.813650608062744
Epoch 417/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:57, 59.93s/it]  7%|▋         | 2/29 [01:00<11:20, 25.22s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.8109047412872314
Epoch 418/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:20, 60.73s/it]  7%|▋         | 2/29 [01:01<11:29, 25.55s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.8057751655578613
Epoch 419/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:39, 61.41s/it]  7%|▋         | 2/29 [01:02<11:37, 25.83s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.7917280197143555
Epoch 420/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:49, 59.61s/it]  7%|▋         | 2/29 [01:00<11:17, 25.09s/it] 10%|█         | 3/29 [01:01<06:05, 14.05s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.00s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7907135486602783
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0035, 0.0148, 0.0027,  ..., 0.0042, 0.0002, 0.0190],
        [0.0034, 0.0097, 0.0022,  ..., 0.0024, 0.0001, 0.0184],
        [0.0345, 0.0059, 0.0033,  ..., 0.0050, 0.0164, 0.0243],
        ...,
        [0.0077, 0.0080, 0.0191,  ..., 0.0042, 0.0018, 0.0204],
        [0.0046, 0.0086, 0.0129,  ..., 0.0052, 0.0053, 0.0198],
        [0.0099, 0.0045, 0.0044,  ..., 0.0029, 0.0023, 0.0228]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9958, 0.9957, 0.9948, 0.9948, 0.9943, 0.9942, 0.9942, 0.9941, 0.9941,
         0.9937],
        [0.9972, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9773, 0.9692, 0.9686, 0.9685, 0.9683, 0.9682, 0.9679, 0.9661, 0.9657,
         0.9653],
        [0.9929, 0.9921, 0.9920, 0.9917, 0.9912, 0.9901, 0.9900, 0.9892, 0.9888,
         0.9884],
        [0.9879, 0.9871, 0.9857, 0.9845, 0.9840, 0.9833, 0.9833, 0.9830, 0.9826,
         0.9825],
        [0.9837, 0.9833, 0.9797, 0.9766, 0.9744, 0.9733, 0.9733, 0.9730, 0.9727,
         0.9723],
        [0.9816, 0.9708, 0.9692, 0.9686, 0.9682, 0.9663, 0.9659, 0.9658, 0.9637,
         0.9630],
        [0.9764, 0.9745, 0.9695, 0.9662, 0.9612, 0.9588, 0.9585, 0.9553, 0.9553,
         0.9545],
        [0.9973, 0.9966, 0.9966, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960,
         0.9960],
        [0.9933, 0.9892, 0.9876, 0.9872, 0.9857, 0.9854, 0.9835, 0.9831, 0.9823,
         0.9823],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9931, 0.9922, 0.9905, 0.9904, 0.9898, 0.9897, 0.9894, 0.9891, 0.9889,
         0.9885],
        [0.9908, 0.9892, 0.9879, 0.9868, 0.9860, 0.9845, 0.9838, 0.9823, 0.9821,
         0.9812],
        [0.9984, 0.9982, 0.9980, 0.9979, 0.9978, 0.9975, 0.9972, 0.9972, 0.9972,
         0.9971],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9964, 0.9963, 0.9961, 0.9959, 0.9959, 0.9955, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9950, 0.9945, 0.9943, 0.9943, 0.9943, 0.9943, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9944, 0.9936, 0.9934, 0.9934, 0.9933, 0.9933, 0.9931, 0.9931, 0.9931,
         0.9929],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9948, 0.9939, 0.9938, 0.9937, 0.9936, 0.9931, 0.9930, 0.9927, 0.9924,
         0.9924],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9979, 0.9976,
         0.9974],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9948, 0.9947, 0.9941, 0.9941, 0.9938, 0.9937, 0.9937, 0.9937, 0.9936,
         0.9932],
        [0.9989, 0.9988, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9985, 0.9984, 0.9984, 0.9983, 0.9981, 0.9980, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9882, 0.9870, 0.9776, 0.9713, 0.9697, 0.9677, 0.9676, 0.9648, 0.9648,
         0.9611],
        [0.9961, 0.9959, 0.9958, 0.9958, 0.9956, 0.9956, 0.9954, 0.9954, 0.9954,
         0.9953],
        [0.9979, 0.9979, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9975],
        [0.9964, 0.9962, 0.9961, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9856, 0.9831, 0.9799, 0.9759, 0.9748, 0.9728, 0.9725, 0.9708, 0.9683,
         0.9683],
        [0.9955, 0.9951, 0.9950, 0.9948, 0.9948, 0.9947, 0.9946, 0.9946, 0.9945,
         0.9943],
        [0.9921, 0.9916, 0.9911, 0.9909, 0.9907, 0.9902, 0.9898, 0.9897, 0.9895,
         0.9895],
        [0.9959, 0.9956, 0.9956, 0.9956, 0.9954, 0.9953, 0.9951, 0.9951, 0.9951,
         0.9950],
        [0.9860, 0.9850, 0.9847, 0.9843, 0.9825, 0.9821, 0.9813, 0.9803, 0.9790,
         0.9787],
        [0.9983, 0.9983, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9980, 0.9979, 0.9978, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9972, 0.9970, 0.9968, 0.9967, 0.9967, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9963],
        [0.9892, 0.9867, 0.9856, 0.9852, 0.9843, 0.9836, 0.9835, 0.9835, 0.9831,
         0.9824],
        [0.9864, 0.9795, 0.9778, 0.9766, 0.9761, 0.9760, 0.9760, 0.9755, 0.9754,
         0.9752],
        [0.9868, 0.9865, 0.9741, 0.9711, 0.9618, 0.9602, 0.9573, 0.9568, 0.9564,
         0.9563],
        [0.9728, 0.9693, 0.9682, 0.9664, 0.9659, 0.9642, 0.9629, 0.9628, 0.9628,
         0.9551],
        [0.9902, 0.9892, 0.9890, 0.9886, 0.9881, 0.9879, 0.9875, 0.9874, 0.9870,
         0.9866],
        [0.9939, 0.9937, 0.9937, 0.9935, 0.9933, 0.9931, 0.9928, 0.9927, 0.9926,
         0.9922],
        [0.9915, 0.9911, 0.9910, 0.9910, 0.9908, 0.9905, 0.9902, 0.9901, 0.9898,
         0.9897],
        [0.9909, 0.9906, 0.9896, 0.9894, 0.9884, 0.9884, 0.9874, 0.9870, 0.9867,
         0.9865],
        [0.9937, 0.9928, 0.9927, 0.9921, 0.9916, 0.9915, 0.9906, 0.9897, 0.9895,
         0.9892],
        [0.9901, 0.9876, 0.9868, 0.9863, 0.9855, 0.9852, 0.9848, 0.9846, 0.9842,
         0.9832],
        [0.9951, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9944, 0.9942, 0.9941,
         0.9939],
        [0.9955, 0.9948, 0.9946, 0.9945, 0.9943, 0.9930, 0.9929, 0.9928, 0.9928,
         0.9927],
        [0.9942, 0.9912, 0.9900, 0.9897, 0.9894, 0.9891, 0.9888, 0.9886, 0.9886,
         0.9881],
        [0.9913, 0.9909, 0.9907, 0.9904, 0.9865, 0.9862, 0.9861, 0.9854, 0.9853,
         0.9850],
        [0.9918, 0.9914, 0.9908, 0.9907, 0.9888, 0.9887, 0.9885, 0.9874, 0.9862,
         0.9855],
        [0.9967, 0.9938, 0.9925, 0.9923, 0.9919, 0.9908, 0.9882, 0.9881, 0.9879,
         0.9874],
        [0.9901, 0.9886, 0.9879, 0.9878, 0.9877, 0.9873, 0.9872, 0.9866, 0.9865,
         0.9864],
        [0.9916, 0.9913, 0.9870, 0.9854, 0.9841, 0.9835, 0.9832, 0.9832, 0.9823,
         0.9819],
        [0.9921, 0.9919, 0.9916, 0.9914, 0.9911, 0.9893, 0.9858, 0.9856, 0.9849,
         0.9845],
        [0.9924, 0.9919, 0.9919, 0.9918, 0.9918, 0.9916, 0.9912, 0.9907, 0.9899,
         0.9891]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1506385.3750, 1505780.7500, 1486588.1250, 1485444.5000, 1475817.1250,
         1472492.2500, 1472113.2500, 1471341.2500, 1470226.1250, 1462621.1250],
        [1537667.3750, 1525132.3750, 1523934.3750, 1522619.6250, 1521668.8750,
         1520953.6250, 1520875.2500, 1520849.1250, 1520705.5000, 1518634.5000],
        [1156814.6250, 1030124.2500, 1021145.1875, 1020136.8125, 1017339.7500,
         1016675.3750, 1012259.8125,  985778.0625,  981045.6250,  974741.3125],
        [1445662.5000, 1429605.0000, 1426633.2500, 1420698.6250, 1410352.7500,
         1389680.8750, 1388218.5000, 1371522.0000, 1362736.8750, 1356802.8750],
        [1346276.2500, 1330324.0000, 1305369.7500, 1281567.8750, 1273814.6250,
         1260667.1250, 1259973.5000, 1254805.2500, 1248761.1250, 1246971.3750],
        [1267363.3750, 1260170.6250, 1197300.2500, 1144899.6250, 1110510.1250,
         1092879.5000, 1092612.6250, 1088431.7500, 1084039.5000, 1077151.5000],
        [1231241.7500, 1054607.3750, 1030292.3125, 1022061.9375, 1016342.8750,
          989035.3125,  983440.0000,  981500.5000,  953426.3750,  943001.8750],
        [1142418.3750, 1112140.2500, 1035709.6250,  986922.8750,  919672.0625,
          888979.3125,  884738.6250,  845643.2500,  845444.9375,  835714.6875],
        [1539083.2500, 1525336.1250, 1523575.5000, 1518520.1250, 1516369.7500,
         1514251.1250, 1512588.5000, 1512584.1250, 1512194.7500, 1512011.6250],
        [1455159.5000, 1371196.3750, 1339628.0000, 1332469.8750, 1304990.1250,
         1299633.5000, 1265151.0000, 1256727.3750, 1243575.8750, 1243323.3750],
        [1553103.7500, 1552000.7500, 1551842.3750, 1550672.1250, 1549358.0000,
         1547367.5000, 1546768.5000, 1544504.3750, 1543862.3750, 1543435.5000],
        [1450418.5000, 1431131.5000, 1397422.1250, 1395986.3750, 1383010.7500,
         1380680.7500, 1375939.6250, 1369048.1250, 1365489.6250, 1357992.6250],
        [1402653.3750, 1372066.1250, 1347180.5000, 1324652.3750, 1311063.8750,
         1281995.7500, 1269675.2500, 1242332.5000, 1238597.7500, 1223901.5000],
        [1563113.0000, 1559035.2500, 1554760.6250, 1553428.2500, 1551432.5000,
         1545080.5000, 1538213.0000, 1537607.3750, 1537179.2500, 1536424.3750],
        [1576441.2500, 1575396.6250, 1574872.3750, 1574858.8750, 1574840.8750,
         1574352.8750, 1573853.0000, 1573581.3750, 1573024.6250, 1572316.7500],
        [1574318.3750, 1571556.6250, 1571229.8750, 1570217.2500, 1568737.0000,
         1568657.7500, 1566750.0000, 1566524.3750, 1565901.5000, 1565618.0000],
        [1519201.0000, 1517460.5000, 1514473.5000, 1509858.8750, 1509134.7500,
         1501284.1250, 1498959.3750, 1497719.0000, 1496131.6250, 1495626.5000],
        [1489872.3750, 1478760.2500, 1476214.1250, 1475870.7500, 1475544.1250,
         1475456.8750, 1470373.2500, 1469760.7500, 1468651.0000, 1467617.6250],
        [1478252.6250, 1460783.8750, 1457270.3750, 1455623.1250, 1454755.8750,
         1453499.3750, 1450923.5000, 1450188.8750, 1449123.0000, 1445240.6250],
        [1552249.3750, 1549349.1250, 1549335.8750, 1547960.8750, 1547484.1250,
         1545412.0000, 1544869.8750, 1544588.3750, 1541959.8750, 1541823.1250],
        [1551044.8750, 1547673.0000, 1546961.7500, 1546865.8750, 1546647.6250,
         1544712.2500, 1541604.0000, 1540472.3750, 1538731.0000, 1537188.0000],
        [1485647.0000, 1466792.1250, 1464617.1250, 1463614.6250, 1460322.8750,
         1449136.7500, 1449013.8750, 1442541.7500, 1435018.3750, 1434926.6250],
        [1574027.0000, 1570323.6250, 1562244.1250, 1561505.3750, 1561492.0000,
         1556852.6250, 1553543.7500, 1552538.0000, 1545836.6250, 1542941.0000],
        [1578606.1250, 1575255.3750, 1572402.1250, 1572232.7500, 1572189.2500,
         1572007.8750, 1571345.3750, 1571102.5000, 1570566.3750, 1569015.2500],
        [1486070.7500, 1483352.1250, 1471988.2500, 1471390.3750, 1464058.5000,
         1462769.0000, 1462336.6250, 1461607.3750, 1459626.6250, 1452989.3750],
        [1575839.8750, 1572189.2500, 1569404.3750, 1567868.0000, 1567613.8750,
         1566688.7500, 1563540.8750, 1563439.5000, 1562516.8750, 1562227.8750],
        [1565447.7500, 1564116.6250, 1563233.7500, 1561556.0000, 1557792.7500,
         1556281.1250, 1552059.8750, 1551667.7500, 1551099.6250, 1550845.2500],
        [1575653.6250, 1574412.8750, 1573063.6250, 1572633.1250, 1572511.6250,
         1571616.6250, 1570931.8750, 1570018.1250, 1569973.2500, 1569917.8750],
        [1577910.7500, 1577760.2500, 1576714.7500, 1574716.2500, 1574654.6250,
         1574581.0000, 1574394.8750, 1574006.0000, 1573807.8750, 1573057.6250],
        [1579890.7500, 1578922.2500, 1574904.0000, 1574815.3750, 1574099.0000,
         1573788.3750, 1573482.2500, 1573431.1250, 1572154.8750, 1571559.7500],
        [1579321.3750, 1579270.1250, 1578762.6250, 1577021.6250, 1576793.0000,
         1576041.3750, 1576035.3750, 1575066.1250, 1575042.1250, 1574867.8750],
        [1579095.3750, 1577423.1250, 1574908.3750, 1574361.7500, 1574315.2500,
         1574211.7500, 1574168.1250, 1574075.1250, 1573527.2500, 1573410.2500],
        [1351523.5000, 1329612.5000, 1161570.2500, 1061870.6250, 1038138.3125,
         1009324.5625, 1007001.6250,  967912.5000,  967719.6250,  917821.5625],
        [1514537.1250, 1510119.5000, 1507870.2500, 1506642.6250, 1503628.2500,
         1502272.3750, 1498895.0000, 1498572.0000, 1497871.8750, 1495891.8750],
        [1554060.8750, 1552202.0000, 1549477.7500, 1546863.0000, 1545637.6250,
         1544911.1250, 1544883.0000, 1544696.0000, 1544420.5000, 1544276.1250],
        [1519747.2500, 1515402.5000, 1513872.8750, 1513116.5000, 1512478.8750,
         1510385.8750, 1510303.7500, 1509690.3750, 1506658.3750, 1506290.7500],
        [1303029.0000, 1256692.7500, 1201501.5000, 1134293.6250, 1115757.5000,
         1085057.2500, 1080755.8750, 1053896.5000, 1017831.7500, 1017506.6250],
        [1500461.1250, 1492510.5000, 1490877.2500, 1484897.7500, 1484858.0000,
         1484243.5000, 1481517.0000, 1480604.6250, 1480035.7500, 1475427.3750],
        [1430374.2500, 1419882.0000, 1408338.0000, 1405549.8750, 1401720.0000,
         1391134.0000, 1382715.3750, 1381145.6250, 1377387.6250, 1377272.0000],
        [1509677.5000, 1503062.0000, 1503062.0000, 1502996.0000, 1498576.2500,
         1495546.7500, 1493144.0000, 1492815.0000, 1492177.3750, 1489518.6250],
        [1309867.8750, 1292144.1250, 1286559.3750, 1278677.0000, 1246731.1250,
         1238456.0000, 1224961.7500, 1207789.1250, 1185638.6250, 1180791.1250],
        [1561669.1250, 1560874.0000, 1556618.1250, 1556140.1250, 1555476.8750,
         1554713.1250, 1554554.5000, 1552621.0000, 1552570.6250, 1552012.5000],
        [1554455.1250, 1553423.7500, 1551107.0000, 1546513.3750, 1545264.7500,
         1544984.7500, 1544503.0000, 1543342.7500, 1541618.6250, 1541236.5000],
        [1536667.6250, 1532983.5000, 1528652.0000, 1527142.3750, 1526455.1250,
         1523523.1250, 1521909.7500, 1521590.3750, 1520898.5000, 1517029.3750],
        [1370836.7500, 1322857.1250, 1303108.5000, 1294532.1250, 1277899.2500,
         1266608.2500, 1264326.0000, 1263800.3750, 1256797.0000, 1243874.8750],
        [1318496.7500, 1193900.1250, 1166109.8750, 1145454.5000, 1136640.2500,
         1135181.0000, 1135141.0000, 1128445.7500, 1126442.6250, 1123287.6250],
        [1325610.3750, 1320500.1250, 1104933.3750, 1059674.3750,  927319.2500,
          906742.0000,  869114.4375,  863681.7500,  858838.1250,  857614.5625],
        [1084654.7500, 1032709.3125, 1016256.6250,  990178.1875,  983648.2500,
          958967.0625,  941566.7500,  940277.3125,  940076.3750,  842858.3125],
        [1390407.2500, 1371512.7500, 1366838.2500, 1359357.0000, 1349344.5000,
         1346940.2500, 1337779.3750, 1336098.8750, 1328621.2500, 1321848.3750],
        [1466734.7500, 1463555.8750, 1462392.3750, 1458667.8750, 1455216.3750,
         1450302.2500, 1444303.7500, 1441790.7500, 1438859.5000, 1430678.3750],
        [1416592.6250, 1410259.8750, 1408170.1250, 1406737.8750, 1402500.8750,
         1397436.8750, 1391333.1250, 1389025.0000, 1384037.2500, 1380461.0000],
        [1404753.8750, 1399341.2500, 1378527.1250, 1374747.2500, 1356211.7500,
         1355650.6250, 1336157.5000, 1329310.7500, 1322873.6250, 1319178.5000],
        [1463025.7500, 1443447.2500, 1442631.1250, 1428551.5000, 1419487.8750,
         1417473.7500, 1398396.7500, 1380788.7500, 1376543.3750, 1371904.0000],
        [1388407.7500, 1340143.0000, 1324719.3750, 1315488.7500, 1300904.5000,
         1295357.1250, 1288488.2500, 1284488.6250, 1277134.1250, 1259234.7500],
        [1492339.6250, 1488741.7500, 1488168.2500, 1487999.5000, 1487999.5000,
         1487534.0000, 1476343.7500, 1473332.2500, 1471516.6250, 1467379.7500],
        [1501103.7500, 1485719.3750, 1482259.0000, 1479938.2500, 1475300.7500,
         1448631.1250, 1445348.1250, 1444043.3750, 1443019.2500, 1441396.2500],
        [1473980.2500, 1411049.6250, 1387268.2500, 1381129.8750, 1374639.7500,
         1368745.2500, 1364050.1250, 1360002.7500, 1359578.7500, 1349366.3750],
        [1412381.2500, 1404548.8750, 1400818.0000, 1394597.0000, 1319836.6250,
         1313597.0000, 1312175.8750, 1299465.0000, 1296620.2500, 1291858.3750],
        [1422538.3750, 1414332.8750, 1402414.0000, 1401113.2500, 1363285.5000,
         1362208.1250, 1357490.2500, 1337100.8750, 1313608.2500, 1300415.8750],
        [1526683.6250, 1463804.5000, 1437086.2500, 1432968.3750, 1424448.5000,
         1402606.6250, 1351528.7500, 1349854.2500, 1346032.3750, 1337107.2500],
        [1389566.7500, 1360201.2500, 1346873.3750, 1345267.5000, 1342843.7500,
         1335195.7500, 1333334.2500, 1321845.7500, 1320208.0000, 1316904.6250],
        [1419142.7500, 1412493.0000, 1328267.7500, 1298319.1250, 1275882.7500,
         1263523.2500, 1259752.5000, 1258290.0000, 1242220.0000, 1236170.3750],
        [1429971.8750, 1426037.3750, 1420242.2500, 1416148.1250, 1408565.0000,
         1373993.6250, 1306818.3750, 1302431.5000, 1290288.5000, 1282245.1250],
        [1434995.1250, 1426323.1250, 1425765.5000, 1424008.5000, 1423751.7500,
         1418379.7500, 1411593.3750, 1400481.3750, 1385726.5000, 1369651.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1506385.3750,       0.0000],
         [1505780.7500,       0.0000],
         [1486588.1250,       0.0000],
         ...,
         [1471341.2500,       0.0000],
         [1470226.1250,       0.0000],
         [1462621.1250,       0.0000]],

        [[1537667.3750,       0.0000],
         [1525132.3750,       0.0000],
         [1523934.3750,       0.0000],
         ...,
         [1520849.1250,       0.0000],
         [1520705.5000,       0.0000],
         [1518634.5000,       0.0000]],

        [[1156814.6250,       0.0000],
         [      0.0000, 1030124.2500],
         [      0.0000, 1021145.1875],
         ...,
         [ 985778.0625,       0.0000],
         [ 981045.6250,       0.0000],
         [ 974741.3125,       0.0000]],

        ...,

        [[1419142.7500,       0.0000],
         [1412493.0000,       0.0000],
         [1328267.7500,       0.0000],
         ...,
         [1258290.0000,       0.0000],
         [1242220.0000,       0.0000],
         [1236170.3750,       0.0000]],

        [[1429971.8750,       0.0000],
         [1426037.3750,       0.0000],
         [1420242.2500,       0.0000],
         ...,
         [      0.0000, 1302431.5000],
         [1290288.5000,       0.0000],
         [      0.0000, 1282245.1250]],

        [[      0.0000, 1434995.1250],
         [      0.0000, 1426323.1250],
         [      0.0000, 1425765.5000],
         ...,
         [      0.0000, 1400481.3750],
         [      0.0000, 1385726.5000],
         [1369651.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13336696.0000,  1472113.2500],
        [15233041.0000,        0.0000],
        [ 5115055.0000,  5101006.0000],
        [12612232.0000,  1389680.8750],
        [10293059.0000,  2515472.5000],
        [ 9177847.0000,  2237512.2500],
        [ 4997671.0000,  5207279.5000],
        [ 8608405.0000,   888979.3125],
        [12161732.0000,  3024783.2500],
        [11740659.0000,  1371196.3750],
        [15482916.0000,        0.0000],
        [13907120.0000,        0.0000],
        [13014119.0000,        0.0000],
        [15476274.0000,        0.0000],
        [15743538.0000,        0.0000],
        [15689512.0000,        0.0000],
        [13540648.0000,  1519201.0000],
        [11790632.0000,  2957490.0000],
        [14555662.0000,        0.0000],
        [15465033.0000,        0.0000],
        [15441900.0000,        0.0000],
        [13088017.0000,  1463614.6250],
        [15581304.0000,        0.0000],
        [15724723.0000,        0.0000],
        [10242708.0000,  4433481.5000],
        [15671328.0000,        0.0000],
        [15574100.0000,        0.0000],
        [15720733.0000,        0.0000],
        [15751604.0000,        0.0000],
        [15747046.0000,        0.0000],
        [15768222.0000,        0.0000],
        [15749497.0000,        0.0000],
        [ 2934147.7500,  7878347.0000],
        [ 9021386.0000,  6014915.0000],
        [12381634.0000,  3089794.0000],
        [12097416.0000,  3020531.2500],
        [ 3187160.5000,  8079162.0000],
        [11878680.0000,  2976754.0000],
        [12592804.0000,  1382715.3750],
        [14980575.0000,        0.0000],
        [ 9912740.0000,  2538875.2500],
        [15557249.0000,        0.0000],
        [15466450.0000,        0.0000],
        [13730397.0000,  1526455.1250],
        [ 2508201.0000, 10356440.0000],
        [ 1145454.5000, 10463645.0000],
        [ 5283310.0000,  4810718.5000],
        [ 2742102.7500,  6989090.0000],
        [ 4034918.5000,  9473829.0000],
        [10131883.0000,  4380619.0000],
        [12578385.0000,  1408170.1250],
        [ 1319178.5000, 12257574.0000],
        [ 1371904.0000, 12770346.0000],
        [ 2640208.0000, 10434158.0000],
        [11841482.0000,  2979873.5000],
        [10184636.0000,  4462124.0000],
        [ 2728748.0000, 11101064.0000],
        [ 5228098.0000,  8217801.0000],
        [ 1300415.8750, 12374091.0000],
        [ 2688636.0000, 11383484.0000],
        [10689340.0000,  2722901.0000],
        [11730538.0000,  1263523.2500],
        [ 9765247.0000,  3891495.0000],
        [ 1369651.5000, 12751026.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 421/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:07, 60.28s/it]  7%|▋         | 2/29 [01:01<11:24, 25.36s/it] 10%|█         | 3/29 [01:02<06:09, 14.20s/it] 14%|█▍        | 4/29 [01:03<03:43,  8.96s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.7984204292297363
Epoch 422/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.44s/it]  7%|▋         | 2/29 [00:58<10:53, 24.20s/it] 10%|█         | 3/29 [00:59<05:52, 13.57s/it] 14%|█▍        | 4/29 [01:00<03:34,  8.58s/it] 17%|█▋        | 5/29 [01:01<02:19,  5.82s/it] 21%|██        | 6/29 [01:02<01:35,  4.15s/it] 24%|██▍       | 7/29 [01:02<01:08,  3.10s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.40s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.8020575046539307
Epoch 423/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:54, 59.80s/it]  7%|▋         | 2/29 [01:00<11:19, 25.17s/it] 10%|█         | 3/29 [01:01<06:06, 14.10s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.89s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.02s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7853198051452637
Epoch 424/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:23, 58.69s/it]  7%|▋         | 2/29 [01:01<11:42, 26.01s/it] 10%|█         | 3/29 [01:02<06:18, 14.56s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.17s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.20s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8015260696411133
Epoch 425/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:49, 61.76s/it]  7%|▋         | 2/29 [01:02<11:41, 25.97s/it] 10%|█         | 3/29 [01:03<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.16s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.805274724960327
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0139, 0.0022,  ..., 0.0041, 0.0001, 0.0194],
        [0.0030, 0.0095, 0.0021,  ..., 0.0023, 0.0002, 0.0184],
        [0.0329, 0.0063, 0.0036,  ..., 0.0054, 0.0152, 0.0243],
        ...,
        [0.0074, 0.0079, 0.0183,  ..., 0.0040, 0.0017, 0.0208],
        [0.0042, 0.0083, 0.0120,  ..., 0.0049, 0.0049, 0.0201],
        [0.0093, 0.0044, 0.0041,  ..., 0.0027, 0.0022, 0.0227]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9962, 0.9952, 0.9952, 0.9949, 0.9947, 0.9947, 0.9947, 0.9946,
         0.9943],
        [0.9973, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9764, 0.9694, 0.9688, 0.9663, 0.9658, 0.9653, 0.9652, 0.9650, 0.9649,
         0.9632],
        [0.9932, 0.9925, 0.9923, 0.9922, 0.9917, 0.9909, 0.9908, 0.9898, 0.9896,
         0.9894],
        [0.9880, 0.9874, 0.9862, 0.9845, 0.9845, 0.9842, 0.9836, 0.9836, 0.9836,
         0.9833],
        [0.9841, 0.9831, 0.9806, 0.9766, 0.9758, 0.9747, 0.9743, 0.9736, 0.9730,
         0.9720],
        [0.9800, 0.9694, 0.9693, 0.9681, 0.9667, 0.9666, 0.9649, 0.9647, 0.9633,
         0.9627],
        [0.9766, 0.9735, 0.9691, 0.9682, 0.9615, 0.9577, 0.9575, 0.9570, 0.9561,
         0.9558],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9938, 0.9900, 0.9887, 0.9881, 0.9866, 0.9862, 0.9851, 0.9839, 0.9838,
         0.9833],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9938, 0.9932, 0.9914, 0.9913, 0.9904, 0.9903, 0.9903, 0.9902, 0.9901,
         0.9894],
        [0.9919, 0.9903, 0.9893, 0.9885, 0.9870, 0.9861, 0.9858, 0.9844, 0.9840,
         0.9833],
        [0.9984, 0.9982, 0.9981, 0.9980, 0.9979, 0.9977, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9965, 0.9964, 0.9963, 0.9961, 0.9960, 0.9958, 0.9957, 0.9956, 0.9955,
         0.9955],
        [0.9954, 0.9948, 0.9947, 0.9946, 0.9945, 0.9944, 0.9943, 0.9943, 0.9943,
         0.9943],
        [0.9945, 0.9938, 0.9938, 0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9932],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9975],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9952, 0.9945, 0.9943, 0.9941, 0.9941, 0.9937, 0.9936, 0.9935, 0.9928,
         0.9926],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9976,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9951, 0.9951, 0.9945, 0.9945, 0.9943, 0.9942, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9990, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9983, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9882, 0.9868, 0.9777, 0.9716, 0.9688, 0.9670, 0.9669, 0.9643, 0.9642,
         0.9596],
        [0.9964, 0.9963, 0.9960, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9955],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9967, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9961, 0.9961,
         0.9961],
        [0.9852, 0.9827, 0.9793, 0.9759, 0.9738, 0.9735, 0.9716, 0.9710, 0.9686,
         0.9686],
        [0.9959, 0.9955, 0.9953, 0.9951, 0.9951, 0.9951, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9924, 0.9919, 0.9916, 0.9912, 0.9911, 0.9911, 0.9903, 0.9903, 0.9902,
         0.9900],
        [0.9961, 0.9958, 0.9957, 0.9957, 0.9955, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9953],
        [0.9849, 0.9848, 0.9843, 0.9842, 0.9824, 0.9813, 0.9809, 0.9795, 0.9790,
         0.9781],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9897, 0.9872, 0.9862, 0.9856, 0.9851, 0.9839, 0.9838, 0.9836, 0.9834,
         0.9828],
        [0.9863, 0.9793, 0.9788, 0.9779, 0.9777, 0.9772, 0.9769, 0.9766, 0.9765,
         0.9759],
        [0.9872, 0.9860, 0.9738, 0.9713, 0.9616, 0.9588, 0.9563, 0.9563, 0.9554,
         0.9552],
        [0.9727, 0.9692, 0.9684, 0.9663, 0.9656, 0.9631, 0.9628, 0.9624, 0.9615,
         0.9532],
        [0.9909, 0.9899, 0.9891, 0.9889, 0.9886, 0.9882, 0.9881, 0.9877, 0.9875,
         0.9873],
        [0.9943, 0.9941, 0.9941, 0.9941, 0.9938, 0.9935, 0.9934, 0.9934, 0.9932,
         0.9929],
        [0.9917, 0.9915, 0.9913, 0.9913, 0.9909, 0.9906, 0.9904, 0.9902, 0.9902,
         0.9899],
        [0.9910, 0.9910, 0.9897, 0.9897, 0.9889, 0.9887, 0.9873, 0.9872, 0.9869,
         0.9867],
        [0.9937, 0.9928, 0.9928, 0.9921, 0.9917, 0.9916, 0.9905, 0.9898, 0.9897,
         0.9893],
        [0.9903, 0.9877, 0.9868, 0.9867, 0.9858, 0.9853, 0.9850, 0.9849, 0.9844,
         0.9834],
        [0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9948, 0.9947, 0.9946,
         0.9942],
        [0.9957, 0.9951, 0.9950, 0.9949, 0.9946, 0.9934, 0.9934, 0.9931, 0.9931,
         0.9931],
        [0.9944, 0.9913, 0.9901, 0.9900, 0.9894, 0.9892, 0.9889, 0.9887, 0.9886,
         0.9882],
        [0.9916, 0.9909, 0.9909, 0.9904, 0.9870, 0.9866, 0.9864, 0.9858, 0.9857,
         0.9855],
        [0.9919, 0.9916, 0.9908, 0.9906, 0.9890, 0.9888, 0.9886, 0.9876, 0.9863,
         0.9858],
        [0.9967, 0.9939, 0.9929, 0.9925, 0.9921, 0.9909, 0.9884, 0.9881, 0.9879,
         0.9877],
        [0.9901, 0.9887, 0.9883, 0.9879, 0.9879, 0.9873, 0.9871, 0.9870, 0.9865,
         0.9862],
        [0.9917, 0.9910, 0.9875, 0.9854, 0.9843, 0.9836, 0.9836, 0.9834, 0.9827,
         0.9820],
        [0.9924, 0.9923, 0.9920, 0.9917, 0.9914, 0.9898, 0.9863, 0.9862, 0.9853,
         0.9843],
        [0.9926, 0.9923, 0.9921, 0.9920, 0.9920, 0.9915, 0.9914, 0.9908, 0.9898,
         0.9898]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515074.3750, 1514885.1250, 1495049.0000, 1493447.2500, 1486995.0000,
         1484570.6250, 1484290.2500, 1483200.7500, 1481114.5000, 1474386.5000],
        [1540487.0000, 1527228.3750, 1526245.5000, 1525154.2500, 1524435.7500,
         1523675.6250, 1523119.2500, 1522984.1250, 1520701.1250, 1520627.2500],
        [1141738.7500, 1034113.6875, 1025429.3125,  989196.6250,  982229.9375,
          974236.6875,  973458.5000,  970693.0625,  969067.0625,  946059.9375],
        [1453022.6250, 1437668.8750, 1434472.3750, 1431131.5000, 1421643.3750,
         1404689.5000, 1403032.0000, 1383666.5000, 1379296.2500, 1375863.3750],
        [1348616.3750, 1336286.2500, 1313169.8750, 1282778.5000, 1281899.2500,
         1276369.5000, 1266838.8750, 1266222.8750, 1265985.0000, 1260561.3750],
        [1274957.0000, 1257156.5000, 1213594.5000, 1146246.7500, 1132258.6250,
         1114969.2500, 1108720.7500, 1097903.1250, 1087786.3750, 1072480.3750],
        [1203376.3750, 1033880.9375, 1032857.0625, 1013900.3125,  994790.5000,
          993749.4375,  969156.7500,  967130.0625,  947621.2500,  939040.6250],
        [1145937.5000, 1095890.5000, 1029355.3125, 1015858.3125,  923111.3125,
          874741.3125,  872629.1250,  866205.8125,  855122.0000,  850841.5625],
        [1544036.1250, 1530684.0000, 1530179.0000, 1524059.3750, 1523610.3750,
         1521899.6250, 1519070.5000, 1518043.7500, 1517434.3750, 1516802.2500],
        [1465148.0000, 1387646.6250, 1361628.8750, 1349635.2500, 1320864.1250,
         1313340.2500, 1293919.8750, 1271262.3750, 1269146.1250, 1261469.2500],
        [1556020.0000, 1555347.8750, 1555346.5000, 1555322.6250, 1551472.3750,
         1549912.2500, 1549615.1250, 1548982.7500, 1548270.8750, 1547414.7500],
        [1464019.3750, 1453200.0000, 1414658.1250, 1413792.1250, 1395782.6250,
         1393316.8750, 1392296.7500, 1391556.0000, 1388929.6250, 1375298.0000],
        [1426275.5000, 1393512.2500, 1373226.0000, 1358641.5000, 1329275.2500,
         1311756.7500, 1307181.1250, 1281473.8750, 1274045.3750, 1260747.6250],
        [1564859.5000, 1560737.1250, 1556549.8750, 1556325.6250, 1554068.3750,
         1547518.0000, 1541531.8750, 1540736.7500, 1540635.3750, 1539172.7500],
        [1577813.0000, 1576988.5000, 1576193.1250, 1576182.6250, 1575464.2500,
         1575360.5000, 1575159.3750, 1575096.2500, 1574542.0000, 1573705.8750],
        [1576021.8750, 1573558.7500, 1572555.1250, 1571805.3750, 1571126.5000,
         1571119.0000, 1570248.8750, 1570072.1250, 1568348.1250, 1567972.7500],
        [1523290.7500, 1519703.7500, 1518760.5000, 1513646.2500, 1511831.3750,
         1506875.3750, 1505496.5000, 1503384.5000, 1501378.6250, 1500043.2500],
        [1498087.6250, 1486619.3750, 1483386.0000, 1480470.5000, 1479492.3750,
         1478247.0000, 1475198.1250, 1475110.7500, 1474597.3750, 1474435.6250],
        [1479759.1250, 1465205.2500, 1464445.2500, 1458847.2500, 1458093.3750,
         1455327.5000, 1454927.8750, 1454386.8750, 1452988.0000, 1452791.2500],
        [1555573.3750, 1553529.0000, 1552188.7500, 1551007.8750, 1549318.1250,
         1549073.0000, 1548849.8750, 1548186.7500, 1546640.2500, 1545189.5000],
        [1554299.5000, 1552114.7500, 1551297.8750, 1550987.2500, 1549822.0000,
         1549412.6250, 1546329.0000, 1544031.6250, 1543100.0000, 1542946.8750],
        [1494108.2500, 1479774.6250, 1475330.3750, 1471984.0000, 1470352.2500,
         1463045.2500, 1460015.0000, 1458608.0000, 1444810.6250, 1440496.1250],
        [1574623.0000, 1572946.6250, 1562636.0000, 1562126.5000, 1561736.2500,
         1558152.3750, 1554570.7500, 1554010.5000, 1547364.6250, 1545017.1250],
        [1579675.3750, 1576553.8750, 1574514.8750, 1574234.2500, 1573967.0000,
         1573390.7500, 1573359.1250, 1572421.6250, 1571161.1250, 1571020.2500],
        [1493189.5000, 1493148.1250, 1479766.1250, 1478595.2500, 1474276.8750,
         1472151.1250, 1471004.5000, 1469675.2500, 1469458.0000, 1466709.6250],
        [1577044.1250, 1573221.2500, 1570474.8750, 1569067.6250, 1568490.1250,
         1567815.7500, 1566591.7500, 1565186.3750, 1564511.8750, 1564388.0000],
        [1566466.1250, 1565555.2500, 1562759.7500, 1562419.8750, 1559924.6250,
         1557360.6250, 1554465.6250, 1554370.6250, 1553542.3750, 1552289.2500],
        [1576532.8750, 1575136.7500, 1574687.7500, 1574048.0000, 1574007.5000,
         1573428.1250, 1571887.8750, 1571574.6250, 1570818.0000, 1570136.5000],
        [1579184.2500, 1578999.0000, 1578813.8750, 1576202.2500, 1575930.1250,
         1575742.2500, 1575356.1250, 1575175.8750, 1574958.0000, 1574914.5000],
        [1581300.1250, 1580241.8750, 1576448.6250, 1575674.7500, 1575652.0000,
         1575414.7500, 1575314.1250, 1574840.8750, 1573994.1250, 1573333.6250],
        [1580998.6250, 1580493.6250, 1580282.6250, 1578859.0000, 1578533.8750,
         1578148.3750, 1577576.7500, 1576642.6250, 1576469.7500, 1576167.6250],
        [1580581.0000, 1578538.3750, 1576750.8750, 1576675.7500, 1576286.3750,
         1575942.1250, 1575828.0000, 1575562.0000, 1574950.5000, 1574887.5000],
        [1352240.5000, 1325313.1250, 1164354.1250, 1066447.6250, 1025068.5000,
          998135.6250,  996832.3125,  961450.4375,  960263.8750,  898956.6875],
        [1520112.6250, 1517977.1250, 1512106.7500, 1509880.3750, 1507510.7500,
         1505539.5000, 1505525.2500, 1505408.8750, 1504632.3750, 1501033.5000],
        [1555929.3750, 1553306.6250, 1552816.5000, 1549795.3750, 1548508.7500,
         1547503.3750, 1547482.6250, 1547467.8750, 1547329.2500, 1546414.5000],
        [1526204.7500, 1520627.2500, 1519780.6250, 1519424.0000, 1519350.2500,
         1518426.0000, 1517639.8750, 1514459.1250, 1513784.7500, 1513503.2500],
        [1295972.3750, 1250364.0000, 1189933.0000, 1134733.0000, 1100212.1250,
         1096030.5000, 1066266.6250, 1056834.5000, 1022113.6250, 1021386.7500],
        [1509830.0000, 1499811.6250, 1495772.0000, 1492594.2500, 1492123.2500,
         1492023.6250, 1489701.8750, 1489564.0000, 1487217.6250, 1487204.8750],
        [1436377.8750, 1424835.6250, 1418360.7500, 1410617.7500, 1410207.5000,
         1409200.6250, 1393803.3750, 1392866.5000, 1391288.0000, 1387906.0000],
        [1513874.2500, 1507213.1250, 1505337.1250, 1505337.1250, 1501550.5000,
         1501017.7500, 1499994.6250, 1498380.5000, 1495772.0000, 1495589.5000],
        [1290513.6250, 1287676.2500, 1279660.2500, 1276354.8750, 1244617.7500,
         1225528.5000, 1218636.0000, 1194745.2500, 1185013.5000, 1169667.3750],
        [1564655.1250, 1562725.3750, 1559390.6250, 1558702.3750, 1558660.6250,
         1557928.0000, 1557544.7500, 1556405.7500, 1556141.6250, 1555919.1250],
        [1557085.7500, 1556794.7500, 1554849.5000, 1551087.7500, 1550429.6250,
         1550036.3750, 1549053.6250, 1547962.3750, 1546975.1250, 1546205.1250],
        [1539999.3750, 1536348.2500, 1533166.1250, 1533113.6250, 1531472.5000,
         1529506.3750, 1526584.6250, 1524850.2500, 1523994.0000, 1523922.7500],
        [1382127.3750, 1332542.2500, 1314302.5000, 1302060.1250, 1292827.0000,
         1271454.0000, 1270403.1250, 1265910.2500, 1261695.5000, 1251010.3750],
        [1315388.3750, 1189901.2500, 1181552.6250, 1166435.8750, 1164298.6250,
         1155351.5000, 1149768.7500, 1145027.5000, 1144472.8750, 1133804.8750],
        [1332016.1250, 1310432.6250, 1100568.8750, 1061676.2500,  924626.6875,
          888597.8750,  857379.8125,  857222.8750,  846651.9375,  843361.6875],
        [1084163.6250, 1029963.1250, 1018537.6875,  988897.6250,  979218.3125,
          944171.6875,  941155.5625,  935785.6875,  922913.2500,  819733.4375],
        [1405679.8750, 1385964.3750, 1369328.8750, 1365571.7500, 1359543.6250,
         1351604.8750, 1349850.3750, 1343317.6250, 1338228.6250, 1335619.8750],
        [1475169.8750, 1471937.6250, 1471791.7500, 1470868.5000, 1464695.3750,
         1459086.6250, 1456589.6250, 1455359.3750, 1452913.2500, 1446038.8750],
        [1421997.2500, 1417968.5000, 1413991.7500, 1412515.8750, 1404302.3750,
         1398915.6250, 1395014.7500, 1392098.8750, 1390305.1250, 1385501.7500],
        [1408209.1250, 1407349.7500, 1381880.8750, 1380389.7500, 1365832.2500,
         1361136.7500, 1333990.3750, 1332849.8750, 1326880.1250, 1324007.0000],
        [1463385.6250, 1444480.0000, 1443042.6250, 1430010.0000, 1421427.8750,
         1419645.0000, 1397748.7500, 1383692.8750, 1381795.2500, 1373034.8750],
        [1392736.3750, 1342151.1250, 1324913.8750, 1324076.3750, 1305972.3750,
         1297197.8750, 1292247.7500, 1290702.0000, 1279765.2500, 1261963.7500],
        [1494916.3750, 1493360.3750, 1493092.6250, 1493092.6250, 1492795.1250,
         1491090.5000, 1485693.7500, 1482896.7500, 1481252.8750, 1472989.5000],
        [1505647.2500, 1491138.8750, 1490706.6250, 1488758.7500, 1481411.0000,
         1457138.5000, 1456442.5000, 1450302.2500, 1449728.5000, 1449728.5000],
        [1476677.3750, 1413914.8750, 1390091.7500, 1386789.3750, 1374613.5000,
         1371696.0000, 1365548.3750, 1362321.1250, 1358890.3750, 1352316.5000],
        [1419130.6250, 1406072.7500, 1405769.6250, 1395205.0000, 1329059.7500,
         1322362.7500, 1317062.8750, 1306099.5000, 1305390.8750, 1301317.7500],
        [1425011.0000, 1419718.1250, 1403291.6250, 1398468.7500, 1367734.0000,
         1364530.2500, 1359678.6250, 1339759.6250, 1315244.2500, 1306951.7500],
        [1527379.7500, 1467531.0000, 1445033.8750, 1438600.1250, 1428671.3750,
         1405926.5000, 1355145.1250, 1350319.0000, 1345357.3750, 1342485.1250],
        [1388578.6250, 1362478.3750, 1353222.2500, 1346035.0000, 1345522.8750,
         1334224.6250, 1330801.1250, 1328418.5000, 1320029.2500, 1314284.8750],
        [1420767.7500, 1408082.8750, 1338983.0000, 1299336.0000, 1278095.5000,
         1266652.8750, 1266007.8750, 1263232.8750, 1249945.3750, 1238082.8750],
        [1435997.1250, 1434110.0000, 1427048.3750, 1421609.3750, 1414384.2500,
         1382985.6250, 1314945.7500, 1314525.6250, 1297618.5000, 1278257.6250],
        [1440155.3750, 1433645.1250, 1429339.1250, 1428217.8750, 1427716.6250,
         1417238.5000, 1415008.7500, 1403025.3750, 1383183.6250, 1382942.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515074.3750,       0.0000],
         [1514885.1250,       0.0000],
         [1495049.0000,       0.0000],
         ...,
         [1483200.7500,       0.0000],
         [      0.0000, 1481114.5000],
         [1474386.5000,       0.0000]],

        [[1540487.0000,       0.0000],
         [1527228.3750,       0.0000],
         [1526245.5000,       0.0000],
         ...,
         [1522984.1250,       0.0000],
         [1520701.1250,       0.0000],
         [1520627.2500,       0.0000]],

        [[1141738.7500,       0.0000],
         [      0.0000, 1034113.6875],
         [1025429.3125,       0.0000],
         ...,
         [ 970693.0625,       0.0000],
         [ 969067.0625,       0.0000],
         [      0.0000,  946059.9375]],

        ...,

        [[1420767.7500,       0.0000],
         [1408082.8750,       0.0000],
         [1338983.0000,       0.0000],
         ...,
         [1263232.8750,       0.0000],
         [1249945.3750,       0.0000],
         [      0.0000, 1238082.8750]],

        [[1435997.1250,       0.0000],
         [1434110.0000,       0.0000],
         [1427048.3750,       0.0000],
         ...,
         [      0.0000, 1314525.6250],
         [1297618.5000,       0.0000],
         [1278257.6250,       0.0000]],

        [[      0.0000, 1440155.3750],
         [      0.0000, 1433645.1250],
         [      0.0000, 1429339.1250],
         ...,
         [      0.0000, 1403025.3750],
         [1383183.6250,       0.0000],
         [      0.0000, 1382942.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13431899.0000,  1481114.5000],
        [15254658.0000,        0.0000],
        [ 4106928.0000,  5899295.5000],
        [12721454.0000,  1403032.0000],
        [ 9105342.0000,  3793385.5000],
        [ 9261923.0000,  2244150.0000],
        [ 4967300.0000,  5128203.5000],
        [ 8654952.0000,   874741.3125],
        [12209315.0000,  3036505.0000],
        [11906414.0000,  1387646.6250],
        [15517706.0000,        0.0000],
        [12707552.0000,  1375298.0000],
        [13316136.0000,        0.0000],
        [15502136.0000,        0.0000],
        [15756505.0000,        0.0000],
        [15712828.0000,        0.0000],
        [13581120.0000,  1523290.7500],
        [13307557.0000,  1498087.6250],
        [14596771.0000,        0.0000],
        [15499556.0000,        0.0000],
        [15484342.0000,        0.0000],
        [11746044.0000,  2912480.0000],
        [15593184.0000,        0.0000],
        [15740298.0000,        0.0000],
        [10309486.0000,  4458489.0000],
        [15686792.0000,        0.0000],
        [15589154.0000,        0.0000],
        [15732258.0000,        0.0000],
        [15765276.0000,        0.0000],
        [15762214.0000,        0.0000],
        [15784174.0000,        0.0000],
        [15766003.0000,        0.0000],
        [ 2893924.5000,  7855138.0000],
        [ 9053291.0000,  6036436.0000],
        [12401582.0000,  3094971.2500],
        [12146210.0000,  3036990.0000],
        [ 3178433.5000,  8055413.0000],
        [11944008.0000,  2991835.2500],
        [12681661.0000,  1393803.3750],
        [15024068.0000,        0.0000],
        [ 9840119.0000,  2532294.0000],
        [15588074.0000,        0.0000],
        [15510479.0000,        0.0000],
        [13769792.0000,  1533166.1250],
        [ 2521413.5000, 10422919.0000],
        [ 1164298.6250, 10581704.0000],
        [ 5217841.0000,  4804694.0000],
        [ 2678432.5000,  6986107.5000],
        [ 4067101.0000,  9537609.0000],
        [10216949.0000,  4407501.5000],
        [12618620.0000,  1413991.7500],
        [ 1324007.0000, 12298518.0000],
        [ 1373034.8750, 12785229.0000],
        [ 2648990.2500, 10462737.0000],
        [11895174.0000,  2986007.0000],
        [10242806.0000,  4478197.0000],
        [ 2734017.0000, 11118842.0000],
        [ 5257613.0000,  8249858.5000],
        [ 1306951.7500, 12393436.0000],
        [ 2697630.2500, 11408819.0000],
        [10706599.0000,  2716997.0000],
        [10524452.0000,  2504735.7500],
        [11092010.0000,  2629471.5000],
        [ 1383183.6250, 12777289.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 426/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:42, 57.25s/it]  7%|▋         | 2/29 [01:01<11:51, 26.34s/it] 10%|█         | 3/29 [01:02<06:23, 14.73s/it] 14%|█▍        | 4/29 [01:03<03:51,  9.28s/it] 17%|█▋        | 5/29 [01:04<02:30,  6.27s/it] 21%|██        | 6/29 [01:05<01:42,  4.45s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.54s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.7937638759613037
Epoch 427/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:17, 58.49s/it]  7%|▋         | 2/29 [01:01<11:32, 25.65s/it] 10%|█         | 3/29 [01:02<06:13, 14.36s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.788907527923584
Epoch 428/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.23s/it]  7%|▋         | 2/29 [01:01<11:24, 25.34s/it] 10%|█         | 3/29 [01:02<06:08, 14.19s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.789335012435913
Epoch 429/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:45, 61.61s/it]  7%|▋         | 2/29 [01:02<11:39, 25.91s/it] 10%|█         | 3/29 [01:03<06:16, 14.50s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7926251888275146
Epoch 430/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:30, 58.96s/it]  7%|▋         | 2/29 [01:00<11:22, 25.29s/it] 10%|█         | 3/29 [01:01<06:08, 14.16s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.94s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.05s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7907979488372803
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0029, 0.0138, 0.0022,  ..., 0.0041, 0.0001, 0.0199],
        [0.0030, 0.0096, 0.0021,  ..., 0.0023, 0.0002, 0.0186],
        [0.0324, 0.0064, 0.0037,  ..., 0.0053, 0.0151, 0.0242],
        ...,
        [0.0077, 0.0080, 0.0188,  ..., 0.0040, 0.0017, 0.0208],
        [0.0045, 0.0082, 0.0125,  ..., 0.0050, 0.0050, 0.0202],
        [0.0094, 0.0044, 0.0041,  ..., 0.0026, 0.0022, 0.0228]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9962, 0.9952, 0.9952, 0.9950, 0.9949, 0.9949, 0.9947, 0.9947,
         0.9943],
        [0.9973, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9757, 0.9693, 0.9684, 0.9657, 0.9652, 0.9651, 0.9646, 0.9642, 0.9640,
         0.9635],
        [0.9935, 0.9927, 0.9925, 0.9924, 0.9921, 0.9913, 0.9912, 0.9905, 0.9900,
         0.9898],
        [0.9889, 0.9873, 0.9870, 0.9855, 0.9849, 0.9848, 0.9847, 0.9846, 0.9845,
         0.9844],
        [0.9848, 0.9838, 0.9814, 0.9781, 0.9771, 0.9762, 0.9757, 0.9742, 0.9741,
         0.9737],
        [0.9791, 0.9705, 0.9701, 0.9683, 0.9677, 0.9649, 0.9642, 0.9639, 0.9634,
         0.9625],
        [0.9765, 0.9733, 0.9691, 0.9680, 0.9609, 0.9582, 0.9564, 0.9564, 0.9547,
         0.9542],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9941, 0.9904, 0.9895, 0.9882, 0.9875, 0.9871, 0.9863, 0.9851, 0.9845,
         0.9838],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9939, 0.9935, 0.9914, 0.9913, 0.9909, 0.9907, 0.9907, 0.9904, 0.9903,
         0.9899],
        [0.9922, 0.9913, 0.9896, 0.9895, 0.9874, 0.9873, 0.9867, 0.9854, 0.9850,
         0.9839],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9979, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9986],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9960, 0.9957, 0.9957, 0.9955, 0.9955,
         0.9954],
        [0.9955, 0.9950, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943,
         0.9943],
        [0.9944, 0.9938, 0.9936, 0.9936, 0.9935, 0.9933, 0.9932, 0.9932, 0.9932,
         0.9931],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9953, 0.9947, 0.9942, 0.9942, 0.9940, 0.9940, 0.9938, 0.9936, 0.9929,
         0.9928],
        [0.9988, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9976,
         0.9974],
        [0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9953, 0.9952, 0.9947, 0.9946, 0.9944, 0.9942, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9884, 0.9869, 0.9776, 0.9711, 0.9683, 0.9680, 0.9680, 0.9647, 0.9642,
         0.9607],
        [0.9964, 0.9963, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9957, 0.9957,
         0.9954],
        [0.9980, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9966, 0.9964, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9960],
        [0.9855, 0.9831, 0.9797, 0.9759, 0.9743, 0.9738, 0.9721, 0.9713, 0.9690,
         0.9688],
        [0.9959, 0.9955, 0.9952, 0.9952, 0.9952, 0.9952, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9929, 0.9923, 0.9920, 0.9916, 0.9914, 0.9911, 0.9909, 0.9906, 0.9905,
         0.9904],
        [0.9960, 0.9958, 0.9956, 0.9956, 0.9956, 0.9955, 0.9955, 0.9955, 0.9952,
         0.9951],
        [0.9849, 0.9849, 0.9845, 0.9844, 0.9824, 0.9815, 0.9811, 0.9796, 0.9792,
         0.9785],
        [0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9967, 0.9965, 0.9965,
         0.9965],
        [0.9896, 0.9867, 0.9858, 0.9853, 0.9847, 0.9838, 0.9835, 0.9835, 0.9834,
         0.9824],
        [0.9858, 0.9793, 0.9788, 0.9787, 0.9784, 0.9776, 0.9776, 0.9772, 0.9769,
         0.9762],
        [0.9872, 0.9858, 0.9738, 0.9713, 0.9620, 0.9597, 0.9564, 0.9561, 0.9557,
         0.9557],
        [0.9732, 0.9687, 0.9683, 0.9666, 0.9655, 0.9631, 0.9629, 0.9623, 0.9620,
         0.9539],
        [0.9912, 0.9898, 0.9892, 0.9887, 0.9885, 0.9881, 0.9881, 0.9872, 0.9872,
         0.9872],
        [0.9942, 0.9941, 0.9941, 0.9941, 0.9938, 0.9933, 0.9933, 0.9933, 0.9932,
         0.9929],
        [0.9918, 0.9914, 0.9913, 0.9912, 0.9907, 0.9903, 0.9902, 0.9902, 0.9899,
         0.9899],
        [0.9910, 0.9908, 0.9896, 0.9895, 0.9890, 0.9888, 0.9871, 0.9870, 0.9867,
         0.9866],
        [0.9938, 0.9929, 0.9929, 0.9922, 0.9918, 0.9917, 0.9905, 0.9898, 0.9897,
         0.9894],
        [0.9905, 0.9877, 0.9870, 0.9867, 0.9858, 0.9856, 0.9852, 0.9849, 0.9842,
         0.9834],
        [0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9949, 0.9946, 0.9946, 0.9945,
         0.9942],
        [0.9957, 0.9951, 0.9949, 0.9949, 0.9946, 0.9933, 0.9933, 0.9932, 0.9930,
         0.9930],
        [0.9945, 0.9913, 0.9901, 0.9901, 0.9894, 0.9893, 0.9890, 0.9889, 0.9885,
         0.9883],
        [0.9916, 0.9911, 0.9909, 0.9905, 0.9870, 0.9869, 0.9862, 0.9859, 0.9858,
         0.9856],
        [0.9919, 0.9916, 0.9908, 0.9905, 0.9890, 0.9888, 0.9887, 0.9874, 0.9863,
         0.9859],
        [0.9967, 0.9939, 0.9929, 0.9926, 0.9922, 0.9909, 0.9884, 0.9883, 0.9881,
         0.9875],
        [0.9900, 0.9889, 0.9884, 0.9882, 0.9880, 0.9875, 0.9874, 0.9872, 0.9868,
         0.9863],
        [0.9916, 0.9909, 0.9873, 0.9850, 0.9841, 0.9835, 0.9834, 0.9831, 0.9824,
         0.9818],
        [0.9924, 0.9923, 0.9919, 0.9916, 0.9913, 0.9897, 0.9861, 0.9860, 0.9851,
         0.9842],
        [0.9926, 0.9923, 0.9921, 0.9921, 0.9920, 0.9916, 0.9913, 0.9907, 0.9897,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 0, 1, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1518287.0000, 1516673.3750, 1494972.0000, 1493599.7500, 1489674.8750,
         1488176.7500, 1487928.5000, 1482936.2500, 1482653.3750, 1475821.5000],
        [1538892.3750, 1527641.8750, 1525835.0000, 1525500.3750, 1524680.1250,
         1523370.5000, 1523042.2500, 1522162.3750, 1521230.6250, 1520852.1250],
        [1130181.8750, 1032191.3750, 1019383.0625,  980219.0000,  974007.3125,
          972682.6875,  965197.8125,  959895.7500,  956476.3750,  950145.0625],
        [1459403.8750, 1442866.3750, 1437873.2500, 1436479.2500, 1429376.0000,
         1412352.8750, 1410966.2500, 1396463.0000, 1386686.2500, 1383963.3750],
        [1364760.6250, 1335461.8750, 1328229.8750, 1300554.7500, 1290517.3750,
         1287382.8750, 1286383.8750, 1284645.3750, 1281607.1250, 1280146.1250],
        [1288430.5000, 1270504.8750, 1227460.7500, 1169594.8750, 1154305.1250,
         1139591.3750, 1130714.5000, 1106698.8750, 1104617.2500, 1099001.0000],
        [1187718.7500, 1049786.7500, 1043538.1250, 1016779.1250, 1008290.3750,
          969778.0000,  959042.9375,  955604.7500,  949384.1875,  936306.0625],
        [1143681.8750, 1093476.7500, 1028847.9375, 1013221.7500,  915674.3125,
          880265.3750,  858943.8125,  858665.3750,  837616.8750,  831935.9375],
        [1544813.7500, 1531858.1250, 1530451.8750, 1524992.7500, 1524578.2500,
         1522430.8750, 1520463.3750, 1518269.6250, 1517569.0000, 1517353.3750],
        [1470306.0000, 1394841.8750, 1377046.1250, 1352481.6250, 1337714.2500,
         1331255.5000, 1315722.1250, 1292707.5000, 1282330.7500, 1270277.1250],
        [1555834.5000, 1555423.5000, 1555152.1250, 1554846.6250, 1549987.6250,
         1548356.6250, 1548325.5000, 1548272.3750, 1548234.0000, 1546629.8750],
        [1467375.5000, 1458225.5000, 1414343.6250, 1412595.3750, 1404669.3750,
         1401157.3750, 1400442.6250, 1396018.2500, 1393165.3750, 1384725.1250],
        [1432438.2500, 1413952.5000, 1378803.1250, 1377019.8750, 1335762.5000,
         1334915.6250, 1322906.3750, 1299674.3750, 1291036.8750, 1270868.3750],
        [1564547.6250, 1560003.3750, 1555696.5000, 1555336.0000, 1553647.5000,
         1547202.2500, 1541886.2500, 1540421.0000, 1540269.6250, 1538515.2500],
        [1577375.1250, 1576732.8750, 1575716.7500, 1575665.6250, 1575262.8750,
         1575105.1250, 1574753.7500, 1574647.1250, 1574462.3750, 1573300.6250],
        [1575856.5000, 1573252.6250, 1571932.8750, 1571748.5000, 1571376.8750,
         1571209.0000, 1569567.5000, 1569227.7500, 1568016.1250, 1567741.0000],
        [1523036.5000, 1518610.0000, 1518453.6250, 1514183.2500, 1511133.6250,
         1505957.3750, 1504926.6250, 1501626.2500, 1500760.2500, 1498081.8750],
        [1500694.3750, 1489071.1250, 1481649.8750, 1481361.6250, 1479105.8750,
         1477712.8750, 1477226.7500, 1475655.3750, 1475267.0000, 1474153.0000],
        [1476983.0000, 1465523.8750, 1460004.0000, 1459987.2500, 1457798.6250,
         1455223.3750, 1452922.8750, 1451687.5000, 1451493.6250, 1450678.6250],
        [1555419.0000, 1552881.6250, 1551701.7500, 1550885.0000, 1549525.0000,
         1548443.7500, 1548185.2500, 1548014.0000, 1546665.2500, 1546107.8750],
        [1553986.7500, 1552616.5000, 1551139.6250, 1550380.8750, 1548940.0000,
         1548807.0000, 1544999.3750, 1544042.0000, 1543077.8750, 1542108.3750],
        [1496682.5000, 1482584.1250, 1473676.6250, 1472625.7500, 1468943.7500,
         1468936.7500, 1464434.1250, 1460701.6250, 1446821.0000, 1443148.5000],
        [1574145.6250, 1573161.1250, 1562119.0000, 1561691.5000, 1561349.0000,
         1557565.5000, 1554929.6250, 1553834.1250, 1546626.8750, 1543066.0000],
        [1579100.0000, 1576442.6250, 1573856.0000, 1573761.3750, 1573501.7500,
         1573147.6250, 1573068.1250, 1572963.0000, 1570735.6250, 1570016.7500],
        [1495485.3750, 1493804.8750, 1483987.3750, 1480864.5000, 1477962.2500,
         1473593.7500, 1471258.3750, 1469685.1250, 1468950.7500, 1467543.5000],
        [1576444.2500, 1572927.0000, 1570112.5000, 1568798.3750, 1568361.6250,
         1567594.5000, 1566165.8750, 1564959.6250, 1563253.1250, 1563226.2500],
        [1566478.0000, 1564999.7500, 1561855.3750, 1561483.0000, 1559384.7500,
         1556336.1250, 1553822.3750, 1553780.8750, 1553087.5000, 1551189.8750],
        [1576345.0000, 1574603.5000, 1574590.1250, 1574504.5000, 1573785.3750,
         1573543.7500, 1572561.1250, 1571640.6250, 1571400.7500, 1570353.6250],
        [1579002.0000, 1578779.2500, 1578353.1250, 1575936.1250, 1575506.3750,
         1575492.7500, 1575195.3750, 1574881.5000, 1574818.3750, 1574462.3750],
        [1581036.3750, 1579838.0000, 1576277.3750, 1575458.2500, 1575303.5000,
         1575219.3750, 1574852.8750, 1574620.0000, 1573605.2500, 1572772.6250],
        [1580890.0000, 1580368.5000, 1580047.3750, 1578595.5000, 1578288.5000,
         1578086.7500, 1577388.6250, 1576719.3750, 1576075.8750, 1575952.6250],
        [1580077.6250, 1578472.1250, 1576520.7500, 1576385.6250, 1576277.3750,
         1575592.0000, 1575425.2500, 1575204.3750, 1574587.0000, 1574366.3750],
        [1355632.3750, 1328032.1250, 1162843.8750, 1059335.8750, 1017590.0625,
         1013699.2500, 1013458.5625,  966804.5625,  960102.6875,  913310.8750],
        [1519117.0000, 1518042.3750, 1509488.8750, 1508907.3750, 1507663.1250,
         1505319.8750, 1505305.5000, 1504207.7500, 1504101.6250, 1499293.8750],
        [1554837.7500, 1552985.2500, 1552046.6250, 1549015.2500, 1548195.6250,
         1547285.0000, 1547053.2500, 1546477.8750, 1546454.3750, 1546299.5000],
        [1525359.2500, 1520453.2500, 1520170.5000, 1519406.7500, 1518721.5000,
         1517362.0000, 1516533.1250, 1515353.3750, 1512983.7500, 1512050.5000],
        [1301031.1250, 1257725.0000, 1196716.8750, 1134507.8750, 1108418.3750,
         1100665.5000, 1074617.1250, 1061417.0000, 1027065.7500, 1024199.8125],
        [1508518.8750, 1501570.5000, 1495201.6250, 1495134.5000, 1494531.5000,
         1493853.2500, 1490938.3750, 1489814.1250, 1488792.8750, 1486860.3750],
        [1446691.3750, 1433337.5000, 1427805.2500, 1419703.1250, 1414405.7500,
         1410157.7500, 1404340.0000, 1398870.2500, 1396574.8750, 1395499.1250],
        [1511747.7500, 1506930.1250, 1502792.5000, 1502579.0000, 1502579.0000,
         1500230.6250, 1500094.7500, 1499934.5000, 1493998.5000, 1493060.0000],
        [1290346.3750, 1289573.7500, 1282187.7500, 1281506.7500, 1245210.1250,
         1227915.0000, 1222157.8750, 1195792.7500, 1188520.8750, 1177944.3750],
        [1564523.8750, 1562190.5000, 1558969.8750, 1558889.6250, 1558688.8750,
         1557825.5000, 1556579.5000, 1556218.8750, 1555969.5000, 1555313.7500],
        [1557565.5000, 1556698.2500, 1555040.8750, 1550768.3750, 1550450.2500,
         1550272.8750, 1549378.7500, 1548030.2500, 1546845.2500, 1546426.3750],
        [1538924.6250, 1534605.6250, 1531890.2500, 1531716.3750, 1530346.8750,
         1528943.5000, 1525829.2500, 1522811.3750, 1522724.1250, 1522237.7500],
        [1378428.3750, 1323642.1250, 1306938.0000, 1297821.5000, 1286213.3750,
         1269546.8750, 1264933.8750, 1264036.7500, 1262389.8750, 1244848.0000],
        [1306398.5000, 1189787.6250, 1182992.3750, 1179888.3750, 1175670.6250,
         1162776.2500, 1161385.3750, 1154952.6250, 1150470.7500, 1139228.5000],
        [1331959.0000, 1306058.3750, 1101399.5000, 1062219.0000,  929268.6250,
          900172.2500,  858256.0000,  855349.5625,  850195.9375,  849835.1875],
        [1091826.2500, 1023628.5625, 1017329.0625,  993463.1875,  977884.7500,
          945135.6250,  942374.3750,  933546.5000,  929990.3125,  828182.1875],
        [1410294.8750, 1382855.1250, 1372143.3750, 1360878.5000, 1358304.7500,
         1351086.7500, 1350160.5000, 1333522.3750, 1333485.5000, 1333334.2500],
        [1473430.6250, 1470450.5000, 1470153.1250, 1470087.3750, 1465188.5000,
         1454948.6250, 1454133.0000, 1453918.0000, 1451335.8750, 1444977.5000],
        [1423105.6250, 1416198.1250, 1413234.1250, 1410504.7500, 1401065.2500,
         1392523.7500, 1390966.8750, 1390567.7500, 1385656.5000, 1384636.6250],
        [1408244.0000, 1403674.3750, 1379129.3750, 1377352.1250, 1368242.7500,
         1363371.3750, 1330672.8750, 1329906.6250, 1322680.5000, 1321106.0000],
        [1464977.6250, 1445827.8750, 1445548.0000, 1431233.8750, 1423222.3750,
         1420968.3750, 1397756.7500, 1383995.1250, 1381342.0000, 1376017.0000],
        [1396938.5000, 1342539.0000, 1328150.0000, 1324099.1250, 1307212.2500,
         1302015.3750, 1295118.6250, 1290699.5000, 1276631.2500, 1262796.8750],
        [1495321.3750, 1493028.6250, 1493028.6250, 1492538.7500, 1491245.5000,
         1488710.5000, 1482010.2500, 1481059.2500, 1479515.0000, 1473142.6250],
        [1504965.3750, 1491712.1250, 1488611.1250, 1486941.2500, 1481654.0000,
         1455005.5000, 1454839.0000, 1452018.3750, 1448459.8750, 1448459.8750],
        [1478931.0000, 1413982.2500, 1389190.5000, 1389075.2500, 1375262.6250,
         1372685.2500, 1367072.7500, 1366111.0000, 1357164.0000, 1353264.8750],
        [1419255.1250, 1408680.5000, 1405663.7500, 1398006.1250, 1328612.3750,
         1326710.6250, 1314688.6250, 1308513.1250, 1305891.5000, 1303467.6250],
        [1426389.6250, 1418517.7500, 1403737.3750, 1396837.2500, 1367096.2500,
         1362918.8750, 1362221.0000, 1337575.2500, 1316058.5000, 1307577.6250],
        [1527612.8750, 1467279.0000, 1446114.6250, 1439442.7500, 1432465.5000,
         1406170.5000, 1356293.2500, 1353099.5000, 1349509.1250, 1339081.2500],
        [1387117.3750, 1365185.0000, 1356064.3750, 1351247.8750, 1348710.2500,
         1338208.1250, 1337021.7500, 1332514.3750, 1324414.8750, 1316391.1250],
        [1419525.8750, 1405524.3750, 1334208.0000, 1291810.3750, 1275771.8750,
         1264705.8750, 1261759.1250, 1256326.0000, 1243692.1250, 1234017.2500],
        [1434725.5000, 1433505.5000, 1426177.5000, 1420102.6250, 1412383.8750,
         1381687.1250, 1311330.2500, 1309659.2500, 1293864.3750, 1276801.6250],
        [1439537.5000, 1432991.6250, 1429442.8750, 1428941.2500, 1427343.6250,
         1418627.2500, 1412934.8750, 1400421.3750, 1381621.2500, 1381190.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1518287.0000,       0.0000],
         [1516673.3750,       0.0000],
         [1494972.0000,       0.0000],
         ...,
         [1482936.2500,       0.0000],
         [      0.0000, 1482653.3750],
         [1475821.5000,       0.0000]],

        [[1538892.3750,       0.0000],
         [1527641.8750,       0.0000],
         [1525835.0000,       0.0000],
         ...,
         [1522162.3750,       0.0000],
         [1521230.6250,       0.0000],
         [1520852.1250,       0.0000]],

        [[1130181.8750,       0.0000],
         [      0.0000, 1032191.3750],
         [1019383.0625,       0.0000],
         ...,
         [ 959895.7500,       0.0000],
         [ 956476.3750,       0.0000],
         [      0.0000,  950145.0625]],

        ...,

        [[1419525.8750,       0.0000],
         [1405524.3750,       0.0000],
         [1334208.0000,       0.0000],
         ...,
         [1256326.0000,       0.0000],
         [1243692.1250,       0.0000],
         [1234017.2500,       0.0000]],

        [[1434725.5000,       0.0000],
         [1433505.5000,       0.0000],
         [1426177.5000,       0.0000],
         ...,
         [      0.0000, 1309659.2500],
         [1293864.3750,       0.0000],
         [1276801.6250,       0.0000]],

        [[      0.0000, 1439537.5000],
         [      0.0000, 1432991.6250],
         [      0.0000, 1429442.8750],
         ...,
         [      0.0000, 1400421.3750],
         [      0.0000, 1381621.2500],
         [1381190.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13448070.0000,  1482653.3750],
        [15253208.0000,        0.0000],
        [ 4065937.0000,  5874443.0000],
        [12785463.0000,  1410966.2500],
        [ 9188515.0000,  3851175.5000],
        [ 9414625.0000,  2276293.7500],
        [ 4987305.5000,  5088923.5000],
        [ 8603665.0000,   858665.3750],
        [13735212.0000,  1517569.0000],
        [12029841.0000,  1394841.8750],
        [15511063.0000,        0.0000],
        [14132718.0000,        0.0000],
        [13457378.0000,        0.0000],
        [15497526.0000,        0.0000],
        [15753023.0000,        0.0000],
        [15709928.0000,        0.0000],
        [13573734.0000,  1523036.5000],
        [13311203.0000,  1500694.3750],
        [14582303.0000,        0.0000],
        [15497828.0000,        0.0000],
        [15480098.0000,        0.0000],
        [13205929.0000,  1472625.7500],
        [15588488.0000,        0.0000],
        [15736592.0000,        0.0000],
        [10326302.0000,  4456834.0000],
        [15681844.0000,        0.0000],
        [15582418.0000,        0.0000],
        [15733328.0000,        0.0000],
        [15762428.0000,        0.0000],
        [15758983.0000,        0.0000],
        [15782413.0000,        0.0000],
        [15762908.0000,        0.0000],
        [ 2940468.7500,  7850342.0000],
        [ 9046228.0000,  6035219.0000],
        [12397066.0000,  3093584.5000],
        [12143140.0000,  3035254.5000],
        [ 3194035.2500,  8092329.5000],
        [11948444.0000,  2996772.0000],
        [12748514.0000,  1398870.2500],
        [13520886.0000,  1493060.0000],
        [ 9866372.0000,  2534784.0000],
        [15585170.0000,        0.0000],
        [15511476.0000,        0.0000],
        [13758139.0000,  1531890.2500],
        [ 2509782.0000, 10389017.0000],
        [ 1175670.6250, 10627881.0000],
        [ 5243077.5000,  4801636.0000],
        [ 2700547.0000,  6982814.0000],
        [ 4066544.5000,  9519522.0000],
        [10202896.0000,  4405726.5000],
        [12597955.0000,  1410504.7500],
        [ 1321106.0000, 12283274.0000],
        [ 1376017.0000, 12794872.0000],
        [ 2652249.0000, 10473952.0000],
        [11885569.0000,  2984032.0000],
        [10234335.0000,  4478331.5000],
        [ 2742335.5000, 11120404.0000],
        [ 5257705.5000,  8261783.0000],
        [ 1307577.6250, 12391352.0000],
        [ 2695374.5000, 11421694.0000],
        [10737243.0000,  2719631.7500],
        [11722634.0000,  1264705.8750],
        [11079249.0000,  2620989.5000],
        [ 1381190.5000, 12771862.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 431/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:41, 59.34s/it]  7%|▋         | 2/29 [01:00<11:14, 24.98s/it] 10%|█         | 3/29 [01:01<06:03, 14.00s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.83s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7908811569213867
Epoch 432/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:58, 57.79s/it]  7%|▋         | 2/29 [01:02<11:57, 26.57s/it] 10%|█         | 3/29 [01:03<06:26, 14.86s/it] 14%|█▍        | 4/29 [01:04<03:53,  9.36s/it] 17%|█▋        | 5/29 [01:05<02:31,  6.31s/it] 21%|██        | 6/29 [01:06<01:43,  4.48s/it] 24%|██▍       | 7/29 [01:07<01:12,  3.32s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.55s/it] 31%|███       | 9/29 [01:08<00:40,  2.04s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.70s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:11<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.779299020767212
Epoch 433/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:11, 58.26s/it]  7%|▋         | 2/29 [00:59<11:02, 24.54s/it] 10%|█         | 3/29 [01:00<05:57, 13.75s/it] 14%|█▍        | 4/29 [01:01<03:37,  8.69s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.89s/it] 21%|██        | 6/29 [01:02<01:36,  4.20s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.91s/it]
Epoch loss is 2.8026010990142822
Epoch 434/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:46, 59.53s/it]  7%|▋         | 2/29 [01:00<11:16, 25.05s/it] 10%|█         | 3/29 [01:01<06:04, 14.04s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.86s/it] 17%|█▋        | 5/29 [01:03<02:23,  6.00s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7983040809631348
Epoch 435/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:29, 58.92s/it]  7%|▋         | 2/29 [00:59<11:09, 24.80s/it] 10%|█         | 3/29 [01:00<06:01, 13.90s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.78s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.7932515144348145
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0143, 0.0023,  ..., 0.0041, 0.0001, 0.0194],
        [0.0033, 0.0097, 0.0021,  ..., 0.0023, 0.0001, 0.0184],
        [0.0338, 0.0062, 0.0035,  ..., 0.0054, 0.0157, 0.0241],
        ...,
        [0.0077, 0.0081, 0.0186,  ..., 0.0042, 0.0019, 0.0205],
        [0.0043, 0.0086, 0.0119,  ..., 0.0050, 0.0050, 0.0202],
        [0.0098, 0.0044, 0.0043,  ..., 0.0029, 0.0023, 0.0228]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9960, 0.9952, 0.9950, 0.9948, 0.9947, 0.9946, 0.9945, 0.9945,
         0.9941],
        [0.9972, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9764, 0.9690, 0.9683, 0.9671, 0.9666, 0.9665, 0.9662, 0.9648, 0.9648,
         0.9645],
        [0.9935, 0.9924, 0.9922, 0.9920, 0.9917, 0.9910, 0.9908, 0.9896, 0.9895,
         0.9893],
        [0.9883, 0.9868, 0.9864, 0.9846, 0.9846, 0.9845, 0.9842, 0.9839, 0.9839,
         0.9834],
        [0.9843, 0.9831, 0.9806, 0.9777, 0.9761, 0.9755, 0.9752, 0.9740, 0.9734,
         0.9732],
        [0.9797, 0.9711, 0.9709, 0.9680, 0.9672, 0.9658, 0.9644, 0.9639, 0.9630,
         0.9626],
        [0.9759, 0.9742, 0.9685, 0.9674, 0.9607, 0.9564, 0.9561, 0.9551, 0.9550,
         0.9532],
        [0.9974, 0.9967, 0.9967, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9936, 0.9897, 0.9887, 0.9875, 0.9866, 0.9864, 0.9847, 0.9839, 0.9835,
         0.9832],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9935, 0.9930, 0.9910, 0.9907, 0.9903, 0.9900, 0.9900, 0.9899, 0.9898,
         0.9890],
        [0.9913, 0.9907, 0.9884, 0.9878, 0.9864, 0.9860, 0.9855, 0.9838, 0.9833,
         0.9826],
        [0.9984, 0.9981, 0.9979, 0.9979, 0.9979, 0.9975, 0.9973, 0.9972, 0.9971,
         0.9971],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9964, 0.9962, 0.9962, 0.9960, 0.9960, 0.9956, 0.9955, 0.9955, 0.9953,
         0.9953],
        [0.9952, 0.9946, 0.9946, 0.9944, 0.9944, 0.9943, 0.9942, 0.9941, 0.9941,
         0.9941],
        [0.9945, 0.9936, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932, 0.9931,
         0.9931],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974, 0.9974,
         0.9973],
        [0.9951, 0.9943, 0.9940, 0.9939, 0.9938, 0.9935, 0.9935, 0.9933, 0.9927,
         0.9926],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9979, 0.9976,
         0.9975],
        [0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9951, 0.9950, 0.9945, 0.9943, 0.9940, 0.9940, 0.9939, 0.9939, 0.9938,
         0.9936],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9983],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9881, 0.9868, 0.9775, 0.9711, 0.9692, 0.9665, 0.9665, 0.9638, 0.9637,
         0.9599],
        [0.9962, 0.9962, 0.9959, 0.9958, 0.9957, 0.9957, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9964, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960, 0.9960,
         0.9959],
        [0.9852, 0.9823, 0.9791, 0.9757, 0.9738, 0.9726, 0.9715, 0.9703, 0.9678,
         0.9677],
        [0.9957, 0.9953, 0.9951, 0.9951, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948,
         0.9948],
        [0.9924, 0.9919, 0.9915, 0.9913, 0.9911, 0.9908, 0.9903, 0.9901, 0.9901,
         0.9899],
        [0.9960, 0.9957, 0.9956, 0.9956, 0.9955, 0.9953, 0.9953, 0.9953, 0.9952,
         0.9952],
        [0.9853, 0.9845, 0.9842, 0.9839, 0.9822, 0.9812, 0.9809, 0.9797, 0.9786,
         0.9778],
        [0.9984, 0.9983, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9980, 0.9980, 0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9968, 0.9967, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9893, 0.9867, 0.9856, 0.9850, 0.9845, 0.9834, 0.9834, 0.9833, 0.9833,
         0.9825],
        [0.9857, 0.9788, 0.9787, 0.9773, 0.9772, 0.9770, 0.9768, 0.9760, 0.9756,
         0.9756],
        [0.9871, 0.9866, 0.9738, 0.9708, 0.9608, 0.9588, 0.9554, 0.9554, 0.9551,
         0.9546],
        [0.9725, 0.9685, 0.9684, 0.9661, 0.9655, 0.9629, 0.9628, 0.9620, 0.9616,
         0.9533],
        [0.9908, 0.9895, 0.9891, 0.9884, 0.9884, 0.9879, 0.9879, 0.9872, 0.9871,
         0.9870],
        [0.9939, 0.9939, 0.9939, 0.9938, 0.9936, 0.9932, 0.9930, 0.9929, 0.9929,
         0.9925],
        [0.9915, 0.9913, 0.9912, 0.9908, 0.9906, 0.9901, 0.9900, 0.9899, 0.9899,
         0.9898],
        [0.9909, 0.9908, 0.9896, 0.9894, 0.9886, 0.9882, 0.9871, 0.9871, 0.9867,
         0.9865],
        [0.9936, 0.9927, 0.9927, 0.9919, 0.9915, 0.9914, 0.9905, 0.9897, 0.9893,
         0.9890],
        [0.9901, 0.9875, 0.9866, 0.9865, 0.9854, 0.9850, 0.9848, 0.9847, 0.9840,
         0.9832],
        [0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9945, 0.9945, 0.9944,
         0.9940],
        [0.9956, 0.9950, 0.9948, 0.9948, 0.9945, 0.9933, 0.9933, 0.9929, 0.9929,
         0.9929],
        [0.9944, 0.9911, 0.9900, 0.9897, 0.9891, 0.9891, 0.9887, 0.9886, 0.9886,
         0.9880],
        [0.9914, 0.9909, 0.9907, 0.9902, 0.9866, 0.9864, 0.9861, 0.9856, 0.9853,
         0.9852],
        [0.9917, 0.9914, 0.9908, 0.9908, 0.9887, 0.9885, 0.9885, 0.9872, 0.9860,
         0.9855],
        [0.9967, 0.9938, 0.9926, 0.9925, 0.9920, 0.9906, 0.9882, 0.9880, 0.9879,
         0.9875],
        [0.9898, 0.9885, 0.9881, 0.9881, 0.9879, 0.9875, 0.9870, 0.9869, 0.9863,
         0.9862],
        [0.9915, 0.9908, 0.9869, 0.9851, 0.9839, 0.9833, 0.9831, 0.9831, 0.9822,
         0.9817],
        [0.9921, 0.9921, 0.9916, 0.9915, 0.9910, 0.9895, 0.9860, 0.9855, 0.9850,
         0.9839],
        [0.9924, 0.9920, 0.9919, 0.9918, 0.9917, 0.9915, 0.9912, 0.9907, 0.9899,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 0, 1, 1],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1512914.5000, 1512367.7500, 1493971.5000, 1490597.1250, 1486077.8750,
         1484020.0000, 1480949.1250, 1479304.6250, 1478945.0000, 1470279.3750],
        [1537957.7500, 1526214.8750, 1525257.3750, 1523366.2500, 1522474.3750,
         1522274.1250, 1522274.1250, 1520489.5000, 1519854.5000, 1519611.0000],
        [1143114.7500, 1027443.8750, 1017136.9375, 1000318.7500,  992974.4375,
          991290.3125,  987302.2500,  967919.8750,  967655.0000,  963629.7500],
        [1458076.6250, 1435231.8750, 1431535.5000, 1428318.6250, 1421156.6250,
         1406413.2500, 1403607.5000, 1378951.6250, 1377001.5000, 1373837.7500],
        [1353086.7500, 1325855.6250, 1317369.3750, 1284217.8750, 1284123.7500,
         1282262.3750, 1276866.1250, 1272373.3750, 1271563.1250, 1263041.3750],
        [1279049.0000, 1257501.8750, 1213558.5000, 1163196.6250, 1137308.1250,
         1127674.3750, 1123376.5000, 1104155.0000, 1093931.5000, 1091032.0000],
        [1196979.3750, 1058558.2500, 1055469.6250, 1013406.3750, 1002011.5625,
          982197.1875,  963015.1250,  956128.0000,  943959.1875,  937821.6875],
        [1134393.2500, 1106462.3750, 1021136.4375, 1005113.5000,  912484.6875,
          858031.8125,  854800.6875,  843126.8750,  841095.8125,  819627.0625],
        [1541073.2500, 1526872.8750, 1526156.6250, 1520608.3750, 1520530.1250,
         1518220.3750, 1515279.6250, 1515048.5000, 1514488.0000, 1513711.1250],
        [1460910.6250, 1381538.3750, 1362483.6250, 1339324.0000, 1322003.3750,
         1317449.7500, 1285861.3750, 1271793.6250, 1264978.5000, 1259401.7500],
        [1555628.2500, 1554495.2500, 1554358.8750, 1554175.0000, 1550700.2500,
         1548591.3750, 1548222.2500, 1547805.8750, 1546449.8750, 1545466.6250],
        [1458274.1250, 1448227.7500, 1407606.2500, 1400832.7500, 1393476.3750,
         1387245.7500, 1386559.3750, 1385328.7500, 1384303.8750, 1367920.5000],
        [1413798.8750, 1401921.8750, 1355364.8750, 1343918.6250, 1318387.3750,
         1309553.1250, 1300486.5000, 1270554.6250, 1261055.5000, 1248842.1250],
        [1563184.5000, 1558414.0000, 1553923.1250, 1553806.0000, 1552418.2500,
         1544598.7500, 1539051.0000, 1537253.8750, 1536400.8750, 1535911.6250],
        [1577014.1250, 1576161.6250, 1575844.5000, 1575554.3750, 1574833.3750,
         1574785.2500, 1574615.6250, 1574488.0000, 1573459.7500, 1573140.1250],
        [1575428.2500, 1572577.6250, 1571627.1250, 1571053.2500, 1570248.8750,
         1569411.8750, 1569395.3750, 1568844.7500, 1566995.1250, 1566815.7500],
        [1520744.7500, 1516222.1250, 1515458.8750, 1510793.7500, 1510403.2500,
         1502090.3750, 1500814.5000, 1499858.8750, 1496815.1250, 1496773.7500],
        [1494895.0000, 1482349.5000, 1480644.1250, 1477552.1250, 1477063.2500,
         1475824.2500, 1472847.6250, 1471852.0000, 1471765.1250, 1470928.7500],
        [1479098.7500, 1460885.5000, 1457555.3750, 1457124.5000, 1454252.2500,
         1453384.3750, 1452765.0000, 1451284.6250, 1449955.2500, 1449428.3750],
        [1554012.0000, 1552655.0000, 1549786.6250, 1549740.7500, 1548201.5000,
         1547087.1250, 1546752.2500, 1545456.2500, 1545261.7500, 1543916.8750],
        [1552841.6250, 1550268.5000, 1550216.7500, 1548764.1250, 1547668.5000,
         1547484.1250, 1543728.3750, 1541277.6250, 1541192.3750, 1539349.0000],
        [1491117.5000, 1474276.8750, 1469390.7500, 1466555.7500, 1464724.7500,
         1459348.2500, 1459154.7500, 1453529.8750, 1442342.2500, 1439064.0000],
        [1574210.2500, 1571829.5000, 1561813.6250, 1561603.6250, 1561115.2500,
         1557642.7500, 1553835.6250, 1552992.7500, 1546712.5000, 1543155.7500],
        [1578969.0000, 1575942.1250, 1573366.6250, 1573183.6250, 1573086.1250,
         1572456.1250, 1572430.6250, 1571577.6250, 1569887.8750, 1569879.0000],
        [1491887.0000, 1489764.3750, 1478943.6250, 1475151.6250, 1469473.3750,
         1469281.5000, 1467652.7500, 1467347.6250, 1464279.1250, 1459899.5000],
        [1576242.7500, 1572627.1250, 1570191.8750, 1568401.8750, 1567732.0000,
         1567283.5000, 1565068.5000, 1564899.8750, 1563277.0000, 1562983.2500],
        [1565907.6250, 1564725.2500, 1562382.7500, 1561777.8750, 1558503.1250,
         1557030.8750, 1552744.0000, 1552600.2500, 1551922.2500, 1551334.7500],
        [1575619.0000, 1574660.6250, 1574013.6250, 1573002.1250, 1572331.6250,
         1571846.0000, 1570925.7500, 1570181.3750, 1569714.2500, 1569480.7500],
        [1578219.2500, 1578186.1250, 1577677.5000, 1575051.1250, 1574914.5000,
         1574797.2500, 1574791.2500, 1574791.2500, 1573962.5000, 1573792.8750],
        [1580697.1250, 1579666.2500, 1575704.6250, 1574867.8750, 1574819.7500,
         1574671.1250, 1574315.2500, 1573983.5000, 1573210.6250, 1572568.6250],
        [1580275.0000, 1579887.7500, 1579375.6250, 1578139.3750, 1577662.3750,
         1576755.5000, 1576737.3750, 1576179.6250, 1576024.8750, 1575175.8750],
        [1579559.3750, 1577790.3750, 1575888.0000, 1575736.2500, 1575042.1250,
         1575024.1250, 1574723.7500, 1574561.5000, 1574126.1250, 1574051.0000],
        [1350742.7500, 1325602.7500, 1161090.7500, 1059691.5000, 1030483.8750,
          991929.5625,  991825.5000,  954152.2500,  952391.3125,  902676.5000],
        [1516810.8750, 1515071.5000, 1508695.8750, 1508157.8750, 1505420.3750,
         1504955.2500, 1501494.6250, 1501488.7500, 1499391.0000, 1498350.5000],
        [1554725.0000, 1552162.1250, 1551207.6250, 1548000.7500, 1547403.0000,
         1546824.6250, 1546606.3750, 1546106.3750, 1545841.0000, 1544575.1250],
        [1521050.7500, 1516742.7500, 1515159.7500, 1514164.5000, 1514105.2500,
         1513139.6250, 1512406.7500, 1512041.8750, 1510499.7500, 1509093.0000],
        [1294450.6250, 1243104.1250, 1187491.0000, 1131627.1250, 1100607.8750,
         1082620.0000, 1064471.3750, 1046462.1875, 1010384.0000, 1008407.6875],
        [1504906.3750, 1495984.6250, 1491245.5000, 1491089.0000, 1488582.7500,
         1487511.2500, 1486824.8750, 1485413.2500, 1485363.7500, 1484801.5000],
        [1435439.8750, 1424623.7500, 1418252.6250, 1413320.2500, 1408904.8750,
         1404141.6250, 1392307.3750, 1390140.7500, 1388670.0000, 1384326.2500],
        [1512215.0000, 1505440.5000, 1502732.2500, 1502732.2500, 1500471.0000,
         1497406.2500, 1496424.1250, 1496280.0000, 1493542.6250, 1493253.5000],
        [1296798.2500, 1282796.8750, 1276077.3750, 1270936.3750, 1241386.1250,
         1222646.2500, 1217559.1250, 1197052.3750, 1178916.5000, 1165415.1250],
        [1563545.2500, 1560954.5000, 1557960.6250, 1557397.6250, 1556754.7500,
         1556450.3750, 1555653.5000, 1554741.3750, 1554424.1250, 1553930.3750],
        [1555609.0000, 1555229.2500, 1553072.7500, 1548858.7500, 1548198.6250,
         1547975.6250, 1547085.7500, 1546989.7500, 1544860.8750, 1544821.2500],
        [1537604.3750, 1533441.1250, 1530344.0000, 1528500.2500, 1528463.8750,
         1527251.5000, 1522288.6250, 1521769.0000, 1521696.3750, 1520795.5000],
        [1374092.0000, 1322784.0000, 1302022.8750, 1291371.7500, 1281950.5000,
         1263163.0000, 1261620.8750, 1261427.1250, 1260468.6250, 1245444.1250],
        [1303930.2500, 1182128.5000, 1181250.6250, 1157464.5000, 1156189.2500,
         1152430.8750, 1148837.1250, 1135223.3750, 1129910.2500, 1129866.0000],
        [1331068.8750, 1321017.8750, 1100490.2500, 1055209.0000,  914493.6250,
          888690.2500,  846775.5000,  846417.0000,  843093.8125,  837224.0000],
        [1080617.8750, 1020112.4375, 1018727.0625,  985328.8125,  977840.0000,
          941503.0000,  940388.5000,  929367.0000,  924306.6875,  821054.0625],
        [1402383.2500, 1376630.0000, 1369071.6250, 1356480.7500, 1355406.1250,
         1346567.7500, 1346001.6250, 1332738.0000, 1330931.8750, 1329318.3750],
        [1467465.1250, 1467405.0000, 1465747.5000, 1464735.8750, 1461355.1250,
         1451497.7500, 1447120.5000, 1446513.3750, 1446066.3750, 1436726.0000],
        [1417206.0000, 1413124.8750, 1410573.3750, 1403057.5000, 1398646.1250,
         1388452.8750, 1387580.5000, 1385188.7500, 1385116.0000, 1383743.0000],
        [1406090.1250, 1402502.2500, 1378805.7500, 1375805.6250, 1358956.5000,
         1351922.0000, 1331809.1250, 1331214.8750, 1323183.8750, 1320175.2500],
        [1460964.8750, 1442457.8750, 1441587.2500, 1426265.8750, 1417316.8750,
         1415909.2500, 1397519.5000, 1381882.2500, 1374386.7500, 1368503.8750],
        [1389007.7500, 1338847.6250, 1322237.8750, 1319673.0000, 1299058.5000,
         1290857.1250, 1288139.3750, 1286475.8750, 1272946.3750, 1258004.5000],
        [1492775.1250, 1489139.2500, 1489139.2500, 1488760.2500, 1488423.8750,
         1487627.7500, 1480073.7500, 1480059.6250, 1477562.0000, 1467843.0000],
        [1502924.3750, 1490227.6250, 1486768.2500, 1484708.0000, 1479976.3750,
         1454386.8750, 1453883.3750, 1446913.5000, 1446913.5000, 1446861.0000],
        [1476892.8750, 1410005.7500, 1388184.0000, 1380659.7500, 1369566.5000,
         1369283.2500, 1361360.0000, 1360286.8750, 1359463.3750, 1348796.3750],
        [1414550.1250, 1405760.3750, 1400782.0000, 1391108.8750, 1320962.3750,
         1317071.6250, 1311264.0000, 1303168.2500, 1296899.7500, 1295052.0000],
        [1421273.2500, 1415609.3750, 1402740.3750, 1402593.2500, 1361647.0000,
         1358793.2500, 1358273.7500, 1332326.1250, 1310515.1250, 1300636.6250],
        [1526974.8750, 1464791.7500, 1439243.7500, 1436861.5000, 1428216.3750,
         1400044.7500, 1352295.8750, 1348518.5000, 1345748.7500, 1338370.2500],
        [1383506.7500, 1358369.6250, 1350507.0000, 1349517.0000, 1346150.5000,
         1338803.0000, 1329408.2500, 1327366.1250, 1316520.3750, 1314681.0000],
        [1416539.8750, 1403062.8750, 1327323.1250, 1294065.5000, 1271689.2500,
         1261297.1250, 1257282.5000, 1256536.8750, 1241136.3750, 1232801.0000],
        [1429149.7500, 1428517.5000, 1419322.7500, 1417709.0000, 1407591.5000,
         1376472.5000, 1309516.8750, 1300885.8750, 1290780.7500, 1272087.1250],
        [1435512.5000, 1427654.1250, 1425447.3750, 1423645.8750, 1422037.8750,
         1416427.8750, 1411263.6250, 1400227.6250, 1384858.5000, 1376855.7500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1512914.5000,       0.0000],
         [1512367.7500,       0.0000],
         [1493971.5000,       0.0000],
         ...,
         [      0.0000, 1479304.6250],
         [1478945.0000,       0.0000],
         [1470279.3750,       0.0000]],

        [[1537957.7500,       0.0000],
         [1526214.8750,       0.0000],
         [1525257.3750,       0.0000],
         ...,
         [1520489.5000,       0.0000],
         [1519854.5000,       0.0000],
         [1519611.0000,       0.0000]],

        [[1143114.7500,       0.0000],
         [      0.0000, 1027443.8750],
         [1017136.9375,       0.0000],
         ...,
         [ 967919.8750,       0.0000],
         [ 967655.0000,       0.0000],
         [ 963629.7500,       0.0000]],

        ...,

        [[1416539.8750,       0.0000],
         [1403062.8750,       0.0000],
         [1327323.1250,       0.0000],
         ...,
         [1256536.8750,       0.0000],
         [1241136.3750,       0.0000],
         [1232801.0000,       0.0000]],

        [[1429149.7500,       0.0000],
         [1428517.5000,       0.0000],
         [1419322.7500,       0.0000],
         ...,
         [      0.0000, 1300885.8750],
         [1290780.7500,       0.0000],
         [      0.0000, 1272087.1250]],

        [[      0.0000, 1435512.5000],
         [      0.0000, 1427654.1250],
         [      0.0000, 1425447.3750],
         ...,
         [      0.0000, 1400227.6250],
         [      0.0000, 1384858.5000],
         [1376855.7500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13410121.0000,  1479304.6250],
        [15239774.0000,        0.0000],
        [ 5059456.5000,  4999330.0000],
        [12707718.0000,  1406413.2500],
        [ 9109957.0000,  3820802.5000],
        [ 9323432.0000,  2267351.5000],
        [ 5009215.5000,  5100331.5000],
        [ 8541472.0000,   854800.6875],
        [12182452.0000,  3029536.5000],
        [11884206.0000,  1381538.3750],
        [15505894.0000,        0.0000],
        [14019776.0000,        0.0000],
        [13223883.0000,        0.0000],
        [15474962.0000,        0.0000],
        [15749896.0000,        0.0000],
        [15702398.0000,        0.0000],
        [13549230.0000,  1520744.7500],
        [13280827.0000,  1494895.0000],
        [14565733.0000,        0.0000],
        [15482870.0000,        0.0000],
        [15462791.0000,        0.0000],
        [11713885.0000,  2905619.7500],
        [15584912.0000,        0.0000],
        [15730778.0000,        0.0000],
        [10282556.0000,  4451125.0000],
        [15678708.0000,        0.0000],
        [15578929.0000,        0.0000],
        [15721776.0000,        0.0000],
        [15756184.0000,        0.0000],
        [15754506.0000,        0.0000],
        [15776214.0000,        0.0000],
        [15756503.0000,        0.0000],
        [ 2886431.5000,  7834155.0000],
        [ 9032895.0000,  6026941.5000],
        [12391005.0000,  3092447.5000],
        [12114152.0000,  3024252.7500],
        [ 3157454.2500,  8012172.0000],
        [11917156.0000,  2984567.5000],
        [12667821.0000,  1392307.3750],
        [15000496.0000,        0.0000],
        [ 9825401.0000,  2524183.0000],
        [15571813.0000,        0.0000],
        [15492700.0000,        0.0000],
        [13743653.0000,  1528500.2500],
        [ 2506871.2500, 10357474.0000],
        [ 1157464.5000, 10519766.0000],
        [ 5176694.0000,  4807786.0000],
        [ 2685749.2500,  6953496.0000],
        [ 4057215.7500,  9488313.0000],
        [10161077.0000,  4393556.0000],
        [12569632.0000,  1403057.5000],
        [ 1320175.2500, 12260290.0000],
        [ 1368503.8750, 12758290.0000],
        [ 2641911.0000, 10423337.0000],
        [11861001.0000,  2980403.0000],
        [10220434.0000,  4473128.5000],
        [ 2729030.0000, 11095469.0000],
        [ 5232294.0000,  8224325.0000],
        [ 1300636.6250, 12363772.0000],
        [ 2690666.0000, 11390400.0000],
        [10701914.0000,  2712915.0000],
        [11700438.0000,  1261297.1250],
        [ 9769544.0000,  3882490.0000],
        [ 1376855.7500, 12747076.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 436/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:58, 59.95s/it]  7%|▋         | 2/29 [01:00<11:21, 25.23s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7904164791107178
Epoch 437/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:45, 59.49s/it]  7%|▋         | 2/29 [01:00<11:16, 25.04s/it] 10%|█         | 3/29 [01:01<06:04, 14.03s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.99s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.80631685256958
Epoch 438/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.53s/it]  7%|▋         | 2/29 [00:59<11:05, 24.65s/it] 10%|█         | 3/29 [01:00<05:59, 13.82s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.7841343879699707
Epoch 439/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:51, 59.69s/it]  7%|▋         | 2/29 [01:00<11:18, 25.13s/it] 10%|█         | 3/29 [01:01<06:05, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7831122875213623
Epoch 440/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:14, 60.52s/it]  7%|▋         | 2/29 [01:01<11:27, 25.46s/it] 10%|█         | 3/29 [01:02<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.08s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.7901558876037598
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0142, 0.0023,  ..., 0.0042, 0.0001, 0.0195],
        [0.0031, 0.0097, 0.0021,  ..., 0.0022, 0.0002, 0.0184],
        [0.0330, 0.0066, 0.0037,  ..., 0.0054, 0.0151, 0.0243],
        ...,
        [0.0076, 0.0081, 0.0187,  ..., 0.0040, 0.0017, 0.0207],
        [0.0042, 0.0085, 0.0121,  ..., 0.0049, 0.0050, 0.0202],
        [0.0095, 0.0045, 0.0043,  ..., 0.0029, 0.0022, 0.0228]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9961, 0.9952, 0.9951, 0.9948, 0.9948, 0.9947, 0.9946, 0.9946,
         0.9942],
        [0.9973, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9759, 0.9690, 0.9686, 0.9665, 0.9656, 0.9655, 0.9655, 0.9653, 0.9650,
         0.9628],
        [0.9931, 0.9925, 0.9923, 0.9920, 0.9916, 0.9909, 0.9907, 0.9897, 0.9895,
         0.9892],
        [0.9880, 0.9871, 0.9862, 0.9845, 0.9844, 0.9843, 0.9836, 0.9834, 0.9834,
         0.9833],
        [0.9839, 0.9830, 0.9806, 0.9765, 0.9759, 0.9747, 0.9747, 0.9738, 0.9727,
         0.9723],
        [0.9799, 0.9689, 0.9688, 0.9676, 0.9664, 0.9662, 0.9641, 0.9640, 0.9623,
         0.9620],
        [0.9761, 0.9732, 0.9684, 0.9678, 0.9607, 0.9575, 0.9569, 0.9558, 0.9553,
         0.9547],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9938, 0.9899, 0.9889, 0.9879, 0.9864, 0.9863, 0.9849, 0.9838, 0.9834,
         0.9834],
        [0.9980, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9937, 0.9933, 0.9914, 0.9911, 0.9905, 0.9902, 0.9902, 0.9901, 0.9901,
         0.9893],
        [0.9917, 0.9905, 0.9888, 0.9884, 0.9866, 0.9861, 0.9860, 0.9841, 0.9838,
         0.9836],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9979, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9965, 0.9964, 0.9963, 0.9961, 0.9960, 0.9957, 0.9957, 0.9956, 0.9954,
         0.9954],
        [0.9953, 0.9948, 0.9945, 0.9945, 0.9944, 0.9944, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9945, 0.9938, 0.9937, 0.9935, 0.9935, 0.9933, 0.9933, 0.9933, 0.9932,
         0.9932],
        [0.9980, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9952, 0.9945, 0.9943, 0.9940, 0.9940, 0.9938, 0.9936, 0.9934, 0.9927,
         0.9927],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9976,
         0.9974],
        [0.9991, 0.9990, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9951, 0.9951, 0.9946, 0.9944, 0.9942, 0.9942, 0.9941, 0.9940, 0.9939,
         0.9939],
        [0.9990, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9881, 0.9867, 0.9774, 0.9712, 0.9690, 0.9660, 0.9660, 0.9640, 0.9633,
         0.9584],
        [0.9964, 0.9963, 0.9959, 0.9959, 0.9958, 0.9957, 0.9956, 0.9956, 0.9956,
         0.9955],
        [0.9980, 0.9979, 0.9979, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9966, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961, 0.9960,
         0.9960],
        [0.9850, 0.9822, 0.9791, 0.9755, 0.9739, 0.9732, 0.9709, 0.9708, 0.9687,
         0.9684],
        [0.9959, 0.9954, 0.9952, 0.9950, 0.9950, 0.9950, 0.9949, 0.9949, 0.9948,
         0.9948],
        [0.9923, 0.9918, 0.9915, 0.9912, 0.9910, 0.9909, 0.9903, 0.9902, 0.9901,
         0.9900],
        [0.9961, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9952],
        [0.9850, 0.9845, 0.9840, 0.9836, 0.9823, 0.9808, 0.9806, 0.9795, 0.9785,
         0.9774],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9969, 0.9969, 0.9968, 0.9968, 0.9966, 0.9966, 0.9965,
         0.9965],
        [0.9894, 0.9866, 0.9855, 0.9853, 0.9846, 0.9836, 0.9835, 0.9834, 0.9833,
         0.9823],
        [0.9858, 0.9790, 0.9787, 0.9776, 0.9776, 0.9768, 0.9767, 0.9763, 0.9763,
         0.9759],
        [0.9868, 0.9855, 0.9738, 0.9705, 0.9609, 0.9590, 0.9559, 0.9558, 0.9556,
         0.9552],
        [0.9723, 0.9684, 0.9680, 0.9660, 0.9655, 0.9627, 0.9625, 0.9625, 0.9613,
         0.9531],
        [0.9908, 0.9897, 0.9890, 0.9887, 0.9885, 0.9881, 0.9879, 0.9875, 0.9873,
         0.9873],
        [0.9942, 0.9941, 0.9940, 0.9940, 0.9937, 0.9934, 0.9933, 0.9933, 0.9931,
         0.9928],
        [0.9916, 0.9914, 0.9912, 0.9909, 0.9907, 0.9903, 0.9903, 0.9901, 0.9900,
         0.9899],
        [0.9909, 0.9909, 0.9896, 0.9894, 0.9886, 0.9885, 0.9870, 0.9870, 0.9866,
         0.9865],
        [0.9937, 0.9926, 0.9926, 0.9919, 0.9914, 0.9914, 0.9904, 0.9896, 0.9894,
         0.9890],
        [0.9900, 0.9875, 0.9866, 0.9864, 0.9855, 0.9850, 0.9850, 0.9847, 0.9841,
         0.9832],
        [0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9950, 0.9947, 0.9947, 0.9946,
         0.9941],
        [0.9957, 0.9951, 0.9950, 0.9949, 0.9947, 0.9934, 0.9933, 0.9931, 0.9930,
         0.9930],
        [0.9943, 0.9911, 0.9900, 0.9896, 0.9891, 0.9890, 0.9887, 0.9886, 0.9884,
         0.9881],
        [0.9914, 0.9910, 0.9906, 0.9902, 0.9865, 0.9863, 0.9861, 0.9855, 0.9852,
         0.9852],
        [0.9917, 0.9913, 0.9907, 0.9905, 0.9886, 0.9885, 0.9883, 0.9871, 0.9860,
         0.9856],
        [0.9967, 0.9938, 0.9926, 0.9925, 0.9920, 0.9908, 0.9882, 0.9879, 0.9877,
         0.9876],
        [0.9898, 0.9884, 0.9881, 0.9880, 0.9879, 0.9871, 0.9871, 0.9870, 0.9863,
         0.9860],
        [0.9915, 0.9908, 0.9870, 0.9851, 0.9840, 0.9835, 0.9833, 0.9832, 0.9824,
         0.9817],
        [0.9923, 0.9922, 0.9919, 0.9916, 0.9913, 0.9897, 0.9862, 0.9860, 0.9851,
         0.9841],
        [0.9925, 0.9922, 0.9919, 0.9919, 0.9919, 0.9914, 0.9913, 0.9906, 0.9897,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1514613.7500, 1514463.3750, 1494183.7500, 1492778.0000, 1485977.1250,
         1485185.2500, 1483062.1250, 1481404.0000, 1481063.6250, 1472514.7500],
        [1540009.6250, 1526545.3750, 1526056.2500, 1523744.0000, 1523584.1250,
         1523135.2500, 1521927.1250, 1520502.5000, 1519844.2500, 1519550.1250],
        [1133687.0000, 1027426.2500, 1021847.5625,  991460.4375,  979251.8750,
          977370.9375,  977177.1875,  974799.0000,  970482.0625,  940547.2500],
        [1450926.2500, 1437670.2500, 1433822.7500, 1428311.7500, 1418903.2500,
         1404958.8750, 1400253.1250, 1380462.2500, 1377385.0000, 1372246.7500],
        [1347775.3750, 1331904.5000, 1314607.1250, 1282263.5000, 1281429.8750,
         1278252.6250, 1266817.1250, 1262525.8750, 1261843.3750, 1261175.7500],
        [1270708.5000, 1255303.1250, 1212192.5000, 1144703.2500, 1133558.3750,
         1115101.1250, 1114304.8750, 1100192.2500, 1083187.0000, 1077853.2500],
        [1201477.3750, 1025936.9375, 1024086.5000, 1007570.3750,  990003.5000,
          987502.8750,  957602.6250,  956613.1875,  933624.8750,  929468.0625],
        [1137965.7500, 1090816.6250, 1018429.8750, 1009742.4375,  913382.2500,
          872260.6250,  864406.0625,  850542.1875,  844663.1250,  838080.3750],
        [1543610.6250, 1530755.6250, 1530066.6250, 1523573.8750, 1521219.0000,
         1521098.6250, 1517797.6250, 1517162.3750, 1516725.5000, 1516690.7500],
        [1464342.0000, 1385916.8750, 1365179.8750, 1347105.8750, 1317854.5000,
         1315049.7500, 1290713.1250, 1270343.7500, 1262927.0000, 1262107.0000],
        [1556132.7500, 1555727.6250, 1555370.1250, 1554751.6250, 1551311.1250,
         1548957.6250, 1548489.5000, 1548234.0000, 1547602.1250, 1547096.0000],
        [1462784.3750, 1454418.7500, 1415778.2500, 1408770.5000, 1396757.3750,
         1392205.1250, 1391889.1250, 1389344.2500, 1389040.8750, 1373995.0000],
        [1420486.0000, 1397042.3750, 1364166.0000, 1355460.5000, 1321025.3750,
         1311414.1250, 1310372.6250, 1275418.0000, 1269228.5000, 1265300.6250],
        [1564313.3750, 1560046.6250, 1555033.3750, 1554928.1250, 1553360.0000,
         1546177.1250, 1541029.2500, 1540676.5000, 1540171.2500, 1538306.8750],
        [1577841.5000, 1576660.7500, 1576582.5000, 1575957.1250, 1575556.0000,
         1575417.7500, 1575366.6250, 1575151.7500, 1574375.3750, 1573804.8750],
        [1575990.1250, 1573653.3750, 1572595.6250, 1571678.0000, 1571080.1250,
         1570976.7500, 1570807.5000, 1569857.8750, 1568122.2500, 1567830.7500],
        [1522910.1250, 1519683.5000, 1518136.5000, 1513418.1250, 1511494.0000,
         1505005.5000, 1503992.5000, 1501828.2500, 1499531.2500, 1498988.0000],
        [1496793.7500, 1486099.1250, 1480069.6250, 1479203.1250, 1476595.6250,
         1476557.7500, 1474414.6250, 1473359.0000, 1472684.6250, 1471988.2500],
        [1478860.3750, 1465026.5000, 1461659.0000, 1457854.2500, 1457463.7500,
         1455025.0000, 1453959.7500, 1453557.6250, 1452167.8750, 1451927.0000],
        [1555331.5000, 1553653.3750, 1551509.3750, 1550687.0000, 1549307.8750,
         1548675.5000, 1548647.5000, 1547766.0000, 1546209.6250, 1545864.5000],
        [1553801.5000, 1551095.1250, 1551093.7500, 1550151.7500, 1548702.1250,
         1548423.0000, 1545331.0000, 1543080.8750, 1542123.0000, 1542009.7500],
        [1494002.8750, 1479069.1250, 1474393.5000, 1469554.6250, 1468690.2500,
         1463797.5000, 1459892.5000, 1456798.0000, 1442047.8750, 1441500.7500],
        [1574851.3750, 1573012.6250, 1562014.7500, 1561889.6250, 1561844.8750,
         1558763.2500, 1554699.8750, 1554671.6250, 1547457.5000, 1543020.3750],
        [1579521.6250, 1576684.7500, 1574225.2500, 1573812.3750, 1573452.2500,
         1573062.1250, 1572915.1250, 1572090.2500, 1570897.2500, 1570310.2500],
        [1492588.6250, 1491801.7500, 1480956.2500, 1476501.3750, 1473166.5000,
         1472474.0000, 1470223.2500, 1469333.2500, 1467398.0000, 1465852.3750],
        [1576669.7500, 1573114.6250, 1570442.0000, 1569331.1250, 1568458.7500,
         1568122.2500, 1566269.0000, 1565446.1250, 1563751.1250, 1563718.2500],
        [1566091.2500, 1565344.6250, 1563282.8750, 1561858.2500, 1559549.7500,
         1556883.8750, 1553820.7500, 1553694.8750, 1553158.5000, 1551885.3750],
        [1576376.5000, 1574770.3750, 1574704.2500, 1573932.3750, 1573735.7500,
         1573237.7500, 1572409.7500, 1571490.7500, 1570927.2500, 1570221.8750],
        [1579071.2500, 1578738.6250, 1578437.3750, 1575828.0000, 1575611.5000,
         1575282.5000, 1575187.8750, 1575181.8750, 1574821.3750, 1574803.2500],
        [1581059.0000, 1580056.6250, 1576178.1250, 1575341.0000, 1575265.8750,
         1575261.5000, 1575127.7500, 1574472.8750, 1573263.2500, 1572925.6250],
        [1580713.7500, 1580621.7500, 1580030.8750, 1578806.3750, 1578508.2500,
         1577680.5000, 1577308.8750, 1576966.0000, 1576423.1250, 1576319.3750],
        [1580165.1250, 1578292.8750, 1576644.1250, 1576098.3750, 1575767.7500,
         1575761.7500, 1575625.1250, 1575063.1250, 1574603.5000, 1574528.5000],
        [1349304.6250, 1322791.6250, 1159340.3750, 1060111.0000, 1027610.4375,
          985124.0000,  984917.3125,  956539.3125,  947451.3750,  883551.3750],
        [1519557.3750, 1517723.8750, 1510001.3750, 1508970.7500, 1506503.2500,
         1505157.6250, 1503496.3750, 1503393.1250, 1503064.7500, 1500721.5000],
        [1555522.8750, 1553160.1250, 1552609.1250, 1549678.7500, 1547859.0000,
         1546831.8750, 1546758.1250, 1546538.5000, 1546436.6250, 1546017.8750],
        [1524526.0000, 1519983.5000, 1518421.7500, 1518359.3750, 1517949.6250,
         1516148.5000, 1515724.8750, 1513608.7500, 1512043.2500, 1512001.5000],
        [1291796.7500, 1241282.1250, 1186544.6250, 1127455.0000, 1102110.7500,
         1091733.5000, 1056718.6250, 1055203.0000, 1022825.4375, 1019310.1250],
        [1508800.8750, 1498454.8750, 1494876.5000, 1490523.2500, 1490517.6250,
         1490183.6250, 1488463.5000, 1488359.8750, 1485481.2500, 1484965.7500],
        [1434564.0000, 1422497.7500, 1418117.2500, 1410461.7500, 1407807.6250,
         1404548.8750, 1393897.6250, 1391614.3750, 1389025.0000, 1386472.0000],
        [1513171.3750, 1506529.1250, 1505374.3750, 1505374.3750, 1502892.7500,
         1499858.8750, 1499815.7500, 1497539.1250, 1495853.3750, 1495184.5000],
        [1291663.6250, 1281607.1250, 1272865.0000, 1266174.6250, 1242663.1250,
         1217225.8750, 1213240.3750, 1193724.7500, 1176323.2500, 1158768.8750],
        [1564507.5000, 1562287.3750, 1558715.6250, 1558228.1250, 1557699.2500,
         1557636.7500, 1557127.5000, 1555637.1250, 1555606.0000, 1555594.1250],
        [1556662.6250, 1556598.8750, 1554446.2500, 1550814.1250, 1549798.3750,
         1549603.3750, 1548764.1250, 1547839.7500, 1546504.5000, 1546186.0000],
        [1538776.3750, 1535882.2500, 1531580.6250, 1531479.7500, 1529811.2500,
         1528966.8750, 1524232.3750, 1523887.8750, 1523193.2500, 1522923.2500],
        [1375946.0000, 1321363.0000, 1300802.8750, 1296282.6250, 1283432.0000,
         1266698.7500, 1264086.1250, 1263185.8750, 1260657.5000, 1242388.2500],
        [1306443.2500, 1184959.2500, 1180799.0000, 1161409.7500, 1161389.7500,
         1149298.5000, 1146722.3750, 1140722.2500, 1140644.0000, 1134130.3750],
        [1326025.0000, 1301773.2500, 1099918.5000, 1050086.1250,  915730.2500,
          891161.6875,  852905.8750,  850531.6250,  848933.5625,  844412.6875],
        [1077859.5000, 1019424.8750, 1013625.8125,  984547.3750,  977462.3125,
          938686.0625,  937200.3125,  936398.9375,  920764.6250,  819277.0000],
        [1403703.8750, 1382123.3750, 1367457.5000, 1361540.6250, 1358245.2500,
         1350240.5000, 1346605.0000, 1339066.0000, 1334919.5000, 1334129.1250],
        [1472686.1250, 1471600.8750, 1469504.2500, 1467890.6250, 1462619.7500,
         1456061.8750, 1453744.7500, 1453364.8750, 1450565.0000, 1443182.8750],
        [1418975.0000, 1414907.6250, 1411650.0000, 1406094.1250, 1401551.6250,
         1394079.7500, 1392326.0000, 1388748.0000, 1386888.6250, 1384722.5000],
        [1405944.0000, 1405729.3750, 1379083.2500, 1375963.1250, 1359455.5000,
         1357085.0000, 1330020.8750, 1329469.1250, 1321843.2500, 1320321.3750],
        [1461900.2500, 1440445.2500, 1440377.8750, 1425050.5000, 1415660.7500,
         1415045.2500, 1395071.8750, 1379233.1250, 1375131.5000, 1367003.7500],
        [1386982.5000, 1338527.1250, 1322277.0000, 1317849.3750, 1300732.1250,
         1291394.0000, 1291227.7500, 1286417.0000, 1274983.7500, 1259294.8750],
        [1495009.0000, 1492631.3750, 1491734.7500, 1491373.6250, 1491373.6250,
         1489929.2500, 1484158.7500, 1484086.5000, 1482131.8750, 1470924.5000],
        [1504922.2500, 1492396.5000, 1489400.6250, 1487877.3750, 1482759.5000,
         1455617.6250, 1454461.7500, 1449967.5000, 1447465.6250, 1447465.6250],
        [1475193.7500, 1409140.0000, 1386372.8750, 1380014.7500, 1370359.6250,
         1366819.8750, 1361123.8750, 1359532.0000, 1356235.1250, 1349291.7500],
        [1414455.6250, 1406644.0000, 1400026.0000, 1391004.0000, 1320121.1250,
         1315057.2500, 1312217.1250, 1301074.6250, 1295989.7500, 1295265.7500],
        [1420652.6250, 1412898.5000, 1400592.2500, 1397728.7500, 1360773.3750,
         1358494.0000, 1354840.1250, 1331565.3750, 1309534.3750, 1303552.2500],
        [1526886.0000, 1463734.6250, 1440121.1250, 1437854.0000, 1428166.0000,
         1402991.8750, 1351764.6250, 1346286.6250, 1343199.7500, 1340647.8750],
        [1383336.5000, 1355726.8750, 1350427.2500, 1347400.1250, 1346935.1250,
         1330612.0000, 1330090.6250, 1329970.1250, 1315409.7500, 1310055.2500],
        [1416815.5000, 1403299.7500, 1328162.6250, 1293755.7500, 1274083.1250,
         1263770.3750, 1261491.0000, 1258455.6250, 1245042.7500, 1232529.3750],
        [1432956.1250, 1430874.8750, 1425781.7500, 1418635.3750, 1412515.8750,
         1380412.2500, 1313464.2500, 1310006.5000, 1294348.1250, 1274890.2500],
        [1437948.6250, 1431730.8750, 1426112.2500, 1425448.7500, 1425409.2500,
         1414389.6250, 1413835.2500, 1399454.7500, 1381710.8750, 1380783.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1514613.7500,       0.0000],
         [1514463.3750,       0.0000],
         [1494183.7500,       0.0000],
         ...,
         [      0.0000, 1481404.0000],
         [1481063.6250,       0.0000],
         [1472514.7500,       0.0000]],

        [[1540009.6250,       0.0000],
         [1526545.3750,       0.0000],
         [1526056.2500,       0.0000],
         ...,
         [1520502.5000,       0.0000],
         [1519844.2500,       0.0000],
         [1519550.1250,       0.0000]],

        [[1133687.0000,       0.0000],
         [      0.0000, 1027426.2500],
         [1021847.5625,       0.0000],
         ...,
         [      0.0000,  974799.0000],
         [ 970482.0625,       0.0000],
         [ 940547.2500,       0.0000]],

        ...,

        [[1416815.5000,       0.0000],
         [1403299.7500,       0.0000],
         [1328162.6250,       0.0000],
         ...,
         [1258455.6250,       0.0000],
         [1245042.7500,       0.0000],
         [1232529.3750,       0.0000]],

        [[1432956.1250,       0.0000],
         [1430874.8750,       0.0000],
         [1425781.7500,       0.0000],
         ...,
         [      0.0000, 1310006.5000],
         [1294348.1250,       0.0000],
         [1274890.2500,       0.0000]],

        [[      0.0000, 1437948.6250],
         [      0.0000, 1431730.8750],
         [      0.0000, 1426112.2500],
         ...,
         [      0.0000, 1399454.7500],
         [      0.0000, 1381710.8750],
         [1380783.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13423842.0000,  1481404.0000],
        [15244898.0000,        0.0000],
        [ 5043741.0000,  4950308.5000],
        [12704687.0000,  1400253.1250],
        [ 9098758.0000,  3789836.0000],
        [ 9262209.0000,  2244895.5000],
        [ 4920687.0000,  5093199.5000],
        [ 8575883.0000,   864406.0625],
        [12204177.0000,  3034523.0000],
        [11895622.0000,  1385916.8750],
        [15513672.0000,        0.0000],
        [12700989.0000,  1373995.0000],
        [13289914.0000,        0.0000],
        [15494042.0000,        0.0000],
        [15756714.0000,        0.0000],
        [15712593.0000,        0.0000],
        [13572078.0000,  1522910.1250],
        [13290971.0000,  1496793.7500],
        [14587501.0000,        0.0000],
        [15497652.0000,        0.0000],
        [15475812.0000,        0.0000],
        [11738144.0000,  2911602.5000],
        [15592225.0000,        0.0000],
        [15736970.0000,        0.0000],
        [10303431.0000,  4456864.5000],
        [15685322.0000,        0.0000],
        [15585571.0000,        0.0000],
        [15731807.0000,        0.0000],
        [15762963.0000,        0.0000],
        [15758952.0000,        0.0000],
        [15783378.0000,        0.0000],
        [15762550.0000,        0.0000],
        [ 2853592.7500,  7823149.0000],
        [ 9045812.0000,  6032778.0000],
        [12398218.0000,  3093194.7500],
        [12134683.0000,  3034084.2500],
        [ 3180139.2500,  8014840.0000],
        [11931650.0000,  2988978.0000],
        [12665108.0000,  1393897.6250],
        [15021594.0000,        0.0000],
        [ 9789987.0000,  2524270.2500],
        [15583039.0000,        0.0000],
        [15507218.0000,        0.0000],
        [13759254.0000,  1531479.7500],
        [ 2503045.7500, 10371798.0000],
        [ 1161409.7500, 10545108.0000],
        [ 5203675.5000,  4777803.0000],
        [ 2676440.5000,  6948806.5000],
        [ 5394751.5000,  8183279.5000],
        [10199110.0000,  4402111.0000],
        [12593849.0000,  1406094.1250],
        [ 1321843.2500, 12263072.0000],
        [ 1367003.7500, 12747916.0000],
        [ 2640126.5000, 10429559.0000],
        [11888415.0000,  2984938.2500],
        [10232256.0000,  4480078.0000],
        [ 2723055.0000, 11091029.0000],
        [ 5229402.5000,  8222452.5000],
        [ 1303552.2500, 12347080.0000],
        [ 2692412.5000, 11389240.0000],
        [10686536.0000,  2713427.0000],
        [11713636.0000,  1263770.3750],
        [11070414.0000,  2623470.7500],
        [ 1380783.5000, 12756040.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 441/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:15, 60.56s/it]  7%|▋         | 2/29 [01:01<11:27, 25.48s/it] 10%|█         | 3/29 [01:02<06:11, 14.27s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.776545524597168
Epoch 442/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:45, 57.35s/it]  7%|▋         | 2/29 [01:00<11:22, 25.28s/it] 10%|█         | 3/29 [01:01<06:08, 14.16s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.05s/it] 21%|██        | 6/29 [01:03<01:39,  4.30s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.47s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.07it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7824385166168213
Epoch 443/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:59, 57.84s/it]  7%|▋         | 2/29 [00:58<10:57, 24.36s/it] 10%|█         | 3/29 [00:59<05:55, 13.66s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.63s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.85s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.07it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  2.90s/it]
Epoch loss is 2.785811424255371
Epoch 444/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:39, 61.43s/it]  7%|▋         | 2/29 [01:02<11:37, 25.84s/it] 10%|█         | 3/29 [01:03<06:15, 14.46s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:06<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.788961410522461
Epoch 445/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:40, 57.17s/it]  7%|▋         | 2/29 [00:58<10:57, 24.35s/it] 10%|█         | 3/29 [01:01<06:13, 14.38s/it] 14%|█▍        | 4/29 [01:01<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:02<02:27,  6.13s/it] 21%|██        | 6/29 [01:03<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.50s/it] 31%|███       | 9/29 [01:06<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7869415283203125
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0144, 0.0024,  ..., 0.0042, 0.0001, 0.0195],
        [0.0035, 0.0100, 0.0023,  ..., 0.0026, 0.0002, 0.0189],
        [0.0327, 0.0064, 0.0036,  ..., 0.0053, 0.0151, 0.0243],
        ...,
        [0.0078, 0.0082, 0.0188,  ..., 0.0042, 0.0020, 0.0206],
        [0.0045, 0.0087, 0.0121,  ..., 0.0052, 0.0051, 0.0204],
        [0.0103, 0.0046, 0.0043,  ..., 0.0028, 0.0023, 0.0231]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9960, 0.9950, 0.9949, 0.9948, 0.9948, 0.9947, 0.9944, 0.9944,
         0.9941],
        [0.9971, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9751, 0.9700, 0.9683, 0.9662, 0.9656, 0.9650, 0.9647, 0.9645, 0.9639,
         0.9630],
        [0.9935, 0.9926, 0.9926, 0.9922, 0.9918, 0.9911, 0.9906, 0.9903, 0.9899,
         0.9895],
        [0.9888, 0.9874, 0.9867, 0.9851, 0.9845, 0.9845, 0.9842, 0.9842, 0.9840,
         0.9839],
        [0.9843, 0.9837, 0.9812, 0.9769, 0.9757, 0.9755, 0.9755, 0.9744, 0.9731,
         0.9730],
        [0.9795, 0.9704, 0.9687, 0.9685, 0.9681, 0.9649, 0.9646, 0.9639, 0.9636,
         0.9636],
        [0.9764, 0.9727, 0.9680, 0.9678, 0.9600, 0.9580, 0.9562, 0.9555, 0.9548,
         0.9545],
        [0.9974, 0.9968, 0.9967, 0.9966, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9941, 0.9899, 0.9894, 0.9885, 0.9873, 0.9865, 0.9858, 0.9850, 0.9847,
         0.9833],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9938, 0.9938, 0.9914, 0.9914, 0.9906, 0.9903, 0.9903, 0.9902, 0.9902,
         0.9901],
        [0.9922, 0.9907, 0.9894, 0.9893, 0.9877, 0.9872, 0.9872, 0.9860, 0.9850,
         0.9848],
        [0.9983, 0.9981, 0.9978, 0.9978, 0.9978, 0.9975, 0.9972, 0.9971, 0.9970,
         0.9970],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9984],
        [0.9963, 0.9962, 0.9961, 0.9960, 0.9958, 0.9956, 0.9955, 0.9953, 0.9953,
         0.9951],
        [0.9953, 0.9948, 0.9945, 0.9945, 0.9945, 0.9944, 0.9943, 0.9942, 0.9942,
         0.9941],
        [0.9943, 0.9936, 0.9934, 0.9934, 0.9933, 0.9933, 0.9931, 0.9931, 0.9931,
         0.9930],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9952, 0.9947, 0.9942, 0.9942, 0.9939, 0.9937, 0.9937, 0.9935, 0.9927,
         0.9927],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9979, 0.9976,
         0.9974],
        [0.9990, 0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9951, 0.9951, 0.9946, 0.9945, 0.9943, 0.9941, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9989, 0.9988, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9984, 0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9885, 0.9871, 0.9781, 0.9703, 0.9692, 0.9690, 0.9681, 0.9658, 0.9634,
         0.9624],
        [0.9962, 0.9961, 0.9957, 0.9957, 0.9956, 0.9956, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9965, 0.9963, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9960, 0.9959,
         0.9958],
        [0.9854, 0.9828, 0.9797, 0.9759, 0.9740, 0.9727, 0.9720, 0.9698, 0.9672,
         0.9670],
        [0.9956, 0.9953, 0.9951, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948,
         0.9947],
        [0.9928, 0.9920, 0.9920, 0.9914, 0.9913, 0.9911, 0.9906, 0.9905, 0.9905,
         0.9904],
        [0.9959, 0.9955, 0.9954, 0.9953, 0.9953, 0.9952, 0.9951, 0.9951, 0.9950,
         0.9949],
        [0.9858, 0.9847, 0.9846, 0.9845, 0.9820, 0.9817, 0.9814, 0.9803, 0.9792,
         0.9788],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9971, 0.9968, 0.9967, 0.9967, 0.9966, 0.9966, 0.9963, 0.9963, 0.9963,
         0.9962],
        [0.9889, 0.9863, 0.9852, 0.9845, 0.9839, 0.9834, 0.9833, 0.9832, 0.9830,
         0.9822],
        [0.9858, 0.9794, 0.9786, 0.9781, 0.9780, 0.9775, 0.9770, 0.9769, 0.9765,
         0.9762],
        [0.9871, 0.9867, 0.9736, 0.9707, 0.9604, 0.9586, 0.9550, 0.9546, 0.9543,
         0.9538],
        [0.9736, 0.9692, 0.9683, 0.9667, 0.9661, 0.9634, 0.9626, 0.9625, 0.9616,
         0.9546],
        [0.9909, 0.9894, 0.9888, 0.9883, 0.9881, 0.9877, 0.9876, 0.9869, 0.9868,
         0.9867],
        [0.9939, 0.9939, 0.9936, 0.9936, 0.9934, 0.9929, 0.9927, 0.9927, 0.9927,
         0.9924],
        [0.9914, 0.9911, 0.9905, 0.9904, 0.9900, 0.9896, 0.9894, 0.9893, 0.9889,
         0.9889],
        [0.9908, 0.9904, 0.9893, 0.9892, 0.9887, 0.9881, 0.9872, 0.9869, 0.9865,
         0.9862],
        [0.9938, 0.9929, 0.9928, 0.9921, 0.9916, 0.9916, 0.9905, 0.9897, 0.9893,
         0.9893],
        [0.9904, 0.9875, 0.9866, 0.9865, 0.9856, 0.9855, 0.9849, 0.9847, 0.9839,
         0.9832],
        [0.9951, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9942, 0.9941, 0.9940,
         0.9939],
        [0.9955, 0.9948, 0.9945, 0.9943, 0.9942, 0.9930, 0.9929, 0.9928, 0.9927,
         0.9926],
        [0.9944, 0.9912, 0.9901, 0.9900, 0.9894, 0.9890, 0.9889, 0.9888, 0.9888,
         0.9881],
        [0.9914, 0.9910, 0.9908, 0.9903, 0.9866, 0.9864, 0.9861, 0.9858, 0.9853,
         0.9853],
        [0.9920, 0.9913, 0.9909, 0.9908, 0.9889, 0.9888, 0.9888, 0.9870, 0.9861,
         0.9856],
        [0.9967, 0.9939, 0.9926, 0.9924, 0.9921, 0.9905, 0.9883, 0.9883, 0.9882,
         0.9872],
        [0.9901, 0.9890, 0.9882, 0.9879, 0.9879, 0.9877, 0.9872, 0.9868, 0.9866,
         0.9864],
        [0.9914, 0.9908, 0.9868, 0.9850, 0.9840, 0.9832, 0.9830, 0.9828, 0.9820,
         0.9817],
        [0.9920, 0.9918, 0.9915, 0.9915, 0.9908, 0.9893, 0.9858, 0.9849, 0.9848,
         0.9841],
        [0.9922, 0.9918, 0.9918, 0.9917, 0.9916, 0.9914, 0.9911, 0.9906, 0.9899,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 0, 1],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1513330.1250, 1511257.6250, 1489709.0000, 1488274.7500, 1485518.1250,
         1484836.7500, 1483714.3750, 1478223.1250, 1476630.8750, 1470731.0000],
        [1535522.0000, 1524911.2500, 1523114.8750, 1522451.2500, 1522294.3750,
         1520833.2500, 1517971.3750, 1517450.2500, 1516745.6250, 1516716.8750],
        [1121666.8750, 1043168.0625, 1017107.8750,  988130.3125,  978654.4375,
          970990.3125,  966787.9375,  964094.8125,  955975.6875,  943793.5625],
        [1458185.2500, 1439328.7500, 1439072.1250, 1431872.7500, 1423906.6250,
         1409207.2500, 1399410.6250, 1393965.5000, 1385795.2500, 1377855.3750],
        [1363321.8750, 1336474.8750, 1323301.3750, 1293213.0000, 1283053.7500,
         1282483.7500, 1277374.1250, 1276582.5000, 1274009.0000, 1271341.2500],
        [1279607.7500, 1267850.5000, 1223005.3750, 1151037.0000, 1130921.5000,
         1128404.7500, 1127897.0000, 1110486.8750, 1089518.1250, 1088494.1250],
        [1194065.1250, 1048029.1875, 1023874.6250, 1020779.0625, 1015262.6875,
          969009.6875,  964654.9375,  954983.4375,  951723.0625,  951116.0000],
        [1142390.0000, 1082895.6250, 1012490.5625, 1009828.1250,  903244.8125,
          878630.8125,  855405.0625,  847710.3125,  839084.0000,  834999.3125],
        [1541995.1250, 1528501.7500, 1526305.1250, 1523745.3750, 1520005.2500,
         1519696.5000, 1518623.0000, 1515289.7500, 1514932.8750, 1514924.2500],
        [1470575.2500, 1386064.7500, 1375951.3750, 1357520.0000, 1334712.0000,
         1320001.5000, 1307293.2500, 1291109.5000, 1285847.8750, 1260058.8750],
        [1554158.7500, 1552372.2500, 1552350.1250, 1550790.5000, 1546697.7500,
         1546337.8750, 1546135.8750, 1545606.5000, 1544354.2500, 1543653.2500],
        [1465131.2500, 1463747.2500, 1416136.1250, 1415076.2500, 1399347.8750,
         1393941.5000, 1392862.5000, 1391833.5000, 1391423.2500, 1389398.5000],
        [1430943.1250, 1400588.1250, 1375588.0000, 1374160.0000, 1342811.6250,
         1332058.1250, 1332051.8750, 1309339.6250, 1291092.2500, 1287592.8750],
        [1562542.1250, 1557066.5000, 1551644.0000, 1551359.8750, 1551257.8750,
         1544585.5000, 1537893.2500, 1535475.2500, 1533719.0000, 1533283.2500],
        [1575635.5000, 1575102.1250, 1574605.1250, 1574403.8750, 1573965.5000,
         1573792.8750, 1573659.3750, 1573413.2500, 1572582.1250, 1572213.2500],
        [1574543.5000, 1571444.2500, 1570567.7500, 1569903.0000, 1569108.1250,
         1567648.2500, 1567455.5000, 1565988.2500, 1565841.8750, 1565202.8750],
        [1518104.6250, 1515817.3750, 1514332.0000, 1510715.7500, 1506999.1250,
         1502259.5000, 1500804.6250, 1497212.1250, 1496361.3750, 1493020.0000],
        [1496379.8750, 1485559.2500, 1479895.8750, 1479148.1250, 1479135.3750,
         1476832.2500, 1475041.8750, 1472818.1250, 1472221.3750, 1471001.7500],
        [1475162.8750, 1459607.1250, 1455763.3750, 1455466.2500, 1455007.0000,
         1454085.8750, 1451133.7500, 1449170.0000, 1449123.0000, 1448854.8750],
        [1552021.3750, 1549683.1250, 1547949.0000, 1547810.2500, 1545584.5000,
         1545124.6250, 1545108.3750, 1543886.0000, 1543239.7500, 1542223.1250],
        [1550487.3750, 1549466.0000, 1549095.1250, 1547770.5000, 1547338.0000,
         1546994.2500, 1541021.8750, 1538863.0000, 1538791.1250, 1537897.6250],
        [1493440.1250, 1482973.0000, 1473391.3750, 1472076.7500, 1467567.3750,
         1463539.2500, 1462078.6250, 1458715.1250, 1442633.8750, 1441983.2500],
        [1573365.2500, 1571075.6250, 1561246.2500, 1561124.1250, 1560930.6250,
         1556861.6250, 1553531.8750, 1552899.5000, 1545907.3750, 1542998.3750],
        [1577522.5000, 1575042.1250, 1572265.7500, 1571979.3750, 1571508.6250,
         1571490.7500, 1571116.0000, 1570909.3750, 1568378.0000, 1568313.6250],
        [1493173.8750, 1493153.8750, 1482365.0000, 1479983.5000, 1474418.8750,
         1470952.6250, 1469993.3750, 1468841.5000, 1468048.8750, 1466200.6250],
        [1575341.0000, 1572271.7500, 1569616.8750, 1568108.7500, 1567536.1250,
         1566636.5000, 1564224.0000, 1563429.0000, 1562360.3750, 1562226.2500],
        [1565256.5000, 1563801.7500, 1561314.7500, 1560805.5000, 1558183.6250,
         1556995.1250, 1551759.5000, 1551093.7500, 1550660.2500, 1550487.3750],
        [1574873.8750, 1574175.6250, 1573233.1250, 1572390.2500, 1572387.2500,
         1571577.6250, 1571120.6250, 1570311.6250, 1570199.3750, 1569483.7500],
        [1577354.0000, 1577158.5000, 1576552.5000, 1574267.2500, 1574072.1250,
         1573693.7500, 1573485.2500, 1573345.7500, 1572738.1250, 1572373.7500],
        [1580005.2500, 1578678.3750, 1574926.5000, 1574126.1250, 1573853.0000,
         1573438.7500, 1573380.2500, 1572655.6250, 1572520.6250, 1572081.2500],
        [1579306.2500, 1579146.6250, 1578841.0000, 1576967.3750, 1576838.1250,
         1576337.3750, 1575930.1250, 1575530.5000, 1575229.8750, 1574495.3750],
        [1578020.5000, 1577351.0000, 1575332.0000, 1574878.5000, 1573992.5000,
         1573982.0000, 1573911.5000, 1573627.7500, 1573053.1250, 1572961.6250],
        [1357060.5000, 1331555.2500, 1169676.2500, 1047614.5000, 1030522.2500,
         1027559.5000, 1014833.8125,  981760.6875,  948417.7500,  935372.5625],
        [1515360.6250, 1514202.0000, 1505192.1250, 1504951.0000, 1503096.3750,
         1501885.5000, 1499293.8750, 1499000.8750, 1497389.1250, 1496462.6250],
        [1553176.3750, 1550651.5000, 1549758.5000, 1546756.7500, 1546596.0000,
         1546031.1250, 1545730.5000, 1545419.5000, 1545244.0000, 1544310.0000],
        [1522828.7500, 1517780.3750, 1515759.5000, 1515590.5000, 1514950.2500,
         1512718.3750, 1512568.2500, 1512141.3750, 1508721.7500, 1507934.8750],
        [1299907.5000, 1252415.5000, 1197762.7500, 1134054.6250, 1103932.7500,
         1083093.0000, 1072145.1250, 1039275.5000, 1001571.1875,  998492.6250],
        [1502892.7500, 1497083.6250, 1491258.3750, 1490483.5000, 1488181.1250,
         1487233.2500, 1485994.2500, 1485671.1250, 1484996.8750, 1483861.5000],
        [1444386.2500, 1427933.2500, 1426664.5000, 1414709.2500, 1414133.3750,
         1408424.0000, 1399505.3750, 1397631.3750, 1397588.7500, 1395724.0000],
        [1509609.7500, 1499657.1250, 1498029.0000, 1495518.2500, 1495518.2500,
         1494783.8750, 1492993.0000, 1492460.6250, 1489704.7500, 1487484.3750],
        [1306336.1250, 1286836.6250, 1283761.1250, 1283184.6250, 1236822.5000,
         1232182.7500, 1226486.0000, 1208403.1250, 1189219.3750, 1182495.0000],
        [1561871.7500, 1558901.5000, 1556359.8750, 1555554.0000, 1555355.2500,
         1555092.7500, 1552726.1250, 1552638.7500, 1552375.2500, 1551522.7500],
        [1553786.7500, 1553403.0000, 1550336.5000, 1546137.2500, 1546035.6250,
         1545776.1250, 1545099.6250, 1543066.0000, 1542818.8750, 1542530.5000],
        [1535271.7500, 1529655.1250, 1526602.1250, 1526318.2500, 1523869.0000,
         1523393.7500, 1518882.2500, 1518659.1250, 1517120.5000, 1516151.3750],
        [1365677.2500, 1315828.7500, 1295359.6250, 1282925.2500, 1271360.6250,
         1263043.7500, 1261367.0000, 1259417.2500, 1256155.8750, 1240619.3750],
        [1307244.6250, 1192936.0000, 1179276.3750, 1171206.6250, 1169487.7500,
         1160407.7500, 1151528.8750, 1151220.3750, 1143538.0000, 1138951.5000],
        [1330915.3750, 1323123.3750, 1097907.2500, 1053738.7500,  908435.0000,
          886030.4375,  841366.1875,  836998.8750,  832557.4375,  826981.0000],
        [1096965.3750, 1031326.5000, 1017903.5625,  994087.7500,  986061.1250,
          948395.1250,  938019.3125,  936121.2500,  924813.6875,  836083.8125],
        [1405882.2500, 1374685.6250, 1363373.8750, 1353068.6250, 1350889.6250,
         1342627.2500, 1340306.6250, 1327752.3750, 1324882.3750, 1324098.0000],
        [1465996.5000, 1465869.1250, 1460910.6250, 1460824.1250, 1455748.1250,
         1445261.2500, 1442677.8750, 1442329.8750, 1441856.7500, 1435289.2500],
        [1414807.7500, 1408868.6250, 1397638.1250, 1395417.8750, 1386427.1250,
         1379912.1250, 1374749.8750, 1374361.8750, 1366309.0000, 1365188.8750],
        [1404148.3750, 1395995.6250, 1373735.5000, 1372190.5000, 1361560.0000,
         1350772.3750, 1332460.8750, 1327318.1250, 1318849.0000, 1314741.2500],
        [1464214.8750, 1446866.6250, 1444670.1250, 1429835.5000, 1420276.0000,
         1419769.6250, 1397524.7500, 1382290.8750, 1374341.0000, 1373958.2500],
        [1394671.5000, 1339523.2500, 1320714.1250, 1319189.8750, 1302892.2500,
         1300327.8750, 1290527.2500, 1287018.2500, 1270964.2500, 1259429.3750],
        [1491330.8750, 1487195.1250, 1485444.5000, 1485444.5000, 1484996.8750,
         1484892.0000, 1473398.2500, 1471829.6250, 1469812.6250, 1465816.1250],
        [1500119.1250, 1486347.1250, 1478922.5000, 1476169.0000, 1473568.3750,
         1448448.7500, 1445741.1250, 1443265.5000, 1442310.6250, 1439455.1250],
        [1477788.8750, 1411954.2500, 1388675.3750, 1387106.8750, 1374609.6250,
         1367701.3750, 1365996.3750, 1364586.2500, 1363315.3750, 1350160.5000],
        [1416183.2500, 1407182.1250, 1403785.5000, 1394074.5000, 1321642.8750,
         1318572.2500, 1312646.5000, 1306332.3750, 1297819.0000, 1297064.2500],
        [1427025.1250, 1414249.2500, 1405969.3750, 1403473.6250, 1364972.7500,
         1364648.7500, 1363405.1250, 1328475.6250, 1311974.3750, 1302338.2500],
        [1527008.3750, 1466413.1250, 1439295.8750, 1435188.0000, 1429538.3750,
         1397780.7500, 1354430.7500, 1353942.5000, 1352706.0000, 1332750.6250],
        [1388398.5000, 1367681.7500, 1352174.6250, 1347150.8750, 1345987.5000,
         1343286.8750, 1332403.7500, 1324589.1250, 1321421.0000, 1317149.6250],
        [1415155.8750, 1404084.1250, 1326035.1250, 1291995.1250, 1272740.0000,
         1259084.6250, 1254690.3750, 1251055.7500, 1237001.7500, 1232465.8750],
        [1426567.8750, 1423891.6250, 1417160.1250, 1416415.7500, 1403392.0000,
         1372860.7500, 1306383.5000, 1289704.1250, 1287568.2500, 1274678.6250],
        [1432215.6250, 1423854.8750, 1423811.5000, 1421849.5000, 1419890.1250,
         1416249.5000, 1408951.8750, 1398905.0000, 1385415.8750, 1371312.6250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1513330.1250,       0.0000],
         [1511257.6250,       0.0000],
         [1489709.0000,       0.0000],
         ...,
         [1478223.1250,       0.0000],
         [      0.0000, 1476630.8750],
         [1470731.0000,       0.0000]],

        [[1535522.0000,       0.0000],
         [1524911.2500,       0.0000],
         [1523114.8750,       0.0000],
         ...,
         [1517450.2500,       0.0000],
         [1516745.6250,       0.0000],
         [1516716.8750,       0.0000]],

        [[1121666.8750,       0.0000],
         [      0.0000, 1043168.0625],
         [1017107.8750,       0.0000],
         ...,
         [ 964094.8125,       0.0000],
         [ 955975.6875,       0.0000],
         [      0.0000,  943793.5625]],

        ...,

        [[1415155.8750,       0.0000],
         [1404084.1250,       0.0000],
         [1326035.1250,       0.0000],
         ...,
         [1251055.7500,       0.0000],
         [1237001.7500,       0.0000],
         [1232465.8750,       0.0000]],

        [[1426567.8750,       0.0000],
         [1423891.6250,       0.0000],
         [1417160.1250,       0.0000],
         ...,
         [      0.0000, 1289704.1250],
         [1287568.2500,       0.0000],
         [      0.0000, 1274678.6250]],

        [[      0.0000, 1432215.6250],
         [      0.0000, 1423854.8750],
         [      0.0000, 1423811.5000],
         ...,
         [      0.0000, 1398905.0000],
         [      0.0000, 1385415.8750],
         [1371312.6250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13405596.0000,  1476630.8750],
        [15218012.0000,        0.0000],
        [ 4058845.2500,  5891525.0000],
        [12759188.0000,  1399410.6250],
        [10427198.0000,  2553956.5000],
        [ 9335700.0000,  2261524.0000],
        [ 5009061.0000,  5084437.0000],
        [ 8551274.0000,   855405.0625],
        [13709095.0000,  1514924.2500],
        [12003070.0000,  1386064.7500],
        [15482457.0000,        0.0000],
        [14118898.0000,        0.0000],
        [13476226.0000,        0.0000],
        [15458826.0000,        0.0000],
        [15739373.0000,        0.0000],
        [15687703.0000,        0.0000],
        [13537522.0000,  1518104.6250],
        [13291654.0000,  1496379.8750],
        [14553374.0000,        0.0000],
        [15462630.0000,        0.0000],
        [15447724.0000,        0.0000],
        [13186322.0000,  1472076.7500],
        [15579940.0000,        0.0000],
        [15718527.0000,        0.0000],
        [11780805.0000,  2986327.7500],
        [15671751.0000,        0.0000],
        [15570357.0000,        0.0000],
        [15719754.0000,        0.0000],
        [15745041.0000,        0.0000],
        [15745666.0000,        0.0000],
        [15768623.0000,        0.0000],
        [15747110.0000,        0.0000],
        [ 3006499.5000,  7837873.0000],
        [ 9021241.0000,  6015593.5000],
        [12381659.0000,  3092015.5000],
        [12112516.0000,  3028478.0000],
        [ 2143208.2500,  9039443.0000],
        [10424318.0000,  4473339.0000],
        [12729110.0000,  1397588.7500],
        [13466055.0000,  1489704.7500],
        [ 9912068.0000,  2523659.0000],
        [15552398.0000,        0.0000],
        [15468990.0000,        0.0000],
        [13712056.0000,  1523869.0000],
        [ 2500036.5000, 10311718.0000],
        [ 1169487.7500, 10596310.0000],
        [ 5132369.0000,  4805685.0000],
        [ 2720600.2500,  6989177.0000],
        [ 4040540.5000,  9467026.0000],
        [10139281.0000,  4377483.0000],
        [12468264.0000,  1395417.8750],
        [ 1314741.2500, 12237030.0000],
        [ 1373958.2500, 12779790.0000],
        [ 2639904.0000, 10445354.0000],
        [11823938.0000,  2976223.0000],
        [10174312.0000,  4460034.5000],
        [ 2740606.0000, 11111288.0000],
        [ 5235370.0000,  8239932.5000],
        [       0.0000, 13686533.0000],
        [ 2687181.5000, 11401874.0000],
        [10719441.0000,  2720802.2500],
        [11685225.0000,  1259084.6250],
        [ 9747857.0000,  3870766.0000],
        [ 1371312.6250, 12731144.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 446/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:23, 58.69s/it]  7%|▋         | 2/29 [01:01<11:41, 25.97s/it] 10%|█         | 3/29 [01:02<06:17, 14.53s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.16s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.19s/it] 21%|██        | 6/29 [01:05<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.52s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.8016622066497803
Epoch 447/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:38, 59.23s/it]  7%|▋         | 2/29 [01:00<11:13, 24.93s/it] 10%|█         | 3/29 [01:01<06:03, 13.97s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.82s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.07it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7850325107574463
Epoch 448/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:28, 58.86s/it]  7%|▋         | 2/29 [00:59<11:09, 24.78s/it] 10%|█         | 3/29 [01:00<06:01, 13.89s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.77s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.94s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.7743980884552
Epoch 449/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:48, 57.46s/it]  7%|▋         | 2/29 [01:01<11:45, 26.14s/it] 10%|█         | 3/29 [01:02<06:20, 14.62s/it] 14%|█▍        | 4/29 [01:03<03:50,  9.21s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.22s/it] 21%|██        | 6/29 [01:05<01:41,  4.42s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.7745823860168457
Epoch 450/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:39, 59.28s/it]  7%|▋         | 2/29 [01:00<11:13, 24.96s/it] 10%|█         | 3/29 [01:01<06:03, 13.99s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.83s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7927441596984863
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0143, 0.0023,  ..., 0.0041, 0.0002, 0.0191],
        [0.0032, 0.0096, 0.0021,  ..., 0.0023, 0.0001, 0.0185],
        [0.0336, 0.0062, 0.0033,  ..., 0.0051, 0.0159, 0.0247],
        ...,
        [0.0077, 0.0081, 0.0185,  ..., 0.0041, 0.0019, 0.0207],
        [0.0045, 0.0084, 0.0121,  ..., 0.0050, 0.0051, 0.0201],
        [0.0098, 0.0044, 0.0042,  ..., 0.0028, 0.0022, 0.0230]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9960, 0.9959, 0.9951, 0.9950, 0.9946, 0.9946, 0.9945, 0.9944, 0.9944,
         0.9941],
        [0.9973, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9772, 0.9692, 0.9689, 0.9680, 0.9678, 0.9677, 0.9674, 0.9651, 0.9650,
         0.9648],
        [0.9932, 0.9925, 0.9922, 0.9919, 0.9915, 0.9906, 0.9904, 0.9892, 0.9891,
         0.9890],
        [0.9879, 0.9871, 0.9858, 0.9844, 0.9842, 0.9835, 0.9835, 0.9833, 0.9828,
         0.9827],
        [0.9842, 0.9831, 0.9801, 0.9770, 0.9748, 0.9747, 0.9741, 0.9729, 0.9727,
         0.9719],
        [0.9813, 0.9710, 0.9708, 0.9689, 0.9676, 0.9660, 0.9660, 0.9655, 0.9645,
         0.9639],
        [0.9756, 0.9749, 0.9693, 0.9674, 0.9613, 0.9581, 0.9578, 0.9550, 0.9550,
         0.9547],
        [0.9973, 0.9967, 0.9966, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9937, 0.9898, 0.9880, 0.9876, 0.9863, 0.9862, 0.9840, 0.9834, 0.9834,
         0.9830],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9933, 0.9925, 0.9908, 0.9907, 0.9900, 0.9898, 0.9898, 0.9897, 0.9894,
         0.9886],
        [0.9912, 0.9895, 0.9883, 0.9874, 0.9863, 0.9847, 0.9845, 0.9836, 0.9821,
         0.9821],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9979, 0.9977, 0.9973, 0.9973, 0.9972,
         0.9972],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986,
         0.9985],
        [0.9964, 0.9962, 0.9961, 0.9960, 0.9960, 0.9956, 0.9954, 0.9953, 0.9953,
         0.9953],
        [0.9952, 0.9946, 0.9946, 0.9944, 0.9944, 0.9943, 0.9943, 0.9942, 0.9942,
         0.9942],
        [0.9945, 0.9935, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932, 0.9930,
         0.9929],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975,
         0.9974],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9973],
        [0.9949, 0.9940, 0.9939, 0.9938, 0.9938, 0.9931, 0.9931, 0.9931, 0.9927,
         0.9923],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9980, 0.9976,
         0.9975],
        [0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9949, 0.9948, 0.9941, 0.9941, 0.9939, 0.9938, 0.9937, 0.9937, 0.9936,
         0.9935],
        [0.9990, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9880, 0.9868, 0.9778, 0.9705, 0.9688, 0.9685, 0.9681, 0.9655, 0.9635,
         0.9621],
        [0.9963, 0.9962, 0.9959, 0.9959, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954,
         0.9954],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9964, 0.9962, 0.9962, 0.9962, 0.9961, 0.9961, 0.9961, 0.9960, 0.9960,
         0.9959],
        [0.9853, 0.9827, 0.9797, 0.9761, 0.9742, 0.9725, 0.9719, 0.9713, 0.9683,
         0.9680],
        [0.9957, 0.9952, 0.9952, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948, 0.9947,
         0.9946],
        [0.9923, 0.9917, 0.9912, 0.9910, 0.9909, 0.9904, 0.9898, 0.9898, 0.9897,
         0.9895],
        [0.9960, 0.9958, 0.9956, 0.9956, 0.9955, 0.9954, 0.9953, 0.9953, 0.9953,
         0.9952],
        [0.9855, 0.9846, 0.9845, 0.9842, 0.9822, 0.9814, 0.9813, 0.9801, 0.9791,
         0.9783],
        [0.9984, 0.9983, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9980],
        [0.9980, 0.9980, 0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9975],
        [0.9972, 0.9971, 0.9969, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965, 0.9965,
         0.9964],
        [0.9893, 0.9867, 0.9856, 0.9850, 0.9843, 0.9835, 0.9835, 0.9834, 0.9833,
         0.9825],
        [0.9864, 0.9794, 0.9783, 0.9782, 0.9769, 0.9767, 0.9767, 0.9757, 0.9755,
         0.9754],
        [0.9872, 0.9863, 0.9739, 0.9712, 0.9613, 0.9588, 0.9554, 0.9554, 0.9551,
         0.9547],
        [0.9730, 0.9687, 0.9682, 0.9664, 0.9659, 0.9633, 0.9624, 0.9624, 0.9623,
         0.9543],
        [0.9904, 0.9894, 0.9891, 0.9889, 0.9881, 0.9881, 0.9879, 0.9878, 0.9871,
         0.9868],
        [0.9939, 0.9939, 0.9939, 0.9938, 0.9936, 0.9932, 0.9930, 0.9928, 0.9928,
         0.9924],
        [0.9916, 0.9913, 0.9911, 0.9909, 0.9907, 0.9905, 0.9902, 0.9900, 0.9899,
         0.9898],
        [0.9910, 0.9908, 0.9896, 0.9894, 0.9888, 0.9884, 0.9872, 0.9872, 0.9867,
         0.9865],
        [0.9938, 0.9928, 0.9928, 0.9920, 0.9916, 0.9915, 0.9905, 0.9898, 0.9894,
         0.9891],
        [0.9902, 0.9878, 0.9870, 0.9865, 0.9857, 0.9855, 0.9851, 0.9848, 0.9843,
         0.9834],
        [0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949, 0.9946, 0.9944, 0.9943,
         0.9940],
        [0.9956, 0.9949, 0.9949, 0.9947, 0.9945, 0.9931, 0.9931, 0.9930, 0.9929,
         0.9929],
        [0.9943, 0.9913, 0.9901, 0.9900, 0.9892, 0.9891, 0.9889, 0.9886, 0.9885,
         0.9881],
        [0.9915, 0.9909, 0.9909, 0.9903, 0.9867, 0.9866, 0.9863, 0.9857, 0.9854,
         0.9853],
        [0.9919, 0.9914, 0.9907, 0.9906, 0.9888, 0.9886, 0.9885, 0.9872, 0.9861,
         0.9856],
        [0.9967, 0.9940, 0.9926, 0.9925, 0.9920, 0.9908, 0.9883, 0.9881, 0.9878,
         0.9874],
        [0.9898, 0.9889, 0.9883, 0.9882, 0.9882, 0.9875, 0.9874, 0.9873, 0.9867,
         0.9862],
        [0.9915, 0.9908, 0.9871, 0.9851, 0.9840, 0.9835, 0.9831, 0.9831, 0.9823,
         0.9817],
        [0.9922, 0.9921, 0.9918, 0.9917, 0.9912, 0.9896, 0.9862, 0.9859, 0.9850,
         0.9840],
        [0.9925, 0.9921, 0.9920, 0.9920, 0.9920, 0.9914, 0.9913, 0.9906, 0.9897,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1511886.1250, 1509622.6250, 1492006.6250, 1491029.3750, 1482352.2500,
         1480860.2500, 1479018.3750, 1477649.5000, 1476869.0000, 1469984.8750],
        [1538974.6250, 1526778.2500, 1525074.2500, 1524341.3750, 1522458.5000,
         1522388.7500, 1522380.1250, 1522343.8750, 1521001.5000, 1520934.7500],
        [1156246.5000, 1031184.8750, 1026219.8125, 1013604.5000, 1010356.9375,
         1008174.9375, 1003881.5000,  971774.0000,  970494.1250,  967363.4375],
        [1452633.2500, 1437694.8750, 1430967.7500, 1425674.3750, 1418014.5000,
         1399053.1250, 1394340.5000, 1372064.8750, 1369490.8750, 1368280.6250],
        [1345646.0000, 1331239.0000, 1307135.0000, 1279949.6250, 1276533.7500,
         1265041.2500, 1264123.5000, 1260708.0000, 1251065.2500, 1249138.7500],
        [1277264.3750, 1257176.8750, 1203684.0000, 1151552.0000, 1116141.6250,
         1114792.8750, 1105837.8750, 1086737.0000, 1083670.5000, 1070727.8750],
        [1225496.8750, 1057297.1250, 1055057.0000, 1026211.0000, 1006768.3125,
          984945.5000,  984329.5000,  977696.3125,  963839.2500,  954904.1250],
        [1129898.5000, 1118270.3750, 1031839.0625, 1004623.7500,  921281.1250,
          879545.4375,  875934.2500,  841848.5000,  841728.1250,  838324.9375],
        [1540472.3750, 1526212.0000, 1525062.6250, 1519780.6250, 1518540.3750,
         1516981.6250, 1515969.2500, 1514729.2500, 1513637.6250, 1513579.7500],
        [1462349.1250, 1383543.6250, 1347643.1250, 1340647.8750, 1315071.1250,
         1313121.0000, 1273158.7500, 1262585.0000, 1262578.8750, 1254453.5000],
        [1555035.0000, 1554816.8750, 1554077.2500, 1554041.6250, 1551207.6250,
         1548951.7500, 1548771.5000, 1547262.8750, 1546085.6250, 1545984.0000],
        [1455267.7500, 1438092.6250, 1403689.1250, 1401943.3750, 1387296.0000,
         1382616.5000, 1382360.7500, 1380750.6250, 1374610.8750, 1360175.2500],
        [1412265.2500, 1377316.7500, 1354314.3750, 1335974.0000, 1316638.3750,
         1285592.8750, 1282604.8750, 1265312.6250, 1239099.8750, 1238749.0000],
        [1563801.7500, 1559628.6250, 1555520.0000, 1554596.1250, 1552425.5000,
         1547710.0000, 1540594.3750, 1538863.0000, 1538556.3750, 1538534.3750],
        [1577190.0000, 1576271.3750, 1575649.0000, 1575604.0000, 1575392.1250,
         1575256.8750, 1574597.5000, 1574501.5000, 1574349.8750, 1573306.6250],
        [1575596.5000, 1573048.6250, 1571851.8750, 1571771.0000, 1570537.7500,
         1570009.2500, 1569437.3750, 1568361.6250, 1567534.6250, 1567156.5000],
        [1519586.3750, 1515511.0000, 1514524.1250, 1511801.1250, 1510976.6250,
         1502109.0000, 1499209.5000, 1497134.8750, 1496551.1250, 1496247.1250],
        [1494581.3750, 1481449.2500, 1481093.2500, 1477467.6250, 1476376.0000,
         1476039.6250, 1474594.6250, 1473468.6250, 1472252.2500, 1472024.7500],
        [1479177.8750, 1457936.3750, 1457836.2500, 1455534.2500, 1454987.5000,
         1454538.0000, 1452514.2500, 1451652.8750, 1448067.5000, 1446218.1250],
        [1554022.3750, 1552150.2500, 1551141.0000, 1549933.0000, 1549021.2500,
         1547749.7500, 1547225.8750, 1547081.2500, 1545009.7500, 1542793.8750],
        [1553152.6250, 1550069.0000, 1549337.2500, 1548972.5000, 1548579.6250,
         1547073.8750, 1544093.5000, 1543643.0000, 1541380.6250, 1540028.7500],
        [1487812.1250, 1469072.6250, 1465934.8750, 1464677.1250, 1463717.8750,
         1450025.6250, 1450009.1250, 1450009.1250, 1442775.6250, 1433349.7500],
        [1574378.3750, 1572223.6250, 1562156.2500, 1562153.2500, 1561521.7500,
         1558485.3750, 1555171.3750, 1554916.3750, 1547103.3750, 1543737.2500],
        [1579353.0000, 1575964.6250, 1573417.7500, 1573360.6250, 1572972.1250,
         1572939.1250, 1572387.2500, 1572309.1250, 1571074.1250, 1569989.7500],
        [1487473.1250, 1486269.1250, 1470642.6250, 1470593.5000, 1466179.5000,
         1463699.7500, 1463532.2500, 1462603.0000, 1460825.6250, 1457819.5000],
        [1576708.7500, 1572765.1250, 1570419.5000, 1569368.5000, 1567942.7500,
         1567933.8750, 1565386.5000, 1564941.6250, 1563263.5000, 1563212.8750],
        [1566530.3750, 1565519.3750, 1563393.2500, 1562125.0000, 1559484.3750,
         1557818.0000, 1553721.5000, 1553545.2500, 1552966.0000, 1551823.1250],
        [1576369.0000, 1574427.8750, 1574315.2500, 1573863.3750, 1573627.7500,
         1573351.7500, 1572486.1250, 1571514.6250, 1570963.2500, 1569991.2500],
        [1578944.8750, 1578631.6250, 1577955.8750, 1575605.5000, 1575392.1250,
         1575100.7500, 1575075.1250, 1575060.1250, 1574904.0000, 1574262.6250],
        [1580805.6250, 1580207.2500, 1575700.2500, 1575441.7500, 1575217.8750,
         1574961.0000, 1574686.1250, 1574313.7500, 1573216.6250, 1573005.1250],
        [1580749.8750, 1579967.6250, 1579948.1250, 1578013.1250, 1577802.3750,
         1577405.2500, 1577254.7500, 1576293.8750, 1575973.6250, 1575906.1250],
        [1579966.1250, 1578211.6250, 1576042.7500, 1575942.1250, 1575471.7500,
         1575369.6250, 1575296.0000, 1575178.8750, 1574681.7500, 1574521.0000],
        [1348482.5000, 1326094.5000, 1165497.3750, 1049659.6250, 1024684.4375,
         1020633.0625, 1015275.3125,  977152.9375,  950407.0000,  931008.1875],
        [1517288.2500, 1515295.5000, 1509648.6250, 1509183.6250, 1505822.3750,
         1505775.0000, 1502013.1250, 1501066.5000, 1499128.0000, 1499069.5000],
        [1554857.0000, 1553475.6250, 1551337.7500, 1548393.3750, 1547583.0000,
         1546715.5000, 1546501.5000, 1546032.6250, 1545922.0000, 1545836.6250],
        [1521113.1250, 1516450.7500, 1515911.3750, 1515308.5000, 1513656.3750,
         1513130.8750, 1513066.0000, 1511998.6250, 1510812.3750, 1508989.3750],
        [1296998.7500, 1250131.3750, 1197253.2500, 1137194.3750, 1106576.3750,
         1080989.0000, 1071482.7500, 1062630.3750, 1017331.9375, 1013518.5000],
        [1505757.8750, 1495101.7500, 1494034.1250, 1490502.0000, 1487786.5000,
         1487278.6250, 1486836.2500, 1485091.7500, 1483223.3750, 1482294.3750],
        [1433727.0000, 1422341.7500, 1411471.0000, 1407158.0000, 1405452.0000,
         1395082.6250, 1383962.0000, 1383954.1250, 1380944.1250, 1377071.1250],
        [1511710.2500, 1506780.5000, 1503694.2500, 1503694.2500, 1499880.2500,
         1498853.5000, 1496615.2500, 1496516.8750, 1496121.6250, 1493730.7500],
        [1300021.5000, 1285037.6250, 1282814.0000, 1277153.6250, 1240905.7500,
         1226571.5000, 1225045.8750, 1204628.0000, 1187493.2500, 1173855.6250],
        [1563470.7500, 1562419.8750, 1558038.0000, 1557385.8750, 1557385.8750,
         1557180.8750, 1556132.7500, 1554953.3750, 1554704.2500, 1554169.1250],
        [1556083.7500, 1555864.2500, 1553472.6250, 1549139.3750, 1548628.3750,
         1548055.2500, 1547782.2500, 1547012.0000, 1545345.7500, 1544928.6250],
        [1538261.3750, 1535210.2500, 1530351.2500, 1530171.7500, 1528303.5000,
         1526600.6250, 1523569.6250, 1522086.8750, 1521980.8750, 1520118.3750],
        [1373180.1250, 1323283.6250, 1302477.3750, 1291401.3750, 1279223.3750,
         1263723.3750, 1263682.2500, 1262932.8750, 1261521.0000, 1245748.1250],
        [1317083.0000, 1192344.6250, 1173780.7500, 1172743.5000, 1150282.1250,
         1147450.8750, 1147042.7500, 1130214.1250, 1128344.6250, 1125995.8750],
        [1332105.1250, 1315579.1250, 1102286.3750, 1060932.2500,  921113.3125,
          888066.7500,  846586.5625,  846329.0000,  843109.9375,  837752.6875],
        [1088894.8750, 1022806.0000, 1016202.2500,  990833.7500,  982853.0625,
          946819.0625,  935631.2500,  935063.8750,  933829.6250,  832862.3750],
        [1395326.1250, 1376272.8750, 1369369.3750, 1366221.7500, 1350776.2500,
         1349854.2500, 1346846.5000, 1343968.5000, 1331423.1250, 1325001.1250],
        [1466927.7500, 1466146.0000, 1465725.1250, 1464425.8750, 1461114.0000,
         1452517.0000, 1446997.6250, 1444675.6250, 1444536.5000, 1435507.0000],
        [1418594.8750, 1413100.6250, 1408794.7500, 1405092.7500, 1400683.1250,
         1397879.3750, 1390838.3750, 1388255.5000, 1385988.2500, 1383773.3750],
        [1406488.5000, 1403444.1250, 1380326.6250, 1376063.0000, 1362917.6250,
         1356263.5000, 1332857.5000, 1332800.1250, 1323818.8750, 1320231.8750],
        [1463776.5000, 1443773.5000, 1443761.0000, 1427910.0000, 1418638.1250,
         1417717.0000, 1398196.7500, 1383167.7500, 1374848.2500, 1369189.1250],
        [1391506.8750, 1343480.3750, 1328195.6250, 1319071.6250, 1305287.5000,
         1301166.3750, 1294137.1250, 1288390.0000, 1278916.0000, 1261707.5000],
        [1494058.3750, 1491527.1250, 1490868.7500, 1490688.1250, 1490688.1250,
         1488755.8750, 1481233.1250, 1477803.1250, 1474731.0000, 1469317.8750],
        [1503116.5000, 1488574.2500, 1487443.2500, 1484518.2500, 1480176.8750,
         1449638.6250, 1449135.3750, 1447228.1250, 1445618.2500, 1445163.5000],
        [1475779.1250, 1412529.2500, 1388450.2500, 1388162.8750, 1372377.6250,
         1369942.7500, 1365595.1250, 1359818.5000, 1357811.2500, 1349529.7500],
        [1417114.2500, 1406098.1250, 1404968.2500, 1393768.7500, 1322929.1250,
         1320946.0000, 1315754.7500, 1305495.5000, 1298778.6250, 1297356.1250],
        [1424895.5000, 1415510.8750, 1401423.3750, 1399860.3750, 1363606.7500,
         1360657.8750, 1358268.5000, 1333602.5000, 1312244.7500, 1302882.3750],
        [1527285.1250, 1468292.5000, 1440614.1250, 1436849.2500, 1427637.6250,
         1403156.5000, 1354479.7500, 1349717.7500, 1344628.7500, 1336899.3750],
        [1383662.5000, 1365625.1250, 1353106.0000, 1352370.6250, 1351713.1250,
         1338849.0000, 1336612.5000, 1334677.6250, 1323616.8750, 1314700.0000],
        [1416706.1250, 1404097.5000, 1330168.0000, 1292590.3750, 1273546.2500,
         1263492.0000, 1257813.7500, 1257421.5000, 1242233.0000, 1232654.0000],
        [1431773.1250, 1429023.0000, 1422473.3750, 1420601.1250, 1410456.2500,
         1378824.1250, 1313845.0000, 1308540.6250, 1291708.1250, 1272595.6250],
        [1437974.6250, 1429051.6250, 1427493.3750, 1426904.0000, 1426833.2500,
         1414569.0000, 1413999.7500, 1400123.5000, 1381882.2500, 1378537.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1511886.1250,       0.0000],
         [1509622.6250,       0.0000],
         [1492006.6250,       0.0000],
         ...,
         [1477649.5000,       0.0000],
         [      0.0000, 1476869.0000],
         [1469984.8750,       0.0000]],

        [[1538974.6250,       0.0000],
         [1526778.2500,       0.0000],
         [1525074.2500,       0.0000],
         ...,
         [1522343.8750,       0.0000],
         [1521001.5000,       0.0000],
         [1520934.7500,       0.0000]],

        [[1156246.5000,       0.0000],
         [1031184.8750,       0.0000],
         [      0.0000, 1026219.8125],
         ...,
         [ 971774.0000,       0.0000],
         [ 970494.1250,       0.0000],
         [ 967363.4375,       0.0000]],

        ...,

        [[1416706.1250,       0.0000],
         [1404097.5000,       0.0000],
         [1330168.0000,       0.0000],
         ...,
         [1257421.5000,       0.0000],
         [1242233.0000,       0.0000],
         [1232654.0000,       0.0000]],

        [[1431773.1250,       0.0000],
         [1429023.0000,       0.0000],
         [1422473.3750,       0.0000],
         ...,
         [      0.0000, 1308540.6250],
         [1291708.1250,       0.0000],
         [1272595.6250,       0.0000]],

        [[      0.0000, 1437974.6250],
         [      0.0000, 1429051.6250],
         [      0.0000, 1427493.3750],
         ...,
         [      0.0000, 1400123.5000],
         [      0.0000, 1381882.2500],
         [1378537.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13394411.0000,  1476869.0000],
        [15246675.0000,        0.0000],
        [ 5097063.0000,  5062237.5000],
        [12669161.0000,  1399053.1250],
        [ 9052276.0000,  3778303.5000],
        [ 9232362.0000,  2235222.5000],
        [ 5057308.5000,  5179236.5000],
        [ 8607360.0000,   875934.2500],
        [12175417.0000,  3029549.0000],
        [11831609.0000,  1383543.6250],
        [15506234.0000,        0.0000],
        [12606628.0000,  1360175.2500],
        [13107868.0000,        0.0000],
        [15490229.0000,        0.0000],
        [15752120.0000,        0.0000],
        [15705306.0000,        0.0000],
        [13544064.0000,  1519586.3750],
        [11812514.0000,  2966833.5000],
        [14558463.0000,        0.0000],
        [15486128.0000,        0.0000],
        [15466332.0000,        0.0000],
        [13112707.0000,  1464677.1250],
        [15591848.0000,        0.0000],
        [15733767.0000,        0.0000],
        [10255070.0000,  4434568.0000],
        [15681943.0000,        0.0000],
        [15586927.0000,        0.0000],
        [15730910.0000,        0.0000],
        [15760932.0000,        0.0000],
        [15757556.0000,        0.0000],
        [15779315.0000,        0.0000],
        [15760682.0000,        0.0000],
        [ 2976325.7500,  7832569.5000],
        [ 9036332.0000,  6027959.5000],
        [12394121.0000,  3092534.0000],
        [12113713.0000,  3026723.7500],
        [ 3186538.5000,  8047568.5000],
        [11915527.0000,  2982380.5000],
        [12617201.0000,  1383962.0000],
        [15007597.0000,        0.0000],
        [ 9877584.0000,  2525943.5000],
        [15575841.0000,        0.0000],
        [15496312.0000,        0.0000],
        [13746484.0000,  1530171.7500],
        [ 2507269.0000, 10359904.0000],
        [ 1172743.5000, 10512538.0000],
        [ 5182958.5000,  4810903.0000],
        [ 2714745.5000,  6971051.0000],
        [ 4047499.2500,  9507561.0000],
        [10156105.0000,  4392467.5000],
        [12587908.0000,  1405092.7500],
        [ 1320231.8750, 12274979.0000],
        [ 1369189.1250, 12771789.0000],
        [ 2647267.2500, 10464592.0000],
        [11866857.0000,  2982814.2500],
        [10208745.0000,  4471868.0000],
        [ 2729761.2500, 11110235.0000],
        [ 5240975.0000,  8242235.0000],
        [ 1302882.3750, 12370071.0000],
        [ 2691379.0000, 11398182.0000],
        [10732422.0000,  2722511.5000],
        [11707231.0000,  1263492.0000],
        [11057454.0000,  2622385.5000],
        [ 1378537.5000, 12758832.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 451/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:32, 61.17s/it]  7%|▋         | 2/29 [01:02<11:34, 25.73s/it] 10%|█         | 3/29 [01:03<06:14, 14.40s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.08s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.7879819869995117
Epoch 452/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.81s/it]  7%|▋         | 2/29 [00:58<11:04, 24.63s/it] 10%|█         | 3/29 [00:59<05:58, 13.80s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.72s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.91s/it] 21%|██        | 6/29 [01:02<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.90s/it]
Epoch loss is 2.7783167362213135
Epoch 453/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:42, 59.37s/it]  7%|▋         | 2/29 [01:00<11:14, 24.99s/it] 10%|█         | 3/29 [01:01<06:04, 14.00s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.84s/it] 17%|█▋        | 5/29 [01:03<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.04it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.06it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7958247661590576
Epoch 454/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:30, 56.80s/it]  7%|▋         | 2/29 [01:00<11:27, 25.48s/it] 10%|█         | 3/29 [01:01<06:10, 14.26s/it] 14%|█▍        | 4/29 [01:02<03:44,  9.00s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.08s/it] 21%|██        | 6/29 [01:04<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.779879093170166
Epoch 455/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:10, 60.36s/it]  7%|▋         | 2/29 [01:01<11:25, 25.40s/it] 10%|█         | 3/29 [01:02<06:09, 14.22s/it] 14%|█▍        | 4/29 [01:03<03:44,  8.97s/it] 17%|█▋        | 5/29 [01:04<02:25,  6.07s/it] 21%|██        | 6/29 [01:04<01:39,  4.32s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.75885272026062
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0032, 0.0144, 0.0023,  ..., 0.0042, 0.0001, 0.0196],
        [0.0034, 0.0099, 0.0022,  ..., 0.0026, 0.0001, 0.0190],
        [0.0335, 0.0062, 0.0036,  ..., 0.0052, 0.0155, 0.0243],
        ...,
        [0.0080, 0.0081, 0.0189,  ..., 0.0041, 0.0018, 0.0208],
        [0.0045, 0.0086, 0.0126,  ..., 0.0052, 0.0052, 0.0203],
        [0.0101, 0.0045, 0.0042,  ..., 0.0030, 0.0024, 0.0232]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9960, 0.9951, 0.9950, 0.9947, 0.9947, 0.9946, 0.9943, 0.9943,
         0.9940],
        [0.9972, 0.9966, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9756, 0.9694, 0.9674, 0.9673, 0.9665, 0.9661, 0.9657, 0.9643, 0.9640,
         0.9640],
        [0.9936, 0.9925, 0.9924, 0.9923, 0.9922, 0.9912, 0.9911, 0.9901, 0.9898,
         0.9895],
        [0.9885, 0.9869, 0.9865, 0.9848, 0.9846, 0.9844, 0.9844, 0.9842, 0.9841,
         0.9835],
        [0.9846, 0.9832, 0.9805, 0.9783, 0.9765, 0.9758, 0.9753, 0.9739, 0.9738,
         0.9737],
        [0.9796, 0.9715, 0.9714, 0.9674, 0.9670, 0.9637, 0.9636, 0.9635, 0.9629,
         0.9627],
        [0.9759, 0.9739, 0.9686, 0.9655, 0.9598, 0.9567, 0.9557, 0.9556, 0.9530,
         0.9518],
        [0.9974, 0.9968, 0.9967, 0.9964, 0.9963, 0.9963, 0.9962, 0.9962, 0.9961,
         0.9961],
        [0.9938, 0.9898, 0.9888, 0.9877, 0.9872, 0.9870, 0.9853, 0.9843, 0.9842,
         0.9836],
        [0.9979, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9935, 0.9929, 0.9908, 0.9907, 0.9906, 0.9902, 0.9902, 0.9900, 0.9896,
         0.9895],
        [0.9915, 0.9911, 0.9885, 0.9884, 0.9865, 0.9864, 0.9863, 0.9843, 0.9838,
         0.9828],
        [0.9983, 0.9981, 0.9979, 0.9978, 0.9978, 0.9975, 0.9972, 0.9971, 0.9971,
         0.9970],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9963, 0.9961, 0.9961, 0.9959, 0.9958, 0.9955, 0.9954, 0.9953, 0.9952,
         0.9951],
        [0.9953, 0.9947, 0.9945, 0.9944, 0.9944, 0.9944, 0.9942, 0.9942, 0.9941,
         0.9941],
        [0.9945, 0.9936, 0.9935, 0.9932, 0.9932, 0.9932, 0.9932, 0.9932, 0.9931,
         0.9930],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9950, 0.9941, 0.9938, 0.9938, 0.9937, 0.9936, 0.9934, 0.9932, 0.9926,
         0.9926],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9982, 0.9980, 0.9979, 0.9979, 0.9976,
         0.9974],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9986,
         0.9986],
        [0.9951, 0.9949, 0.9946, 0.9942, 0.9940, 0.9939, 0.9939, 0.9937, 0.9937,
         0.9937],
        [0.9989, 0.9988, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9990, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9884, 0.9868, 0.9773, 0.9706, 0.9684, 0.9682, 0.9681, 0.9650, 0.9621,
         0.9616],
        [0.9962, 0.9961, 0.9957, 0.9957, 0.9956, 0.9956, 0.9955, 0.9954, 0.9953,
         0.9952],
        [0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9964, 0.9962, 0.9961, 0.9961, 0.9961, 0.9961, 0.9960, 0.9959, 0.9959,
         0.9959],
        [0.9857, 0.9829, 0.9797, 0.9759, 0.9746, 0.9728, 0.9728, 0.9707, 0.9679,
         0.9678],
        [0.9955, 0.9953, 0.9951, 0.9950, 0.9949, 0.9949, 0.9948, 0.9948, 0.9947,
         0.9947],
        [0.9927, 0.9921, 0.9917, 0.9915, 0.9910, 0.9910, 0.9905, 0.9903, 0.9903,
         0.9902],
        [0.9959, 0.9956, 0.9955, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952, 0.9950,
         0.9949],
        [0.9854, 0.9847, 0.9843, 0.9843, 0.9822, 0.9815, 0.9810, 0.9796, 0.9786,
         0.9784],
        [0.9983, 0.9982, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9980, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9971, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9963, 0.9963,
         0.9962],
        [0.9888, 0.9860, 0.9847, 0.9846, 0.9839, 0.9836, 0.9834, 0.9830, 0.9830,
         0.9819],
        [0.9855, 0.9792, 0.9787, 0.9776, 0.9772, 0.9771, 0.9768, 0.9763, 0.9758,
         0.9757],
        [0.9868, 0.9859, 0.9737, 0.9706, 0.9608, 0.9601, 0.9568, 0.9560, 0.9552,
         0.9550],
        [0.9734, 0.9684, 0.9683, 0.9662, 0.9653, 0.9631, 0.9623, 0.9620, 0.9616,
         0.9537],
        [0.9908, 0.9892, 0.9891, 0.9881, 0.9880, 0.9879, 0.9877, 0.9869, 0.9868,
         0.9867],
        [0.9937, 0.9937, 0.9937, 0.9935, 0.9935, 0.9928, 0.9927, 0.9926, 0.9926,
         0.9922],
        [0.9913, 0.9910, 0.9908, 0.9900, 0.9900, 0.9896, 0.9896, 0.9895, 0.9895,
         0.9893],
        [0.9908, 0.9905, 0.9893, 0.9891, 0.9886, 0.9882, 0.9872, 0.9868, 0.9864,
         0.9863],
        [0.9937, 0.9929, 0.9927, 0.9919, 0.9917, 0.9916, 0.9905, 0.9897, 0.9895,
         0.9892],
        [0.9903, 0.9874, 0.9867, 0.9866, 0.9854, 0.9853, 0.9849, 0.9844, 0.9837,
         0.9829],
        [0.9951, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948, 0.9942, 0.9942, 0.9941,
         0.9939],
        [0.9955, 0.9948, 0.9945, 0.9944, 0.9943, 0.9928, 0.9928, 0.9928, 0.9927,
         0.9926],
        [0.9944, 0.9911, 0.9899, 0.9898, 0.9892, 0.9890, 0.9888, 0.9887, 0.9886,
         0.9880],
        [0.9912, 0.9909, 0.9906, 0.9903, 0.9863, 0.9863, 0.9860, 0.9854, 0.9851,
         0.9850],
        [0.9917, 0.9912, 0.9906, 0.9906, 0.9889, 0.9887, 0.9885, 0.9868, 0.9858,
         0.9855],
        [0.9967, 0.9939, 0.9924, 0.9923, 0.9919, 0.9906, 0.9882, 0.9880, 0.9879,
         0.9872],
        [0.9896, 0.9887, 0.9881, 0.9881, 0.9881, 0.9876, 0.9874, 0.9871, 0.9866,
         0.9861],
        [0.9914, 0.9908, 0.9866, 0.9849, 0.9839, 0.9832, 0.9828, 0.9828, 0.9820,
         0.9817],
        [0.9920, 0.9919, 0.9916, 0.9914, 0.9909, 0.9893, 0.9859, 0.9852, 0.9848,
         0.9838],
        [0.9923, 0.9918, 0.9918, 0.9918, 0.9917, 0.9913, 0.9912, 0.9905, 0.9897,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 0, 1, 0, 1, 1, 1, 0, 1, 0],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1512833.7500, 1511338.3750, 1492150.2500, 1490375.5000, 1484007.2500,
         1483652.0000, 1481252.8750, 1475991.7500, 1475622.8750, 1469522.5000],
        [1536546.0000, 1524924.3750, 1522977.0000, 1522805.6250, 1521118.8750,
         1520370.6250, 1518686.7500, 1518345.0000, 1518276.8750, 1517673.2500],
        [1129539.6250, 1033755.7500, 1003928.4375, 1002357.6250,  992343.0000,
          986662.1875,  981011.0000,  961591.7500,  957488.4375,  957076.7500],
        [1461356.5000, 1437694.8750, 1434948.6250, 1432870.0000, 1431407.1250,
         1411780.5000, 1408535.5000, 1389877.0000, 1382849.7500, 1376648.2500],
        [1356955.6250, 1327316.7500, 1319384.8750, 1288748.7500, 1284834.1250,
         1280081.3750, 1279994.7500, 1276571.5000, 1275166.2500, 1264300.7500],
        [1283391.5000, 1258321.2500, 1210577.3750, 1173329.6250, 1144524.1250,
         1133006.0000, 1124968.6250, 1102987.7500, 1101321.7500, 1099706.5000],
        [1195323.0000, 1065725.7500, 1063983.1250, 1005101.0625,  998429.7500,
          952647.5000,  952047.1250,  950182.1875,  941336.8750,  938837.3125],
        [1134115.2500, 1102294.7500, 1021462.6875,  978136.5625,  901083.5625,
          862610.8125,  850182.1250,  848592.0625,  817990.3750,  803282.1250],
        [1541323.1250, 1528369.1250, 1526616.6250, 1520437.2500, 1518116.1250,
         1517095.8750, 1516384.1250, 1515412.6250, 1513644.7500, 1513526.3750],
        [1464937.0000, 1383002.7500, 1363463.6250, 1341947.6250, 1332633.7500,
         1328864.5000, 1296852.7500, 1278773.3750, 1276615.3750, 1265812.3750],
        [1553579.2500, 1552409.2500, 1552289.2500, 1551425.0000, 1548161.6250,
         1546085.6250, 1545910.2500, 1545258.8750, 1544133.3750, 1543944.8750],
        [1459367.7500, 1445658.2500, 1403060.1250, 1400887.5000, 1399209.1250,
         1391622.5000, 1391187.1250, 1386445.5000, 1378412.6250, 1377153.8750],
        [1417045.2500, 1409591.6250, 1358491.3750, 1356856.1250, 1320283.5000,
         1317375.6250, 1316563.1250, 1277927.2500, 1270314.7500, 1252445.2500],
        [1562239.7500, 1557767.5000, 1552849.0000, 1551821.6250, 1551524.1250,
         1543513.5000, 1538082.5000, 1536370.2500, 1534346.5000, 1533322.6250],
        [1575901.5000, 1575007.6250, 1574606.5000, 1574447.3750, 1574391.8750,
         1573994.1250, 1573779.3750, 1573297.6250, 1573143.1250, 1572378.1250],
        [1574430.8750, 1571727.5000, 1571024.6250, 1570230.7500, 1569459.7500,
         1568126.7500, 1567294.0000, 1566506.5000, 1565983.7500, 1565694.0000],
        [1517920.7500, 1514644.0000, 1513712.6250, 1508878.5000, 1508117.6250,
         1499637.1250, 1499017.8750, 1497383.5000, 1495217.2500, 1492966.0000],
        [1496067.3750, 1483363.5000, 1479657.5000, 1478216.0000, 1476279.0000,
         1476242.3750, 1473620.3750, 1472957.1250, 1471708.8750, 1471095.6250],
        [1478513.5000, 1460619.5000, 1457985.0000, 1453096.0000, 1452529.5000,
         1452113.8750, 1451681.8750, 1451250.0000, 1449070.5000, 1449013.8750],
        [1552776.5000, 1549718.6250, 1549223.6250, 1548415.6250, 1546899.7500,
         1546394.0000, 1545061.3750, 1544050.8750, 1543447.1250, 1542914.3750],
        [1550703.2500, 1549621.0000, 1548278.2500, 1548014.0000, 1547053.2500,
         1546896.8750, 1541085.1250, 1540845.5000, 1539137.5000, 1538372.8750],
        [1491023.7500, 1471818.3750, 1465300.3750, 1464668.7500, 1462179.0000,
         1459977.3750, 1455335.8750, 1452097.3750, 1440531.7500, 1439131.1250],
        [1573447.6250, 1571603.1250, 1561553.0000, 1561270.0000, 1560637.3750,
         1556254.3750, 1553188.2500, 1552852.0000, 1545403.2500, 1541533.3750],
        [1578151.3750, 1575434.2500, 1572178.7500, 1572174.2500, 1572169.7500,
         1572027.3750, 1572025.8750, 1571471.2500, 1569275.7500, 1568553.0000],
        [1491753.2500, 1488815.6250, 1481228.7500, 1473832.6250, 1469247.8750,
         1466926.5000, 1465883.2500, 1463247.6250, 1462432.7500, 1461731.5000],
        [1575291.3750, 1572148.7500, 1569506.1250, 1568294.2500, 1567392.6250,
         1567083.2500, 1563886.7500, 1563775.0000, 1561983.5000, 1561974.5000],
        [1565497.0000, 1564222.3750, 1561454.6250, 1560603.2500, 1557736.3750,
         1557004.1250, 1551980.0000, 1551966.6250, 1551252.0000, 1550778.6250],
        [1575443.2500, 1573692.3750, 1573383.1250, 1572963.0000, 1572811.6250,
         1572540.1250, 1571379.8750, 1571155.0000, 1571056.2500, 1570045.1250],
        [1577686.5000, 1577409.6250, 1577039.6250, 1574222.2500, 1574201.1250,
         1573917.5000, 1573792.8750, 1573684.8750, 1573260.2500, 1573110.1250],
        [1579845.6250, 1578952.3750, 1575254.0000, 1574372.3750, 1573890.3750,
         1573692.3750, 1573615.7500, 1573447.6250, 1571995.8750, 1571910.3750],
        [1579494.6250, 1579152.7500, 1579121.0000, 1577178.0000, 1577054.7500,
         1576523.8750, 1576429.1250, 1575408.7500, 1575106.7500, 1574555.5000],
        [1578500.7500, 1577600.7500, 1575169.8750, 1574777.7500, 1574558.5000,
         1574394.8750, 1574315.2500, 1573876.8750, 1573597.8750, 1573290.2500],
        [1355284.7500, 1324672.6250, 1156618.1250, 1051683.6250, 1018307.4375,
         1016332.1875, 1014707.0625,  970673.6875,  931171.5625,  924364.0000],
        [1515301.2500, 1513051.6250, 1505829.6250, 1505087.3750, 1503684.2500,
         1501758.1250, 1500704.3750, 1497753.3750, 1495859.0000, 1495036.2500],
        [1553041.6250, 1551287.5000, 1549786.6250, 1546663.8750, 1546411.6250,
         1545823.2500, 1545807.1250, 1545319.2500, 1544691.5000, 1544517.7500],
        [1520253.1250, 1515908.5000, 1514620.8750, 1513797.7500, 1513777.5000,
         1513255.0000, 1510614.8750, 1509208.1250, 1508989.3750, 1508507.3750],
        [1304842.1250, 1253351.0000, 1197241.8750, 1134650.7500, 1113720.6250,
         1084373.5000, 1084290.7500, 1052607.7500, 1011413.5625, 1010522.7500],
        [1500900.5000, 1496476.8750, 1492452.0000, 1489872.3750, 1487128.3750,
         1486999.3750, 1486600.8750, 1485960.2500, 1484078.0000, 1482673.2500],
        [1441045.6250, 1430056.3750, 1421970.1250, 1417285.7500, 1407791.3750,
         1406307.3750, 1396758.7500, 1393916.2500, 1392594.2500, 1390797.1250],
        [1510223.1250, 1503542.1250, 1499608.5000, 1498584.8750, 1498584.8750,
         1497397.6250, 1496672.5000, 1493863.2500, 1489610.8750, 1488720.5000],
        [1298725.2500, 1286883.2500, 1279541.8750, 1278366.1250, 1240407.6250,
         1228949.5000, 1219676.5000, 1196048.2500, 1179494.5000, 1175880.2500],
        [1561828.5000, 1560383.0000, 1556352.3750, 1556052.5000, 1555893.7500,
         1554812.5000, 1553191.1250, 1553032.6250, 1552190.1250, 1552042.1250],
        [1554452.2500, 1553817.8750, 1551052.2500, 1546615.1250, 1546438.1250,
         1546329.0000, 1545211.6250, 1543752.0000, 1542605.5000, 1541799.5000],
        [1535503.0000, 1530459.2500, 1526417.2500, 1525570.2500, 1524818.2500,
         1524097.1250, 1520234.2500, 1518553.5000, 1517023.3750, 1516572.1250],
        [1364558.8750, 1310922.6250, 1287024.3750, 1284977.5000, 1271006.6250,
         1266959.7500, 1262444.1250, 1255830.1250, 1255306.7500, 1236089.0000],
        [1300817.6250, 1189000.5000, 1180160.6250, 1162750.7500, 1155622.5000,
         1154535.3750, 1149584.5000, 1141052.0000, 1133045.0000, 1131509.5000],
        [1325774.6250, 1308638.0000, 1099466.3750, 1051290.5000,  913956.5000,
          904760.4375,  862744.9375,  853692.8125,  843377.7500,  840855.1875],
        [1094484.6250, 1019630.0625, 1016991.4375,  987490.6250,  974605.6250,
          944144.6875,  933380.8750,  930064.7500,  924209.6875,  826162.6875],
        [1403172.5000, 1370661.5000, 1370285.1250, 1350746.6250, 1348228.0000,
         1347019.8750, 1343084.3750, 1327620.6250, 1325887.1250, 1324143.3750],
        [1463250.3750, 1462757.8750, 1462589.0000, 1459167.3750, 1459157.5000,
         1444474.5000, 1442847.1250, 1440538.7500, 1440318.8750, 1431737.6250],
        [1412623.6250, 1407371.3750, 1403298.2500, 1388188.0000, 1387030.1250,
         1379508.1250, 1378624.3750, 1378314.1250, 1376593.1250, 1373338.6250],
        [1402422.0000, 1397483.5000, 1373468.2500, 1370466.7500, 1359398.5000,
         1352491.8750, 1331974.2500, 1325641.8750, 1318320.7500, 1315409.7500],
        [1463317.3750, 1446770.0000, 1442254.1250, 1426397.8750, 1420752.8750,
         1419413.5000, 1396309.8750, 1380457.0000, 1377905.2500, 1370870.7500],
        [1393379.3750, 1335860.6250, 1323567.6250, 1321114.8750, 1298934.6250,
         1297733.6250, 1290716.7500, 1281174.5000, 1268048.8750, 1253413.1250],
        [1491588.3750, 1486966.6250, 1486935.3750, 1486935.3750, 1485275.8750,
         1484828.3750, 1472552.6250, 1472141.2500, 1470160.2500, 1467416.1250],
        [1500053.2500, 1485355.2500, 1480226.2500, 1476688.6250, 1474269.7500,
         1444907.1250, 1444617.7500, 1444485.5000, 1442552.7500, 1439646.0000],
        [1476522.5000, 1408729.0000, 1385730.3750, 1383353.6250, 1371188.3750,
         1367289.2500, 1362972.2500, 1362121.1250, 1359703.1250, 1348765.5000],
        [1412180.5000, 1406060.6250, 1400092.8750, 1392934.2500, 1316455.1250,
         1316320.7500, 1310125.2500, 1299212.1250, 1294286.5000, 1291772.1250],
        [1422240.0000, 1411038.8750, 1399302.5000, 1398463.3750, 1364799.6250,
         1361636.6250, 1358392.7500, 1325726.6250, 1306736.1250, 1300867.3750],
        [1526306.6250, 1466839.6250, 1436000.0000, 1434126.3750, 1425395.7500,
         1399588.1250, 1351177.0000, 1347931.0000, 1345632.0000, 1332368.1250],
        [1379489.7500, 1361496.3750, 1350961.7500, 1350849.6250, 1349963.6250,
         1339884.8750, 1335809.6250, 1331618.7500, 1321910.0000, 1311987.0000],
        [1415463.6250, 1403947.5000, 1321707.1250, 1289136.0000, 1271757.1250,
         1259183.1250, 1252395.0000, 1251197.6250, 1237067.8750, 1232355.3750],
        [1426773.3750, 1426075.5000, 1419050.7500, 1415809.2500, 1404621.1250,
         1372740.2500, 1307658.6250, 1294801.2500, 1288119.6250, 1269356.8750],
        [1433996.5000, 1423732.8750, 1423648.6250, 1422619.8750, 1420496.8750,
         1413738.1250, 1411069.7500, 1396493.6250, 1380629.5000, 1371604.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1512833.7500,       0.0000],
         [1511338.3750,       0.0000],
         [1492150.2500,       0.0000],
         ...,
         [      0.0000, 1475991.7500],
         [1475622.8750,       0.0000],
         [1469522.5000,       0.0000]],

        [[1536546.0000,       0.0000],
         [1524924.3750,       0.0000],
         [1522977.0000,       0.0000],
         ...,
         [1518345.0000,       0.0000],
         [1518276.8750,       0.0000],
         [1517673.2500,       0.0000]],

        [[1129539.6250,       0.0000],
         [      0.0000, 1033755.7500],
         [1003928.4375,       0.0000],
         ...,
         [      0.0000,  961591.7500],
         [ 957488.4375,       0.0000],
         [ 957076.7500,       0.0000]],

        ...,

        [[1415463.6250,       0.0000],
         [1403947.5000,       0.0000],
         [1321707.1250,       0.0000],
         ...,
         [1251197.6250,       0.0000],
         [1237067.8750,       0.0000],
         [1232355.3750,       0.0000]],

        [[1426773.3750,       0.0000],
         [1426075.5000,       0.0000],
         [1419050.7500,       0.0000],
         ...,
         [      0.0000, 1294801.2500],
         [1288119.6250,       0.0000],
         [      0.0000, 1269356.8750]],

        [[      0.0000, 1433996.5000],
         [      0.0000, 1423732.8750],
         [      0.0000, 1423648.6250],
         ...,
         [      0.0000, 1396493.6250],
         [      0.0000, 1380629.5000],
         [1371604.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13400756.0000,  1475991.7500],
        [15221724.0000,        0.0000],
        [ 4048033.2500,  5957721.5000],
        [12759433.0000,  1408535.5000],
        [ 9118112.0000,  3835242.2500],
        [ 9355817.0000,  2276317.5000],
        [ 5025694.5000,  5037919.0000],
        [ 7667875.5000,  1651874.2500],
        [13697282.0000,  1513644.7500],
        [11949901.0000,  1383002.7500],
        [15483198.0000,        0.0000],
        [14033004.0000,        0.0000],
        [13296894.0000,        0.0000],
        [15461838.0000,        0.0000],
        [15740947.0000,        0.0000],
        [15690477.0000,        0.0000],
        [13529574.0000,  1517920.7500],
        [13283141.0000,  1496067.3750],
        [14555874.0000,        0.0000],
        [15468902.0000,        0.0000],
        [15450008.0000,        0.0000],
        [13137395.0000,  1464668.7500],
        [15577742.0000,        0.0000],
        [15723462.0000,        0.0000],
        [10282799.0000,  4442300.0000],
        [15671336.0000,        0.0000],
        [15572494.0000,        0.0000],
        [15724469.0000,        0.0000],
        [15748325.0000,        0.0000],
        [15746977.0000,        0.0000],
        [15770025.0000,        0.0000],
        [15750082.0000,        0.0000],
        [ 2955403.2500,  7808412.0000],
        [ 9017818.0000,  6016247.5000],
        [12382225.0000,  3091126.5000],
        [12105322.0000,  3023610.2500],
        [ 3176851.2500,  8070163.0000],
        [10424120.0000,  4469022.5000],
        [12705929.0000,  1392594.2500],
        [14976808.0000,        0.0000],
        [ 9856682.0000,  2527291.0000],
        [15555779.0000,        0.0000],
        [15472073.0000,        0.0000],
        [13714430.0000,  1524818.2500],
        [ 2491919.0000, 10303202.0000],
        [ 1155622.5000, 10542456.0000],
        [ 5219388.0000,  4785169.5000],
        [ 2700372.0000,  6950792.5000],
        [ 5373172.0000,  8137677.0000],
        [10125264.0000,  4381575.5000],
        [12496702.0000,  1388188.0000],
        [ 1315409.7500, 12231668.0000],
        [ 1370870.7500, 12773578.0000],
        [ 2644682.5000, 10419262.0000],
        [11828384.0000,  2976416.7500],
        [10173124.0000,  4459678.0000],
        [ 2733309.5000, 11093066.0000],
        [ 5220079.0000,  8219361.0000],
        [       0.0000, 13649204.0000],
        [ 2683545.0000, 11381820.0000],
        [10718672.0000,  2715299.5000],
        [11675028.0000,  1259183.1250],
        [ 9753190.0000,  3871816.7500],
        [ 1371604.3750, 12726426.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 456/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:23, 56.56s/it]  7%|▋         | 2/29 [00:59<11:12, 24.92s/it] 10%|█         | 3/29 [01:00<06:10, 14.25s/it] 14%|█▍        | 4/29 [01:01<03:44,  8.99s/it] 17%|█▋        | 5/29 [01:02<02:25,  6.08s/it] 21%|██        | 6/29 [01:03<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:04<01:10,  3.21s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.48s/it] 31%|███       | 9/29 [01:06<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.93s/it]
Epoch loss is 2.7791152000427246
Epoch 457/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:44, 57.32s/it]  7%|▋         | 2/29 [01:01<11:36, 25.81s/it] 10%|█         | 3/29 [01:01<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:02<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.04it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.05it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.06it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.7820334434509277
Epoch 458/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:25, 60.92s/it]  7%|▋         | 2/29 [01:01<11:31, 25.63s/it] 10%|█         | 3/29 [01:02<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.12s/it] 21%|██        | 6/29 [01:05<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.7902204990386963
Epoch 459/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:38, 61.38s/it]  7%|▋         | 2/29 [01:02<11:37, 25.82s/it] 10%|█         | 3/29 [01:03<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:05<02:27,  6.16s/it] 21%|██        | 6/29 [01:05<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7802624702453613
Epoch 460/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:43, 61.55s/it]  7%|▋         | 2/29 [01:02<11:38, 25.89s/it] 10%|█         | 3/29 [01:03<06:16, 14.49s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.17s/it] 21%|██        | 6/29 [01:06<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.51s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7901313304901123
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0030, 0.0139, 0.0022,  ..., 0.0041, 0.0001, 0.0196],
        [0.0030, 0.0096, 0.0021,  ..., 0.0022, 0.0001, 0.0187],
        [0.0328, 0.0065, 0.0035,  ..., 0.0052, 0.0149, 0.0245],
        ...,
        [0.0078, 0.0080, 0.0183,  ..., 0.0039, 0.0017, 0.0210],
        [0.0043, 0.0083, 0.0121,  ..., 0.0049, 0.0050, 0.0203],
        [0.0095, 0.0044, 0.0041,  ..., 0.0029, 0.0021, 0.0230]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9962, 0.9952, 0.9952, 0.9950, 0.9948, 0.9947, 0.9947, 0.9946,
         0.9942],
        [0.9973, 0.9967, 0.9967, 0.9966, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9763, 0.9695, 0.9689, 0.9671, 0.9660, 0.9660, 0.9657, 0.9652, 0.9651,
         0.9637],
        [0.9934, 0.9927, 0.9924, 0.9921, 0.9917, 0.9910, 0.9909, 0.9898, 0.9896,
         0.9893],
        [0.9882, 0.9872, 0.9864, 0.9847, 0.9847, 0.9845, 0.9840, 0.9838, 0.9837,
         0.9837],
        [0.9842, 0.9830, 0.9807, 0.9772, 0.9759, 0.9754, 0.9754, 0.9736, 0.9730,
         0.9726],
        [0.9803, 0.9703, 0.9700, 0.9685, 0.9665, 0.9659, 0.9649, 0.9646, 0.9639,
         0.9632],
        [0.9755, 0.9738, 0.9683, 0.9677, 0.9605, 0.9562, 0.9560, 0.9559, 0.9546,
         0.9541],
        [0.9975, 0.9968, 0.9968, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9938, 0.9899, 0.9888, 0.9879, 0.9865, 0.9865, 0.9849, 0.9839, 0.9836,
         0.9833],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9936, 0.9933, 0.9915, 0.9910, 0.9905, 0.9903, 0.9902, 0.9901, 0.9900,
         0.9891],
        [0.9916, 0.9905, 0.9886, 0.9881, 0.9865, 0.9859, 0.9858, 0.9840, 0.9837,
         0.9832],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9979, 0.9976, 0.9974, 0.9973, 0.9972,
         0.9972],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9960, 0.9957, 0.9956, 0.9956, 0.9955,
         0.9954],
        [0.9954, 0.9949, 0.9946, 0.9945, 0.9945, 0.9945, 0.9943, 0.9943, 0.9943,
         0.9943],
        [0.9946, 0.9939, 0.9936, 0.9936, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932,
         0.9931],
        [0.9980, 0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9952, 0.9945, 0.9943, 0.9940, 0.9940, 0.9937, 0.9936, 0.9934, 0.9928,
         0.9928],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9977,
         0.9975],
        [0.9991, 0.9990, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9952, 0.9951, 0.9945, 0.9944, 0.9942, 0.9941, 0.9941, 0.9940, 0.9939,
         0.9938],
        [0.9990, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9989],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9882, 0.9868, 0.9777, 0.9708, 0.9684, 0.9672, 0.9670, 0.9642, 0.9631,
         0.9595],
        [0.9964, 0.9963, 0.9960, 0.9959, 0.9959, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9966, 0.9964, 0.9963, 0.9963, 0.9963, 0.9963, 0.9961, 0.9961, 0.9961,
         0.9960],
        [0.9851, 0.9824, 0.9792, 0.9756, 0.9739, 0.9727, 0.9715, 0.9708, 0.9682,
         0.9681],
        [0.9959, 0.9954, 0.9953, 0.9952, 0.9951, 0.9951, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9924, 0.9919, 0.9916, 0.9913, 0.9911, 0.9909, 0.9903, 0.9903, 0.9900,
         0.9900],
        [0.9961, 0.9958, 0.9957, 0.9957, 0.9957, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9953],
        [0.9853, 0.9847, 0.9842, 0.9838, 0.9823, 0.9812, 0.9811, 0.9799, 0.9787,
         0.9780],
        [0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9981, 0.9981, 0.9980, 0.9980,
         0.9980],
        [0.9981, 0.9980, 0.9980, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9973, 0.9971, 0.9969, 0.9969, 0.9969, 0.9968, 0.9966, 0.9966, 0.9966,
         0.9965],
        [0.9894, 0.9867, 0.9855, 0.9853, 0.9846, 0.9839, 0.9837, 0.9835, 0.9834,
         0.9826],
        [0.9859, 0.9793, 0.9792, 0.9783, 0.9778, 0.9773, 0.9771, 0.9766, 0.9765,
         0.9759],
        [0.9868, 0.9854, 0.9738, 0.9706, 0.9612, 0.9591, 0.9559, 0.9554, 0.9554,
         0.9553],
        [0.9730, 0.9686, 0.9684, 0.9666, 0.9659, 0.9632, 0.9626, 0.9622, 0.9620,
         0.9538],
        [0.9908, 0.9897, 0.9892, 0.9889, 0.9885, 0.9882, 0.9880, 0.9877, 0.9874,
         0.9872],
        [0.9942, 0.9941, 0.9940, 0.9940, 0.9938, 0.9934, 0.9932, 0.9932, 0.9932,
         0.9927],
        [0.9916, 0.9915, 0.9912, 0.9909, 0.9907, 0.9904, 0.9903, 0.9901, 0.9900,
         0.9900],
        [0.9911, 0.9911, 0.9899, 0.9896, 0.9887, 0.9885, 0.9875, 0.9875, 0.9871,
         0.9870],
        [0.9938, 0.9928, 0.9928, 0.9920, 0.9915, 0.9915, 0.9905, 0.9898, 0.9896,
         0.9891],
        [0.9902, 0.9876, 0.9869, 0.9866, 0.9858, 0.9854, 0.9853, 0.9849, 0.9843,
         0.9835],
        [0.9952, 0.9952, 0.9951, 0.9951, 0.9951, 0.9951, 0.9948, 0.9947, 0.9946,
         0.9941],
        [0.9957, 0.9952, 0.9950, 0.9950, 0.9947, 0.9935, 0.9934, 0.9931, 0.9931,
         0.9931],
        [0.9944, 0.9912, 0.9901, 0.9899, 0.9893, 0.9891, 0.9889, 0.9889, 0.9886,
         0.9882],
        [0.9915, 0.9912, 0.9908, 0.9903, 0.9867, 0.9865, 0.9864, 0.9858, 0.9855,
         0.9854],
        [0.9918, 0.9914, 0.9907, 0.9907, 0.9889, 0.9888, 0.9885, 0.9872, 0.9861,
         0.9859],
        [0.9968, 0.9939, 0.9927, 0.9926, 0.9921, 0.9908, 0.9884, 0.9882, 0.9881,
         0.9878],
        [0.9899, 0.9886, 0.9883, 0.9881, 0.9881, 0.9873, 0.9872, 0.9872, 0.9866,
         0.9862],
        [0.9914, 0.9908, 0.9868, 0.9851, 0.9840, 0.9836, 0.9835, 0.9832, 0.9825,
         0.9818],
        [0.9923, 0.9922, 0.9920, 0.9917, 0.9913, 0.9897, 0.9863, 0.9860, 0.9853,
         0.9843],
        [0.9926, 0.9922, 0.9921, 0.9920, 0.9920, 0.9915, 0.9914, 0.9908, 0.9901,
         0.9898]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 0, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1516444.8750, 1515298.3750, 1494962.1250, 1493253.5000, 1489048.5000,
         1486456.2500, 1484441.7500, 1483265.7500, 1482483.7500, 1473922.5000],
        [1540256.3750, 1527716.2500, 1526574.3750, 1524850.2500, 1524280.2500,
         1524235.2500, 1522817.1250, 1522340.8750, 1521458.3750, 1520396.7500],
        [1141492.7500, 1035688.8750, 1025933.0625,  999650.2500,  984769.8750,
          983919.3125,  980838.9375,  973452.0000,  972107.6875,  953139.1250],
        [1455781.3750, 1440846.3750, 1435249.6250, 1429836.8750, 1421174.2500,
         1406532.7500, 1405013.7500, 1382987.0000, 1379869.8750, 1373123.7500],
        [1352956.3750, 1331962.8750, 1317986.3750, 1286977.7500, 1285237.3750,
         1281828.3750, 1273328.8750, 1268836.3750, 1268558.1250, 1268028.2500],
        [1277734.7500, 1255291.2500, 1213986.8750, 1155493.6250, 1134001.6250,
         1126470.5000, 1125851.8750, 1098279.1250, 1087878.7500, 1082094.6250],
        [1207295.0000, 1046641.8750, 1041891.3750, 1020336.2500,  991009.5625,
          983205.5000,  969542.1250,  964886.7500,  955117.2500,  946125.8750],
        [1127869.1250, 1101295.5000, 1017778.3125, 1008130.7500,  909729.3125,
          856554.3750,  853758.7500,  852278.1875,  836228.1250,  830358.5625],
        [1543573.8750, 1529548.7500, 1529439.3750, 1523366.2500, 1522184.1250,
         1520792.6250, 1518282.7500, 1517806.3750, 1516705.2500, 1516576.5000],
        [1465272.3750, 1385229.6250, 1363450.6250, 1345893.7500, 1320433.3750,
         1319585.0000, 1290011.6250, 1272135.6250, 1266201.1250, 1260782.6250],
        [1557176.3750, 1555988.7500, 1555933.8750, 1555604.5000, 1551904.5000,
         1549581.1250, 1549304.8750, 1549250.2500, 1548102.6250, 1547767.5000],
        [1461402.5000, 1453736.5000, 1416545.3750, 1406365.0000, 1397347.6250,
         1393036.5000, 1391686.1250, 1389336.2500, 1387767.1250, 1370395.0000],
        [1418854.6250, 1397386.2500, 1359602.1250, 1350012.5000, 1318737.0000,
         1309204.7500, 1306139.3750, 1274135.3750, 1267191.7500, 1258468.8750],
        [1564320.8750, 1559665.8750, 1554587.1250, 1554425.5000, 1553880.1250,
         1547349.8750, 1541690.7500, 1539937.7500, 1538610.6250, 1538293.7500],
        [1577912.1250, 1576707.3750, 1576668.2500, 1576143.6250, 1575853.5000,
         1575649.0000, 1575640.0000, 1575366.6250, 1574503.0000, 1574120.1250],
        [1576182.6250, 1573840.8750, 1572963.0000, 1571768.0000, 1571469.7500,
         1571465.1250, 1570551.2500, 1570229.3750, 1568343.6250, 1568225.5000],
        [1522549.8750, 1518269.6250, 1517828.1250, 1513898.8750, 1512187.5000,
         1504247.8750, 1503393.1250, 1501928.6250, 1499916.0000, 1499128.0000],
        [1497627.6250, 1486867.3750, 1481959.2500, 1480385.7500, 1479417.6250,
         1478757.3750, 1475908.6250, 1475029.2500, 1474686.1250, 1474230.3750],
        [1480846.1250, 1466583.7500, 1460392.5000, 1460332.5000, 1458082.3750,
         1455509.3750, 1454166.2500, 1454114.8750, 1453129.2500, 1451135.1250],
        [1555686.1250, 1554287.6250, 1551880.8750, 1551484.2500, 1550151.7500,
         1549288.6250, 1548774.5000, 1547730.6250, 1547118.1250, 1545748.1250],
        [1554145.3750, 1551700.2500, 1551681.1250, 1550565.6250, 1549145.2500,
         1549037.5000, 1545997.2500, 1543397.1250, 1542655.5000, 1542487.7500],
        [1494423.2500, 1478540.2500, 1474361.1250, 1469896.6250, 1468582.3750,
         1463510.0000, 1461298.0000, 1457289.8750, 1444813.3750, 1443452.7500],
        [1575112.7500, 1572993.1250, 1562765.6250, 1562595.7500, 1561719.8750,
         1559412.8750, 1555668.2500, 1555622.2500, 1547777.8750, 1545219.0000],
        [1579729.6250, 1576662.1250, 1574181.6250, 1574042.1250, 1573270.6250,
         1573219.6250, 1572727.5000, 1572711.0000, 1570891.3750, 1570615.6250],
        [1493286.3750, 1492325.3750, 1480340.6250, 1477249.2500, 1472374.3750,
         1471254.2500, 1469954.2500, 1469301.0000, 1467283.2500, 1464617.1250],
        [1576848.6250, 1573273.7500, 1571066.6250, 1569840.0000, 1568505.1250,
         1568327.1250, 1566715.7500, 1565813.3750, 1564392.5000, 1563952.5000],
        [1566886.0000, 1565897.1250, 1563913.6250, 1562501.8750, 1559817.6250,
         1557920.6250, 1554465.6250, 1554145.3750, 1553557.1250, 1552502.5000],
        [1576505.8750, 1575069.1250, 1575015.1250, 1573889.0000, 1573699.7500,
         1573420.7500, 1572553.6250, 1571640.6250, 1571221.0000, 1570316.1250],
        [1579340.8750, 1579068.2500, 1578729.5000, 1575933.1250, 1575851.8750,
         1575740.7500, 1575727.1250, 1575629.5000, 1575222.5000, 1574779.3750],
        [1581250.3750, 1580436.2500, 1576262.2500, 1575605.5000, 1575599.3750,
         1575584.5000, 1575078.2500, 1574393.3750, 1573686.3750, 1573371.2500],
        [1581161.5000, 1580840.2500, 1580193.6250, 1578872.6250, 1578526.2500,
         1577810.0000, 1577722.6250, 1577430.7500, 1576605.1250, 1576465.2500],
        [1580208.7500, 1578485.7500, 1576832.1250, 1576236.7500, 1575925.6250,
         1575919.6250, 1575760.2500, 1575515.3750, 1574989.6250, 1574834.8750],
        [1351737.5000, 1324728.2500, 1163531.6250, 1054203.1250, 1019076.8750,
         1001693.4375,  999474.8125,  959309.1875,  944358.1250,  896732.1250],
        [1519805.2500, 1518288.5000, 1510707.1250, 1509521.8750, 1508426.7500,
         1506309.3750, 1504186.2500, 1504103.0000, 1503826.2500, 1501302.7500],
        [1556221.7500, 1553428.2500, 1553000.0000, 1549916.6250, 1548567.7500,
         1548022.8750, 1547817.6250, 1547349.8750, 1547292.2500, 1546281.7500],
        [1524559.3750, 1520770.7500, 1518820.0000, 1518276.8750, 1517524.1250,
         1517080.0000, 1514060.5000, 1513781.8750, 1512643.2500, 1511998.6250],
        [1294324.7500, 1244008.8750, 1188283.0000, 1129279.0000, 1101504.5000,
         1084240.1250, 1065328.5000, 1055070.1250, 1016702.5000, 1014978.0625],
        [1509612.7500, 1499189.5000, 1495459.7500, 1494099.7500, 1491605.3750,
         1491170.1250, 1490574.3750, 1489057.0000, 1488357.0000, 1487860.3750],
        [1435862.8750, 1424679.5000, 1419724.8750, 1413885.1250, 1408868.6250,
         1405015.0000, 1393994.7500, 1392624.7500, 1388121.7500, 1387707.5000],
        [1513611.6250, 1507273.5000, 1505940.1250, 1505940.1250, 1504362.6250,
         1499968.8750, 1499735.7500, 1499416.8750, 1497344.8750, 1495533.8750],
        [1297919.2500, 1285473.8750, 1277728.6250, 1268965.8750, 1241944.0000,
         1223871.1250, 1222198.6250, 1200175.3750, 1180276.6250, 1168953.6250],
        [1564537.1250, 1562874.5000, 1559097.7500, 1558283.1250, 1558238.6250,
         1557720.0000, 1557325.0000, 1556043.6250, 1556014.0000, 1555758.7500],
        [1557154.1250, 1556227.6250, 1554471.5000, 1550487.3750, 1549930.0000,
         1549498.3750, 1548929.6250, 1548130.6250, 1546803.8750, 1546168.3750],
        [1538987.7500, 1536251.5000, 1531842.1250, 1531571.7500, 1530165.8750,
         1528940.6250, 1524646.6250, 1524004.1250, 1523716.3750, 1522985.6250],
        [1375812.2500, 1322929.1250, 1300596.8750, 1296301.2500, 1283677.8750,
         1271725.6250, 1267099.8750, 1264751.7500, 1261989.1250, 1247334.1250],
        [1308630.5000, 1190808.2500, 1189320.2500, 1173001.8750, 1165616.2500,
         1156606.0000, 1153414.8750, 1145560.5000, 1144135.6250, 1134734.1250],
        [1326007.3750, 1298623.7500, 1099903.7500, 1050831.5000,  920004.5000,
          892761.6875,  851835.3125,  846041.8125,  846040.1250,  844583.4375],
        [1087398.5000, 1021241.5625, 1019428.7500,  992705.5625,  982541.8750,
          946362.3125,  937425.5625,  933015.1875,  929389.1875,  826704.9375],
        [1403831.1250, 1381813.6250, 1371385.8750, 1364791.8750, 1358790.6250,
         1352254.5000, 1347560.8750, 1342097.2500, 1336158.8750, 1332429.1250],
        [1472239.6250, 1471502.6250, 1469600.8750, 1468296.7500, 1463854.6250,
         1455961.8750, 1453153.0000, 1451958.8750, 1451654.2500, 1442266.5000],
        [1420020.0000, 1417210.1250, 1410890.8750, 1405326.0000, 1401526.2500,
         1395561.6250, 1392437.5000, 1389427.6250, 1387495.7500, 1387261.6250],
        [1410113.3750, 1409786.6250, 1385091.0000, 1379235.7500, 1361982.1250,
         1357714.2500, 1339132.3750, 1338450.6250, 1331701.2500, 1328376.7500],
        [1464610.1250, 1443948.3750, 1443193.8750, 1426912.1250, 1417992.8750,
         1417936.1250, 1397740.7500, 1382820.8750, 1378623.0000, 1369605.7500],
        [1390437.7500, 1341254.1250, 1326303.2500, 1322027.3750, 1306812.1250,
         1298331.5000, 1297742.2500, 1290494.0000, 1277940.7500, 1263464.2500],
        [1495200.1250, 1493296.2500, 1492558.7500, 1492558.7500, 1491942.5000,
         1491303.8750, 1485726.3750, 1483704.3750, 1482274.5000, 1470903.5000],
        [1505581.1250, 1493720.7500, 1490483.5000, 1488974.6250, 1484079.5000,
         1457510.8750, 1455895.2500, 1450321.6250, 1450144.6250, 1450144.6250],
        [1476739.3750, 1412223.5000, 1389797.3750, 1386290.8750, 1373261.2500,
         1369978.1250, 1365857.0000, 1364712.5000, 1359593.0000, 1352920.2500],
        [1418195.7500, 1410621.7500, 1403710.6250, 1394204.7500, 1322741.1250,
         1320366.6250, 1318308.2500, 1305971.2500, 1300015.3750, 1299533.1250],
        [1424333.0000, 1415816.0000, 1401876.5000, 1401601.1250, 1364995.0000,
         1363290.6250, 1357900.7500, 1332963.0000, 1311187.7500, 1308564.3750],
        [1528115.5000, 1467045.3750, 1441634.0000, 1440581.2500, 1430397.5000,
         1403904.7500, 1356498.8750, 1351701.5000, 1349653.3750, 1343923.6250],
        [1384433.2500, 1359852.2500, 1353149.8750, 1350975.8750, 1350355.0000,
         1335542.2500, 1333798.3750, 1333781.8750, 1322270.6250, 1313964.1250],
        [1416172.5000, 1403294.3750, 1326037.6250, 1293273.5000, 1273285.0000,
         1265324.7500, 1264502.1250, 1258296.1250, 1246259.1250, 1233924.3750],
        [1433239.0000, 1431969.7500, 1426728.5000, 1422020.2500, 1413031.8750,
         1380780.8750, 1316781.6250, 1310931.2500, 1297077.8750, 1277956.5000],
        [1439095.5000, 1431606.6250, 1428993.0000, 1427146.3750, 1427004.7500,
         1417852.2500, 1414979.1250, 1403128.3750, 1388627.6250, 1383806.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1516444.8750,       0.0000],
         [1515298.3750,       0.0000],
         [1494962.1250,       0.0000],
         ...,
         [      0.0000, 1483265.7500],
         [1482483.7500,       0.0000],
         [1473922.5000,       0.0000]],

        [[1540256.3750,       0.0000],
         [1527716.2500,       0.0000],
         [1526574.3750,       0.0000],
         ...,
         [1522340.8750,       0.0000],
         [1521458.3750,       0.0000],
         [1520396.7500,       0.0000]],

        [[1141492.7500,       0.0000],
         [      0.0000, 1035688.8750],
         [1025933.0625,       0.0000],
         ...,
         [ 973452.0000,       0.0000],
         [ 972107.6875,       0.0000],
         [ 953139.1250,       0.0000]],

        ...,

        [[1416172.5000,       0.0000],
         [1403294.3750,       0.0000],
         [1326037.6250,       0.0000],
         ...,
         [1258296.1250,       0.0000],
         [1246259.1250,       0.0000],
         [1233924.3750,       0.0000]],

        [[1433239.0000,       0.0000],
         [1431969.7500,       0.0000],
         [1426728.5000,       0.0000],
         ...,
         [      0.0000, 1310931.2500],
         [1297077.8750,       0.0000],
         [1277956.5000,       0.0000]],

        [[      0.0000, 1439095.5000],
         [      0.0000, 1431606.6250],
         [      0.0000, 1428993.0000],
         ...,
         [      0.0000, 1403128.3750],
         [      0.0000, 1388627.6250],
         [1383806.2500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13436312.0000,  1483265.7500],
        [15254925.0000,        0.0000],
        [ 5066124.5000,  4984867.0000],
        [12725402.0000,  1405013.7500],
        [ 9125507.0000,  3810193.5000],
        [ 9303311.0000,  2253772.7500],
        [ 5010113.0000,  5115939.0000],
        [ 8540222.0000,   853758.7500],
        [13719992.0000,  1518282.7500],
        [11903766.0000,  1385229.6250],
        [15520615.0000,        0.0000],
        [14067617.0000,        0.0000],
        [13259732.0000,        0.0000],
        [15492762.0000,        0.0000],
        [15758563.0000,        0.0000],
        [15715040.0000,        0.0000],
        [13570798.0000,  1522549.8750],
        [13307242.0000,  1497627.6250],
        [14594292.0000,        0.0000],
        [15502151.0000,        0.0000],
        [15480813.0000,        0.0000],
        [11742818.0000,  2913349.5000],
        [15598888.0000,        0.0000],
        [15738051.0000,        0.0000],
        [10301120.0000,  4456866.0000],
        [15688736.0000,        0.0000],
        [15591606.0000,        0.0000],
        [15733330.0000,        0.0000],
        [15766022.0000,        0.0000],
        [15761267.0000,        0.0000],
        [15785628.0000,        0.0000],
        [15764708.0000,        0.0000],
        [ 2897900.2500,  7816945.0000],
        [ 9049266.0000,  6037211.0000],
        [12403257.0000,  3094642.0000],
        [12136635.0000,  3032880.5000],
        [ 3173277.0000,  8020442.5000],
        [11946191.0000,  2990795.0000],
        [12676490.0000,  1393994.7500],
        [15029129.0000,        0.0000],
        [ 9840089.0000,  2527418.0000],
        [15585893.0000,        0.0000],
        [15507801.0000,        0.0000],
        [13761541.0000,  1531571.7500],
        [ 2509323.2500, 10382895.0000],
        [ 1173001.8750, 10588826.0000],
        [ 5201267.0000,  4775366.0000],
        [ 2706082.5000,  6970130.5000],
        [ 4066335.5000,  9524778.0000],
        [10196835.0000,  4403654.0000],
        [12601832.0000,  1405326.0000],
        [ 1328376.7500, 12313208.0000],
        [ 1369605.7500, 12773778.0000],
        [ 2648330.5000, 10466477.0000],
        [11892965.0000,  2986504.0000],
        [10243475.0000,  4483381.0000],
        [ 2729571.0000, 11121802.0000],
        [ 5247036.0000,  8246632.0000],
        [ 1308564.3750, 12373963.0000],
        [ 2700422.5000, 11413033.0000],
        [10718148.0000,  2719975.5000],
        [11715044.0000,  1265324.7500],
        [11082804.0000,  2627713.0000],
        [ 1383806.2500, 12778434.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 461/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:53, 57.63s/it]  7%|▋         | 2/29 [00:58<11:00, 24.44s/it] 10%|█         | 3/29 [01:01<06:13, 14.35s/it] 14%|█▍        | 4/29 [01:02<03:46,  9.05s/it] 17%|█▋        | 5/29 [01:03<02:26,  6.12s/it] 21%|██        | 6/29 [01:03<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:05<00:52,  2.49s/it] 31%|███       | 9/29 [01:06<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7697057723999023
Epoch 462/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:52, 59.73s/it]  7%|▋         | 2/29 [01:00<11:18, 25.14s/it] 10%|█         | 3/29 [01:01<06:06, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7876017093658447
Epoch 463/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:35, 61.26s/it]  7%|▋         | 2/29 [01:02<11:35, 25.77s/it] 10%|█         | 3/29 [01:03<06:14, 14.42s/it] 14%|█▍        | 4/29 [01:04<03:47,  9.09s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.14s/it] 21%|██        | 6/29 [01:05<01:40,  4.37s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.01s/it]
Epoch loss is 2.7939252853393555
Epoch 464/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:26, 58.82s/it]  7%|▋         | 2/29 [00:59<11:08, 24.76s/it] 10%|█         | 3/29 [01:00<06:00, 13.88s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.76s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.93s/it] 21%|██        | 6/29 [01:03<01:37,  4.23s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.15s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.44s/it] 31%|███       | 9/29 [01:06<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.785684585571289
Epoch 465/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:52, 59.72s/it]  7%|▋         | 2/29 [01:00<11:18, 25.13s/it] 10%|█         | 3/29 [01:01<06:05, 14.08s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.88s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.01s/it] 21%|██        | 6/29 [01:04<01:38,  4.28s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.18s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.46s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.7784688472747803
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0147, 0.0025,  ..., 0.0042, 0.0002, 0.0191],
        [0.0035, 0.0099, 0.0022,  ..., 0.0023, 0.0001, 0.0185],
        [0.0338, 0.0062, 0.0035,  ..., 0.0053, 0.0156, 0.0245],
        ...,
        [0.0077, 0.0080, 0.0183,  ..., 0.0040, 0.0018, 0.0206],
        [0.0043, 0.0086, 0.0118,  ..., 0.0049, 0.0049, 0.0202],
        [0.0098, 0.0044, 0.0043,  ..., 0.0030, 0.0022, 0.0228]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9959, 0.9959, 0.9949, 0.9948, 0.9946, 0.9946, 0.9943, 0.9943, 0.9942,
         0.9938],
        [0.9972, 0.9967, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9964,
         0.9963],
        [0.9760, 0.9685, 0.9684, 0.9675, 0.9668, 0.9663, 0.9662, 0.9651, 0.9643,
         0.9633],
        [0.9929, 0.9923, 0.9922, 0.9917, 0.9912, 0.9902, 0.9902, 0.9895, 0.9891,
         0.9888],
        [0.9883, 0.9870, 0.9865, 0.9846, 0.9845, 0.9842, 0.9838, 0.9836, 0.9835,
         0.9834],
        [0.9840, 0.9835, 0.9810, 0.9765, 0.9757, 0.9753, 0.9750, 0.9741, 0.9726,
         0.9725],
        [0.9805, 0.9697, 0.9693, 0.9684, 0.9673, 0.9669, 0.9652, 0.9647, 0.9633,
         0.9627],
        [0.9763, 0.9732, 0.9693, 0.9664, 0.9606, 0.9567, 0.9565, 0.9561, 0.9552,
         0.9540],
        [0.9974, 0.9967, 0.9967, 0.9965, 0.9963, 0.9962, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9937, 0.9897, 0.9889, 0.9879, 0.9865, 0.9860, 0.9846, 0.9840, 0.9830,
         0.9829],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9934, 0.9933, 0.9911, 0.9906, 0.9901, 0.9900, 0.9898, 0.9897, 0.9896,
         0.9895],
        [0.9912, 0.9901, 0.9883, 0.9879, 0.9863, 0.9861, 0.9857, 0.9841, 0.9840,
         0.9830],
        [0.9983, 0.9981, 0.9979, 0.9979, 0.9978, 0.9976, 0.9973, 0.9972, 0.9971,
         0.9971],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9964, 0.9962, 0.9962, 0.9960, 0.9959, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9952],
        [0.9951, 0.9945, 0.9944, 0.9943, 0.9942, 0.9942, 0.9941, 0.9940, 0.9940,
         0.9939],
        [0.9943, 0.9936, 0.9935, 0.9933, 0.9933, 0.9932, 0.9932, 0.9932, 0.9931,
         0.9929],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9950, 0.9943, 0.9939, 0.9939, 0.9938, 0.9935, 0.9933, 0.9929, 0.9925,
         0.9925],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9977,
         0.9976],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9950, 0.9949, 0.9944, 0.9943, 0.9940, 0.9938, 0.9938, 0.9938, 0.9937,
         0.9937],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9984, 0.9984, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9882, 0.9870, 0.9778, 0.9708, 0.9698, 0.9660, 0.9660, 0.9643, 0.9638,
         0.9592],
        [0.9962, 0.9961, 0.9958, 0.9958, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9952],
        [0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9964, 0.9963, 0.9962, 0.9961, 0.9961, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9958],
        [0.9852, 0.9822, 0.9791, 0.9755, 0.9743, 0.9723, 0.9720, 0.9704, 0.9681,
         0.9677],
        [0.9957, 0.9952, 0.9951, 0.9948, 0.9948, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9945],
        [0.9926, 0.9919, 0.9916, 0.9911, 0.9911, 0.9909, 0.9902, 0.9901, 0.9900,
         0.9899],
        [0.9959, 0.9956, 0.9956, 0.9956, 0.9955, 0.9954, 0.9952, 0.9951, 0.9951,
         0.9950],
        [0.9858, 0.9845, 0.9842, 0.9835, 0.9824, 0.9812, 0.9810, 0.9802, 0.9785,
         0.9781],
        [0.9984, 0.9982, 0.9981, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9980, 0.9980, 0.9979, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9972, 0.9970, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964,
         0.9964],
        [0.9893, 0.9868, 0.9857, 0.9850, 0.9845, 0.9839, 0.9836, 0.9832, 0.9832,
         0.9827],
        [0.9862, 0.9796, 0.9793, 0.9780, 0.9776, 0.9769, 0.9768, 0.9766, 0.9763,
         0.9762],
        [0.9867, 0.9860, 0.9736, 0.9699, 0.9599, 0.9581, 0.9551, 0.9547, 0.9547,
         0.9542],
        [0.9724, 0.9692, 0.9673, 0.9665, 0.9660, 0.9639, 0.9626, 0.9624, 0.9619,
         0.9543],
        [0.9904, 0.9892, 0.9887, 0.9885, 0.9881, 0.9878, 0.9875, 0.9874, 0.9868,
         0.9867],
        [0.9939, 0.9939, 0.9938, 0.9937, 0.9934, 0.9931, 0.9928, 0.9928, 0.9927,
         0.9924],
        [0.9915, 0.9913, 0.9908, 0.9907, 0.9904, 0.9902, 0.9897, 0.9896, 0.9895,
         0.9892],
        [0.9911, 0.9908, 0.9897, 0.9895, 0.9883, 0.9881, 0.9877, 0.9875, 0.9870,
         0.9869],
        [0.9936, 0.9927, 0.9926, 0.9919, 0.9914, 0.9913, 0.9905, 0.9896, 0.9893,
         0.9889],
        [0.9900, 0.9876, 0.9869, 0.9864, 0.9855, 0.9850, 0.9850, 0.9847, 0.9842,
         0.9833],
        [0.9952, 0.9950, 0.9950, 0.9950, 0.9950, 0.9950, 0.9945, 0.9944, 0.9944,
         0.9939],
        [0.9956, 0.9950, 0.9948, 0.9946, 0.9945, 0.9931, 0.9931, 0.9929, 0.9929,
         0.9928],
        [0.9944, 0.9912, 0.9900, 0.9895, 0.9893, 0.9892, 0.9890, 0.9886, 0.9885,
         0.9882],
        [0.9913, 0.9911, 0.9906, 0.9902, 0.9863, 0.9862, 0.9861, 0.9856, 0.9851,
         0.9850],
        [0.9917, 0.9912, 0.9908, 0.9906, 0.9888, 0.9886, 0.9884, 0.9870, 0.9859,
         0.9856],
        [0.9967, 0.9938, 0.9925, 0.9924, 0.9920, 0.9908, 0.9883, 0.9881, 0.9879,
         0.9877],
        [0.9902, 0.9887, 0.9882, 0.9881, 0.9877, 0.9875, 0.9872, 0.9868, 0.9866,
         0.9863],
        [0.9915, 0.9910, 0.9868, 0.9854, 0.9842, 0.9835, 0.9834, 0.9834, 0.9825,
         0.9818],
        [0.9920, 0.9920, 0.9918, 0.9916, 0.9911, 0.9895, 0.9862, 0.9856, 0.9850,
         0.9849],
        [0.9925, 0.9920, 0.9920, 0.9920, 0.9919, 0.9917, 0.9912, 0.9907, 0.9901,
         0.9895]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 0, 0, 1, 1, 1, 0, 0],
        [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 0, 0, 1, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1509398.1250, 1509139.0000, 1486847.6250, 1485190.8750, 1481933.8750,
         1481613.1250, 1474850.6250, 1474837.8750, 1473565.6250, 1465241.6250],
        [1536610.5000, 1525820.5000, 1523478.0000, 1522072.2500, 1521877.8750,
         1521629.6250, 1521049.2500, 1519802.3750, 1519345.7500, 1518481.1250],
        [1135404.1250, 1020605.8750, 1018561.9375, 1005712.7500,  996109.0625,
          989390.0625,  988103.8125,  972701.2500,  961078.2500,  946853.3125],
        [1445669.3750, 1433702.3750, 1431931.5000, 1421558.0000, 1410551.8750,
         1391207.0000, 1390838.3750, 1377205.1250, 1369573.1250, 1363660.0000],
        [1353701.1250, 1329376.6250, 1319729.6250, 1285184.6250, 1282733.1250,
         1276767.5000, 1270119.7500, 1265287.3750, 1263951.1250, 1261693.1250],
        [1272709.6250, 1263593.1250, 1219082.2500, 1144194.6250, 1130271.2500,
         1123897.3750, 1118936.1250, 1105311.7500, 1081632.5000, 1079991.3750],
        [1211596.1250, 1038608.6875, 1031617.6250, 1018612.5000, 1003745.5625,
          997548.3750,  973214.3125,  966362.9375,  947454.0625,  939361.2500],
        [1140638.5000, 1091497.2500, 1032802.8750,  990410.5000,  912076.6250,
          861789.3750,  859504.3750,  854914.8750,  843681.8125,  829336.8750],
        [1541292.3750, 1526656.0000, 1526171.1250, 1521351.0000, 1518423.1250,
         1514944.5000, 1513958.0000, 1513657.7500, 1513550.8750, 1513395.1250],
        [1462314.2500, 1381326.1250, 1365859.6250, 1345469.0000, 1319778.7500,
         1309691.7500, 1285096.3750, 1272766.6250, 1254684.3750, 1252875.3750],
        [1554775.3750, 1553958.6250, 1552909.7500, 1552597.2500, 1548619.3750,
         1546374.7500, 1546068.0000, 1545970.7500, 1544875.7500, 1544765.1250],
        [1456345.2500, 1454038.7500, 1409258.3750, 1399330.5000, 1389191.8750,
         1387321.2500, 1384024.0000, 1381891.5000, 1379167.3750, 1378266.7500],
        [1410609.6250, 1388664.6250, 1354146.5000, 1346671.7500, 1315074.8750,
         1311288.8750, 1304372.8750, 1275908.2500, 1272538.5000, 1255565.3750],
        [1562585.3750, 1558348.6250, 1552957.2500, 1552545.5000, 1551802.3750,
         1545848.3750, 1538930.5000, 1537457.7500, 1535415.2500, 1534937.8750],
        [1577280.3750, 1575871.3750, 1575833.8750, 1575539.3750, 1575419.1250,
         1575356.1250, 1574962.5000, 1574653.1250, 1574174.2500, 1573666.7500],
        [1575443.2500, 1572964.6250, 1572393.2500, 1571771.0000, 1570442.0000,
         1570169.3750, 1568696.6250, 1567612.3750, 1567286.5000, 1567099.7500],
        [1519948.6250, 1516405.8750, 1515286.8750, 1511427.7500, 1509350.6250,
         1501215.3750, 1500066.1250, 1499561.2500, 1496013.1250, 1494709.7500],
        [1492113.2500, 1479489.5000, 1476329.6250, 1474442.7500, 1473943.7500,
         1473790.5000, 1469926.1250, 1469683.6250, 1468333.1250, 1467465.1250],
        [1475836.8750, 1460034.5000, 1457887.6250, 1454665.6250, 1454181.5000,
         1452543.2500, 1452384.0000, 1451259.7500, 1450320.3750, 1446367.2500],
        [1553201.5000, 1550431.1250, 1549219.1250, 1548752.3750, 1547742.5000,
         1547187.5000, 1546267.1250, 1545077.5000, 1544796.1250, 1543251.3750],
        [1550874.7500, 1548622.3750, 1548529.2500, 1546317.1250, 1546149.1250,
         1545151.2500, 1541427.6250, 1539357.7500, 1538833.7500, 1537278.7500],
        [1489843.8750, 1475434.5000, 1467270.6250, 1467115.3750, 1465589.6250,
         1458591.3750, 1453699.0000, 1446952.1250, 1438611.1250, 1438445.1250],
        [1575378.6250, 1572336.1250, 1562871.5000, 1562810.3750, 1562583.8750,
         1559155.7500, 1555649.0000, 1555482.7500, 1548366.8750, 1545795.3750],
        [1578366.7500, 1575731.7500, 1572868.6250, 1572513.1250, 1572292.6250,
         1571811.5000, 1571646.6250, 1571253.8750, 1570513.8750, 1568811.8750],
        [1489007.2500, 1488200.8750, 1477204.1250, 1474676.2500, 1468438.1250,
         1464083.6250, 1464064.1250, 1463652.3750, 1463415.0000, 1463001.8750],
        [1576224.7500, 1573156.6250, 1571364.7500, 1569515.1250, 1569147.0000,
         1568026.5000, 1565885.1250, 1565089.3750, 1564462.6250, 1564376.1250],
        [1566399.0000, 1565259.6250, 1564237.3750, 1563139.7500, 1558357.5000,
         1558350.0000, 1553385.2500, 1553041.6250, 1552438.8750, 1552350.1250],
        [1576178.1250, 1575401.1250, 1574357.3750, 1573461.1250, 1573077.1250,
         1571765.0000, 1571573.1250, 1571390.2500, 1570780.5000, 1570346.1250],
        [1578323.0000, 1578077.7500, 1577516.5000, 1575488.2500, 1575052.6250,
         1574585.6250, 1574482.0000, 1574199.7500, 1574105.1250, 1573563.2500],
        [1580362.3750, 1579547.3750, 1575249.3750, 1574597.5000, 1574576.6250,
         1574566.0000, 1574527.0000, 1574013.6250, 1572888.0000, 1572459.2500],
        [1580068.6250, 1580037.0000, 1579622.6250, 1578073.2500, 1577816.0000,
         1576949.5000, 1576701.2500, 1576472.7500, 1576190.1250, 1576167.6250],
        [1579228.0000, 1577870.0000, 1575970.6250, 1575273.5000, 1575073.6250,
         1574851.3750, 1574788.2500, 1574509.0000, 1574249.2500, 1573817.0000],
        [1351602.1250, 1328511.0000, 1165367.3750, 1054546.0000, 1038827.6250,
          984671.2500,  984542.6250,  961341.3750,  954445.3125,  894015.0000],
        [1515451.7500, 1513080.5000, 1506368.2500, 1506365.3750, 1503299.8750,
         1501375.7500, 1500555.5000, 1498850.7500, 1495740.6250, 1494654.1250],
        [1554652.3750, 1552256.8750, 1550715.0000, 1547668.5000, 1546333.3750,
         1545886.6250, 1545835.0000, 1545596.3750, 1545425.3750, 1544099.3750],
        [1520002.2500, 1517247.7500, 1515258.0000, 1513240.6250, 1512965.0000,
         1510347.1250, 1509372.2500, 1508178.0000, 1507891.7500, 1507451.7500],
        [1295510.2500, 1240840.6250, 1187578.2500, 1127966.8750, 1108028.3750,
         1076742.7500, 1072624.7500, 1048862.1250, 1014055.0625, 1009195.5625],
        [1504229.2500, 1493980.0000, 1492012.2500, 1486641.8750, 1485638.5000,
         1484553.6250, 1483021.2500, 1482391.8750, 1481621.6250, 1479004.2500],
        [1439110.5000, 1425182.3750, 1418950.6250, 1410234.3750, 1409985.6250,
         1404727.0000, 1391642.3750, 1389317.6250, 1387824.0000, 1385889.0000],
        [1510273.6250, 1502663.5000, 1501938.5000, 1501938.5000, 1500910.5000,
         1497493.3750, 1493963.0000, 1492887.6250, 1491660.8750, 1490976.8750],
        [1306511.8750, 1283187.1250, 1276145.5000, 1264920.6250, 1243993.5000,
         1223515.2500, 1220324.6250, 1206131.6250, 1177029.2500, 1170886.1250],
        [1563417.1250, 1560454.3750, 1557786.8750, 1556717.5000, 1556336.1250,
         1556098.6250, 1555714.2500, 1554360.3750, 1554052.0000, 1553961.6250],
        [1554731.0000, 1554471.5000, 1551957.7500, 1547465.0000, 1546572.3750,
         1546330.5000, 1545659.6250, 1545052.5000, 1543637.1250, 1543323.6250],
        [1537160.1250, 1533457.1250, 1530508.8750, 1529206.0000, 1526969.0000,
         1526088.3750, 1523835.6250, 1521324.8750, 1520823.0000, 1519547.2500],
        [1373088.5000, 1325526.8750, 1303994.8750, 1291986.5000, 1281764.6250,
         1272136.8750, 1266261.5000, 1258971.8750, 1258609.2500, 1249490.2500],
        [1314598.3750, 1195215.8750, 1190796.8750, 1168141.2500, 1161487.2500,
         1151231.3750, 1148647.6250, 1145611.8750, 1139908.8750, 1138688.6250],
        [1322507.7500, 1310775.1250, 1097775.3750, 1040365.3125,  901933.8125,
          879490.0625,  842190.6250,  837810.2500,  837503.5625,  831968.5000],
        [1078754.1250, 1030713.8750, 1003269.0000,  991877.5000,  984415.8750,
          954867.7500,  937807.3750,  935769.5625,  929019.6250,  832622.5000],
        [1394609.0000, 1370941.2500, 1361431.5000, 1358653.2500, 1350684.7500,
         1343784.0000, 1338473.6250, 1337505.1250, 1324944.1250, 1324336.6250],
        [1467188.1250, 1466329.1250, 1465423.2500, 1462869.3750, 1456085.3750,
         1450450.2500, 1444152.1250, 1443900.1250, 1442799.0000, 1435075.8750],
        [1416406.2500, 1412990.1250, 1403832.3750, 1402054.3750, 1395416.6250,
         1391695.3750, 1381429.0000, 1379505.3750, 1377257.6250, 1371901.3750],
        [1408457.5000, 1404168.5000, 1381725.3750, 1377620.2500, 1353251.8750,
         1349971.3750, 1341571.3750, 1337760.2500, 1329741.8750, 1327790.3750],
        [1461501.5000, 1442739.8750, 1440710.3750, 1425441.8750, 1416248.1250,
         1414262.7500, 1397734.1250, 1380229.2500, 1373239.0000, 1366043.3750],
        [1387027.3750, 1339868.2500, 1328082.8750, 1317133.2500, 1300950.3750,
         1291576.2500, 1291470.2500, 1286489.3750, 1276670.1250, 1261130.0000],
        [1493901.7500, 1490089.7500, 1490089.7500, 1489961.8750, 1489883.7500,
         1489146.5000, 1479144.0000, 1478328.8750, 1476645.0000, 1467388.1250],
        [1502917.1250, 1489166.3750, 1484995.3750, 1482435.7500, 1478760.2500,
         1450069.8750, 1449915.1250, 1446205.7500, 1445517.7500, 1443743.1250],
        [1476654.8750, 1411134.3750, 1387494.5000, 1377969.7500, 1374330.3750,
         1372237.6250, 1367872.2500, 1359007.0000, 1357512.2500, 1351611.2500],
        [1413390.3750, 1410141.6250, 1398372.6250, 1391382.2500, 1314946.8750,
         1314905.5000, 1313022.1250, 1302523.3750, 1293811.3750, 1290769.7500],
        [1421720.6250, 1411804.7500, 1403329.1250, 1399799.0000, 1363598.8750,
         1360271.2500, 1355470.8750, 1329787.3750, 1309082.3750, 1302775.5000],
        [1527561.8750, 1463935.7500, 1437213.7500, 1436210.8750, 1427334.1250,
         1402256.1250, 1353606.7500, 1350214.6250, 1347102.1250, 1342235.5000],
        [1390794.5000, 1360938.1250, 1352864.7500, 1349300.7500, 1342011.6250,
         1338806.7500, 1332082.2500, 1324499.5000, 1320880.5000, 1315676.8750],
        [1416981.7500, 1406826.5000, 1325841.6250, 1298383.5000, 1277482.5000,
         1263783.6250, 1262240.6250, 1261656.8750, 1245699.5000, 1234004.3750],
        [1428088.3750, 1427850.1250, 1422941.3750, 1420063.3750, 1408894.1250,
         1377273.3750, 1314143.2500, 1303345.8750, 1292388.2500, 1289036.5000],
        [1437090.5000, 1427925.0000, 1427550.5000, 1426792.5000, 1424989.3750,
         1421602.6250, 1411748.2500, 1400522.7500, 1389500.5000, 1376534.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1509398.1250,       0.0000],
         [1509139.0000,       0.0000],
         [1486847.6250,       0.0000],
         ...,
         [1474837.8750,       0.0000],
         [1473565.6250,       0.0000],
         [1465241.6250,       0.0000]],

        [[1536610.5000,       0.0000],
         [1525820.5000,       0.0000],
         [1523478.0000,       0.0000],
         ...,
         [1519802.3750,       0.0000],
         [1519345.7500,       0.0000],
         [1518481.1250,       0.0000]],

        [[1135404.1250,       0.0000],
         [      0.0000, 1020605.8750],
         [1018561.9375,       0.0000],
         ...,
         [ 972701.2500,       0.0000],
         [ 961078.2500,       0.0000],
         [      0.0000,  946853.3125]],

        ...,

        [[1416981.7500,       0.0000],
         [1406826.5000,       0.0000],
         [1325841.6250,       0.0000],
         ...,
         [1261656.8750,       0.0000],
         [1245699.5000,       0.0000],
         [1234004.3750,       0.0000]],

        [[1428088.3750,       0.0000],
         [1427850.1250,       0.0000],
         [1422941.3750,       0.0000],
         ...,
         [      0.0000, 1303345.8750],
         [1292388.2500,       0.0000],
         [      0.0000, 1289036.5000]],

        [[      0.0000, 1437090.5000],
         [      0.0000, 1427925.0000],
         [      0.0000, 1427550.5000],
         ...,
         [      0.0000, 1400522.7500],
         [      0.0000, 1389500.5000],
         [1376534.1250,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13367768.0000,  1474850.6250],
        [15230166.0000,        0.0000],
        [ 4087745.5000,  5946775.0000],
        [12645059.0000,  1390838.3750],
        [10374472.0000,  2534071.0000],
        [ 9290114.0000,  2249506.5000],
        [ 4975654.0000,  5152467.0000],
        [ 8557149.0000,   859504.3750],
        [13689742.0000,  1513657.7500],
        [11868536.0000,  1381326.1250],
        [15490915.0000,        0.0000],
        [14018836.0000,        0.0000],
        [13234842.0000,        0.0000],
        [15470829.0000,        0.0000],
        [15752756.0000,        0.0000],
        [15703880.0000,        0.0000],
        [13544037.0000,  1519948.6250],
        [13253404.0000,  1492113.2500],
        [14555482.0000,        0.0000],
        [15475926.0000,        0.0000],
        [15442542.0000,        0.0000],
        [13134438.0000,  1467115.3750],
        [15600431.0000,        0.0000],
        [15725810.0000,        0.0000],
        [10275120.0000,  4440623.0000],
        [15687248.0000,        0.0000],
        [15586960.0000,        0.0000],
        [15728330.0000,        0.0000],
        [15755394.0000,        0.0000],
        [15752787.0000,        0.0000],
        [15778098.0000,        0.0000],
        [15755632.0000,        0.0000],
        [ 2863229.0000,  7854641.0000],
        [ 9017431.0000,  6018311.5000],
        [12387157.0000,  3091312.0000],
        [12098519.0000,  3023436.0000],
        [ 3170945.5000,  8010459.0000],
        [11892473.0000,  2980622.0000],
        [12673545.0000,  1389317.6250],
        [13493730.0000,  1490976.8750],
        [ 9845465.0000,  2527180.5000],
        [15568899.0000,        0.0000],
        [15479202.0000,        0.0000],
        [13741951.0000,  1526969.0000],
        [ 2508462.0000, 10373368.0000],
        [ 1168141.2500, 10586187.0000],
        [ 5130897.0000,  4771424.0000],
        [ 2725297.5000,  6953819.5000],
        [ 5358619.0000,  8146744.0000],
        [10148130.0000,  4386143.0000],
        [12530434.0000,  1402054.3750],
        [ 1327790.3750, 12284268.0000],
        [ 1366043.3750, 12752107.0000],
        [ 2645216.0000, 10435182.0000],
        [11860716.0000,  2983863.5000],
        [10202883.0000,  4470844.0000],
        [ 2725384.5000, 11110440.0000],
        [ 5223145.5000,  8220120.0000],
        [ 1302775.5000, 12354864.0000],
        [ 2695842.2500, 11391830.0000],
        [10704979.0000,  2722876.7500],
        [11729118.0000,  1263783.6250],
        [ 9777499.0000,  3906525.5000],
        [ 1376534.1250, 12767722.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 466/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:07, 58.14s/it]  7%|▋         | 2/29 [00:59<11:10, 24.83s/it] 10%|█         | 3/29 [01:00<06:01, 13.92s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.79s/it] 17%|█▋        | 5/29 [01:02<02:22,  5.95s/it] 21%|██        | 6/29 [01:03<01:37,  4.24s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.773880958557129
Epoch 467/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:35, 59.12s/it]  7%|▋         | 2/29 [01:01<11:31, 25.62s/it] 10%|█         | 3/29 [01:02<06:12, 14.34s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.04s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:04<01:40,  4.35s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.49s/it] 31%|███       | 9/29 [01:07<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.760735034942627
Epoch 468/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:05, 58.06s/it]  7%|▋         | 2/29 [00:59<11:00, 24.46s/it] 10%|█         | 3/29 [00:59<05:56, 13.72s/it] 14%|█▍        | 4/29 [01:00<03:36,  8.67s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.88s/it] 21%|██        | 6/29 [01:02<01:36,  4.19s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.12s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.42s/it] 31%|███       | 9/29 [01:05<00:39,  1.95s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 2.7753255367279053
Epoch 469/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:40, 59.30s/it]  7%|▋         | 2/29 [01:00<11:13, 24.96s/it] 10%|█         | 3/29 [01:01<06:03, 13.98s/it] 14%|█▍        | 4/29 [01:02<03:40,  8.83s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.98s/it] 21%|██        | 6/29 [01:03<01:37,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.772156000137329
Epoch 470/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:46, 57.37s/it]  7%|▋         | 2/29 [00:58<10:56, 24.32s/it] 10%|█         | 3/29 [00:59<05:54, 13.64s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.72s/it] 17%|█▋        | 5/29 [01:02<02:27,  6.13s/it] 21%|██        | 6/29 [01:03<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:04<01:11,  3.24s/it] 28%|██▊       | 8/29 [01:04<00:52,  2.50s/it] 31%|███       | 9/29 [01:05<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.7780728340148926
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0144, 0.0024,  ..., 0.0042, 0.0001, 0.0195],
        [0.0034, 0.0100, 0.0022,  ..., 0.0026, 0.0001, 0.0188],
        [0.0326, 0.0065, 0.0037,  ..., 0.0053, 0.0148, 0.0243],
        ...,
        [0.0080, 0.0082, 0.0190,  ..., 0.0040, 0.0018, 0.0208],
        [0.0046, 0.0087, 0.0126,  ..., 0.0052, 0.0052, 0.0202],
        [0.0100, 0.0045, 0.0043,  ..., 0.0030, 0.0022, 0.0231]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9961, 0.9960, 0.9951, 0.9950, 0.9948, 0.9948, 0.9947, 0.9944, 0.9944,
         0.9941],
        [0.9972, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9963, 0.9963, 0.9963,
         0.9963],
        [0.9751, 0.9698, 0.9679, 0.9664, 0.9657, 0.9652, 0.9652, 0.9647, 0.9643,
         0.9641],
        [0.9935, 0.9926, 0.9926, 0.9922, 0.9918, 0.9912, 0.9908, 0.9903, 0.9898,
         0.9895],
        [0.9886, 0.9873, 0.9867, 0.9850, 0.9846, 0.9845, 0.9843, 0.9841, 0.9840,
         0.9839],
        [0.9844, 0.9834, 0.9808, 0.9773, 0.9763, 0.9759, 0.9756, 0.9744, 0.9733,
         0.9733],
        [0.9797, 0.9709, 0.9696, 0.9687, 0.9679, 0.9646, 0.9645, 0.9637, 0.9636,
         0.9634],
        [0.9762, 0.9731, 0.9680, 0.9675, 0.9601, 0.9577, 0.9560, 0.9557, 0.9543,
         0.9535],
        [0.9974, 0.9969, 0.9968, 0.9966, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962,
         0.9962],
        [0.9940, 0.9900, 0.9893, 0.9883, 0.9871, 0.9869, 0.9856, 0.9847, 0.9845,
         0.9836],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9938, 0.9936, 0.9912, 0.9912, 0.9907, 0.9905, 0.9904, 0.9903, 0.9903,
         0.9901],
        [0.9917, 0.9909, 0.9892, 0.9886, 0.9872, 0.9869, 0.9866, 0.9854, 0.9844,
         0.9842],
        [0.9983, 0.9981, 0.9978, 0.9978, 0.9978, 0.9975, 0.9973, 0.9971, 0.9971,
         0.9970],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9964, 0.9962, 0.9962, 0.9960, 0.9959, 0.9956, 0.9955, 0.9954, 0.9952,
         0.9952],
        [0.9953, 0.9949, 0.9945, 0.9944, 0.9944, 0.9944, 0.9942, 0.9942, 0.9942,
         0.9942],
        [0.9944, 0.9936, 0.9934, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932, 0.9931,
         0.9931],
        [0.9979, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9952, 0.9945, 0.9941, 0.9940, 0.9939, 0.9936, 0.9936, 0.9935, 0.9929,
         0.9927],
        [0.9988, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9979, 0.9979, 0.9976,
         0.9975],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9951, 0.9951, 0.9948, 0.9945, 0.9942, 0.9941, 0.9940, 0.9940, 0.9939,
         0.9939],
        [0.9989, 0.9988, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984, 0.9984, 0.9983,
         0.9983],
        [0.9984, 0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9979, 0.9978, 0.9978,
         0.9978],
        [0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9883, 0.9869, 0.9775, 0.9701, 0.9683, 0.9682, 0.9681, 0.9647, 0.9618,
         0.9616],
        [0.9962, 0.9962, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9954,
         0.9953],
        [0.9980, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9965, 0.9963, 0.9962, 0.9962, 0.9961, 0.9960, 0.9960, 0.9960, 0.9960,
         0.9958],
        [0.9855, 0.9827, 0.9795, 0.9756, 0.9745, 0.9729, 0.9722, 0.9704, 0.9676,
         0.9674],
        [0.9956, 0.9953, 0.9951, 0.9950, 0.9950, 0.9948, 0.9948, 0.9948, 0.9948,
         0.9947],
        [0.9929, 0.9922, 0.9920, 0.9915, 0.9913, 0.9913, 0.9908, 0.9906, 0.9906,
         0.9905],
        [0.9960, 0.9956, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953, 0.9952, 0.9950,
         0.9950],
        [0.9857, 0.9846, 0.9843, 0.9841, 0.9820, 0.9813, 0.9811, 0.9798, 0.9787,
         0.9782],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9980, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974,
         0.9974],
        [0.9971, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9889, 0.9861, 0.9848, 0.9847, 0.9840, 0.9839, 0.9835, 0.9829, 0.9829,
         0.9821],
        [0.9859, 0.9797, 0.9789, 0.9783, 0.9780, 0.9772, 0.9771, 0.9769, 0.9764,
         0.9762],
        [0.9866, 0.9858, 0.9738, 0.9701, 0.9602, 0.9601, 0.9567, 0.9558, 0.9556,
         0.9546],
        [0.9732, 0.9685, 0.9677, 0.9662, 0.9655, 0.9634, 0.9623, 0.9620, 0.9608,
         0.9543],
        [0.9909, 0.9892, 0.9889, 0.9883, 0.9883, 0.9879, 0.9876, 0.9871, 0.9869,
         0.9868],
        [0.9939, 0.9939, 0.9938, 0.9936, 0.9934, 0.9930, 0.9929, 0.9928, 0.9928,
         0.9924],
        [0.9914, 0.9911, 0.9906, 0.9903, 0.9901, 0.9898, 0.9895, 0.9895, 0.9893,
         0.9893],
        [0.9909, 0.9907, 0.9894, 0.9893, 0.9885, 0.9882, 0.9874, 0.9870, 0.9867,
         0.9865],
        [0.9938, 0.9929, 0.9928, 0.9920, 0.9916, 0.9915, 0.9904, 0.9897, 0.9893,
         0.9891],
        [0.9902, 0.9875, 0.9867, 0.9864, 0.9856, 0.9854, 0.9852, 0.9847, 0.9839,
         0.9832],
        [0.9951, 0.9950, 0.9949, 0.9949, 0.9949, 0.9948, 0.9944, 0.9942, 0.9942,
         0.9938],
        [0.9955, 0.9949, 0.9946, 0.9944, 0.9943, 0.9930, 0.9929, 0.9928, 0.9927,
         0.9926],
        [0.9944, 0.9912, 0.9900, 0.9899, 0.9892, 0.9890, 0.9888, 0.9888, 0.9887,
         0.9882],
        [0.9914, 0.9911, 0.9907, 0.9903, 0.9864, 0.9863, 0.9862, 0.9858, 0.9852,
         0.9852],
        [0.9918, 0.9911, 0.9909, 0.9908, 0.9887, 0.9887, 0.9886, 0.9868, 0.9859,
         0.9855],
        [0.9967, 0.9938, 0.9925, 0.9924, 0.9920, 0.9906, 0.9883, 0.9883, 0.9880,
         0.9873],
        [0.9900, 0.9889, 0.9882, 0.9881, 0.9879, 0.9874, 0.9874, 0.9868, 0.9866,
         0.9865],
        [0.9913, 0.9908, 0.9865, 0.9848, 0.9838, 0.9832, 0.9829, 0.9828, 0.9819,
         0.9815],
        [0.9920, 0.9919, 0.9916, 0.9915, 0.9910, 0.9894, 0.9859, 0.9852, 0.9849,
         0.9841],
        [0.9923, 0.9919, 0.9918, 0.9918, 0.9917, 0.9915, 0.9912, 0.9906, 0.9899,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 0],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1513839.6250, 1511463.7500, 1491120.3750, 1490726.5000, 1486732.7500,
         1485151.2500, 1484103.5000, 1477098.5000, 1476970.3750, 1470300.3750],
        [1537317.0000, 1525426.2500, 1523200.6250, 1523114.8750, 1522761.8750,
         1521786.5000, 1518559.2500, 1518453.6250, 1518430.3750, 1518259.5000],
        [1121348.1250, 1039373.6250, 1011629.6250,  990765.7500,  980206.8125,
          973687.7500,  973131.7500,  966161.1875,  961114.9375,  957734.1875],
        [1457530.3750, 1439843.7500, 1438939.1250, 1431455.0000, 1423807.3750,
         1410391.7500, 1402331.1250, 1393907.0000, 1383754.8750, 1376759.8750],
        [1360456.8750, 1335141.0000, 1323364.5000, 1292401.8750, 1284127.2500,
         1282697.7500, 1278098.0000, 1275566.3750, 1272811.6250, 1270847.8750],
        [1281146.2500, 1263088.2500, 1217065.7500, 1157792.3750, 1140361.1250,
         1134290.5000, 1129578.3750, 1110806.7500, 1092347.0000, 1092200.1250],
        [1196966.8750, 1055490.7500, 1036086.0000, 1023012.7500, 1011417.4375,
          964532.6250,  963359.6250,  952631.1250,  951831.0625,  948778.6875],
        [1138369.5000, 1089657.3750, 1012869.1875, 1005622.5625,  904714.7500,
          875126.0000,  853373.7500,  850043.5000,  832999.0000,  823763.8750],
        [1542757.0000, 1529986.3750, 1528098.0000, 1523916.8750, 1519638.5000,
         1519044.3750, 1518472.3750, 1516559.2500, 1515756.6250, 1515346.1250],
        [1468620.1250, 1387837.2500, 1373193.2500, 1353410.6250, 1331797.7500,
         1327092.7500, 1303127.1250, 1286707.7500, 1281827.0000, 1265708.6250],
        [1555230.6250, 1553337.8750, 1553278.5000, 1552134.0000, 1548071.5000,
         1547116.7500, 1546482.3750, 1546094.6250, 1545518.1250, 1544766.7500],
        [1464515.1250, 1460524.7500, 1411585.3750, 1410507.5000, 1400481.3750,
         1397796.6250, 1395065.3750, 1394022.6250, 1393823.2500, 1389350.8750],
        [1421094.3750, 1404803.3750, 1372448.2500, 1359696.6250, 1333059.5000,
         1326773.8750, 1321266.0000, 1299327.5000, 1281058.3750, 1276252.6250],
        [1562727.0000, 1557847.7500, 1551670.6250, 1551651.5000, 1551414.6250,
         1545009.7500, 1538725.0000, 1536285.1250, 1534492.8750, 1533341.6250],
        [1575942.1250, 1574839.2500, 1574816.7500, 1574514.8750, 1574477.5000,
         1574270.2500, 1573901.0000, 1573501.7500, 1572990.1250, 1572610.6250],
        [1574488.0000, 1571837.0000, 1570752.1250, 1570404.5000, 1569211.2500,
         1568780.3750, 1567010.0000, 1566303.3750, 1566243.5000, 1565544.7500],
        [1519909.6250, 1516692.1250, 1516618.5000, 1511806.8750, 1508895.8750,
         1502690.7500, 1501284.1250, 1497671.8750, 1494840.8750, 1494592.7500],
        [1496992.1250, 1486936.8750, 1479701.2500, 1478010.1250, 1477390.1250,
         1477249.2500, 1473665.2500, 1473517.8750, 1472384.1250, 1472292.8750],
        [1476812.6250, 1461434.6250, 1456189.6250, 1455823.0000, 1454793.2500,
         1454737.7500, 1452785.7500, 1452737.2500, 1450206.8750, 1449446.3750],
        [1552672.8750, 1550219.7500, 1548849.8750, 1548714.0000, 1546488.2500,
         1546091.6250, 1545546.1250, 1545397.2500, 1543560.5000, 1543102.8750],
        [1550899.8750, 1550746.1250, 1549494.0000, 1547986.0000, 1547841.3750,
         1547425.1250, 1542102.3750, 1540127.2500, 1539780.6250, 1539652.8750],
        [1494411.7500, 1480264.3750, 1470830.6250, 1469243.6250, 1467529.5000,
         1461385.8750, 1459867.3750, 1458857.0000, 1445768.6250, 1441760.5000],
        [1573737.3750, 1571313.8750, 1561353.5000, 1561279.1250, 1561265.6250,
         1557140.7500, 1553634.1250, 1553246.0000, 1545880.7500, 1543095.5000],
        [1577960.3750, 1575522.8750, 1572132.2500, 1572099.3750, 1572001.7500,
         1571832.3750, 1571706.6250, 1571006.7500, 1568807.3750, 1568446.8750],
        [1492584.5000, 1492563.1250, 1484709.3750, 1479421.7500, 1473560.0000,
         1469917.6250, 1468730.8750, 1468223.8750, 1467752.0000, 1465909.7500],
        [1575262.8750, 1572316.7500, 1569581.0000, 1568666.6250, 1567456.8750,
         1567056.3750, 1564164.2500, 1563642.2500, 1562162.2500, 1562071.3750],
        [1565198.2500, 1564147.8750, 1561855.3750, 1560576.3750, 1557571.3750,
         1557463.0000, 1552055.5000, 1551521.2500, 1551181.0000, 1550994.6250],
        [1575085.6250, 1573801.8750, 1573371.2500, 1572657.1250, 1572298.7500,
         1571511.6250, 1570762.5000, 1570725.1250, 1570211.3750, 1569319.0000],
        [1577682.0000, 1577678.8750, 1576708.7500, 1574702.6250, 1574660.6250,
         1573917.5000, 1573686.3750, 1573647.2500, 1573383.1250, 1572328.6250],
        [1580109.3750, 1578883.1250, 1575040.6250, 1574013.6250, 1573889.0000,
         1573887.3750, 1573702.7500, 1573015.5000, 1572198.2500, 1572057.2500],
        [1579283.7500, 1579279.1250, 1579137.6250, 1577152.5000, 1576988.5000,
         1576448.6250, 1576143.6250, 1575521.3750, 1575498.7500, 1574916.0000],
        [1578249.3750, 1577441.2500, 1575423.6250, 1574501.5000, 1574304.8750,
         1574214.6250, 1574136.6250, 1573884.3750, 1573345.7500, 1573227.1250],
        [1354725.2500, 1327016.8750, 1160543.8750, 1043923.3750, 1018186.1250,
         1016715.1250, 1014217.5000,  967011.0625,  927456.2500,  925281.2500],
        [1516520.1250, 1515029.7500, 1505846.7500, 1505658.6250, 1505037.1250,
         1502071.7500, 1500780.1250, 1499516.8750, 1497490.5000, 1495750.6250],
        [1554287.6250, 1551252.0000, 1550635.1250, 1546702.2500, 1546349.6250,
         1546329.0000, 1546261.2500, 1546009.0000, 1545988.5000, 1544575.1250],
        [1521956.2500, 1517723.8750, 1516427.5000, 1514854.8750, 1514359.3750,
         1512320.2500, 1512020.2500, 1511112.0000, 1510707.1250, 1507515.1250],
        [1300517.5000, 1249275.6250, 1194752.0000, 1129675.3750, 1111385.2500,
         1086499.6250, 1076529.1250, 1048903.1250, 1008017.3125, 1004995.5625],
        [1503520.6250, 1497376.2500, 1491272.5000, 1490152.3750, 1489610.8750,
         1486761.1250, 1486690.2500, 1486490.2500, 1486328.7500, 1484112.0000],
        [1445339.8750, 1431823.7500, 1427048.3750, 1418263.3750, 1413681.5000,
         1412603.3750, 1402957.1250, 1399636.1250, 1398471.5000, 1396754.6250],
        [1510580.3750, 1502210.6250, 1502169.2500, 1499659.8750, 1499659.8750,
         1497960.3750, 1496938.0000, 1494048.3750, 1490423.7500, 1490398.1250],
        [1304332.0000, 1284548.7500, 1278738.0000, 1274565.6250, 1238235.1250,
         1225817.1250, 1221175.6250, 1199157.1250, 1180903.6250, 1171884.7500],
        [1562052.0000, 1559985.6250, 1556505.3750, 1555168.5000, 1555030.5000,
         1555003.8750, 1553546.6250, 1552954.2500, 1552862.3750, 1552239.0000],
        [1554286.1250, 1553462.2500, 1550657.3750, 1546705.1250, 1546343.7500,
         1545913.2500, 1545460.7500, 1543310.3750, 1542701.1250, 1542558.3750],
        [1535324.3750, 1531376.1250, 1527053.5000, 1526338.6250, 1524536.2500,
         1523809.3750, 1519469.0000, 1519399.3750, 1517881.7500, 1517579.1250],
        [1365233.2500, 1312490.0000, 1288093.8750, 1286571.5000, 1272451.1250,
         1271523.1250, 1264929.0000, 1254000.2500, 1252833.5000, 1239021.8750],
        [1308470.7500, 1198281.3750, 1183929.1250, 1172925.7500, 1169362.8750,
         1155473.7500, 1154439.5000, 1149787.5000, 1141520.0000, 1138258.7500],
        [1321497.8750, 1307116.2500, 1101418.5000, 1044597.5625,  906526.6875,
          904801.8750,  862415.8750,  851321.2500,  848544.3125,  836526.5000],
        [1091750.2500, 1020740.1250, 1009081.0625,  987595.1250,  977867.9375,
          948738.0000,  933721.9375,  929915.7500,  913586.1875,  833387.5625],
        [1404808.7500, 1372140.7500, 1366512.3750, 1354413.8750, 1353502.2500,
         1345928.5000, 1341190.1250, 1331282.1250, 1326253.8750, 1325233.6250],
        [1466762.7500, 1466025.7500, 1464153.5000, 1461310.5000, 1456385.3750,
         1447723.7500, 1445197.8750, 1444696.2500, 1443703.2500, 1435178.5000],
        [1415304.3750, 1409411.6250, 1399731.0000, 1393937.6250, 1389684.7500,
         1382625.6250, 1378311.5000, 1377768.6250, 1373579.6250, 1373013.8750],
        [1404477.7500, 1401184.1250, 1375173.3750, 1373104.1250, 1358140.2500,
         1351133.1250, 1336218.6250, 1329872.5000, 1323142.3750, 1320346.5000],
        [1464976.1250, 1446742.3750, 1443085.2500, 1427414.3750, 1419291.7500,
         1417999.6250, 1395995.6250, 1380913.8750, 1374267.5000, 1370269.5000],
        [1391177.8750, 1338127.7500, 1322660.3750, 1318471.6250, 1303072.5000,
         1299550.5000, 1295292.8750, 1285481.2500, 1272136.8750, 1259620.3750],
        [1492480.5000, 1489471.7500, 1487704.2500, 1486860.3750, 1486860.3750,
         1486715.6250, 1476279.0000, 1473443.3750, 1473359.0000, 1464747.0000],
        [1500781.6250, 1487033.3750, 1481794.0000, 1477153.5000, 1476153.5000,
         1447389.6250, 1445418.5000, 1444251.3750, 1442001.1250, 1439102.3750],
        [1476815.3750, 1410915.1250, 1386497.1250, 1385500.5000, 1371306.1250,
         1367063.7500, 1364309.1250, 1363758.8750, 1362695.3750, 1351175.6250],
        [1414647.2500, 1409625.3750, 1401344.5000, 1393578.6250, 1318141.0000,
         1316333.3750, 1314355.1250, 1305569.0000, 1296054.0000, 1295113.7500],
        [1423715.1250, 1410019.2500, 1405146.5000, 1402305.6250, 1361666.5000,
         1360978.3750, 1359495.6250, 1325858.1250, 1308742.8750, 1300283.1250],
        [1526753.5000, 1464661.7500, 1437337.1250, 1436231.3750, 1427904.5000,
         1399701.6250, 1354032.8750, 1353555.1250, 1348676.7500, 1335301.5000],
        [1386449.6250, 1364916.8750, 1352096.0000, 1349701.0000, 1346355.8750,
         1336175.3750, 1336110.3750, 1325146.3750, 1321726.0000, 1318984.7500],
        [1413228.6250, 1402280.2500, 1319364.7500, 1288826.2500, 1269703.0000,
         1259308.0000, 1252769.0000, 1252557.5000, 1236118.5000, 1229479.3750],
        [1427325.8750, 1426401.8750, 1419932.1250, 1417269.6250, 1406850.6250,
         1374496.8750, 1307933.0000, 1294600.0000, 1289107.7500, 1275678.2500],
        [1434419.0000, 1425050.5000, 1423947.2500, 1423662.2500, 1422111.2500,
         1416737.2500, 1410312.3750, 1399181.1250, 1385497.8750, 1372995.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1513839.6250,       0.0000],
         [1511463.7500,       0.0000],
         [1491120.3750,       0.0000],
         ...,
         [      0.0000, 1477098.5000],
         [1476970.3750,       0.0000],
         [1470300.3750,       0.0000]],

        [[1537317.0000,       0.0000],
         [1525426.2500,       0.0000],
         [1523200.6250,       0.0000],
         ...,
         [1518453.6250,       0.0000],
         [1518430.3750,       0.0000],
         [1518259.5000,       0.0000]],

        [[1121348.1250,       0.0000],
         [      0.0000, 1039373.6250],
         [1011629.6250,       0.0000],
         ...,
         [ 966161.1875,       0.0000],
         [ 961114.9375,       0.0000],
         [      0.0000,  957734.1875]],

        ...,

        [[1413228.6250,       0.0000],
         [1402280.2500,       0.0000],
         [1319364.7500,       0.0000],
         ...,
         [1252557.5000,       0.0000],
         [1236118.5000,       0.0000],
         [1229479.3750,       0.0000]],

        [[1427325.8750,       0.0000],
         [1426401.8750,       0.0000],
         [1419932.1250,       0.0000],
         ...,
         [      0.0000, 1294600.0000],
         [1289107.7500,       0.0000],
         [      0.0000, 1275678.2500]],

        [[      0.0000, 1434419.0000],
         [      0.0000, 1425050.5000],
         [      0.0000, 1423947.2500],
         ...,
         [      0.0000, 1399181.1250],
         [      0.0000, 1385497.8750],
         [1372995.5000,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13410408.0000,  1477098.5000],
        [15227310.0000,        0.0000],
        [ 4060253.7500,  5914900.0000],
        [12756389.0000,  1402331.1250],
        [ 9151000.0000,  3824512.5000],
        [ 9350078.0000,  2268599.0000],
        [ 5031753.5000,  5072353.5000],
        [ 8536496.0000,   850043.5000],
        [13714230.0000,  1515346.1250],
        [11991486.0000,  1387837.2500],
        [15492030.0000,        0.0000],
        [14117673.0000,        0.0000],
        [13395781.0000,        0.0000],
        [15463166.0000,        0.0000],
        [15741864.0000,        0.0000],
        [15690575.0000,        0.0000],
        [13545095.0000,  1519909.6250],
        [13291148.0000,  1496992.1250],
        [14564968.0000,        0.0000],
        [15470643.0000,        0.0000],
        [15456055.0000,        0.0000],
        [13179088.0000,  1470830.6250],
        [15581947.0000,        0.0000],
        [15721517.0000,        0.0000],
        [11778226.0000,  2985147.5000],
        [15672380.0000,        0.0000],
        [15572564.0000,        0.0000],
        [15719744.0000,        0.0000],
        [15748395.0000,        0.0000],
        [15746797.0000,        0.0000],
        [15770370.0000,        0.0000],
        [15748729.0000,        0.0000],
        [ 2960182.5000,  7794894.5000],
        [ 9023339.0000,  6020364.0000],
        [12386030.0000,  3092358.5000],
        [12110249.0000,  3028747.7500],
        [ 3165284.0000,  8045266.5000],
        [11913666.0000,  2988648.7500],
        [12749826.0000,  1396754.6250],
        [14984048.0000,        0.0000],
        [ 9856574.0000,  2522784.0000],
        [15555349.0000,        0.0000],
        [15471398.0000,        0.0000],
        [13718231.0000,  1524536.2500],
        [ 2491855.5000, 10315292.0000],
        [ 1172925.7500, 10599524.0000],
        [ 5210137.0000,  4774630.0000],
        [ 2715847.5000,  6930536.5000],
        [ 4046160.0000,  9475106.0000],
        [10149288.0000,  4381849.5000],
        [12499431.0000,  1393937.6250],
        [ 1320346.5000, 12252446.0000],
        [ 1370269.5000, 12770686.0000],
        [ 2641132.0000, 10444460.0000],
        [11837737.0000,  2980184.7500],
        [10177110.0000,  4463968.5000],
        [ 2734001.5000, 11106036.0000],
        [ 5231371.0000,  8233390.5000],
        [ 1300283.1250, 12357928.0000],
        [ 2689334.5000, 11394822.0000],
        [10715102.0000,  2722560.0000],
        [11664327.0000,  1259308.0000],
        [ 9761385.0000,  3878211.2500],
        [ 1372995.5000, 12740920.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 471/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:17, 60.63s/it]  7%|▋         | 2/29 [01:01<11:28, 25.51s/it] 10%|█         | 3/29 [01:02<06:11, 14.28s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.01s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.09s/it] 21%|██        | 6/29 [01:05<01:39,  4.33s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.79011607170105
Epoch 472/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:50, 57.50s/it]  7%|▋         | 2/29 [00:58<10:53, 24.22s/it] 10%|█         | 3/29 [00:59<05:53, 13.58s/it] 14%|█▍        | 4/29 [01:00<03:34,  8.58s/it] 17%|█▋        | 5/29 [01:01<02:19,  5.82s/it] 21%|██        | 6/29 [01:02<01:35,  4.15s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.10s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.40s/it] 31%|███       | 9/29 [01:04<00:38,  1.94s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.779527425765991
Epoch 473/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:34, 59.09s/it]  7%|▋         | 2/29 [01:00<11:11, 24.87s/it] 10%|█         | 3/29 [01:00<06:02, 13.94s/it] 14%|█▍        | 4/29 [01:01<03:39,  8.80s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.96s/it] 21%|██        | 6/29 [01:03<01:37,  4.25s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.16s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.97s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7865586280822754
Epoch 474/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:50, 57.52s/it]  7%|▋         | 2/29 [01:01<11:38, 25.87s/it] 10%|█         | 3/29 [01:02<06:16, 14.48s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.13s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.769285202026367
Epoch 475/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:57, 59.91s/it]  7%|▋         | 2/29 [01:00<11:20, 25.21s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.91s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.29s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.78621506690979
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.7885e-03, 1.3499e-02, 1.9811e-03,  ..., 3.9901e-03, 5.7400e-05,
         1.9892e-02],
        [2.6851e-03, 9.4998e-03, 1.9947e-03,  ..., 2.1940e-03, 1.7018e-04,
         1.8569e-02],
        [3.2170e-02, 6.6032e-03, 3.8260e-03,  ..., 5.4622e-03, 1.4701e-02,
         2.3952e-02],
        ...,
        [7.5862e-03, 8.0420e-03, 1.8229e-02,  ..., 3.8627e-03, 1.7318e-03,
         2.1047e-02],
        [4.1351e-03, 8.2097e-03, 1.1608e-02,  ..., 4.6998e-03, 4.7903e-03,
         2.0488e-02],
        [9.1146e-03, 4.4271e-03, 3.9829e-03,  ..., 2.7399e-03, 2.0702e-03,
         2.2853e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9965, 0.9956, 0.9954, 0.9953, 0.9951, 0.9951, 0.9950, 0.9949,
         0.9946],
        [0.9974, 0.9968, 0.9968, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965,
         0.9965],
        [0.9749, 0.9689, 0.9681, 0.9655, 0.9649, 0.9648, 0.9646, 0.9639, 0.9639,
         0.9628],
        [0.9939, 0.9930, 0.9927, 0.9927, 0.9923, 0.9917, 0.9917, 0.9903, 0.9902,
         0.9901],
        [0.9885, 0.9872, 0.9869, 0.9853, 0.9851, 0.9848, 0.9847, 0.9846, 0.9844,
         0.9841],
        [0.9848, 0.9829, 0.9807, 0.9777, 0.9770, 0.9764, 0.9762, 0.9739, 0.9739,
         0.9737],
        [0.9781, 0.9714, 0.9704, 0.9673, 0.9669, 0.9639, 0.9633, 0.9631, 0.9628,
         0.9615],
        [0.9754, 0.9733, 0.9694, 0.9665, 0.9595, 0.9572, 0.9560, 0.9543, 0.9540,
         0.9518],
        [0.9976, 0.9970, 0.9970, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9964],
        [0.9941, 0.9907, 0.9897, 0.9885, 0.9877, 0.9873, 0.9863, 0.9850, 0.9843,
         0.9842],
        [0.9982, 0.9981, 0.9981, 0.9981, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9940, 0.9936, 0.9916, 0.9912, 0.9909, 0.9908, 0.9908, 0.9908, 0.9906,
         0.9897],
        [0.9924, 0.9915, 0.9897, 0.9896, 0.9873, 0.9873, 0.9865, 0.9855, 0.9853,
         0.9838],
        [0.9985, 0.9983, 0.9980, 0.9980, 0.9980, 0.9978, 0.9975, 0.9975, 0.9975,
         0.9974],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9986,
         0.9986],
        [0.9967, 0.9965, 0.9964, 0.9963, 0.9961, 0.9959, 0.9959, 0.9957, 0.9956,
         0.9955],
        [0.9956, 0.9951, 0.9947, 0.9946, 0.9946, 0.9945, 0.9945, 0.9944, 0.9944,
         0.9944],
        [0.9945, 0.9940, 0.9937, 0.9936, 0.9936, 0.9934, 0.9933, 0.9932, 0.9932,
         0.9931],
        [0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976,
         0.9975],
        [0.9954, 0.9946, 0.9943, 0.9943, 0.9942, 0.9941, 0.9939, 0.9935, 0.9932,
         0.9930],
        [0.9989, 0.9989, 0.9983, 0.9983, 0.9983, 0.9982, 0.9981, 0.9980, 0.9977,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9987,
         0.9987],
        [0.9953, 0.9952, 0.9947, 0.9945, 0.9944, 0.9944, 0.9942, 0.9941, 0.9941,
         0.9941],
        [0.9990, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9992, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9880, 0.9866, 0.9776, 0.9708, 0.9685, 0.9670, 0.9666, 0.9636, 0.9619,
         0.9586],
        [0.9965, 0.9965, 0.9960, 0.9960, 0.9960, 0.9959, 0.9959, 0.9958, 0.9958,
         0.9956],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9967, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9961],
        [0.9850, 0.9821, 0.9789, 0.9758, 0.9736, 0.9731, 0.9709, 0.9704, 0.9686,
         0.9685],
        [0.9961, 0.9957, 0.9954, 0.9954, 0.9954, 0.9953, 0.9953, 0.9952, 0.9950,
         0.9950],
        [0.9928, 0.9922, 0.9920, 0.9917, 0.9915, 0.9910, 0.9910, 0.9906, 0.9905,
         0.9904],
        [0.9962, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9956, 0.9956, 0.9955,
         0.9954],
        [0.9842, 0.9841, 0.9837, 0.9834, 0.9821, 0.9805, 0.9804, 0.9787, 0.9785,
         0.9771],
        [0.9985, 0.9984, 0.9983, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9982, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978,
         0.9977],
        [0.9973, 0.9973, 0.9971, 0.9970, 0.9970, 0.9969, 0.9967, 0.9967, 0.9966,
         0.9966],
        [0.9896, 0.9865, 0.9856, 0.9852, 0.9848, 0.9838, 0.9838, 0.9835, 0.9831,
         0.9824],
        [0.9854, 0.9797, 0.9795, 0.9792, 0.9787, 0.9781, 0.9780, 0.9775, 0.9772,
         0.9759],
        [0.9870, 0.9849, 0.9736, 0.9705, 0.9611, 0.9586, 0.9555, 0.9545, 0.9545,
         0.9545],
        [0.9725, 0.9688, 0.9672, 0.9661, 0.9652, 0.9632, 0.9615, 0.9613, 0.9607,
         0.9517],
        [0.9913, 0.9898, 0.9895, 0.9889, 0.9886, 0.9885, 0.9884, 0.9875, 0.9874,
         0.9874],
        [0.9943, 0.9943, 0.9943, 0.9942, 0.9940, 0.9936, 0.9936, 0.9935, 0.9934,
         0.9931],
        [0.9916, 0.9916, 0.9914, 0.9908, 0.9908, 0.9906, 0.9905, 0.9904, 0.9902,
         0.9901],
        [0.9911, 0.9911, 0.9897, 0.9896, 0.9889, 0.9886, 0.9873, 0.9871, 0.9868,
         0.9868],
        [0.9936, 0.9927, 0.9927, 0.9919, 0.9916, 0.9914, 0.9905, 0.9897, 0.9895,
         0.9890],
        [0.9902, 0.9876, 0.9869, 0.9867, 0.9858, 0.9853, 0.9852, 0.9850, 0.9841,
         0.9835],
        [0.9954, 0.9953, 0.9952, 0.9952, 0.9952, 0.9950, 0.9949, 0.9949, 0.9949,
         0.9943],
        [0.9958, 0.9952, 0.9952, 0.9951, 0.9949, 0.9936, 0.9934, 0.9933, 0.9932,
         0.9931],
        [0.9944, 0.9912, 0.9900, 0.9899, 0.9892, 0.9891, 0.9889, 0.9887, 0.9885,
         0.9881],
        [0.9916, 0.9911, 0.9909, 0.9902, 0.9866, 0.9866, 0.9863, 0.9859, 0.9855,
         0.9854],
        [0.9918, 0.9914, 0.9907, 0.9904, 0.9885, 0.9885, 0.9884, 0.9871, 0.9860,
         0.9860],
        [0.9967, 0.9939, 0.9928, 0.9927, 0.9922, 0.9910, 0.9883, 0.9881, 0.9877,
         0.9877],
        [0.9898, 0.9887, 0.9885, 0.9883, 0.9882, 0.9877, 0.9872, 0.9870, 0.9868,
         0.9861],
        [0.9914, 0.9905, 0.9871, 0.9848, 0.9840, 0.9835, 0.9833, 0.9832, 0.9825,
         0.9817],
        [0.9925, 0.9924, 0.9921, 0.9918, 0.9915, 0.9899, 0.9865, 0.9863, 0.9853,
         0.9845],
        [0.9927, 0.9924, 0.9921, 0.9921, 0.9921, 0.9916, 0.9912, 0.9906, 0.9901,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 0, 1, 1, 1, 0, 1, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1521876.3750, 1521541.1250, 1503268.3750, 1497923.2500, 1495448.2500,
         1492289.8750, 1491466.0000, 1489993.1250, 1488866.6250, 1481371.5000],
        [1541999.6250, 1529201.6250, 1528350.2500, 1528233.5000, 1525744.8750,
         1525401.5000, 1524293.3750, 1522692.2500, 1521882.1250, 1521877.8750],
        [1118674.7500, 1026136.6250, 1014305.5000,  977734.6250,  969464.5000,
          967842.3750,  965610.3125,  956165.3750,  955438.8750,  940966.2500],
        [1466016.0000, 1447054.2500, 1441202.3750, 1440985.2500, 1434551.8750,
         1421148.6250, 1420643.1250, 1392938.2500, 1391049.2500, 1388517.6250],
        [1357714.2500, 1332666.8750, 1327395.2500, 1297394.5000, 1293610.1250,
         1288446.5000, 1285277.7500, 1283458.8750, 1279908.0000, 1275431.3750],
        [1288140.5000, 1254164.0000, 1214227.6250, 1163105.5000, 1151933.1250,
         1142736.5000, 1138586.5000, 1102967.7500, 1101662.1250, 1099074.3750],
        [1169788.8750, 1062825.0000, 1048299.0625, 1002813.6875,  997494.2500,
          955087.1875,  947695.3125,  944543.6875,  940903.3750,  922816.3750],
        [1126192.3750, 1093165.0000, 1033832.6875,  991925.8125,  897714.4375,
          868102.1250,  852988.0625,  833084.0000,  829515.6250,  803715.8750],
        [1546576.8750, 1533951.5000, 1533932.5000, 1527288.0000, 1526680.7500,
         1524459.1250, 1522423.6250, 1521081.1250, 1521071.1250, 1519237.1250],
        [1471828.2500, 1401070.5000, 1381526.5000, 1358595.0000, 1342923.1250,
         1335044.2500, 1315466.1250, 1290832.5000, 1279580.8750, 1276812.6250],
        [1558981.7500, 1558480.8750, 1558034.8750, 1557677.0000, 1553320.0000,
         1551540.3750, 1551293.3750, 1550928.0000, 1550361.6250, 1549621.0000],
        [1469428.5000, 1460442.5000, 1419864.3750, 1410925.8750, 1404299.6250,
         1404112.1250, 1403321.0000, 1402406.0000, 1399085.1250, 1381838.7500],
        [1435645.2500, 1417153.3750, 1380641.3750, 1379168.7500, 1335376.6250,
         1334956.3750, 1319562.2500, 1301008.7500, 1296371.6250, 1270329.2500],
        [1565631.2500, 1561133.0000, 1556177.2500, 1556012.6250, 1555411.6250,
         1549862.0000, 1544333.5000, 1543510.5000, 1543394.2500, 1542387.8750],
        [1578616.6250, 1577584.1250, 1577418.7500, 1576794.5000, 1576366.1250,
         1576313.3750, 1576169.1250, 1576017.2500, 1575507.7500, 1574681.7500],
        [1576984.0000, 1574958.0000, 1573884.3750, 1573560.2500, 1572696.1250,
         1572225.2500, 1572139.7500, 1571275.0000, 1569531.6250, 1569129.1250],
        [1525721.5000, 1521236.3750, 1520525.7500, 1517349.0000, 1514033.1250,
         1508839.7500, 1508625.3750, 1503946.6250, 1503549.3750, 1501307.0000],
        [1503047.6250, 1492807.8750, 1482630.8750, 1481727.6250, 1481490.2500,
         1478591.0000, 1478368.2500, 1478052.5000, 1477698.6250, 1477080.2500],
        [1478921.0000, 1469593.8750, 1462441.2500, 1460066.6250, 1459653.0000,
         1457328.8750, 1454977.7500, 1453125.2500, 1452249.6250, 1450594.1250],
        [1557886.3750, 1556166.8750, 1553908.2500, 1553251.8750, 1551999.2500,
         1551768.3750, 1551067.0000, 1550604.1250, 1549733.3750, 1548926.6250],
        [1556232.2500, 1554118.6250, 1553600.1250, 1552706.8750, 1551571.6250,
         1550450.2500, 1547878.1250, 1547376.3750, 1546118.1250, 1544019.8750],
        [1498490.5000, 1482529.0000, 1475601.8750, 1474517.3750, 1474002.6250,
         1471374.8750, 1466080.2500, 1458580.1250, 1451496.5000, 1447569.0000],
        [1575072.1250, 1574420.3750, 1562375.2500, 1562309.6250, 1561769.0000,
         1559737.2500, 1556420.7500, 1555922.0000, 1547563.8750, 1544891.8750],
        [1580555.3750, 1578165.0000, 1575685.1250, 1575378.6250, 1574702.6250,
         1574645.6250, 1574596.1250, 1573970.0000, 1571820.5000, 1571703.6250],
        [1496906.6250, 1494876.5000, 1483548.8750, 1478736.2500, 1478117.2500,
         1477546.5000, 1473537.5000, 1471502.6250, 1471245.7500, 1470804.0000],
        [1577517.8750, 1573615.7500, 1571355.8750, 1570554.2500, 1569395.3750,
         1568411.0000, 1567977.2500, 1566499.0000, 1565222.2500, 1564570.0000],
        [1566986.1250, 1566068.8750, 1563032.5000, 1562126.5000, 1560985.7500,
         1557399.2500, 1555730.6250, 1554717.6250, 1554520.3750, 1552252.3750],
        [1577125.3750, 1576151.0000, 1575955.6250, 1574825.8750, 1574717.7500,
         1574584.0000, 1574364.7500, 1572481.7500, 1572414.1250, 1571468.2500],
        [1580272.0000, 1579988.7500, 1579464.5000, 1577160.0000, 1576684.7500,
         1576382.6250, 1576263.8750, 1576242.7500, 1576005.2500, 1575913.6250],
        [1581959.3750, 1581087.5000, 1577621.8750, 1576800.5000, 1576438.2500,
         1576367.5000, 1576230.7500, 1575135.2500, 1574624.6250, 1574530.0000],
        [1582051.3750, 1581722.5000, 1581141.7500, 1579755.1250, 1579604.5000,
         1579265.6250, 1578425.3750, 1578326.0000, 1577833.8750, 1576857.7500],
        [1581259.5000, 1579286.7500, 1577811.3750, 1577539.0000, 1577494.0000,
         1577158.5000, 1576650.1250, 1576333.0000, 1576115.0000, 1575922.6250],
        [1347416.8750, 1321073.2500, 1161524.8750, 1053835.2500, 1020243.8125,
          998432.6250,  993541.8750,  951999.9375,  928641.4375,  886341.4375],
        [1522140.6250, 1522111.5000, 1512051.8750, 1511917.8750, 1510485.3750,
         1510204.5000, 1509462.8750, 1507924.8750, 1506996.1250, 1502223.6250],
        [1556350.8750, 1554400.3750, 1553933.5000, 1551358.5000, 1549572.3750,
         1548793.6250, 1548727.2500, 1548601.7500, 1548301.8750, 1547975.6250],
        [1527002.6250, 1522610.8750, 1521679.0000, 1521291.6250, 1519987.8750,
         1519605.2500, 1518323.2500, 1516945.3750, 1516064.5000, 1514378.1250],
        [1290889.1250, 1240058.6250, 1183101.7500, 1131975.7500, 1096975.7500,
         1090461.0000, 1055967.0000, 1048920.1250, 1022266.6875, 1020216.5625],
        [1514140.0000, 1504183.3750, 1499422.5000, 1498699.1250, 1497979.0000,
         1496759.5000, 1495515.3750, 1493663.7500, 1490745.0000, 1489858.1250],
        [1444130.2500, 1431041.3750, 1426763.8750, 1421338.3750, 1416472.3750,
         1407864.0000, 1407305.5000, 1398816.8750, 1397337.0000, 1396202.0000],
        [1515308.5000, 1510847.0000, 1509308.8750, 1507162.8750, 1507162.8750,
         1504542.0000, 1503635.5000, 1503565.1250, 1500245.0000, 1498110.3750],
        [1276291.5000, 1275690.3750, 1268322.2500, 1262911.3750, 1239943.8750,
         1211274.8750, 1209979.6250, 1180972.3750, 1176479.3750, 1153692.2500],
        [1566385.5000, 1563877.8750, 1560909.7500, 1560223.7500, 1559613.8750,
         1559496.2500, 1558415.3750, 1558024.6250, 1557801.6250, 1557476.3750],
        [1559013.0000, 1558914.8750, 1557191.2500, 1553287.3750, 1553259.2500,
         1552789.7500, 1551991.8750, 1551136.6250, 1549822.0000, 1548882.3750],
        [1540435.6250, 1538957.0000, 1535283.3750, 1533136.8750, 1532430.8750,
         1531573.2500, 1526707.0000, 1526344.5000, 1524995.6250, 1524767.3750],
        [1378582.2500, 1320164.0000, 1302222.7500, 1296114.6250, 1287060.0000,
         1269571.0000, 1269238.1250, 1263712.5000, 1257889.2500, 1244730.3750],
        [1298703.1250, 1197633.6250, 1193953.5000, 1188774.8750, 1179999.6250,
         1170896.1250, 1169028.3750, 1160281.6250, 1154860.1250, 1133881.6250],
        [1328398.2500, 1290517.3750, 1098103.1250, 1049714.6250,  918456.3750,
          886240.8750,  847783.9375,  835580.8125,  835527.4375,  834930.8125],
        [1080661.1250, 1025161.4375, 1001507.1875,  985765.8750,  973191.1875,
          946065.4375,  923749.7500,  921273.2500,  913065.2500,  802592.1875],
        [1413517.1250, 1383028.0000, 1377391.6250, 1365026.2500, 1359681.1250,
         1357965.5000, 1355663.5000, 1338196.6250, 1336585.7500, 1336536.0000],
        [1475458.3750, 1475165.6250, 1474297.8750, 1472813.8750, 1467893.5000,
         1460164.0000, 1459575.1250, 1457705.5000, 1456848.1250, 1449342.7500],
        [1419742.5000, 1418872.2500, 1415340.8750, 1403789.5000, 1403630.2500,
         1398422.0000, 1397017.1250, 1394448.1250, 1390290.6250, 1388531.0000],
        [1409223.3750, 1408778.6250, 1381761.0000, 1378512.6250, 1365438.8750,
         1360066.3750, 1335045.5000, 1330127.3750, 1324983.3750, 1324566.3750],
        [1461348.1250, 1441404.5000, 1440908.2500, 1425100.7500, 1418705.7500,
         1415851.1250, 1396847.8750, 1380617.6250, 1377219.6250, 1366702.6250],
        [1392003.3750, 1341475.3750, 1326681.5000, 1324176.1250, 1305912.6250,
         1296758.7500, 1294464.2500, 1291784.3750, 1275913.1250, 1264273.0000],
        [1497711.8750, 1496271.5000, 1494632.6250, 1494369.0000, 1494369.0000,
         1491036.5000, 1488582.7500, 1488436.5000, 1487637.5000, 1474715.6250],
        [1506774.8750, 1495228.6250, 1493836.1250, 1491925.5000, 1487127.0000,
         1459566.7500, 1455853.6250, 1455115.1250, 1451484.0000, 1450502.8750],
        [1476890.1250, 1410819.6250, 1387657.2500, 1385153.1250, 1371833.2500,
         1368728.3750, 1365298.3750, 1360859.0000, 1358757.0000, 1350021.5000],
        [1418416.2500, 1409938.6250, 1404413.5000, 1392175.8750, 1322060.1250,
         1321741.1250, 1315443.6250, 1308026.6250, 1300729.6250, 1298948.3750],
        [1422533.0000, 1414563.6250, 1401421.8750, 1394779.2500, 1357894.2500,
         1357715.5000, 1356765.5000, 1331621.2500, 1310560.1250, 1310318.8750],
        [1527044.7500, 1467780.1250, 1444335.3750, 1441206.5000, 1431932.8750,
         1407025.0000, 1353226.0000, 1350369.2500, 1342453.1250, 1341527.8750],
        [1383314.1250, 1361135.5000, 1357234.0000, 1353501.0000, 1351910.3750,
         1341818.3750, 1333339.2500, 1329679.6250, 1324847.0000, 1311266.5000],
        [1416265.7500, 1397784.7500, 1330996.5000, 1288746.3750, 1274024.7500,
         1264891.6250, 1261118.0000, 1258417.2500, 1247077.1250, 1231400.2500],
        [1436836.8750, 1435750.6250, 1430310.1250, 1422903.5000, 1416516.8750,
         1385936.6250, 1318691.7500, 1316597.0000, 1297249.8750, 1282537.5000],
        [1440989.3750, 1436271.1250, 1429542.3750, 1429517.7500, 1429162.0000,
         1418754.5000, 1410523.5000, 1399404.0000, 1389054.1250, 1380786.1250]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1521876.3750,       0.0000],
         [1521541.1250,       0.0000],
         [1503268.3750,       0.0000],
         ...,
         [1489993.1250,       0.0000],
         [      0.0000, 1488866.6250],
         [1481371.5000,       0.0000]],

        [[1541999.6250,       0.0000],
         [1529201.6250,       0.0000],
         [1528350.2500,       0.0000],
         ...,
         [1522692.2500,       0.0000],
         [1521882.1250,       0.0000],
         [1521877.8750,       0.0000]],

        [[1118674.7500,       0.0000],
         [      0.0000, 1026136.6250],
         [1014305.5000,       0.0000],
         ...,
         [ 956165.3750,       0.0000],
         [ 955438.8750,       0.0000],
         [ 940966.2500,       0.0000]],

        ...,

        [[1416265.7500,       0.0000],
         [1397784.7500,       0.0000],
         [1330996.5000,       0.0000],
         ...,
         [1258417.2500,       0.0000],
         [1247077.1250,       0.0000],
         [1231400.2500,       0.0000]],

        [[1436836.8750,       0.0000],
         [1435750.6250,       0.0000],
         [1430310.1250,       0.0000],
         ...,
         [      0.0000, 1316597.0000],
         [1297249.8750,       0.0000],
         [1282537.5000,       0.0000]],

        [[      0.0000, 1440989.3750],
         [      0.0000, 1436271.1250],
         [      0.0000, 1429542.3750],
         ...,
         [      0.0000, 1399404.0000],
         [1389054.1250,       0.0000],
         [      0.0000, 1380786.1250]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13495178.0000,  1488866.6250],
        [15269678.0000,        0.0000],
        [ 4985551.0000,  4906788.5000],
        [12823464.0000,  1420643.1250],
        [ 9173967.0000,  3847337.0000],
        [10493492.0000,  1163105.5000],
        [ 4984449.5000,  5007817.5000],
        [ 8497152.0000,   833084.0000],
        [13755620.0000,  1521081.1250],
        [12052610.0000,  1401070.5000],
        [15540239.0000,        0.0000],
        [12773885.0000,  1381838.7500],
        [13470214.0000,        0.0000],
        [15517854.0000,        0.0000],
        [15765470.0000,        0.0000],
        [15726383.0000,        0.0000],
        [13599412.0000,  1525721.5000],
        [13328447.0000,  1503047.6250],
        [14598951.0000,        0.0000],
        [15525312.0000,        0.0000],
        [15504072.0000,        0.0000],
        [11778670.0000,  2921571.5000],
        [15600482.0000,        0.0000],
        [15751222.0000,        0.0000],
        [10333794.0000,  4463029.0000],
        [15695118.0000,        0.0000],
        [15593820.0000,        0.0000],
        [15744088.0000,        0.0000],
        [15774379.0000,        0.0000],
        [15770796.0000,        0.0000],
        [15794984.0000,        0.0000],
        [15775570.0000,        0.0000],
        [ 2878316.0000,  7784736.0000],
        [ 9065722.0000,  6049797.5000],
        [12411438.0000,  3096577.5000],
        [10642613.0000,  4555275.0000],
        [ 3166644.5000,  8014188.0000],
        [10490165.0000,  4490801.0000],
        [12748454.0000,  1398816.8750],
        [15059888.0000,        0.0000],
        [ 9739924.0000,  2515634.2500],
        [15602226.0000,        0.0000],
        [15536288.0000,        0.0000],
        [13779348.0000,  1535283.3750],
        [ 2502619.5000, 10386665.0000],
        [ 1188774.8750, 10659238.0000],
        [ 5158520.5000,  4766733.0000],
        [ 2636930.7500,  6936102.0000],
        [ 4080614.5000,  9542977.0000],
        [10231614.0000,  4417650.0000],
        [12626294.0000,  1403789.5000],
        [ 1324983.3750, 12293520.0000],
        [ 1366702.6250, 12758004.0000],
        [ 2650857.5000, 10462584.0000],
        [11919014.0000,  2988748.5000],
        [10258284.0000,  4489130.5000],
        [ 2727485.5000, 11108532.0000],
        [ 5244159.5000,  8247734.0000],
        [ 1310560.1250, 12347612.0000],
        [ 2694754.0000, 11412147.0000],
        [10735052.0000,  2712993.7500],
        [11705830.0000,  1264891.6250],
        [11108042.0000,  2635288.7500],
        [ 1389054.1250, 12774951.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 476/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:16, 56.32s/it]  7%|▋         | 2/29 [00:57<10:46, 23.96s/it] 10%|█         | 3/29 [00:58<05:49, 13.44s/it] 14%|█▍        | 4/29 [00:59<03:32,  8.50s/it] 17%|█▋        | 5/29 [01:00<02:18,  5.77s/it] 21%|██        | 6/29 [01:01<01:34,  4.12s/it] 24%|██▍       | 7/29 [01:02<01:07,  3.07s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.39s/it] 31%|███       | 9/29 [01:04<00:38,  1.93s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.62s/it] 38%|███▊      | 11/29 [01:05<00:25,  1.40s/it] 41%|████▏     | 12/29 [01:06<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:07<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:08<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:09<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:10<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:11<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:12<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:13<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:14<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:17<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:18<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:19<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:20<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:21<00:00,  1.08it/s]100%|██████████| 29/29 [01:22<00:00,  1.08it/s]100%|██████████| 29/29 [01:22<00:00,  2.85s/it]
Epoch loss is 2.787565231323242
Epoch 477/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:17, 58.47s/it]  7%|▋         | 2/29 [00:59<11:04, 24.62s/it] 10%|█         | 3/29 [01:00<06:04, 14.01s/it] 14%|█▍        | 4/29 [01:01<03:41,  8.84s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.99s/it] 21%|██        | 6/29 [01:03<01:38,  4.26s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.45s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:24<00:00,  2.93s/it]
Epoch loss is 2.77821946144104
Epoch 478/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:45, 61.62s/it]  7%|▋         | 2/29 [01:02<11:39, 25.92s/it] 10%|█         | 3/29 [01:03<06:17, 14.50s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.01it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.06it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7573964595794678
Epoch 479/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:57, 59.92s/it]  7%|▋         | 2/29 [01:00<11:21, 25.24s/it] 10%|█         | 3/29 [01:01<06:07, 14.13s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.07it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.97s/it]
Epoch loss is 2.7675282955169678
Epoch 480/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:41, 59.33s/it]  7%|▋         | 2/29 [01:00<11:17, 25.07s/it] 10%|█         | 3/29 [01:01<06:05, 14.05s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.87s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.00s/it] 21%|██        | 6/29 [01:04<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:05<01:09,  3.18s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.03it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.95s/it]
Epoch loss is 2.7689671516418457
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0031, 0.0140, 0.0022,  ..., 0.0040, 0.0001, 0.0193],
        [0.0030, 0.0096, 0.0020,  ..., 0.0020, 0.0001, 0.0184],
        [0.0339, 0.0063, 0.0035,  ..., 0.0053, 0.0155, 0.0244],
        ...,
        [0.0076, 0.0079, 0.0179,  ..., 0.0039, 0.0018, 0.0210],
        [0.0041, 0.0083, 0.0113,  ..., 0.0047, 0.0048, 0.0203],
        [0.0094, 0.0044, 0.0039,  ..., 0.0028, 0.0021, 0.0229]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9962, 0.9961, 0.9954, 0.9951, 0.9949, 0.9946, 0.9946, 0.9946, 0.9946,
         0.9942],
        [0.9974, 0.9967, 0.9967, 0.9967, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965,
         0.9964],
        [0.9772, 0.9691, 0.9687, 0.9679, 0.9675, 0.9670, 0.9668, 0.9659, 0.9653,
         0.9648],
        [0.9935, 0.9925, 0.9921, 0.9920, 0.9918, 0.9912, 0.9908, 0.9895, 0.9894,
         0.9894],
        [0.9879, 0.9868, 0.9862, 0.9847, 0.9846, 0.9840, 0.9838, 0.9837, 0.9837,
         0.9834],
        [0.9842, 0.9829, 0.9805, 0.9777, 0.9761, 0.9752, 0.9751, 0.9734, 0.9733,
         0.9725],
        [0.9805, 0.9713, 0.9707, 0.9679, 0.9671, 0.9656, 0.9646, 0.9646, 0.9629,
         0.9629],
        [0.9757, 0.9751, 0.9689, 0.9683, 0.9613, 0.9569, 0.9568, 0.9562, 0.9552,
         0.9538],
        [0.9974, 0.9968, 0.9968, 0.9965, 0.9964, 0.9964, 0.9963, 0.9963, 0.9962,
         0.9962],
        [0.9935, 0.9898, 0.9883, 0.9873, 0.9867, 0.9860, 0.9842, 0.9833, 0.9831,
         0.9831],
        [0.9981, 0.9981, 0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9933, 0.9924, 0.9908, 0.9904, 0.9904, 0.9901, 0.9901, 0.9899, 0.9897,
         0.9891],
        [0.9909, 0.9907, 0.9881, 0.9870, 0.9861, 0.9850, 0.9839, 0.9827, 0.9819,
         0.9813],
        [0.9984, 0.9982, 0.9980, 0.9980, 0.9980, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9965, 0.9963, 0.9963, 0.9961, 0.9961, 0.9957, 0.9956, 0.9956, 0.9955,
         0.9954],
        [0.9953, 0.9947, 0.9947, 0.9945, 0.9944, 0.9944, 0.9943, 0.9943, 0.9942,
         0.9941],
        [0.9947, 0.9939, 0.9937, 0.9936, 0.9934, 0.9934, 0.9933, 0.9933, 0.9933,
         0.9932],
        [0.9980, 0.9980, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976,
         0.9976],
        [0.9980, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9950, 0.9940, 0.9940, 0.9938, 0.9938, 0.9936, 0.9935, 0.9931, 0.9928,
         0.9926],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9977,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9951, 0.9949, 0.9944, 0.9942, 0.9941, 0.9941, 0.9940, 0.9938, 0.9937,
         0.9937],
        [0.9990, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9984,
         0.9984],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9979,
         0.9979],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988,
         0.9988],
        [0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9882, 0.9867, 0.9779, 0.9712, 0.9688, 0.9661, 0.9661, 0.9643, 0.9637,
         0.9580],
        [0.9964, 0.9963, 0.9960, 0.9960, 0.9959, 0.9958, 0.9957, 0.9957, 0.9956,
         0.9955],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,
         0.9976],
        [0.9966, 0.9964, 0.9963, 0.9963, 0.9963, 0.9962, 0.9962, 0.9962, 0.9960,
         0.9960],
        [0.9850, 0.9821, 0.9788, 0.9757, 0.9738, 0.9730, 0.9709, 0.9709, 0.9685,
         0.9682],
        [0.9960, 0.9954, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9922, 0.9916, 0.9913, 0.9912, 0.9908, 0.9907, 0.9901, 0.9899, 0.9898,
         0.9897],
        [0.9962, 0.9960, 0.9959, 0.9959, 0.9957, 0.9955, 0.9955, 0.9955, 0.9954,
         0.9954],
        [0.9848, 0.9845, 0.9840, 0.9834, 0.9823, 0.9809, 0.9808, 0.9792, 0.9783,
         0.9778],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981, 0.9981,
         0.9981],
        [0.9981, 0.9981, 0.9980, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9976],
        [0.9973, 0.9972, 0.9970, 0.9970, 0.9969, 0.9969, 0.9967, 0.9966, 0.9966,
         0.9966],
        [0.9895, 0.9869, 0.9857, 0.9852, 0.9847, 0.9840, 0.9836, 0.9835, 0.9835,
         0.9826],
        [0.9855, 0.9791, 0.9788, 0.9773, 0.9772, 0.9771, 0.9765, 0.9759, 0.9756,
         0.9754],
        [0.9868, 0.9852, 0.9734, 0.9701, 0.9606, 0.9581, 0.9550, 0.9548, 0.9546,
         0.9543],
        [0.9726, 0.9686, 0.9681, 0.9662, 0.9656, 0.9630, 0.9627, 0.9623, 0.9613,
         0.9523],
        [0.9906, 0.9898, 0.9894, 0.9889, 0.9886, 0.9883, 0.9882, 0.9879, 0.9878,
         0.9873],
        [0.9942, 0.9941, 0.9940, 0.9940, 0.9939, 0.9935, 0.9932, 0.9932, 0.9932,
         0.9927],
        [0.9916, 0.9915, 0.9915, 0.9910, 0.9909, 0.9906, 0.9906, 0.9906, 0.9904,
         0.9904],
        [0.9911, 0.9911, 0.9899, 0.9896, 0.9886, 0.9885, 0.9875, 0.9873, 0.9870,
         0.9869],
        [0.9936, 0.9927, 0.9926, 0.9919, 0.9915, 0.9914, 0.9905, 0.9897, 0.9896,
         0.9890],
        [0.9901, 0.9876, 0.9868, 0.9868, 0.9855, 0.9851, 0.9849, 0.9848, 0.9842,
         0.9833],
        [0.9953, 0.9952, 0.9952, 0.9952, 0.9952, 0.9950, 0.9949, 0.9948, 0.9948,
         0.9942],
        [0.9957, 0.9952, 0.9951, 0.9951, 0.9948, 0.9935, 0.9935, 0.9932, 0.9932,
         0.9932],
        [0.9944, 0.9912, 0.9902, 0.9896, 0.9893, 0.9890, 0.9890, 0.9887, 0.9885,
         0.9882],
        [0.9914, 0.9911, 0.9907, 0.9902, 0.9866, 0.9864, 0.9863, 0.9856, 0.9853,
         0.9853],
        [0.9916, 0.9915, 0.9905, 0.9903, 0.9889, 0.9885, 0.9883, 0.9870, 0.9858,
         0.9857],
        [0.9967, 0.9939, 0.9926, 0.9925, 0.9919, 0.9909, 0.9882, 0.9879, 0.9878,
         0.9875],
        [0.9897, 0.9884, 0.9884, 0.9883, 0.9881, 0.9875, 0.9872, 0.9872, 0.9865,
         0.9861],
        [0.9915, 0.9907, 0.9870, 0.9852, 0.9841, 0.9836, 0.9835, 0.9832, 0.9827,
         0.9820],
        [0.9924, 0.9923, 0.9921, 0.9918, 0.9914, 0.9898, 0.9866, 0.9864, 0.9853,
         0.9845],
        [0.9927, 0.9923, 0.9921, 0.9920, 0.9920, 0.9915, 0.9914, 0.9906, 0.9900,
         0.9897]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1515070.1250, 1513359.0000, 1498566.2500, 1493077.0000, 1487149.6250,
         1482246.2500, 1482058.2500, 1481426.6250, 1480850.2500, 1472302.7500],
        [1541054.2500, 1527483.1250, 1527441.0000, 1526613.7500, 1524562.2500,
         1524039.1250, 1523268.7500, 1521751.6250, 1521280.0000, 1520957.8750],
        [1154931.7500, 1028817.5000, 1023348.5000, 1011531.2500, 1005388.6250,
          998438.3125,  996249.7500,  983552.5625,  974252.5625,  967590.3750],
        [1458250.5000, 1437563.2500, 1429275.1250, 1427798.3750, 1423142.2500,
         1411199.0000, 1403011.8750, 1377230.0000, 1375079.0000, 1375076.3750],
        [1346587.0000, 1324697.8750, 1313146.1250, 1286166.7500, 1284610.0000,
         1272831.0000, 1269624.3750, 1268185.5000, 1267313.8750, 1261681.0000],
        [1276660.5000, 1253569.7500, 1210942.2500, 1163876.7500, 1136651.1250,
         1123644.3750, 1121509.6250, 1094634.8750, 1093303.7500, 1080878.6250],
        [1212053.7500, 1061908.1250, 1053186.1250, 1011360.5000, 1000808.2500,
          978643.1875,  965483.2500,  965476.7500,  941723.0000,  941310.8750],
        [1131707.0000, 1121832.6250, 1026568.3125, 1017094.3125,  920776.9375,
          864117.5625,  863844.8125,  856485.8125,  843718.0625,  827319.3750],
        [1542430.3750, 1529563.2500, 1528172.3750, 1521835.7500, 1520483.6250,
         1519331.3750, 1518549.1250, 1517693.5000, 1516248.2500, 1515544.1250],
        [1459163.1250, 1383906.6250, 1354324.7500, 1335141.0000, 1323095.7500,
         1310673.8750, 1277402.0000, 1261185.3750, 1256412.2500, 1256183.3750],
        [1557525.5000, 1557443.7500, 1556628.5000, 1555948.7500, 1553798.6250,
         1550722.5000, 1549591.5000, 1549485.1250, 1548589.8750, 1548300.3750],
        [1453240.2500, 1434765.2500, 1403204.6250, 1395668.1250, 1394778.0000,
         1389479.3750, 1388356.1250, 1385741.1250, 1381016.6250, 1369754.6250],
        [1405217.3750, 1400761.8750, 1349672.6250, 1328522.5000, 1311255.2500,
         1291770.8750, 1271479.5000, 1249815.5000, 1236473.5000, 1225807.8750],
        [1564262.7500, 1560098.7500, 1555945.7500, 1555172.8750, 1554324.7500,
         1547125.5000, 1542830.6250, 1539921.5000, 1539711.5000, 1539146.3750],
        [1578345.6250, 1577235.2500, 1577193.1250, 1576615.6250, 1576415.7500,
         1575933.1250, 1575822.0000, 1575578.5000, 1575001.6250, 1574545.0000],
        [1576719.3750, 1574650.1250, 1573677.2500, 1572249.2500, 1572202.7500,
         1571824.8750, 1571778.5000, 1571351.2500, 1568810.2500, 1568802.8750],
        [1523081.5000, 1518452.1250, 1516919.2500, 1514024.5000, 1513068.8750,
         1504477.5000, 1502693.6250, 1502060.2500, 1500030.5000, 1498471.8750],
        [1497400.5000, 1483696.0000, 1482608.1250, 1479320.2500, 1477023.8750,
         1476990.0000, 1475745.3750, 1474660.7500, 1473807.2500, 1470597.7500],
        [1483155.5000, 1466515.1250, 1461647.8750, 1461168.3750, 1456503.5000,
         1455376.1250, 1455055.5000, 1454356.3750, 1453559.0000, 1452814.7500],
        [1556340.5000, 1554547.1250, 1552868.2500, 1551956.3750, 1550812.6250,
         1550477.0000, 1549822.0000, 1548612.1250, 1547367.5000, 1546783.3750],
        [1554765.0000, 1551303.7500, 1550706.1250, 1550057.0000, 1549464.3750,
         1548572.1250, 1546082.7500, 1544822.6250, 1543225.0000, 1542096.5000],
        [1490057.0000, 1469858.8750, 1469804.2500, 1464582.1250, 1464097.7500,
         1460444.0000, 1458374.2500, 1450349.3750, 1444015.8750, 1439179.1250],
        [1575285.5000, 1573506.2500, 1563034.0000, 1562807.3750, 1562102.6250,
         1559139.3750, 1555564.3750, 1554862.8750, 1548470.3750, 1544654.7500],
        [1580475.5000, 1577343.5000, 1574761.2500, 1574683.1250, 1574088.6250,
         1573843.8750, 1573807.8750, 1572682.6250, 1572189.2500, 1570828.3750],
        [1493153.8750, 1487074.3750, 1476538.0000, 1472530.2500, 1470652.3750,
         1470587.8750, 1468992.7500, 1465364.6250, 1463616.0000, 1461903.0000],
        [1577169.0000, 1573228.6250, 1571639.0000, 1570334.2500, 1569067.6250,
         1568773.0000, 1567446.3750, 1566269.0000, 1565114.7500, 1565068.5000],
        [1567211.7500, 1566068.8750, 1564080.7500, 1562931.1250, 1560353.2500,
         1557477.8750, 1554994.8750, 1554465.6250, 1554020.8750, 1552139.8750],
        [1576972.0000, 1575497.3750, 1575434.2500, 1574379.8750, 1574324.3750,
         1573210.6250, 1572681.1250, 1571949.3750, 1571412.8750, 1570948.3750],
        [1579991.7500, 1579438.8750, 1579223.5000, 1576456.2500, 1576308.8750,
         1576298.3750, 1576280.3750, 1575924.0000, 1575742.2500, 1575731.7500],
        [1581349.8750, 1580882.5000, 1576544.8750, 1576301.3750, 1576003.7500,
         1575909.0000, 1575641.6250, 1575408.7500, 1573909.8750, 1573890.3750],
        [1581546.0000, 1581437.5000, 1580474.0000, 1579566.8750, 1579164.7500,
         1578354.7500, 1578092.7500, 1577921.2500, 1576821.6250, 1576785.5000],
        [1580927.7500, 1578709.8750, 1576956.8750, 1576486.2500, 1576310.5000,
         1576280.3750, 1576188.6250, 1575769.3750, 1575417.7500, 1575348.6250],
        [1351317.3750, 1322523.0000, 1166696.1250, 1059835.1250, 1025401.9375,
          986547.3750,  985686.0000,  961058.1250,  952213.3125,  878045.2500],
        [1520201.0000, 1516958.3750, 1512474.5000, 1510916.1250, 1508898.7500,
         1507942.1250, 1505375.8750, 1504948.1250, 1502306.7500, 1501384.3750],
        [1556027.3750, 1554593.1250, 1553112.7500, 1550868.8750, 1549191.1250,
         1548204.5000, 1547865.0000, 1547512.1250, 1546960.3750, 1546811.3750],
        [1523741.0000, 1519524.1250, 1517719.5000, 1517499.6250, 1517457.6250,
         1516060.2500, 1514769.6250, 1514700.2500, 1511942.3750, 1511557.5000],
        [1291572.5000, 1240098.7500, 1182377.7500, 1130300.3750, 1100508.1250,
         1087908.7500, 1055932.7500, 1055753.5000, 1020046.2500, 1015932.9375],
        [1510482.5000, 1498081.8750, 1496251.3750, 1494987.6250, 1492489.0000,
         1490557.3750, 1490185.0000, 1489998.7500, 1487387.8750, 1487108.5000],
        [1431000.5000, 1419880.5000, 1413676.1250, 1411831.7500, 1402954.3750,
         1400421.3750, 1390160.6250, 1385459.5000, 1383768.0000, 1380700.5000],
        [1515379.3750, 1510897.3750, 1508674.2500, 1508674.2500, 1505019.8750,
         1501690.7500, 1500960.6250, 1499887.3750, 1499418.2500, 1499029.2500],
        [1287996.8750, 1282190.2500, 1273450.2500, 1262265.8750, 1242557.6250,
         1218094.5000, 1216516.8750, 1189443.8750, 1174499.5000, 1164931.6250],
        [1565317.7500, 1563766.0000, 1559848.7500, 1559416.0000, 1558749.8750,
         1558736.5000, 1558519.5000, 1557354.5000, 1556871.8750, 1556607.7500],
        [1557923.6250, 1556638.8750, 1555647.6250, 1551670.6250, 1550999.0000,
         1550274.3750, 1549896.0000, 1549692.0000, 1548019.8750, 1547184.6250],
        [1540337.2500, 1537888.8750, 1534014.3750, 1533211.5000, 1531449.1250,
         1530711.7500, 1526247.0000, 1525437.7500, 1525114.8750, 1524889.5000],
        [1376846.6250, 1326329.8750, 1304419.0000, 1295672.1250, 1286502.8750,
         1272440.1250, 1266127.5000, 1264349.0000, 1263952.3750, 1247990.8750],
        [1301209.8750, 1187641.6250, 1182305.5000, 1157056.1250, 1154989.0000,
         1154342.6250, 1144443.3750, 1133751.8750, 1130004.0000, 1125906.6250],
        [1325927.6250, 1296072.5000, 1093665.5000, 1043894.5000,  911608.7500,
          879121.0625,  841825.2500,  839614.7500,  836770.5625,  833123.6875],
        [1081437.5000, 1022081.4375, 1014536.8125,  986793.9375,  978487.3750,
          942959.5625,  939493.0000,  934339.1875,  920835.7500,  809333.8125],
        [1398997.0000, 1383640.0000, 1375391.1250, 1365997.7500, 1359710.8750,
         1353288.0000, 1351545.5000, 1345472.7500, 1343652.0000, 1334177.5000],
        [1473071.0000, 1471353.8750, 1468878.0000, 1468454.8750, 1466892.8750,
         1457687.5000, 1452965.7500, 1451993.3750, 1451479.7500, 1442306.5000],
        [1419447.3750, 1418086.2500, 1417204.7500, 1406405.2500, 1406107.6250,
         1398906.2500, 1398508.7500, 1398316.7500, 1394969.5000, 1394246.0000],
        [1409560.7500, 1409087.6250, 1385425.2500, 1380341.1250, 1359768.0000,
         1357200.2500, 1339324.0000, 1334801.1250, 1329725.3750, 1326463.8750],
        [1461410.8750, 1440963.2500, 1440180.1250, 1425043.6250, 1416977.7500,
         1415307.1250, 1396886.6250, 1382162.8750, 1379842.2500, 1367282.8750],
        [1389786.8750, 1340590.3750, 1325950.3750, 1325772.1250, 1300873.6250,
         1293422.7500, 1289931.6250, 1288229.0000, 1277404.5000, 1259820.8750],
        [1496749.5000, 1494591.3750, 1494591.3750, 1494250.7500, 1494249.3750,
         1490914.2500, 1486928.3750, 1485627.2500, 1485426.1250, 1473839.6250],
        [1505727.6250, 1494200.8750, 1493181.0000, 1492674.1250, 1484785.8750,
         1458769.3750, 1457969.7500, 1452337.0000, 1452337.0000, 1451820.3750],
        [1476285.8750, 1411348.3750, 1390261.3750, 1379708.1250, 1373465.6250,
         1368147.6250, 1367743.1250, 1361393.8750, 1356947.8750, 1352706.0000],
        [1415605.5000, 1408523.3750, 1400624.2500, 1391050.5000, 1321882.3750,
         1317295.3750, 1314948.2500, 1302878.6250, 1297072.8750, 1296940.5000],
        [1420121.6250, 1416562.8750, 1396524.2500, 1392829.3750, 1366538.3750,
         1358164.8750, 1354642.5000, 1329918.1250, 1307338.2500, 1304911.7500],
        [1527543.0000, 1467669.5000, 1440009.8750, 1437623.6250, 1425811.6250,
         1404331.8750, 1351530.0000, 1346354.6250, 1344246.7500, 1338381.7500],
        [1382312.0000, 1356636.0000, 1356376.1250, 1353040.2500, 1350513.5000,
         1338983.0000, 1333018.8750, 1332726.5000, 1319767.3750, 1311381.5000],
        [1417581.8750, 1401488.7500, 1329944.7500, 1295008.7500, 1275195.3750,
         1266268.7500, 1264884.3750, 1259055.8750, 1249683.1250, 1237208.2500],
        [1435241.5000, 1433016.1250, 1429376.0000, 1423415.1250, 1414790.2500,
         1384214.1250, 1321542.0000, 1317149.6250, 1297849.8750, 1281993.3750],
        [1440986.6250, 1432934.2500, 1428964.5000, 1427810.6250, 1427698.8750,
         1416672.3750, 1414849.5000, 1400218.2500, 1387932.5000, 1381231.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1515070.1250,       0.0000],
         [1513359.0000,       0.0000],
         [1498566.2500,       0.0000],
         ...,
         [1481426.6250,       0.0000],
         [1480850.2500,       0.0000],
         [1472302.7500,       0.0000]],

        [[1541054.2500,       0.0000],
         [1527483.1250,       0.0000],
         [1527441.0000,       0.0000],
         ...,
         [1521751.6250,       0.0000],
         [1521280.0000,       0.0000],
         [1520957.8750,       0.0000]],

        [[1154931.7500,       0.0000],
         [1028817.5000,       0.0000],
         [      0.0000, 1023348.5000],
         ...,
         [ 983552.5625,       0.0000],
         [ 974252.5625,       0.0000],
         [ 967590.3750,       0.0000]],

        ...,

        [[1417581.8750,       0.0000],
         [1401488.7500,       0.0000],
         [1329944.7500,       0.0000],
         ...,
         [1259055.8750,       0.0000],
         [1249683.1250,       0.0000],
         [      0.0000, 1237208.2500]],

        [[1435241.5000,       0.0000],
         [1433016.1250,       0.0000],
         [1429376.0000,       0.0000],
         ...,
         [      0.0000, 1317149.6250],
         [1297849.8750,       0.0000],
         [1281993.3750,       0.0000]],

        [[      0.0000, 1440986.6250],
         [      0.0000, 1432934.2500],
         [      0.0000, 1428964.5000],
         ...,
         [      0.0000, 1400218.2500],
         [1387932.5000,       0.0000],
         [      0.0000, 1381231.2500]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13423860.0000,  1482246.2500],
        [15258452.0000,        0.0000],
        [ 5109144.5000,  5034956.5000],
        [12706426.0000,  1411199.0000],
        [ 9089720.0000,  3805123.7500],
        [ 9298491.0000,  2257180.5000],
        [ 5009488.5000,  5122465.0000],
        [ 8609347.0000,   864117.5625],
        [13711301.0000,  1518549.1250],
        [11833582.0000,  1383906.6250],
        [15528034.0000,        0.0000],
        [13996004.0000,        0.0000],
        [13070776.0000,        0.0000],
        [15498540.0000,        0.0000],
        [15762685.0000,        0.0000],
        [15722066.0000,        0.0000],
        [13570199.0000,  1523081.5000],
        [11823851.0000,  2967998.2500],
        [14600153.0000,        0.0000],
        [15509586.0000,        0.0000],
        [15481096.0000,        0.0000],
        [13146666.0000,  1464097.7500],
        [15599426.0000,        0.0000],
        [15744704.0000,        0.0000],
        [10277655.0000,  4452758.5000],
        [15694109.0000,        0.0000],
        [15593745.0000,        0.0000],
        [15736811.0000,        0.0000],
        [15771396.0000,        0.0000],
        [15765842.0000,        0.0000],
        [15790165.0000,        0.0000],
        [15768396.0000,        0.0000],
        [ 2850278.5000,  7839045.0000],
        [ 9052659.0000,  6038747.0000],
        [12406674.0000,  3094472.5000],
        [12135914.0000,  3029057.0000],
        [ 3176487.2500,  8003945.0000],
        [11949450.0000,  2988080.5000],
        [12629693.0000,  1390160.6250],
        [15049630.0000,        0.0000],
        [ 9787199.0000,  2524748.0000],
        [15595188.0000,        0.0000],
        [15517946.0000,        0.0000],
        [13775288.0000,  1534014.3750],
        [ 2511943.2500, 10392687.0000],
        [ 1154989.0000, 10516662.0000],
        [ 5142064.0000,  4759560.0000],
        [ 2664508.7500,  6965790.0000],
        [ 4078754.0000,  9533118.0000],
        [10196242.0000,  4408842.0000],
        [12645793.0000,  1406405.2500],
        [       0.0000, 13631697.0000],
        [ 1367282.8750, 12758774.0000],
        [ 2651722.5000, 10440060.0000],
        [11909504.0000,  2987663.7500],
        [10259089.0000,  4484714.5000],
        [ 2724691.0000, 11113317.0000],
        [ 5236650.0000,  8230171.5000],
        [ 1304911.7500, 12342640.0000],
        [ 2695776.7500, 11387725.0000],
        [10719716.0000,  2715038.5000],
        [10492842.0000,  2503477.0000],
        [11099896.0000,  2638691.5000],
        [ 1387932.5000, 12771367.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 481/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:24, 60.88s/it]  7%|▋         | 2/29 [01:01<11:31, 25.61s/it] 10%|█         | 3/29 [01:02<06:12, 14.34s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.04s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.11s/it] 21%|██        | 6/29 [01:05<01:39,  4.35s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:40,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:10<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  3.00s/it]
Epoch loss is 2.793038845062256
Epoch 482/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:27, 56.68s/it]  7%|▋         | 2/29 [00:58<10:58, 24.39s/it] 10%|█         | 3/29 [00:59<05:55, 13.67s/it] 14%|█▍        | 4/29 [01:00<03:35,  8.64s/it] 17%|█▋        | 5/29 [01:01<02:20,  5.86s/it] 21%|██        | 6/29 [01:02<01:36,  4.18s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.11s/it] 28%|██▊       | 8/29 [01:03<00:50,  2.41s/it] 31%|███       | 9/29 [01:04<00:38,  1.95s/it] 34%|███▍      | 10/29 [01:05<00:30,  1.63s/it] 38%|███▊      | 11/29 [01:06<00:25,  1.41s/it] 41%|████▏     | 12/29 [01:07<00:21,  1.26s/it] 45%|████▍     | 13/29 [01:08<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:09<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:10<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:15<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:16<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:17<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:18<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:19<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:20<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:21<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:22<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  1.09it/s]100%|██████████| 29/29 [01:23<00:00,  2.88s/it]
Epoch loss is 2.787060499191284
Epoch 483/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:41, 59.33s/it]  7%|▋         | 2/29 [01:00<11:14, 24.97s/it] 10%|█         | 3/29 [01:02<06:16, 14.50s/it] 14%|█▍        | 4/29 [01:03<03:48,  9.14s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.17s/it] 21%|██        | 6/29 [01:05<01:40,  4.39s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.7776572704315186
Epoch 484/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<27:00, 57.89s/it]  7%|▋         | 2/29 [01:02<11:57, 26.59s/it] 10%|█         | 3/29 [01:03<06:26, 14.87s/it] 14%|█▍        | 4/29 [01:04<03:54,  9.36s/it] 17%|█▋        | 5/29 [01:05<02:31,  6.32s/it] 21%|██        | 6/29 [01:06<01:43,  4.48s/it] 24%|██▍       | 7/29 [01:07<01:13,  3.32s/it] 28%|██▊       | 8/29 [01:08<00:53,  2.56s/it] 31%|███       | 9/29 [01:09<00:40,  2.04s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.70s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.46s/it] 41%|████▏     | 12/29 [01:11<00:22,  1.30s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7757205963134766
Epoch 485/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:20, 60.72s/it]  7%|▋         | 2/29 [01:01<11:29, 25.54s/it] 10%|█         | 3/29 [01:02<06:11, 14.30s/it] 14%|█▍        | 4/29 [01:03<03:45,  9.02s/it] 17%|█▋        | 5/29 [01:04<02:26,  6.10s/it] 21%|██        | 6/29 [01:05<01:39,  4.34s/it] 24%|██▍       | 7/29 [01:06<01:10,  3.22s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.49s/it] 31%|███       | 9/29 [01:08<00:39,  2.00s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.772805690765381
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0034, 0.0150, 0.0025,  ..., 0.0042, 0.0002, 0.0192],
        [0.0035, 0.0100, 0.0022,  ..., 0.0023, 0.0001, 0.0187],
        [0.0333, 0.0065, 0.0034,  ..., 0.0051, 0.0153, 0.0245],
        ...,
        [0.0080, 0.0082, 0.0190,  ..., 0.0039, 0.0018, 0.0207],
        [0.0046, 0.0087, 0.0128,  ..., 0.0052, 0.0053, 0.0201],
        [0.0099, 0.0045, 0.0043,  ..., 0.0030, 0.0022, 0.0231]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9959, 0.9958, 0.9949, 0.9948, 0.9947, 0.9945, 0.9943, 0.9943, 0.9942,
         0.9938],
        [0.9972, 0.9967, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9763, 0.9687, 0.9686, 0.9674, 0.9665, 0.9663, 0.9663, 0.9652, 0.9647,
         0.9638],
        [0.9929, 0.9924, 0.9922, 0.9916, 0.9911, 0.9904, 0.9901, 0.9894, 0.9890,
         0.9886],
        [0.9881, 0.9871, 0.9862, 0.9846, 0.9841, 0.9840, 0.9838, 0.9832, 0.9831,
         0.9831],
        [0.9838, 0.9837, 0.9808, 0.9762, 0.9751, 0.9746, 0.9744, 0.9741, 0.9724,
         0.9722],
        [0.9813, 0.9690, 0.9689, 0.9687, 0.9674, 0.9670, 0.9656, 0.9655, 0.9639,
         0.9638],
        [0.9756, 0.9737, 0.9699, 0.9664, 0.9608, 0.9573, 0.9572, 0.9561, 0.9558,
         0.9539],
        [0.9973, 0.9967, 0.9966, 0.9965, 0.9963, 0.9961, 0.9961, 0.9961, 0.9961,
         0.9961],
        [0.9937, 0.9896, 0.9884, 0.9878, 0.9862, 0.9855, 0.9844, 0.9841, 0.9829,
         0.9825],
        [0.9979, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9934, 0.9932, 0.9912, 0.9909, 0.9899, 0.9898, 0.9898, 0.9896, 0.9895,
         0.9894],
        [0.9910, 0.9897, 0.9877, 0.9876, 0.9859, 0.9858, 0.9853, 0.9842, 0.9839,
         0.9822],
        [0.9983, 0.9981, 0.9979, 0.9979, 0.9978, 0.9976, 0.9972, 0.9971, 0.9971,
         0.9971],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9964, 0.9962, 0.9961, 0.9960, 0.9959, 0.9955, 0.9954, 0.9953, 0.9952,
         0.9952],
        [0.9951, 0.9945, 0.9944, 0.9943, 0.9943, 0.9942, 0.9940, 0.9940, 0.9940,
         0.9939],
        [0.9943, 0.9934, 0.9933, 0.9933, 0.9933, 0.9932, 0.9932, 0.9930, 0.9930,
         0.9930],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9973, 0.9973, 0.9972,
         0.9971],
        [0.9949, 0.9942, 0.9939, 0.9939, 0.9938, 0.9935, 0.9932, 0.9928, 0.9927,
         0.9925],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9976,
         0.9975],
        [0.9990, 0.9989, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9949, 0.9948, 0.9944, 0.9942, 0.9939, 0.9937, 0.9937, 0.9937, 0.9936,
         0.9936],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9986, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9984, 0.9983, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987,
         0.9986],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9879, 0.9869, 0.9772, 0.9704, 0.9687, 0.9678, 0.9675, 0.9644, 0.9642,
         0.9609],
        [0.9962, 0.9961, 0.9958, 0.9957, 0.9956, 0.9956, 0.9954, 0.9954, 0.9953,
         0.9953],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9976],
        [0.9964, 0.9962, 0.9962, 0.9961, 0.9961, 0.9959, 0.9959, 0.9959, 0.9958,
         0.9958],
        [0.9853, 0.9824, 0.9795, 0.9757, 0.9747, 0.9725, 0.9723, 0.9713, 0.9684,
         0.9676],
        [0.9956, 0.9951, 0.9951, 0.9948, 0.9948, 0.9947, 0.9947, 0.9946, 0.9946,
         0.9945],
        [0.9925, 0.9917, 0.9914, 0.9910, 0.9909, 0.9906, 0.9900, 0.9900, 0.9898,
         0.9897],
        [0.9959, 0.9956, 0.9955, 0.9955, 0.9953, 0.9952, 0.9951, 0.9950, 0.9950,
         0.9949],
        [0.9856, 0.9846, 0.9843, 0.9839, 0.9822, 0.9811, 0.9810, 0.9802, 0.9788,
         0.9781],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979,
         0.9979],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9975, 0.9975,
         0.9974],
        [0.9971, 0.9970, 0.9968, 0.9967, 0.9966, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9892, 0.9866, 0.9853, 0.9849, 0.9842, 0.9838, 0.9836, 0.9832, 0.9830,
         0.9824],
        [0.9865, 0.9794, 0.9789, 0.9781, 0.9767, 0.9767, 0.9764, 0.9760, 0.9760,
         0.9760],
        [0.9868, 0.9861, 0.9742, 0.9711, 0.9610, 0.9599, 0.9566, 0.9559, 0.9557,
         0.9555],
        [0.9727, 0.9686, 0.9672, 0.9665, 0.9658, 0.9641, 0.9631, 0.9621, 0.9617,
         0.9553],
        [0.9902, 0.9893, 0.9889, 0.9886, 0.9880, 0.9879, 0.9877, 0.9875, 0.9867,
         0.9866],
        [0.9938, 0.9938, 0.9937, 0.9935, 0.9933, 0.9930, 0.9927, 0.9927, 0.9926,
         0.9922],
        [0.9915, 0.9912, 0.9909, 0.9907, 0.9906, 0.9904, 0.9897, 0.9896, 0.9895,
         0.9893],
        [0.9909, 0.9908, 0.9894, 0.9893, 0.9886, 0.9883, 0.9871, 0.9870, 0.9865,
         0.9864],
        [0.9937, 0.9928, 0.9928, 0.9919, 0.9916, 0.9914, 0.9905, 0.9897, 0.9893,
         0.9890],
        [0.9900, 0.9876, 0.9870, 0.9862, 0.9858, 0.9855, 0.9853, 0.9847, 0.9842,
         0.9833],
        [0.9951, 0.9950, 0.9950, 0.9949, 0.9949, 0.9949, 0.9944, 0.9943, 0.9942,
         0.9938],
        [0.9955, 0.9948, 0.9947, 0.9945, 0.9944, 0.9929, 0.9929, 0.9928, 0.9928,
         0.9927],
        [0.9943, 0.9912, 0.9900, 0.9899, 0.9891, 0.9890, 0.9888, 0.9886, 0.9885,
         0.9879],
        [0.9915, 0.9911, 0.9908, 0.9903, 0.9865, 0.9864, 0.9862, 0.9857, 0.9852,
         0.9852],
        [0.9918, 0.9912, 0.9908, 0.9907, 0.9886, 0.9885, 0.9884, 0.9870, 0.9860,
         0.9854],
        [0.9967, 0.9938, 0.9925, 0.9925, 0.9920, 0.9907, 0.9883, 0.9881, 0.9880,
         0.9874],
        [0.9898, 0.9887, 0.9882, 0.9881, 0.9880, 0.9876, 0.9871, 0.9870, 0.9866,
         0.9865],
        [0.9914, 0.9909, 0.9865, 0.9851, 0.9840, 0.9834, 0.9833, 0.9831, 0.9821,
         0.9816],
        [0.9920, 0.9920, 0.9916, 0.9915, 0.9910, 0.9893, 0.9859, 0.9855, 0.9850,
         0.9841],
        [0.9924, 0.9920, 0.9919, 0.9918, 0.9918, 0.9914, 0.9912, 0.9905, 0.9898,
         0.9893]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1508783.6250, 1508025.5000, 1487569.5000, 1485631.3750, 1483048.0000,
         1478991.5000, 1475331.6250, 1474444.1250, 1473848.1250, 1465198.2500],
        [1536817.1250, 1525659.0000, 1522749.0000, 1522184.1250, 1521956.2500,
         1521544.0000, 1520615.7500, 1519264.7500, 1518198.6250, 1517941.0000],
        [1140463.3750, 1022858.6250, 1022353.4375, 1004320.0625,  992045.8750,
          989427.8125,  988335.7500,  973072.3125,  966417.3125,  954111.3125],
        [1446318.8750, 1435092.3750, 1431640.6250, 1419187.5000, 1409868.6250,
         1395414.0000, 1388406.5000, 1375170.7500, 1368068.0000, 1359637.0000],
        [1350115.5000, 1331899.3750, 1313883.8750, 1285062.0000, 1275274.5000,
         1272722.8750, 1269546.8750, 1259161.5000, 1257046.2500, 1256743.0000],
        [1270002.1250, 1267090.2500, 1216786.0000, 1138629.0000, 1121993.2500,
         1113748.2500, 1109393.3750, 1105871.6250, 1078420.8750, 1075343.0000],
        [1224939.6250, 1027797.6250, 1025817.6250, 1024026.0000, 1004818.3125,
          999310.9375,  979184.6250,  977370.0625,  955407.8750,  954810.3750],
        [1129642.0000, 1098480.2500, 1041697.6875,  989578.7500,  913730.8125,
          869781.8750,  868622.1875,  854927.9375,  851516.1250,  828589.8125],
        [1540625.1250, 1525977.6250, 1524853.1250, 1521304.6250, 1517247.7500,
         1514210.7500, 1514033.1250, 1513940.6250, 1513849.7500, 1512740.0000],
        [1462445.3750, 1379821.2500, 1355408.8750, 1344239.0000, 1313519.2500,
         1300660.2500, 1279771.3750, 1275021.5000, 1253868.6250, 1246000.1250],
        [1554010.5000, 1553908.2500, 1552473.0000, 1551442.8750, 1548307.8750,
         1546408.6250, 1545966.3750, 1545502.0000, 1544723.8750, 1543780.0000],
        [1455696.7500, 1452903.5000, 1410572.0000, 1406075.3750, 1384421.3750,
         1383620.2500, 1383158.5000, 1379634.5000, 1377593.8750, 1375704.7500],
        [1406240.2500, 1381534.3750, 1342003.8750, 1340798.7500, 1308344.7500,
         1306395.8750, 1296356.8750, 1276593.5000, 1270706.1250, 1241797.0000],
        [1562594.3750, 1557963.6250, 1552594.3750, 1551963.6250, 1550333.5000,
         1545776.1250, 1537085.3750, 1536304.2500, 1535951.2500, 1535229.2500],
        [1576492.2500, 1575551.3750, 1575058.6250, 1575010.6250, 1574940.0000,
         1574686.1250, 1574105.1250, 1574090.1250, 1573761.3750, 1572895.6250],
        [1574967.0000, 1572325.6250, 1571651.1250, 1570747.5000, 1569473.2500,
         1569230.7500, 1567358.2500, 1566508.0000, 1566472.1250, 1566037.5000],
        [1519503.7500, 1516411.6250, 1514267.1250, 1510799.3750, 1509129.0000,
         1499874.5000, 1498119.0000, 1496659.6250, 1495084.6250, 1494283.6250],
        [1491340.7500, 1479457.1250, 1476312.7500, 1475661.0000, 1475157.2500,
         1472938.8750, 1469682.1250, 1469404.6250, 1468278.5000, 1467172.7500],
        [1476217.0000, 1455528.7500, 1455144.2500, 1454662.7500, 1453932.0000,
         1452985.2500, 1452634.7500, 1448165.5000, 1447896.3750, 1447037.7500],
        [1552033.3750, 1549384.6250, 1549220.6250, 1547865.0000, 1547611.0000,
         1545668.5000, 1544880.0000, 1544625.2500, 1541655.5000, 1541473.1250],
        [1549634.3750, 1547693.7500, 1547436.8750, 1546753.8750, 1545354.6250,
         1544352.7500, 1540722.1250, 1539487.0000, 1538120.6250, 1536138.6250],
        [1488604.0000, 1474008.3750, 1466786.5000, 1466249.5000, 1465465.2500,
         1458051.7500, 1452666.5000, 1443220.1250, 1440812.0000, 1437778.6250],
        [1574534.5000, 1572388.6250, 1562098.1250, 1562016.2500, 1561871.7500,
         1558082.5000, 1555445.7500, 1553846.1250, 1546998.7500, 1544237.8750],
        [1578130.5000, 1575242.0000, 1571994.3750, 1571937.3750, 1571765.0000,
         1571327.3750, 1571288.5000, 1571042.7500, 1569817.6250, 1568482.7500],
        [1487880.2500, 1486639.1250, 1476643.6250, 1473027.5000, 1466947.5000,
         1463544.7500, 1462961.5000, 1461923.8750, 1461214.3750, 1459765.8750],
        [1575879.0000, 1572633.1250, 1570352.1250, 1569554.0000, 1568102.8750,
         1567600.3750, 1564880.3750, 1564511.8750, 1563230.7500, 1563180.1250],
        [1566074.7500, 1565107.2500, 1563921.1250, 1561895.6250, 1558688.8750,
         1558281.6250, 1553213.3750, 1552776.5000, 1552336.7500, 1551948.8750],
        [1575755.7500, 1574608.1250, 1573689.3750, 1573017.1250, 1572489.1250,
         1572004.7500, 1571777.0000, 1570720.5000, 1570120.0000, 1569720.3750],
        [1578061.2500, 1578020.5000, 1577029.1250, 1575178.8750, 1574795.8750,
         1574204.1250, 1574135.1250, 1574081.1250, 1573731.3750, 1573233.1250],
        [1580300.6250, 1579303.2500, 1574644.1250, 1574234.2500, 1574184.6250,
         1574127.6250, 1573857.3750, 1573498.7500, 1572315.2500, 1572012.3750],
        [1579579.0000, 1579550.3750, 1579502.1250, 1577561.6250, 1577351.0000,
         1576756.8750, 1576381.0000, 1575763.2500, 1575739.2500, 1575617.5000],
        [1578880.1250, 1577494.0000, 1575640.0000, 1575153.3750, 1574427.8750,
         1574199.7500, 1574190.6250, 1574123.1250, 1573853.0000, 1573765.8750],
        [1345902.7500, 1327102.8750, 1156177.1250, 1048779.1250, 1023237.1875,
         1010271.1875, 1006186.6875,  962603.7500,  959817.9375,  914893.1250],
        [1515369.2500, 1514270.0000, 1507207.3750, 1505984.6250, 1503380.1250,
         1502758.1250, 1499112.2500, 1498091.8750, 1497302.0000, 1496753.8750],
        [1553853.3750, 1552764.6250, 1550289.1250, 1546925.0000, 1546329.0000,
         1545972.2500, 1545810.0000, 1545472.5000, 1545298.5000, 1545278.0000],
        [1520258.8750, 1516259.7500, 1515051.3750, 1513263.6250, 1513230.5000,
         1509847.3750, 1509725.0000, 1508224.0000, 1507690.5000, 1506445.7500],
        [1297248.5000, 1244659.2500, 1194812.5000, 1130204.3750, 1115351.1250,
         1081040.5000, 1077041.5000, 1062752.0000, 1018258.8750, 1007925.0000],
        [1503216.8750, 1492944.6250, 1491410.5000, 1485757.5000, 1485547.8750,
         1484153.0000, 1482950.3750, 1482360.7500, 1481900.0000, 1479364.0000],
        [1436716.3750, 1420473.7500, 1415405.6250, 1407047.8750, 1405706.6250,
         1399741.6250, 1386928.2500, 1386815.8750, 1383816.7500, 1381535.7500],
        [1509490.2500, 1502110.3750, 1500489.6250, 1500489.6250, 1496720.8750,
         1493924.3750, 1492010.8750, 1490629.8750, 1490396.7500, 1488723.3750],
        [1303657.8750, 1283997.5000, 1278777.0000, 1272197.5000, 1240844.1250,
         1221755.7500, 1220485.2500, 1205713.0000, 1182169.0000, 1170589.0000],
        [1562201.0000, 1560406.7500, 1556622.5000, 1556195.0000, 1555359.7500,
         1555342.0000, 1554615.3750, 1552979.3750, 1552896.3750, 1552703.8750],
        [1554129.1250, 1553853.3750, 1550916.2500, 1546750.8750, 1545804.1250,
         1545699.5000, 1545288.2500, 1544354.2500, 1543479.6250, 1542767.2500],
        [1535981.8750, 1532601.8750, 1528405.5000, 1527608.5000, 1524947.6250,
         1524104.3750, 1521854.6250, 1520544.6250, 1519525.5000, 1517978.6250],
        [1371887.0000, 1320874.1250, 1297716.2500, 1290160.5000, 1277820.0000,
         1269734.6250, 1265761.7500, 1258500.1250, 1255947.5000, 1243899.7500],
        [1318885.5000, 1192834.8750, 1183785.7500, 1169927.2500, 1146654.5000,
         1146526.6250, 1141711.5000, 1136228.3750, 1135732.2500, 1135263.3750],
        [1325978.2500, 1311810.5000, 1106884.6250, 1058778.3750,  916116.3125,
          902109.3750,  860944.0625,  851936.0625,  849829.5000,  847741.0625],
        [1083564.1250, 1021738.4375, 1001510.0000,  992343.0000,  981884.3750,
          958565.6875,  944744.5000,  931533.9375,  926240.0000,  844519.0000],
        [1392124.1250, 1373668.7500, 1364864.7500, 1359329.7500, 1347433.6250,
         1347224.1250, 1342165.1250, 1337659.5000, 1323561.2500, 1321819.2500],
        [1464346.2500, 1464018.1250, 1463200.0000, 1459072.6250, 1454385.3750,
         1448176.6250, 1442314.6250, 1440846.3750, 1440571.6250, 1431318.5000],
        [1417845.5000, 1410617.7500, 1404902.5000, 1401700.0000, 1398835.5000,
         1395817.2500, 1380385.8750, 1378669.0000, 1376698.2500, 1373325.5000],
        [1404532.7500, 1403152.3750, 1375753.2500, 1373305.8750, 1360321.8750,
         1353755.2500, 1330619.7500, 1329413.5000, 1320559.3750, 1318608.6250],
        [1463262.8750, 1444835.5000, 1443101.7500, 1426267.3750, 1418893.7500,
         1416209.0000, 1397019.7500, 1381713.5000, 1373349.1250, 1367125.0000],
        [1387170.3750, 1340226.1250, 1328269.1250, 1314014.2500, 1305698.3750,
         1300558.5000, 1297201.6250, 1286655.0000, 1276654.3750, 1260051.6250],
        [1492225.7500, 1489947.7500, 1488994.5000, 1488377.0000, 1488377.0000,
         1488286.1250, 1477693.0000, 1474497.6250, 1474108.1250, 1464840.6250],
        [1501258.2500, 1486009.7500, 1483277.2500, 1480354.6250, 1476730.8750,
         1445884.5000, 1445589.3750, 1444606.7500, 1442957.2500, 1441640.8750],
        [1476059.2500, 1410496.7500, 1386814.5000, 1385120.0000, 1369496.0000,
         1368471.1250, 1364659.1250, 1359733.0000, 1358473.1250, 1346158.2500],
        [1416604.7500, 1409197.8750, 1402387.2500, 1393607.8750, 1319289.1250,
         1316846.8750, 1314119.5000, 1304445.1250, 1294933.3750, 1294781.5000],
        [1422600.8750, 1410803.3750, 1403586.1250, 1401704.0000, 1360052.1250,
         1358320.2500, 1355686.7500, 1329956.1250, 1310505.1250, 1298766.1250],
        [1527186.0000, 1464905.0000, 1437829.3750, 1437582.5000, 1428189.1250,
         1401270.8750, 1354845.2500, 1349873.5000, 1347595.6250, 1337225.7500],
        [1382962.0000, 1362004.1250, 1351313.5000, 1350003.5000, 1349101.3750,
         1340676.0000, 1331222.5000, 1329025.5000, 1320975.0000, 1319591.1250],
        [1415228.8750, 1404285.0000, 1320502.7500, 1292727.2500, 1273846.1250,
         1261816.8750, 1260187.5000, 1256516.5000, 1239852.8750, 1230455.3750],
        [1428020.2500, 1426900.0000, 1420109.5000, 1416954.7500, 1406823.7500,
         1373844.2500, 1307966.7500, 1300285.6250, 1290933.3750, 1275660.0000],
        [1436028.6250, 1428422.1250, 1426381.5000, 1424261.0000, 1424091.3750,
         1415672.8750, 1410925.8750, 1397678.0000, 1383628.1250, 1374414.2500]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1508783.6250,       0.0000],
         [1508025.5000,       0.0000],
         [1487569.5000,       0.0000],
         ...,
         [      0.0000, 1474444.1250],
         [1473848.1250,       0.0000],
         [1465198.2500,       0.0000]],

        [[1536817.1250,       0.0000],
         [1525659.0000,       0.0000],
         [1522749.0000,       0.0000],
         ...,
         [1519264.7500,       0.0000],
         [1518198.6250,       0.0000],
         [1517941.0000,       0.0000]],

        [[1140463.3750,       0.0000],
         [      0.0000, 1022858.6250],
         [1022353.4375,       0.0000],
         ...,
         [ 973072.3125,       0.0000],
         [ 966417.3125,       0.0000],
         [ 954111.3125,       0.0000]],

        ...,

        [[1415228.8750,       0.0000],
         [1404285.0000,       0.0000],
         [1320502.7500,       0.0000],
         ...,
         [1256516.5000,       0.0000],
         [1239852.8750,       0.0000],
         [1230455.3750,       0.0000]],

        [[1428020.2500,       0.0000],
         [1426900.0000,       0.0000],
         [1420109.5000,       0.0000],
         ...,
         [      0.0000, 1300285.6250],
         [1290933.3750,       0.0000],
         [      0.0000, 1275660.0000]],

        [[      0.0000, 1436028.6250],
         [      0.0000, 1428422.1250],
         [      0.0000, 1426381.5000],
         ...,
         [      0.0000, 1397678.0000],
         [      0.0000, 1383628.1250],
         [1374414.2500,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13366426.0000,  1474444.1250],
        [15226930.0000,        0.0000],
        [ 5056418.0000,  4996988.5000],
        [12640398.0000,  1388406.5000],
        [10344862.0000,  2526593.0000],
        [ 9252778.0000,  2244500.5000],
        [ 4987859.5000,  5185623.5000],
        [ 8576786.0000,   869781.8750],
        [13686043.0000,  1512740.0000],
        [11830934.0000,  1379821.2500],
        [15486525.0000,        0.0000],
        [14009380.0000,        0.0000],
        [13170771.0000,        0.0000],
        [15465796.0000,        0.0000],
        [15746591.0000,        0.0000],
        [15694772.0000,        0.0000],
        [13534628.0000,  1519503.7500],
        [13254066.0000,  1491340.7500],
        [14544205.0000,        0.0000],
        [15464416.0000,        0.0000],
        [15435694.0000,        0.0000],
        [13127393.0000,  1466249.5000],
        [15591520.0000,        0.0000],
        [15721028.0000,        0.0000],
        [11726030.0000,  2974519.5000],
        [15679924.0000,        0.0000],
        [15584244.0000,        0.0000],
        [15723902.0000,        0.0000],
        [15752470.0000,        0.0000],
        [15748479.0000,        0.0000],
        [15773802.0000,        0.0000],
        [15751726.0000,        0.0000],
        [ 2931351.0000,  7823621.0000],
        [ 9020709.0000,  6019520.0000],
        [12386742.0000,  3091250.2500],
        [12097256.0000,  3022742.0000],
        [ 3196362.0000,  8032931.5000],
        [11891113.0000,  2978492.5000],
        [12637373.0000,  1386815.8750],
        [13474356.0000,  1490629.8750],
        [ 9855344.0000,  2524841.5000],
        [15559322.0000,        0.0000],
        [15473043.0000,        0.0000],
        [13728605.0000,  1524947.6250],
        [ 2499847.2500, 10352454.0000],
        [ 1169927.2500, 10537622.0000],
        [ 5228676.5000,  4803452.0000],
        [ 2747829.2500,  6938814.0000],
        [ 4030115.2500,  9479736.0000],
        [10130774.0000,  4377476.0000],
        [12533895.0000,  1404902.5000],
        [ 1320559.3750, 12249464.0000],
        [ 1367125.0000, 12764653.0000],
        [ 2642283.5000, 10454216.0000],
        [11846836.0000,  2980512.0000],
        [10184311.0000,  4463999.0000],
        [ 2726944.2500, 11098536.0000],
        [ 5230345.0000,  8235869.0000],
        [ 1298766.1250, 12353214.0000],
        [ 2692071.0000, 11394432.0000],
        [10713237.0000,  2723638.0000],
        [11693603.0000,  1261816.8750],
        [ 9763586.0000,  3883912.5000],
        [ 1374414.2500, 12747089.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 70.3125
Top1 accuracy for validation set is 70.3125 size is torch.Size([64, 1])
Epoch 486/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:58, 57.81s/it]  7%|▋         | 2/29 [01:01<11:47, 26.21s/it] 10%|█         | 3/29 [01:02<06:21, 14.66s/it] 14%|█▍        | 4/29 [01:03<03:50,  9.24s/it] 17%|█▋        | 5/29 [01:04<02:29,  6.24s/it] 21%|██        | 6/29 [01:05<01:41,  4.43s/it] 24%|██▍       | 7/29 [01:06<01:12,  3.28s/it] 28%|██▊       | 8/29 [01:07<00:53,  2.53s/it] 31%|███       | 9/29 [01:08<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:09<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:20<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:27<00:00,  3.00s/it]
Epoch loss is 2.773946523666382
Epoch 487/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:02<29:11, 62.57s/it]  7%|▋         | 2/29 [01:03<11:50, 26.30s/it] 10%|█         | 3/29 [01:04<06:22, 14.71s/it] 14%|█▍        | 4/29 [01:05<03:51,  9.27s/it] 17%|█▋        | 5/29 [01:06<02:30,  6.26s/it] 21%|██        | 6/29 [01:07<01:42,  4.44s/it] 24%|██▍       | 7/29 [01:08<01:12,  3.29s/it] 28%|██▊       | 8/29 [01:09<00:53,  2.54s/it] 31%|███       | 9/29 [01:09<00:40,  2.03s/it] 34%|███▍      | 10/29 [01:10<00:32,  1.69s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:12<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:13<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:14<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:15<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:16<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:17<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:18<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:19<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:20<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:23<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:24<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:25<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:26<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:27<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  1.09it/s]100%|██████████| 29/29 [01:28<00:00,  3.05s/it]
Epoch loss is 2.7838332653045654
Epoch 488/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:18, 58.50s/it]  7%|▋         | 2/29 [00:59<11:05, 24.63s/it] 10%|█         | 3/29 [01:00<05:58, 13.81s/it] 14%|█▍        | 4/29 [01:01<03:38,  8.72s/it] 17%|█▋        | 5/29 [01:02<02:21,  5.91s/it] 21%|██        | 6/29 [01:03<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.14s/it] 28%|██▊       | 8/29 [01:04<00:51,  2.44s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:12<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.92s/it]
Epoch loss is 2.7936248779296875
Epoch 489/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:43, 59.42s/it]  7%|▋         | 2/29 [01:00<11:20, 25.21s/it] 10%|█         | 3/29 [01:01<06:07, 14.12s/it] 14%|█▍        | 4/29 [01:02<03:42,  8.92s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.03s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.19s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  2.96s/it]
Epoch loss is 2.790674924850464
Epoch 490/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:52, 57.58s/it]  7%|▋         | 2/29 [00:59<11:03, 24.57s/it] 10%|█         | 3/29 [00:59<05:58, 13.78s/it] 14%|█▍        | 4/29 [01:00<03:37,  8.70s/it] 17%|█▋        | 5/29 [01:01<02:21,  5.90s/it] 21%|██        | 6/29 [01:02<01:36,  4.21s/it] 24%|██▍       | 7/29 [01:03<01:08,  3.13s/it] 28%|██▊       | 8/29 [01:04<00:50,  2.43s/it] 31%|███       | 9/29 [01:05<00:39,  1.96s/it] 34%|███▍      | 10/29 [01:06<00:31,  1.64s/it] 38%|███▊      | 11/29 [01:07<00:25,  1.42s/it] 41%|████▏     | 12/29 [01:08<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:09<00:18,  1.16s/it] 48%|████▊     | 14/29 [01:10<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:11<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:11<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:12<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:13<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:14<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:15<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:16<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:17<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:18<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:19<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:20<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:21<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:22<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:23<00:00,  1.08it/s]100%|██████████| 29/29 [01:24<00:00,  2.90s/it]
Epoch loss is 2.78875732421875
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.8255e-03, 1.3560e-02, 2.0061e-03,  ..., 3.9785e-03, 6.7754e-05,
         1.9873e-02],
        [2.6580e-03, 9.3740e-03, 1.9510e-03,  ..., 2.0012e-03, 1.6640e-04,
         1.8435e-02],
        [3.2351e-02, 6.8215e-03, 3.8943e-03,  ..., 5.5070e-03, 1.4665e-02,
         2.4502e-02],
        ...,
        [7.4077e-03, 7.8935e-03, 1.7806e-02,  ..., 3.7072e-03, 1.6426e-03,
         2.1204e-02],
        [4.0802e-03, 8.1051e-03, 1.1552e-02,  ..., 4.5268e-03, 4.7764e-03,
         2.0443e-02],
        [8.7247e-03, 4.3788e-03, 3.9172e-03,  ..., 2.6806e-03, 1.9127e-03,
         2.2773e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9965, 0.9964, 0.9954, 0.9953, 0.9953, 0.9951, 0.9950, 0.9949, 0.9949,
         0.9946],
        [0.9974, 0.9968, 0.9968, 0.9968, 0.9967, 0.9967, 0.9967, 0.9966, 0.9965,
         0.9965],
        [0.9757, 0.9692, 0.9686, 0.9660, 0.9654, 0.9653, 0.9648, 0.9646, 0.9639,
         0.9631],
        [0.9935, 0.9927, 0.9925, 0.9923, 0.9918, 0.9911, 0.9910, 0.9899, 0.9898,
         0.9896],
        [0.9884, 0.9872, 0.9867, 0.9850, 0.9849, 0.9848, 0.9843, 0.9841, 0.9838,
         0.9837],
        [0.9841, 0.9831, 0.9807, 0.9764, 0.9764, 0.9751, 0.9750, 0.9734, 0.9732,
         0.9729],
        [0.9793, 0.9689, 0.9684, 0.9671, 0.9669, 0.9665, 0.9644, 0.9640, 0.9620,
         0.9613],
        [0.9760, 0.9732, 0.9691, 0.9683, 0.9606, 0.9576, 0.9563, 0.9563, 0.9557,
         0.9548],
        [0.9976, 0.9970, 0.9970, 0.9967, 0.9967, 0.9966, 0.9965, 0.9964, 0.9964,
         0.9963],
        [0.9940, 0.9904, 0.9893, 0.9884, 0.9866, 0.9866, 0.9856, 0.9840, 0.9839,
         0.9837],
        [0.9982, 0.9982, 0.9981, 0.9981, 0.9979, 0.9978, 0.9978, 0.9978, 0.9978,
         0.9978],
        [0.9939, 0.9936, 0.9919, 0.9912, 0.9911, 0.9906, 0.9905, 0.9904, 0.9903,
         0.9896],
        [0.9921, 0.9909, 0.9892, 0.9887, 0.9868, 0.9864, 0.9863, 0.9847, 0.9845,
         0.9839],
        [0.9985, 0.9983, 0.9981, 0.9981, 0.9980, 0.9978, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,
         0.9989],
        [0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987,
         0.9987],
        [0.9967, 0.9965, 0.9964, 0.9963, 0.9961, 0.9959, 0.9959, 0.9957, 0.9957,
         0.9956],
        [0.9955, 0.9950, 0.9947, 0.9946, 0.9945, 0.9945, 0.9945, 0.9944, 0.9944,
         0.9944],
        [0.9946, 0.9942, 0.9939, 0.9938, 0.9937, 0.9935, 0.9935, 0.9934, 0.9934,
         0.9933],
        [0.9981, 0.9981, 0.9980, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978,
         0.9977],
        [0.9981, 0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9976, 0.9976,
         0.9975],
        [0.9953, 0.9947, 0.9946, 0.9942, 0.9941, 0.9940, 0.9940, 0.9936, 0.9930,
         0.9928],
        [0.9990, 0.9989, 0.9984, 0.9984, 0.9984, 0.9983, 0.9981, 0.9981, 0.9977,
         0.9977],
        [0.9992, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9953, 0.9952, 0.9946, 0.9944, 0.9943, 0.9943, 0.9942, 0.9942, 0.9941,
         0.9941],
        [0.9990, 0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9986, 0.9985,
         0.9985],
        [0.9986, 0.9985, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9980, 0.9980,
         0.9979],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9992, 0.9992, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,
         0.9990],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9879, 0.9866, 0.9776, 0.9715, 0.9690, 0.9654, 0.9652, 0.9647, 0.9626,
         0.9562],
        [0.9965, 0.9965, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959, 0.9959,
         0.9957],
        [0.9981, 0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9968, 0.9966, 0.9966, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9962,
         0.9962],
        [0.9848, 0.9818, 0.9785, 0.9756, 0.9735, 0.9733, 0.9713, 0.9702, 0.9690,
         0.9689],
        [0.9962, 0.9956, 0.9955, 0.9954, 0.9954, 0.9952, 0.9952, 0.9952, 0.9951,
         0.9949],
        [0.9924, 0.9917, 0.9916, 0.9913, 0.9912, 0.9907, 0.9905, 0.9904, 0.9903,
         0.9902],
        [0.9962, 0.9960, 0.9959, 0.9959, 0.9959, 0.9957, 0.9957, 0.9956, 0.9956,
         0.9955],
        [0.9844, 0.9842, 0.9838, 0.9831, 0.9825, 0.9807, 0.9805, 0.9794, 0.9783,
         0.9777],
        [0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982,
         0.9982],
        [0.9982, 0.9982, 0.9981, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9978,
         0.9978],
        [0.9974, 0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9968, 0.9968, 0.9968,
         0.9968],
        [0.9900, 0.9872, 0.9862, 0.9857, 0.9854, 0.9842, 0.9841, 0.9837, 0.9835,
         0.9829],
        [0.9857, 0.9796, 0.9793, 0.9792, 0.9788, 0.9776, 0.9774, 0.9773, 0.9771,
         0.9762],
        [0.9870, 0.9848, 0.9739, 0.9707, 0.9620, 0.9583, 0.9557, 0.9556, 0.9552,
         0.9552],
        [0.9720, 0.9684, 0.9676, 0.9664, 0.9655, 0.9630, 0.9625, 0.9624, 0.9615,
         0.9522],
        [0.9910, 0.9901, 0.9892, 0.9891, 0.9888, 0.9884, 0.9882, 0.9880, 0.9877,
         0.9876],
        [0.9945, 0.9943, 0.9943, 0.9943, 0.9940, 0.9937, 0.9937, 0.9937, 0.9935,
         0.9932],
        [0.9918, 0.9918, 0.9915, 0.9913, 0.9910, 0.9907, 0.9907, 0.9905, 0.9902,
         0.9902],
        [0.9915, 0.9914, 0.9902, 0.9899, 0.9888, 0.9887, 0.9878, 0.9875, 0.9874,
         0.9874],
        [0.9937, 0.9927, 0.9926, 0.9919, 0.9914, 0.9914, 0.9906, 0.9898, 0.9894,
         0.9888],
        [0.9901, 0.9879, 0.9870, 0.9869, 0.9859, 0.9856, 0.9852, 0.9852, 0.9844,
         0.9838],
        [0.9955, 0.9955, 0.9954, 0.9954, 0.9954, 0.9953, 0.9952, 0.9951, 0.9951,
         0.9945],
        [0.9959, 0.9954, 0.9954, 0.9954, 0.9951, 0.9938, 0.9937, 0.9935, 0.9934,
         0.9934],
        [0.9944, 0.9913, 0.9902, 0.9898, 0.9895, 0.9892, 0.9890, 0.9887, 0.9884,
         0.9883],
        [0.9917, 0.9913, 0.9909, 0.9903, 0.9868, 0.9866, 0.9865, 0.9859, 0.9855,
         0.9855],
        [0.9918, 0.9916, 0.9906, 0.9903, 0.9888, 0.9887, 0.9882, 0.9875, 0.9862,
         0.9861],
        [0.9968, 0.9939, 0.9929, 0.9928, 0.9923, 0.9911, 0.9885, 0.9882, 0.9881,
         0.9877],
        [0.9900, 0.9885, 0.9885, 0.9882, 0.9882, 0.9876, 0.9873, 0.9872, 0.9867,
         0.9862],
        [0.9916, 0.9909, 0.9874, 0.9854, 0.9843, 0.9840, 0.9839, 0.9836, 0.9831,
         0.9820],
        [0.9926, 0.9926, 0.9923, 0.9920, 0.9916, 0.9900, 0.9869, 0.9868, 0.9856,
         0.9848],
        [0.9929, 0.9927, 0.9924, 0.9923, 0.9922, 0.9918, 0.9914, 0.9908, 0.9904,
         0.9901]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 0, 1, 1],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 0, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 0, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 0],
        [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 0, 1, 0, 1],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1521610.7500, 1520231.3750, 1499142.2500, 1497160.6250, 1495455.3750,
         1491295.3750, 1489504.3750, 1488792.8750, 1486874.5000, 1480594.6250],
        [1542596.6250, 1529790.8750, 1529245.3750, 1528791.8750, 1527270.5000,
         1526741.8750, 1526621.1250, 1523675.6250, 1522870.8750, 1522775.0000],
        [1131453.3750, 1030836.7500, 1021564.0625,  985052.6250,  976717.8125,
          974887.3750,  967774.9375,  964515.0625,  955921.0000,  944546.3125],
        [1457704.1250, 1442589.8750, 1437049.2500, 1433299.2500, 1423989.3750,
         1408970.7500, 1407658.6250, 1384762.1250, 1383295.7500, 1379741.0000],
        [1355346.8750, 1332846.0000, 1323428.7500, 1290870.6250, 1289968.6250,
         1288106.1250, 1278247.8750, 1275025.1250, 1268906.5000, 1268143.1250],
        [1275315.7500, 1256578.7500, 1214461.6250, 1141625.5000, 1141595.0000,
         1121707.5000, 1119789.0000, 1093970.1250, 1091554.5000, 1086619.8750],
        [1191410.2500, 1025897.8750, 1018981.6250, 1000140.3750,  996988.1875,
          990962.3125,  961919.1875,  957531.4375,  929660.3750,  920017.6875],
        [1136342.2500, 1090892.6250, 1029536.9375, 1018098.6875,  911632.2500,
          873660.8125,  857611.2500,  856592.8125,  849463.2500,  839328.1250],
        [1545979.5000, 1533157.3750, 1533002.5000, 1527002.6250, 1525836.5000,
         1524749.8750, 1522126.0000, 1519532.7500, 1519024.2500, 1519002.5000],
        [1469633.1250, 1394293.8750, 1373034.8750, 1355874.1250, 1320725.5000,
         1320588.2500, 1302737.0000, 1272628.2500, 1270983.6250, 1268462.5000],
        [1559069.3750, 1558764.6250, 1558116.6250, 1557329.3750, 1553872.6250,
         1551345.1250, 1550938.3750, 1550747.5000, 1550623.3750, 1550311.3750],
        [1467232.8750, 1459714.3750, 1424619.6250, 1412107.7500, 1409856.5000,
         1398667.5000, 1398122.1250, 1395780.0000, 1392774.8750, 1378716.3750],
        [1429656.8750, 1404578.2500, 1371981.1250, 1362685.0000, 1324881.0000,
         1318154.8750, 1315907.8750, 1286717.6250, 1282350.3750, 1271221.2500],
        [1565941.8750, 1562135.3750, 1557620.3750, 1557379.8750, 1555784.0000,
         1550218.1250, 1545849.8750, 1544467.6250, 1544149.5000, 1543152.8750],
        [1579625.6250, 1578646.7500, 1578289.8750, 1577784.2500, 1577525.5000,
         1577092.2500, 1576865.1250, 1576743.5000, 1576454.7500, 1575479.2500],
        [1577808.3750, 1575760.2500, 1575117.2500, 1574638.1250, 1573582.7500,
         1573540.7500, 1573380.2500, 1572904.6250, 1570847.8750, 1570454.0000],
        [1526380.7500, 1521416.2500, 1520860.7500, 1517482.1250, 1514306.0000,
         1509049.8750, 1508636.8750, 1505950.2500, 1505373.0000, 1502500.1250],
        [1500522.6250, 1490496.2500, 1483082.0000, 1481194.8750, 1479819.7500,
         1479689.8750, 1479338.5000, 1477221.1250, 1477188.6250, 1476768.8750],
        [1482069.6250, 1473481.2500, 1466193.5000, 1463870.0000, 1462339.3750,
         1459289.8750, 1458388.2500, 1457188.3750, 1456888.2500, 1453396.8750],
        [1558240.0000, 1556683.5000, 1554473.0000, 1553397.1250, 1553022.2500,
         1552301.2500, 1551626.3750, 1550729.8750, 1549860.5000, 1549548.6250],
        [1556561.6250, 1553831.1250, 1553494.8750, 1553176.3750, 1551068.6250,
         1550774.2500, 1549024.1250, 1546893.8750, 1546006.1250, 1544835.8750],
        [1497334.8750, 1484130.3750, 1480662.5000, 1473491.0000, 1471585.3750,
         1469446.7500, 1467998.3750, 1460400.7500, 1447472.3750, 1444540.6250],
        [1576567.5000, 1575242.0000, 1563928.5000, 1563721.2500, 1563171.1250,
         1561442.7500, 1558232.5000, 1557980.0000, 1549241.2500, 1547693.7500],
        [1581108.7500, 1578168.0000, 1576260.8750, 1575892.5000, 1574913.0000,
         1574866.3750, 1574549.5000, 1574105.1250, 1573243.6250, 1572414.1250],
        [1495650.7500, 1494068.3750, 1481524.1250, 1477443.6250, 1475917.1250,
         1474213.6250, 1473683.5000, 1472754.8750, 1470893.6250, 1470480.0000],
        [1578258.3750, 1574282.3750, 1572747.0000, 1571450.2500, 1570403.0000,
         1569639.3750, 1569489.7500, 1567984.6250, 1567503.2500, 1566824.7500],
        [1567950.3750, 1567494.3750, 1565334.2500, 1564191.1250, 1562393.2500,
         1559276.2500, 1557766.0000, 1556165.5000, 1556065.8750, 1553680.1250],
        [1578032.6250, 1576847.1250, 1576796.1250, 1576218.7500, 1575522.8750,
         1574973.1250, 1574780.7500, 1573168.6250, 1572957.1250, 1572615.1250],
        [1580844.8750, 1580781.5000, 1580219.2500, 1577764.7500, 1577260.7500,
         1577220.1250, 1577182.6250, 1577071.2500, 1576944.8750, 1576653.1250],
        [1582288.2500, 1581588.2500, 1577770.7500, 1577345.0000, 1577134.3750,
         1576890.8750, 1576857.7500, 1575842.8750, 1575317.1250, 1574890.5000],
        [1582712.3750, 1582449.7500, 1581625.8750, 1580570.3750, 1580291.6250,
         1579755.1250, 1579063.8750, 1579059.2500, 1578818.3750, 1577797.8750],
        [1582000.1250, 1579628.6250, 1578524.8750, 1578166.5000, 1577955.8750,
         1577576.7500, 1577463.8750, 1577080.2500, 1576811.1250, 1576805.1250],
        [1346676.8750, 1321215.6250, 1162468.0000, 1065139.5000, 1028379.0000,
          976398.3750,  972988.8750,  966448.6875,  937759.9375,  855408.3125],
        [1523257.2500, 1522465.7500, 1514311.7500, 1511866.0000, 1510910.2500,
         1509951.0000, 1509945.2500, 1508750.5000, 1508462.7500, 1504149.0000],
        [1557461.5000, 1555392.3750, 1554852.5000, 1552558.8750, 1550308.3750,
         1549251.6250, 1548991.6250, 1548808.5000, 1548783.2500, 1548250.2500],
        [1528684.0000, 1523967.7500, 1523498.3750, 1522147.7500, 1521618.1250,
         1521284.2500, 1520538.8750, 1516930.8750, 1516706.7500, 1515272.5000],
        [1288388.8750, 1234685.8750, 1177579.3750, 1128754.6250, 1095886.2500,
         1093346.5000, 1061887.8750, 1045308.0625, 1027272.3750, 1026212.9375],
        [1516486.8750, 1503139.3750, 1501145.1250, 1497913.2500, 1497560.5000,
         1495255.7500, 1494069.8750, 1493451.5000, 1491411.8750, 1487755.2500],
        [1436573.7500, 1421480.7500, 1419974.0000, 1412451.2500, 1410807.5000,
         1400501.3750, 1397130.3750, 1394786.0000, 1392905.0000, 1390652.6250],
        [1515474.7500, 1510711.5000, 1510206.0000, 1510206.0000, 1509218.2500,
         1504880.6250, 1504123.1250, 1502971.6250, 1501970.0000, 1500934.8750],
        [1280214.3750, 1277532.3750, 1269102.6250, 1257361.6250, 1246966.5000,
         1215197.2500, 1211783.3750, 1191754.5000, 1174397.6250, 1163125.5000],
        [1567068.2500, 1564738.7500, 1561425.0000, 1561363.8750, 1560629.8750,
         1560619.6250, 1560243.1250, 1559265.7500, 1559239.0000, 1558696.2500],
        [1560391.8750, 1559042.7500, 1558269.7500, 1554087.6250, 1553758.6250,
         1553126.0000, 1552480.2500, 1552022.8750, 1550567.1250, 1549820.6250],
        [1542168.6250, 1540775.0000, 1537302.2500, 1536201.6250, 1534564.6250,
         1533865.2500, 1529209.0000, 1529101.0000, 1528640.2500, 1527848.8750],
        [1386621.3750, 1332687.1250, 1314198.5000, 1304748.7500, 1298235.0000,
         1276429.1250, 1274472.0000, 1268693.6250, 1264638.3750, 1254147.2500],
        [1305536.6250, 1195588.6250, 1189893.2500, 1188439.2500, 1182555.8750,
         1162035.7500, 1159041.8750, 1156646.8750, 1153267.6250, 1139314.2500],
        [1328528.7500, 1287945.2500, 1102908.8750, 1052558.6250,  930402.8125,
          882354.8125,  849314.2500,  848349.2500,  843864.4375,  843452.5000],
        [1072845.6250, 1019036.1250, 1007859.6250,  989887.3750,  977647.8750,
          942764.4375,  935982.8750,  934890.9375,  922893.0000,  808146.0625],
        [1407182.1250, 1388505.7500, 1370724.2500, 1369052.1250, 1364138.6250,
         1355593.6250, 1352295.8750, 1348809.2500, 1341901.5000, 1340676.0000],
        [1478634.7500, 1476223.8750, 1475953.7500, 1475578.0000, 1469511.1250,
         1463575.5000, 1463001.8750, 1461578.1250, 1458471.6250, 1452677.6250],
        [1423174.8750, 1422653.7500, 1417364.2500, 1413188.2500, 1407255.8750,
         1402035.5000, 1400637.6250, 1397595.5000, 1392223.7500, 1391390.1250],
        [1417041.1250, 1415076.2500, 1390851.5000, 1384789.8750, 1364201.1250,
         1362221.0000, 1344964.8750, 1337674.8750, 1336105.2500, 1335943.5000],
        [1462282.2500, 1441994.2500, 1439397.5000, 1424547.7500, 1415508.2500,
         1415188.2500, 1399101.0000, 1383154.6250, 1376358.1250, 1364011.1250],
        [1388627.6250, 1345617.8750, 1328737.8750, 1327494.0000, 1309267.1250,
         1302423.8750, 1295743.7500, 1294938.3750, 1281277.0000, 1268975.5000],
        [1500103.3750, 1499755.8750, 1498536.2500, 1498504.8750, 1498504.8750,
         1495337.0000, 1493391.7500, 1493084.1250, 1491292.5000, 1478483.8750],
        [1509601.1250, 1497907.5000, 1497836.1250, 1497643.2500, 1491770.3750,
         1464805.7500, 1462119.1250, 1457754.2500, 1456721.5000, 1456721.5000],
        [1476985.7500, 1413731.3750, 1391917.1250, 1383504.1250, 1377520.3750,
         1370726.8750, 1366753.5000, 1362170.3750, 1355858.7500, 1354133.6250],
        [1420857.2500, 1412825.7500, 1405516.2500, 1393271.6250, 1324523.5000,
         1321951.6250, 1320364.1250, 1309177.2500, 1301592.0000, 1300060.0000],
        [1422993.0000, 1418601.5000, 1400092.8750, 1394146.3750, 1363431.1250,
         1361580.8750, 1351900.1250, 1339472.1250, 1314663.5000, 1312993.3750],
        [1528708.7500, 1467077.5000, 1446070.6250, 1444090.2500, 1433470.0000,
         1409532.5000, 1356932.2500, 1351856.1250, 1350899.8750, 1342497.8750],
        [1387362.1250, 1358404.5000, 1357087.6250, 1352466.1250, 1351928.3750,
         1339625.5000, 1334178.8750, 1331952.6250, 1322779.0000, 1313459.1250],
        [1419892.7500, 1405260.3750, 1337206.6250, 1298436.7500, 1279602.8750,
         1273523.1250, 1270871.0000, 1266540.5000, 1256231.3750, 1238018.0000],
        [1440481.0000, 1438779.8750, 1434001.8750, 1426795.1250, 1420261.1250,
         1388026.5000, 1327400.3750, 1324735.7500, 1303329.7500, 1287335.0000],
        [1445079.3750, 1442291.3750, 1435058.0000, 1434085.3750, 1431782.6250,
         1423104.2500, 1414998.0000, 1403151.1250, 1394355.1250, 1389569.5000]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1521610.7500,       0.0000],
         [1520231.3750,       0.0000],
         [1499142.2500,       0.0000],
         ...,
         [1488792.8750,       0.0000],
         [1486874.5000,       0.0000],
         [1480594.6250,       0.0000]],

        [[1542596.6250,       0.0000],
         [1529790.8750,       0.0000],
         [1529245.3750,       0.0000],
         ...,
         [1523675.6250,       0.0000],
         [1522870.8750,       0.0000],
         [1522775.0000,       0.0000]],

        [[1131453.3750,       0.0000],
         [1030836.7500,       0.0000],
         [      0.0000, 1021564.0625],
         ...,
         [ 964515.0625,       0.0000],
         [      0.0000,  955921.0000],
         [      0.0000,  944546.3125]],

        ...,

        [[1419892.7500,       0.0000],
         [1405260.3750,       0.0000],
         [1337206.6250,       0.0000],
         ...,
         [1266540.5000,       0.0000],
         [1256231.3750,       0.0000],
         [      0.0000, 1238018.0000]],

        [[1440481.0000,       0.0000],
         [1438779.8750,       0.0000],
         [1434001.8750,       0.0000],
         ...,
         [      0.0000, 1324735.7500],
         [1303329.7500,       0.0000],
         [1287335.0000,       0.0000]],

        [[      0.0000, 1445079.3750],
         [      0.0000, 1442291.3750],
         [      0.0000, 1435058.0000],
         ...,
         [      0.0000, 1403151.1250],
         [1394355.1250,       0.0000],
         [      0.0000, 1389569.5000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13481158.0000,  1489504.3750],
        [15280380.0000,        0.0000],
        [ 4094580.0000,  5858689.0000],
        [12750090.0000,  1408970.7500],
        [ 9158815.0000,  3812074.5000],
        [ 9307622.0000,  2235595.5000],
        [ 4891545.5000,  5101963.5000],
        [ 8606566.0000,   856592.8125],
        [13747288.0000,  1522126.0000],
        [11954668.0000,  1394293.8750],
        [15541118.0000,        0.0000],
        [14137593.0000,        0.0000],
        [13368134.0000,        0.0000],
        [15526700.0000,        0.0000],
        [15774507.0000,        0.0000],
        [15738035.0000,        0.0000],
        [13605574.0000,  1526380.7500],
        [13324800.0000,  1500522.6250],
        [14633106.0000,        0.0000],
        [15529883.0000,        0.0000],
        [15505667.0000,        0.0000],
        [11776100.0000,  2920963.5000],
        [15617220.0000,        0.0000],
        [15755522.0000,        0.0000],
        [10323226.0000,  4463402.5000],
        [15708584.0000,        0.0000],
        [15610316.0000,        0.0000],
        [15751912.0000,        0.0000],
        [15781943.0000,        0.0000],
        [15775926.0000,        0.0000],
        [15802146.0000,        0.0000],
        [15782014.0000,        0.0000],
        [ 2804795.5000,  7828088.0000],
        [ 9072957.0000,  6051112.5000],
        [12417626.0000,  3097033.5000],
        [12167963.0000,  3042686.5000],
        [ 3182507.0000,  7996816.0000],
        [11979795.0000,  2998395.0000],
        [12680131.0000,  1397130.3750],
        [15070696.0000,        0.0000],
        [ 9762937.0000,  2524499.0000],
        [15613290.0000,        0.0000],
        [15543568.0000,        0.0000],
        [13802374.0000,  1537302.2500],
        [ 2518785.5000, 10456086.0000],
        [ 1195588.6250, 10636731.0000],
        [ 5197738.0000,  4771941.5000],
        [ 2665930.0000,  6946024.0000],
        [ 5417440.0000,  8221439.0000],
        [10253518.0000,  4421689.0000],
        [12654332.0000,  1413188.2500],
        [       0.0000, 13688869.0000],
        [ 1364011.1250, 12757532.0000],
        [ 2656232.0000, 10486871.0000],
        [11951902.0000,  2995093.0000],
        [10293673.0000,  4499207.5000],
        [ 2722612.2500, 11130690.0000],
        [ 5254125.0000,  8256014.5000],
        [ 1314663.5000, 12365212.0000],
        [ 2707832.0000, 11423304.0000],
        [10729929.0000,  2719314.7500],
        [10536694.0000,  2508889.0000],
        [11139010.0000,  2652136.0000],
        [ 1394355.1250, 12819120.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 491/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:46, 61.67s/it]  7%|▋         | 2/29 [01:02<11:40, 25.94s/it] 10%|█         | 3/29 [01:03<06:17, 14.52s/it] 14%|█▍        | 4/29 [01:04<03:48,  9.15s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.18s/it] 21%|██        | 6/29 [01:06<01:41,  4.39s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:09<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:10<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:21<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.02s/it]
Epoch loss is 2.7769079208374023
Epoch 492/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:57<26:53, 57.61s/it]  7%|▋         | 2/29 [01:01<11:37, 25.82s/it] 10%|█         | 3/29 [01:02<06:15, 14.45s/it] 14%|█▍        | 4/29 [01:03<03:47,  9.11s/it] 17%|█▋        | 5/29 [01:03<02:27,  6.16s/it] 21%|██        | 6/29 [01:04<01:40,  4.38s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.25s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.51s/it] 31%|███       | 9/29 [01:07<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.7669451236724854
Epoch 493/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:02, 60.09s/it]  7%|▋         | 2/29 [01:01<11:22, 25.29s/it] 10%|█         | 3/29 [01:01<06:08, 14.16s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.09it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.785454034805298
Epoch 494/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:06, 60.23s/it]  7%|▋         | 2/29 [01:01<11:24, 25.35s/it] 10%|█         | 3/29 [01:02<06:09, 14.19s/it] 14%|█▍        | 4/29 [01:03<03:43,  8.95s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.06s/it] 21%|██        | 6/29 [01:04<01:39,  4.31s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.7888853549957275
Epoch 495/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:01, 60.05s/it]  7%|▋         | 2/29 [01:00<11:22, 25.27s/it] 10%|█         | 3/29 [01:01<06:07, 14.15s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:24,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:51,  2.47s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.791764736175537
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[0.0033, 0.0146, 0.0025,  ..., 0.0041, 0.0002, 0.0191],
        [0.0036, 0.0099, 0.0022,  ..., 0.0024, 0.0001, 0.0187],
        [0.0337, 0.0063, 0.0035,  ..., 0.0051, 0.0155, 0.0244],
        ...,
        [0.0079, 0.0080, 0.0186,  ..., 0.0040, 0.0018, 0.0206],
        [0.0045, 0.0087, 0.0122,  ..., 0.0051, 0.0052, 0.0201],
        [0.0101, 0.0044, 0.0043,  ..., 0.0030, 0.0023, 0.0230]],
       device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9959, 0.9959, 0.9949, 0.9949, 0.9947, 0.9946, 0.9945, 0.9942, 0.9942,
         0.9939],
        [0.9971, 0.9966, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9758, 0.9693, 0.9676, 0.9676, 0.9669, 0.9664, 0.9663, 0.9650, 0.9649,
         0.9641],
        [0.9933, 0.9924, 0.9923, 0.9919, 0.9916, 0.9908, 0.9905, 0.9900, 0.9895,
         0.9890],
        [0.9885, 0.9870, 0.9865, 0.9848, 0.9847, 0.9846, 0.9843, 0.9836, 0.9835,
         0.9835],
        [0.9841, 0.9837, 0.9805, 0.9772, 0.9754, 0.9754, 0.9751, 0.9743, 0.9734,
         0.9732],
        [0.9804, 0.9702, 0.9698, 0.9683, 0.9676, 0.9654, 0.9649, 0.9641, 0.9638,
         0.9636],
        [0.9759, 0.9735, 0.9678, 0.9667, 0.9592, 0.9566, 0.9556, 0.9544, 0.9540,
         0.9528],
        [0.9973, 0.9967, 0.9966, 0.9965, 0.9963, 0.9962, 0.9962, 0.9961, 0.9961,
         0.9961],
        [0.9937, 0.9896, 0.9888, 0.9877, 0.9867, 0.9865, 0.9848, 0.9843, 0.9834,
         0.9831],
        [0.9980, 0.9979, 0.9979, 0.9978, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975,
         0.9975],
        [0.9935, 0.9931, 0.9909, 0.9908, 0.9905, 0.9902, 0.9901, 0.9900, 0.9899,
         0.9899],
        [0.9909, 0.9908, 0.9880, 0.9878, 0.9865, 0.9859, 0.9858, 0.9841, 0.9836,
         0.9832],
        [0.9983, 0.9981, 0.9978, 0.9978, 0.9978, 0.9975, 0.9972, 0.9971, 0.9970,
         0.9970],
        [0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9989, 0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985, 0.9985,
         0.9985],
        [0.9963, 0.9961, 0.9961, 0.9959, 0.9959, 0.9954, 0.9954, 0.9954, 0.9952,
         0.9951],
        [0.9952, 0.9946, 0.9944, 0.9944, 0.9944, 0.9944, 0.9942, 0.9941, 0.9940,
         0.9940],
        [0.9945, 0.9936, 0.9935, 0.9934, 0.9933, 0.9933, 0.9932, 0.9932, 0.9932,
         0.9929],
        [0.9979, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974,
         0.9974],
        [0.9978, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9974, 0.9973, 0.9973,
         0.9972],
        [0.9951, 0.9942, 0.9940, 0.9938, 0.9937, 0.9935, 0.9934, 0.9933, 0.9926,
         0.9925],
        [0.9989, 0.9987, 0.9983, 0.9983, 0.9983, 0.9981, 0.9980, 0.9979, 0.9977,
         0.9975],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9951, 0.9950, 0.9946, 0.9943, 0.9940, 0.9939, 0.9938, 0.9938, 0.9938,
         0.9937],
        [0.9989, 0.9988, 0.9987, 0.9986, 0.9986, 0.9985, 0.9984, 0.9984, 0.9984,
         0.9984],
        [0.9985, 0.9984, 0.9984, 0.9983, 0.9981, 0.9981, 0.9979, 0.9979, 0.9979,
         0.9978],
        [0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9987, 0.9987,
         0.9987],
        [0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9988],
        [0.9883, 0.9870, 0.9776, 0.9703, 0.9689, 0.9676, 0.9675, 0.9647, 0.9638,
         0.9608],
        [0.9962, 0.9961, 0.9958, 0.9957, 0.9956, 0.9955, 0.9955, 0.9954, 0.9953,
         0.9953],
        [0.9979, 0.9978, 0.9978, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976, 0.9976,
         0.9975],
        [0.9964, 0.9963, 0.9962, 0.9961, 0.9960, 0.9960, 0.9959, 0.9959, 0.9959,
         0.9958],
        [0.9854, 0.9824, 0.9794, 0.9755, 0.9747, 0.9726, 0.9720, 0.9705, 0.9676,
         0.9675],
        [0.9955, 0.9953, 0.9950, 0.9949, 0.9949, 0.9948, 0.9947, 0.9947, 0.9946,
         0.9946],
        [0.9926, 0.9920, 0.9917, 0.9913, 0.9911, 0.9909, 0.9904, 0.9903, 0.9901,
         0.9901],
        [0.9959, 0.9955, 0.9955, 0.9955, 0.9954, 0.9952, 0.9952, 0.9951, 0.9950,
         0.9949],
        [0.9859, 0.9847, 0.9843, 0.9838, 0.9823, 0.9815, 0.9811, 0.9802, 0.9785,
         0.9780],
        [0.9983, 0.9982, 0.9981, 0.9980, 0.9980, 0.9980, 0.9979, 0.9979, 0.9979,
         0.9979],
        [0.9979, 0.9979, 0.9978, 0.9976, 0.9976, 0.9975, 0.9975, 0.9974, 0.9974,
         0.9974],
        [0.9971, 0.9969, 0.9967, 0.9967, 0.9966, 0.9966, 0.9964, 0.9964, 0.9963,
         0.9963],
        [0.9889, 0.9863, 0.9851, 0.9847, 0.9840, 0.9839, 0.9835, 0.9831, 0.9829,
         0.9821],
        [0.9859, 0.9795, 0.9790, 0.9778, 0.9774, 0.9770, 0.9767, 0.9765, 0.9762,
         0.9761],
        [0.9867, 0.9860, 0.9737, 0.9704, 0.9601, 0.9595, 0.9560, 0.9555, 0.9554,
         0.9551],
        [0.9732, 0.9692, 0.9674, 0.9667, 0.9659, 0.9641, 0.9629, 0.9622, 0.9620,
         0.9544],
        [0.9905, 0.9891, 0.9888, 0.9883, 0.9881, 0.9876, 0.9875, 0.9871, 0.9868,
         0.9868],
        [0.9937, 0.9937, 0.9937, 0.9935, 0.9934, 0.9929, 0.9928, 0.9925, 0.9925,
         0.9922],
        [0.9914, 0.9910, 0.9908, 0.9905, 0.9902, 0.9900, 0.9895, 0.9894, 0.9894,
         0.9893],
        [0.9908, 0.9907, 0.9895, 0.9893, 0.9883, 0.9880, 0.9874, 0.9872, 0.9867,
         0.9866],
        [0.9937, 0.9928, 0.9927, 0.9919, 0.9916, 0.9914, 0.9905, 0.9897, 0.9893,
         0.9889],
        [0.9900, 0.9874, 0.9867, 0.9863, 0.9855, 0.9851, 0.9850, 0.9845, 0.9839,
         0.9830],
        [0.9951, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9943, 0.9942, 0.9942,
         0.9939],
        [0.9955, 0.9948, 0.9946, 0.9944, 0.9943, 0.9929, 0.9929, 0.9928, 0.9928,
         0.9927],
        [0.9943, 0.9911, 0.9899, 0.9897, 0.9891, 0.9890, 0.9888, 0.9888, 0.9885,
         0.9881],
        [0.9913, 0.9910, 0.9906, 0.9902, 0.9863, 0.9862, 0.9861, 0.9854, 0.9851,
         0.9850],
        [0.9917, 0.9911, 0.9908, 0.9906, 0.9887, 0.9885, 0.9885, 0.9868, 0.9857,
         0.9852],
        [0.9967, 0.9937, 0.9924, 0.9923, 0.9919, 0.9906, 0.9883, 0.9881, 0.9880,
         0.9874],
        [0.9899, 0.9886, 0.9881, 0.9880, 0.9879, 0.9875, 0.9873, 0.9866, 0.9864,
         0.9863],
        [0.9914, 0.9910, 0.9865, 0.9852, 0.9841, 0.9833, 0.9832, 0.9831, 0.9823,
         0.9818],
        [0.9919, 0.9919, 0.9916, 0.9915, 0.9909, 0.9893, 0.9860, 0.9852, 0.9850,
         0.9847],
        [0.9923, 0.9918, 0.9918, 0.9918, 0.9918, 0.9916, 0.9911, 0.9906, 0.9900,
         0.9892]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 1, 1, 1, 1, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],
        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],
        [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],
        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [0., 1.],
        [1., 0.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1510064.8750, 1509706.2500, 1488083.2500, 1487531.2500, 1482984.3750,
         1481999.0000, 1479265.2500, 1474066.0000, 1473134.2500, 1466495.6250],
        [1535869.1250, 1525320.1250, 1523052.5000, 1522507.8750, 1521755.8750,
         1521349.6250, 1519641.5000, 1517800.5000, 1517787.5000, 1517243.3750],
        [1132366.6250, 1032569.5000, 1007794.2500, 1007359.0000,  997574.1250,
          990509.6875,  988558.1250,  971223.6875,  968947.8125,  957606.3125],
        [1454230.0000, 1435461.8750, 1434317.8750, 1425887.8750, 1419468.8750,
         1402549.1250, 1396962.3750, 1386558.0000, 1377050.1250, 1368370.6250],
        [1357843.7500, 1329047.0000, 1319879.3750, 1287801.6250, 1285684.8750,
         1284088.1250, 1278645.3750, 1266414.8750, 1264894.1250, 1264047.5000],
        [1276023.7500, 1267185.6250, 1211569.5000, 1154671.8750, 1125974.3750,
         1125486.8750, 1120566.7500, 1109094.0000, 1094921.0000, 1090548.2500],
        [1209766.1250, 1045003.1250, 1040113.3125, 1017201.0000, 1007349.3125,
          976049.2500,  969927.8125,  958861.0000,  953819.2500,  951543.3125],
        [1134033.0000, 1095953.2500, 1009647.0625,  993995.7500,  893302.5000,
          860278.5000,  849111.6875,  834821.0000,  829468.9375,  815493.2500],
        [1540839.6250, 1526069.3750, 1525440.8750, 1521593.5000, 1517728.2500,
         1516100.7500, 1515339.0000, 1514563.1250, 1513644.7500, 1513230.5000],
        [1463046.6250, 1380038.3750, 1364134.7500, 1343190.7500, 1322664.1250,
         1319958.7500, 1287315.2500, 1279380.7500, 1263230.5000, 1256317.6250],
        [1554427.0000, 1553163.0000, 1552160.5000, 1551115.8750, 1548188.2500,
         1546396.8750, 1545777.6250, 1545758.3750, 1544090.6250, 1543938.8750],
        [1458499.5000, 1449197.6250, 1404795.3750, 1404220.6250, 1397053.0000,
         1390659.1250, 1388654.1250, 1386562.0000, 1385200.6250, 1385080.3750],
        [1405584.7500, 1402947.7500, 1348737.2500, 1343700.7500, 1320017.8750,
         1308425.7500, 1306352.3750, 1275276.8750, 1266400.3750, 1258220.5000],
        [1562208.3750, 1557327.8750, 1551832.0000, 1551432.5000, 1551351.1250,
         1544671.0000, 1537512.0000, 1535595.2500, 1533954.5000, 1532468.8750],
        [1576293.8750, 1575225.5000, 1574989.6250, 1574869.3750, 1574852.8750,
         1574710.2500, 1574219.2500, 1574078.1250, 1573362.2500, 1573069.6250],
        [1574777.7500, 1572126.2500, 1571672.0000, 1570915.3750, 1569450.7500,
         1569118.6250, 1566750.0000, 1566650.0000, 1566493.1250, 1566106.2500],
        [1517886.0000, 1514558.7500, 1514334.8750, 1509224.0000, 1508310.2500,
         1499016.5000, 1498391.8750, 1498040.5000, 1494282.1250, 1493047.1250],
        [1493679.3750, 1481714.8750, 1478055.3750, 1477786.1250, 1476633.7500,
         1476585.8750, 1472218.5000, 1470474.2500, 1469902.2500, 1467880.8750],
        [1480006.0000, 1461491.7500, 1459225.7500, 1455812.0000, 1454765.5000,
         1454550.3750, 1453116.8750, 1451582.2500, 1451384.3750, 1446850.0000],
        [1552493.6250, 1549158.6250, 1548764.1250, 1548350.6250, 1546885.1250,
         1546094.6250, 1544656.1250, 1544142.1250, 1542805.5000, 1542721.6250],
        [1550364.6250, 1548875.0000, 1548551.3750, 1546979.5000, 1546722.7500,
         1546225.8750, 1541044.0000, 1539141.8750, 1538673.6250, 1536679.3750],
        [1491811.7500, 1473919.7500, 1467887.8750, 1465139.6250, 1462975.5000,
         1457580.3750, 1456656.3750, 1454065.1250, 1439828.6250, 1438637.2500],
        [1574492.3750, 1571426.2500, 1562530.1250, 1562023.6250, 1561888.1250,
         1557840.2500, 1554266.8750, 1553416.3750, 1547493.0000, 1544118.5000],
        [1578082.3750, 1575575.5000, 1572226.7500, 1572057.2500, 1571766.5000,
         1571748.5000, 1571585.1250, 1571021.6250, 1569203.8750, 1568500.6250],
        [1491072.0000, 1489226.0000, 1481737.3750, 1474617.1250, 1468095.1250,
         1465786.6250, 1465294.7500, 1464877.0000, 1464751.2500, 1462478.8750],
        [1575572.5000, 1572600.1250, 1570708.6250, 1569004.8750, 1568170.1250,
         1567385.1250, 1564910.3750, 1564315.0000, 1563704.8750, 1563688.5000],
        [1565349.1250, 1564552.1250, 1563077.1250, 1562101.1250, 1558402.0000,
         1557864.1250, 1552621.0000, 1552486.2500, 1552052.5000, 1551583.3750],
        [1575528.8750, 1574630.6250, 1573774.7500, 1572931.6250, 1572336.1250,
         1571502.7500, 1571104.1250, 1570551.2500, 1570481.0000, 1569908.8750],
        [1577873.0000, 1577552.6250, 1576895.2500, 1575144.2500, 1574585.6250,
         1574330.3750, 1573827.3750, 1573692.3750, 1573521.2500, 1572622.6250],
        [1579996.2500, 1579229.5000, 1575016.5000, 1574130.6250, 1574115.5000,
         1574082.5000, 1573850.0000, 1573444.6250, 1572330.2500, 1572057.2500],
        [1579446.3750, 1579404.1250, 1579366.6250, 1577475.8750, 1577241.2500,
         1576510.3750, 1576181.1250, 1575731.7500, 1575689.6250, 1575189.3750],
        [1578565.3750, 1577557.1250, 1575553.0000, 1574830.3750, 1574291.2500,
         1574237.1250, 1574111.1250, 1574015.0000, 1573576.7500, 1573533.2500],
        [1354012.2500, 1329863.6250, 1161934.8750, 1047004.1875, 1025631.7500,
         1006878.7500, 1006441.9375,  966998.1250,  953943.8750,  913838.8750],
        [1515862.2500, 1513224.7500, 1506514.7500, 1505864.1250, 1503592.3750,
         1501261.1250, 1499905.8750, 1499276.7500, 1496344.1250, 1496194.2500],
        [1553610.3750, 1551758.0000, 1550364.6250, 1546660.8750, 1546550.2500,
         1545776.1250, 1545726.0000, 1545723.0000, 1545683.2500, 1544501.5000],
        [1520598.2500, 1516886.0000, 1514795.6250, 1513611.6250, 1511902.0000,
         1511620.8750, 1509146.2500, 1508805.2500, 1508746.2500, 1506105.3750],
        [1298960.6250, 1244319.8750, 1192262.7500, 1127209.8750, 1114702.5000,
         1081306.5000, 1072557.1250, 1049381.3750, 1006816.3125, 1005473.0000],
        [1501659.2500, 1495492.5000, 1489106.7500, 1488818.3750, 1488382.6250,
         1485726.3750, 1483969.0000, 1483676.1250, 1481371.5000, 1480922.3750],
        [1440582.6250, 1427779.2500, 1421930.8750, 1413176.0000, 1410028.6250,
         1404601.0000, 1396046.2500, 1392850.6250, 1389841.1250, 1389499.2500],
        [1510036.0000, 1501521.8750, 1499933.1250, 1499933.1250, 1498286.2500,
         1494443.1250, 1494189.5000, 1493035.6250, 1490412.3750, 1488550.1250],
        [1307644.8750, 1285270.3750, 1278850.2500, 1268837.5000, 1242096.7500,
         1228501.8750, 1221823.3750, 1206222.5000, 1176958.5000, 1168647.1250],
        [1562063.8750, 1559958.8750, 1556719.1250, 1555614.8750, 1555533.3750,
         1554865.8750, 1553688.8750, 1552905.3750, 1552757.2500, 1551923.7500],
        [1553549.6250, 1552801.7500, 1550184.2500, 1546084.2500, 1545478.3750,
         1544953.7500, 1544267.2500, 1542664.3750, 1541886.2500, 1541415.8750],
        [1535563.0000, 1530951.1250, 1527309.8750, 1526999.6250, 1524120.3750,
         1523767.2500, 1519709.5000, 1519161.7500, 1519002.5000, 1517547.2500],
        [1366027.6250, 1316693.6250, 1292908.3750, 1285927.6250, 1273603.2500,
         1272052.0000, 1264873.5000, 1256657.8750, 1252595.7500, 1240030.2500],
        [1307906.8750, 1193533.5000, 1186240.3750, 1165467.2500, 1158209.8750,
         1151579.5000, 1147715.7500, 1144075.7500, 1139131.7500, 1136884.2500],
        [1323777.2500, 1310490.1250, 1099876.5000, 1049030.1250,  904709.5000,
          897184.5625,  853779.0625,  847521.2500,  846352.4375,  842106.3125],
        [1090801.1250, 1031027.5000, 1004257.8125,  994283.1250,  983877.1250,
          958640.6250,  941580.1875,  932410.3125,  929282.8125,  834002.1250],
        [1397883.3750, 1370187.1250, 1364484.7500, 1354187.8750, 1351094.5000,
         1340176.1250, 1338240.0000, 1331777.5000, 1325821.3750, 1325432.0000],
        [1463345.2500, 1462731.2500, 1462428.6250, 1458790.2500, 1456971.7500,
         1445998.8750, 1442870.5000, 1438446.5000, 1438010.3750, 1430898.1250],
        [1414629.6250, 1407651.8750, 1402554.3750, 1397408.8750, 1391321.2500,
         1386654.5000, 1376958.2500, 1375594.5000, 1374927.0000, 1374188.8750],
        [1404084.1250, 1400985.0000, 1377907.8750, 1373575.6250, 1353880.5000,
         1348999.6250, 1337579.1250, 1332674.3750, 1323647.1250, 1321171.5000],
        [1461769.1250, 1444256.7500, 1441326.1250, 1424770.5000, 1419700.5000,
         1415301.7500, 1396328.5000, 1380375.3750, 1373464.3750, 1366358.6250],
        [1387924.6250, 1336293.8750, 1322458.6250, 1314923.1250, 1299979.3750,
         1293654.6250, 1290939.6250, 1282691.6250, 1272176.8750, 1256149.8750],
        [1492850.6250, 1488311.6250, 1488311.6250, 1488064.7500, 1487424.7500,
         1486908.5000, 1474206.5000, 1473380.0000, 1472943.1250, 1466512.3750],
        [1500667.2500, 1486151.5000, 1480775.5000, 1477521.1250, 1474695.8750,
         1446630.6250, 1446032.0000, 1443578.0000, 1442991.6250, 1441326.1250],
        [1475789.0000, 1410090.5000, 1386006.6250, 1381454.0000, 1368768.7500,
         1367423.6250, 1363364.7500, 1363007.2500, 1358426.5000, 1349757.6250],
        [1414053.7500, 1407623.7500, 1398694.1250, 1391780.3750, 1316107.3750,
         1314340.1250, 1312418.6250, 1299605.0000, 1293167.3750, 1292368.5000],
        [1422343.1250, 1410050.2500, 1402838.0000, 1398351.3750, 1362474.5000,
         1357843.7500, 1357082.5000, 1324718.0000, 1305500.5000, 1296186.2500],
        [1526798.7500, 1463271.2500, 1435353.7500, 1434144.1250, 1426344.8750,
         1399103.7500, 1354362.2500, 1350933.3750, 1347963.1250, 1337079.1250],
        [1385767.3750, 1359830.2500, 1349854.2500, 1348745.0000, 1345848.8750,
         1338634.5000, 1335357.5000, 1321409.6250, 1318193.8750, 1316288.1250],
        [1414853.6250, 1406259.1250, 1320481.2500, 1294712.3750, 1274335.8750,
         1261385.0000, 1259663.5000, 1257910.8750, 1241986.6250, 1233363.0000],
        [1425974.8750, 1424803.1250, 1419236.1250, 1416850.6250, 1405017.8750,
         1372973.2500, 1310118.8750, 1295861.2500, 1291614.5000, 1285644.3750],
        [1434535.3750, 1423660.8750, 1423408.2500, 1423375.7500, 1422716.1250,
         1418684.0000, 1408366.2500, 1399083.7500, 1386401.8750, 1372211.3750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1510064.8750,       0.0000],
         [1509706.2500,       0.0000],
         [1488083.2500,       0.0000],
         ...,
         [      0.0000, 1474066.0000],
         [1473134.2500,       0.0000],
         [1466495.6250,       0.0000]],

        [[1535869.1250,       0.0000],
         [1525320.1250,       0.0000],
         [1523052.5000,       0.0000],
         ...,
         [1517800.5000,       0.0000],
         [1517787.5000,       0.0000],
         [1517243.3750,       0.0000]],

        [[1132366.6250,       0.0000],
         [      0.0000, 1032569.5000],
         [1007794.2500,       0.0000],
         ...,
         [ 971223.6875,       0.0000],
         [ 968947.8125,       0.0000],
         [      0.0000,  957606.3125]],

        ...,

        [[1414853.6250,       0.0000],
         [1406259.1250,       0.0000],
         [1320481.2500,       0.0000],
         ...,
         [1257910.8750,       0.0000],
         [1241986.6250,       0.0000],
         [1233363.0000,       0.0000]],

        [[1425974.8750,       0.0000],
         [1424803.1250,       0.0000],
         [1419236.1250,       0.0000],
         ...,
         [      0.0000, 1295861.2500],
         [1291614.5000,       0.0000],
         [      0.0000, 1285644.3750]],

        [[      0.0000, 1434535.3750],
         [      0.0000, 1423660.8750],
         [      0.0000, 1423408.2500],
         ...,
         [      0.0000, 1399083.7500],
         [      0.0000, 1386401.8750],
         [1372211.3750,       0.0000]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13379263.0000,  1474066.0000],
        [15222328.0000,        0.0000],
        [ 4080332.5000,  5974176.5000],
        [12703894.0000,  1396962.3750],
        [10394807.0000,  2543539.5000],
        [ 9312276.0000,  2263766.0000],
        [ 5007680.0000,  5121953.5000],
        [ 8466993.0000,   849111.6875],
        [13690904.0000,  1513644.7500],
        [11899240.0000,  1380038.3750],
        [15485017.0000,        0.0000],
        [14049922.0000,        0.0000],
        [13235664.0000,        0.0000],
        [15458354.0000,        0.0000],
        [15745670.0000,        0.0000],
        [15694060.0000,        0.0000],
        [13529206.0000,  1517886.0000],
        [13271252.0000,  1493679.3750],
        [14568784.0000,        0.0000],
        [15466072.0000,        0.0000],
        [15443260.0000,        0.0000],
        [13143362.0000,  1465139.6250],
        [15589495.0000,        0.0000],
        [15721769.0000,        0.0000],
        [10285159.0000,  4442777.0000],
        [15680061.0000,        0.0000],
        [15580088.0000,        0.0000],
        [15722750.0000,        0.0000],
        [15750044.0000,        0.0000],
        [15748253.0000,        0.0000],
        [15772236.0000,        0.0000],
        [15750270.0000,        0.0000],
        [ 2927159.5000,  7839389.0000],
        [ 9020686.0000,  6017355.0000],
        [12384906.0000,  3091449.0000],
        [12101317.0000,  3020901.0000],
        [ 3170900.0000,  8022090.0000],
        [11894526.0000,  2984599.2500],
        [12693485.0000,  1392850.6250],
        [13479929.0000,  1490412.3750],
        [ 9857486.0000,  2527367.0000],
        [15556031.0000,        0.0000],
        [15463286.0000,        0.0000],
        [13720012.0000,  1524120.3750],
        [ 2496688.0000, 10324682.0000],
        [ 1165467.2500, 10565278.0000],
        [ 5191653.0000,  4783174.0000],
        [ 2734223.0000,  6965940.0000],
        [ 4041400.7500,  9457884.0000],
        [10121998.0000,  4378493.0000],
        [12504480.0000,  1397408.8750],
        [ 1321171.5000, 12253333.0000],
        [ 1366358.6250, 12757293.0000],
        [ 2637381.7500, 10419811.0000],
        [11838639.0000,  2980275.5000],
        [10178855.0000,  4461514.5000],
        [ 2727195.2500, 11096893.0000],
        [ 5221298.5000,  8218860.5000],
        [ 1296186.2500, 12341202.0000],
        [ 2691441.5000, 11383912.0000],
        [10698804.0000,  2721125.0000],
        [11703566.0000,  1261385.0000],
        [ 9756471.0000,  3891624.5000],
        [ 1372211.3750, 12740232.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
Epoch 496/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:56<26:32, 56.88s/it]  7%|▋         | 2/29 [01:01<11:43, 26.04s/it] 10%|█         | 3/29 [01:02<06:18, 14.57s/it] 14%|█▍        | 4/29 [01:03<03:49,  9.18s/it] 17%|█▋        | 5/29 [01:04<02:28,  6.20s/it] 21%|██        | 6/29 [01:05<01:41,  4.41s/it] 24%|██▍       | 7/29 [01:05<01:11,  3.27s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.52s/it] 31%|███       | 9/29 [01:07<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:09<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.98s/it]
Epoch loss is 2.7835280895233154
Epoch 497/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:00<28:01, 60.05s/it]  7%|▋         | 2/29 [01:00<11:22, 25.27s/it] 10%|█         | 3/29 [01:01<06:07, 14.15s/it] 14%|█▍        | 4/29 [01:02<03:43,  8.93s/it] 17%|█▋        | 5/29 [01:03<02:25,  6.04s/it] 21%|██        | 6/29 [01:04<01:38,  4.30s/it] 24%|██▍       | 7/29 [01:05<01:10,  3.20s/it] 28%|██▊       | 8/29 [01:06<00:52,  2.48s/it] 31%|███       | 9/29 [01:07<00:39,  1.99s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.66s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:14<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:15<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:16<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:17<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:18<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.08it/s]100%|██████████| 29/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.97s/it]
Epoch loss is 2.785111904144287
Epoch 498/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:58<27:25, 58.76s/it]  7%|▋         | 2/29 [01:00<11:15, 25.03s/it] 10%|█         | 3/29 [01:01<06:04, 14.02s/it] 14%|█▍        | 4/29 [01:02<03:41,  8.85s/it] 17%|█▋        | 5/29 [01:02<02:23,  5.99s/it] 21%|██        | 6/29 [01:03<01:38,  4.27s/it] 24%|██▍       | 7/29 [01:04<01:09,  3.17s/it] 28%|██▊       | 8/29 [01:05<00:51,  2.46s/it] 31%|███       | 9/29 [01:06<00:39,  1.98s/it] 34%|███▍      | 10/29 [01:07<00:31,  1.65s/it] 38%|███▊      | 11/29 [01:08<00:25,  1.43s/it] 41%|████▏     | 12/29 [01:09<00:21,  1.27s/it] 45%|████▍     | 13/29 [01:10<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:11<00:16,  1.09s/it] 52%|█████▏    | 15/29 [01:12<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:13<00:13,  1.00s/it] 59%|█████▊    | 17/29 [01:13<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:14<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:15<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:16<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:17<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:18<00:06,  1.08it/s] 79%|███████▉  | 23/29 [01:19<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:20<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:21<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:22<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:23<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:24<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  1.09it/s]100%|██████████| 29/29 [01:25<00:00,  2.94s/it]
Epoch loss is 2.7604150772094727
Epoch 499/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [01:01<28:50, 61.79s/it]  7%|▋         | 2/29 [01:02<11:41, 25.98s/it] 10%|█         | 3/29 [01:03<06:18, 14.54s/it] 14%|█▍        | 4/29 [01:04<03:49,  9.16s/it] 17%|█▋        | 5/29 [01:05<02:28,  6.19s/it] 21%|██        | 6/29 [01:06<01:41,  4.40s/it] 24%|██▍       | 7/29 [01:07<01:11,  3.26s/it] 28%|██▊       | 8/29 [01:08<00:52,  2.52s/it] 31%|███       | 9/29 [01:09<00:40,  2.02s/it] 34%|███▍      | 10/29 [01:10<00:31,  1.68s/it] 38%|███▊      | 11/29 [01:11<00:26,  1.45s/it] 41%|████▏     | 12/29 [01:11<00:21,  1.29s/it] 45%|████▍     | 13/29 [01:12<00:18,  1.18s/it] 48%|████▊     | 14/29 [01:13<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:14<00:14,  1.05s/it] 55%|█████▌    | 16/29 [01:15<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:16<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:17<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:18<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:19<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:20<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:21<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:22<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:22<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:23<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:24<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:25<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  1.08it/s]100%|██████████| 29/29 [01:27<00:00,  3.03s/it]
Epoch loss is 2.788763999938965
Epoch 500/501
  0%|          | 0/29 [00:00<?, ?it/s]  3%|▎         | 1/29 [00:59<27:51, 59.69s/it]  7%|▋         | 2/29 [01:01<11:33, 25.68s/it] 10%|█         | 3/29 [01:02<06:13, 14.37s/it] 14%|█▍        | 4/29 [01:03<03:46,  9.06s/it] 17%|█▋        | 5/29 [01:04<02:27,  6.13s/it] 21%|██        | 6/29 [01:05<01:40,  4.36s/it] 24%|██▍       | 7/29 [01:06<01:11,  3.23s/it] 28%|██▊       | 8/29 [01:07<00:52,  2.50s/it] 31%|███       | 9/29 [01:08<00:40,  2.01s/it] 34%|███▍      | 10/29 [01:08<00:31,  1.67s/it] 38%|███▊      | 11/29 [01:09<00:25,  1.44s/it] 41%|████▏     | 12/29 [01:10<00:21,  1.28s/it] 45%|████▍     | 13/29 [01:11<00:18,  1.17s/it] 48%|████▊     | 14/29 [01:12<00:16,  1.10s/it] 52%|█████▏    | 15/29 [01:13<00:14,  1.04s/it] 55%|█████▌    | 16/29 [01:14<00:13,  1.01s/it] 59%|█████▊    | 17/29 [01:15<00:11,  1.02it/s] 62%|██████▏   | 18/29 [01:16<00:10,  1.04it/s] 66%|██████▌   | 19/29 [01:17<00:09,  1.05it/s] 69%|██████▉   | 20/29 [01:18<00:08,  1.06it/s] 72%|███████▏  | 21/29 [01:19<00:07,  1.07it/s] 76%|███████▌  | 22/29 [01:19<00:06,  1.07it/s] 79%|███████▉  | 23/29 [01:20<00:05,  1.08it/s] 83%|████████▎ | 24/29 [01:21<00:04,  1.08it/s] 86%|████████▌ | 25/29 [01:22<00:03,  1.08it/s] 90%|████████▉ | 26/29 [01:23<00:02,  1.08it/s] 93%|█████████▎| 27/29 [01:24<00:01,  1.08it/s] 97%|█████████▋| 28/29 [01:25<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  1.08it/s]100%|██████████| 29/29 [01:26<00:00,  2.99s/it]
Epoch loss is 2.7836575508117676
saving checkpoint
Extracting features for train set...
feature output is dim torch.Size([7536, 2048])
label output is dim torch.Size([7536, 1])
Extracting features for val set...
feature output is dim torch.Size([64, 2048])
label output is dim torch.Size([64, 1])
TRAIN FEATURES ARE SIZE
 torch.Size([2048, 7536])
TEST FEATURES ARE
 torch.Size([64, 2048])
tensor([[2.9672e-03, 1.3779e-02, 2.0773e-03,  ..., 4.1260e-03, 9.2648e-05,
         1.9992e-02],
        [2.9469e-03, 9.6358e-03, 1.9860e-03,  ..., 2.1985e-03, 1.6905e-04,
         1.8783e-02],
        [3.2491e-02, 6.5050e-03, 3.7006e-03,  ..., 5.3853e-03, 1.4803e-02,
         2.4694e-02],
        ...,
        [7.4639e-03, 7.9873e-03, 1.7631e-02,  ..., 3.7646e-03, 1.7693e-03,
         2.1187e-02],
        [4.1080e-03, 8.1766e-03, 1.1155e-02,  ..., 4.6433e-03, 4.7154e-03,
         2.0646e-02],
        [9.0083e-03, 4.4365e-03, 3.7541e-03,  ..., 2.5819e-03, 2.0410e-03,
         2.2973e-02]], device='cuda:0')
TEST LABELS ARE
 torch.Size([64, 1])
tensor([[0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [0],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
DOT PROD OF TEST FEATURES x TRAIN FEATURES
 torch.Size([64, 7536])
TOP K DOT PROD VALS ARE
 torch.Size([64, 10])
tensor([[0.9963, 0.9963, 0.9952, 0.9952, 0.9951, 0.9950, 0.9948, 0.9948, 0.9947,
         0.9944],
        [0.9973, 0.9968, 0.9967, 0.9967, 0.9965, 0.9965, 0.9965, 0.9965, 0.9964,
         0.9964],
        [0.9758, 0.9698, 0.9693, 0.9659, 0.9652, 0.9649, 0.9644, 0.9643, 0.9641,
         0.9638],
        [0.9935, 0.9926, 0.9924, 0.9922, 0.9919, 0.9910, 0.9909, 0.9900, 0.9898,
         0.9897],
        [0.9886, 0.9873, 0.9867, 0.9850, 0.9849, 0.9847, 0.9842, 0.9841, 0.9841,
         0.9839],
        [0.9841, 0.9837, 0.9816, 0.9765, 0.9764, 0.9751, 0.9749, 0.9737, 0.9733,
         0.9731],
        [0.9800, 0.9688, 0.9678, 0.9675, 0.9670, 0.9664, 0.9647, 0.9644, 0.9622,
         0.9617],
        [0.9766, 0.9734, 0.9698, 0.9685, 0.9613, 0.9583, 0.9574, 0.9572, 0.9567,
         0.9555],
        [0.9975, 0.9969, 0.9969, 0.9966, 0.9966, 0.9965, 0.9964, 0.9963, 0.9963,
         0.9963],
        [0.9940, 0.9903, 0.9894, 0.9885, 0.9870, 0.9861, 0.9859, 0.9843, 0.9842,
         0.9836],
        [0.9981, 0.9980, 0.9980, 0.9980, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977,
         0.9977],
        [0.9938, 0.9936, 0.9916, 0.9913, 0.9908, 0.9904, 0.9904, 0.9903, 0.9901,
         0.9894],
        [0.9921, 0.9909, 0.9893, 0.9888, 0.9870, 0.9868, 0.9866, 0.9849, 0.9848,
         0.9843],
        [0.9984, 0.9983, 0.9981, 0.9981, 0.9980, 0.9977, 0.9974, 0.9974, 0.9973,
         0.9973],
        [0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9990, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987, 0.9986,
         0.9986],
        [0.9966, 0.9963, 0.9963, 0.9962, 0.9960, 0.9958, 0.9958, 0.9955, 0.9955,
         0.9954],
        [0.9954, 0.9949, 0.9947, 0.9946, 0.9945, 0.9944, 0.9943, 0.9943, 0.9943,
         0.9943],
        [0.9945, 0.9940, 0.9937, 0.9937, 0.9935, 0.9934, 0.9934, 0.9933, 0.9933,
         0.9933],
        [0.9981, 0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977,
         0.9976],
        [0.9979, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9976, 0.9975, 0.9975,
         0.9975],
        [0.9952, 0.9947, 0.9944, 0.9942, 0.9940, 0.9938, 0.9938, 0.9937, 0.9927,
         0.9927],
        [0.9989, 0.9988, 0.9983, 0.9983, 0.9983, 0.9982, 0.9981, 0.9980, 0.9977,
         0.9975],
        [0.9991, 0.9990, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9988,
         0.9987],
        [0.9953, 0.9952, 0.9946, 0.9944, 0.9943, 0.9942, 0.9941, 0.9940, 0.9939,
         0.9939],
        [0.9990, 0.9988, 0.9987, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985,
         0.9985],
        [0.9985, 0.9985, 0.9984, 0.9983, 0.9983, 0.9982, 0.9980, 0.9980, 0.9980,
         0.9979],
        [0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988,
         0.9987],
        [0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989,
         0.9989],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,
         0.9988],
        [0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,
         0.9990],
        [0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989, 0.9989,
         0.9989],
        [0.9883, 0.9868, 0.9779, 0.9711, 0.9681, 0.9669, 0.9667, 0.9655, 0.9641,
         0.9591],
        [0.9964, 0.9963, 0.9960, 0.9959, 0.9958, 0.9958, 0.9957, 0.9957, 0.9957,
         0.9955],
        [0.9980, 0.9980, 0.9979, 0.9978, 0.9977, 0.9977, 0.9977, 0.9976, 0.9976,
         0.9976],
        [0.9967, 0.9965, 0.9964, 0.9964, 0.9964, 0.9964, 0.9963, 0.9962, 0.9961,
         0.9961],
        [0.9851, 0.9823, 0.9789, 0.9761, 0.9735, 0.9731, 0.9712, 0.9710, 0.9684,
         0.9680],
        [0.9961, 0.9956, 0.9954, 0.9953, 0.9952, 0.9952, 0.9950, 0.9950, 0.9949,
         0.9949],
        [0.9926, 0.9917, 0.9917, 0.9913, 0.9910, 0.9909, 0.9905, 0.9904, 0.9902,
         0.9902],
        [0.9961, 0.9959, 0.9957, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9953,
         0.9953],
        [0.9845, 0.9844, 0.9841, 0.9838, 0.9823, 0.9810, 0.9809, 0.9795, 0.9787,
         0.9775],
        [0.9985, 0.9984, 0.9982, 0.9982, 0.9982, 0.9982, 0.9982, 0.9981, 0.9981,
         0.9981],
        [0.9981, 0.9981, 0.9981, 0.9979, 0.9978, 0.9978, 0.9978, 0.9977, 0.9977,
         0.9977],
        [0.9973, 0.9972, 0.9970, 0.9970, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966,
         0.9966],
        [0.9897, 0.9868, 0.9859, 0.9852, 0.9849, 0.9839, 0.9838, 0.9835, 0.9834,
         0.9827],
        [0.9861, 0.9793, 0.9792, 0.9791, 0.9787, 0.9775, 0.9773, 0.9770, 0.9769,
         0.9759],
        [0.9869, 0.9851, 0.9735, 0.9705, 0.9609, 0.9581, 0.9549, 0.9543, 0.9539,
         0.9537],
        [0.9729, 0.9683, 0.9681, 0.9666, 0.9656, 0.9640, 0.9626, 0.9618, 0.9617,
         0.9528],
        [0.9908, 0.9900, 0.9890, 0.9889, 0.9886, 0.9881, 0.9880, 0.9878, 0.9875,
         0.9874],
        [0.9943, 0.9942, 0.9942, 0.9941, 0.9940, 0.9935, 0.9934, 0.9934, 0.9933,
         0.9930],
        [0.9918, 0.9916, 0.9911, 0.9911, 0.9906, 0.9904, 0.9903, 0.9902, 0.9898,
         0.9897],
        [0.9912, 0.9911, 0.9899, 0.9896, 0.9889, 0.9887, 0.9875, 0.9873, 0.9870,
         0.9869],
        [0.9938, 0.9928, 0.9928, 0.9920, 0.9916, 0.9916, 0.9906, 0.9899, 0.9897,
         0.9892],
        [0.9904, 0.9879, 0.9873, 0.9870, 0.9859, 0.9855, 0.9854, 0.9852, 0.9844,
         0.9836],
        [0.9954, 0.9953, 0.9953, 0.9953, 0.9953, 0.9951, 0.9948, 0.9948, 0.9948,
         0.9944],
        [0.9958, 0.9951, 0.9951, 0.9951, 0.9947, 0.9935, 0.9935, 0.9934, 0.9933,
         0.9932],
        [0.9944, 0.9914, 0.9902, 0.9900, 0.9894, 0.9892, 0.9889, 0.9889, 0.9888,
         0.9884],
        [0.9916, 0.9911, 0.9910, 0.9904, 0.9868, 0.9868, 0.9864, 0.9860, 0.9856,
         0.9856],
        [0.9919, 0.9916, 0.9906, 0.9903, 0.9891, 0.9888, 0.9886, 0.9874, 0.9861,
         0.9860],
        [0.9968, 0.9940, 0.9928, 0.9927, 0.9922, 0.9911, 0.9885, 0.9882, 0.9878,
         0.9878],
        [0.9901, 0.9888, 0.9886, 0.9883, 0.9882, 0.9877, 0.9875, 0.9871, 0.9869,
         0.9864],
        [0.9917, 0.9910, 0.9874, 0.9853, 0.9843, 0.9837, 0.9836, 0.9834, 0.9828,
         0.9820],
        [0.9925, 0.9924, 0.9922, 0.9919, 0.9915, 0.9899, 0.9866, 0.9865, 0.9854,
         0.9847],
        [0.9927, 0.9925, 0.9923, 0.9922, 0.9922, 0.9917, 0.9912, 0.9906, 0.9901,
         0.9896]], device='cuda:0')
TRAIN LABEL CANDIDATES ARE
 torch.Size([64, 7536])
RETRIEVED CANDIDATES ARE
 torch.Size([64, 10])
tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 0, 1, 1, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [1, 0, 0, 1, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
        [0, 1, 0, 0, 1, 0, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
        [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],
        [1, 1, 0, 1, 0, 1, 1, 1, 0, 1],
        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 0, 0, 1, 1, 1, 1, 1, 1],
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 0, 1, 1, 0, 1],
        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],
        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0')
ONE HOT RETRIEVED CANDIATES ARE
 torch.Size([640, 2])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        ...,
        [0., 1.],
        [1., 0.],
        [0., 1.]], device='cuda:0')
EXP(TOP K VALS / TEMP)
 torch.Size([64, 10])
tensor([[1518586.7500, 1518234.8750, 1495300.0000, 1493874.5000, 1492366.6250,
         1490008.7500, 1485939.0000, 1484960.0000, 1483492.2500, 1477580.3750],
        [1540347.5000, 1527758.5000, 1527105.8750, 1526328.5000, 1523343.0000,
         1523276.1250, 1522878.1250, 1522827.3750, 1520308.2500, 1520011.1250],
        [1133204.8750, 1039017.8750, 1032462.1250,  983597.6250,  973420.3750,
          969359.1250,  962199.9375,  960743.8750,  957809.0000,  954455.2500],
        [1458288.1250, 1440261.1250, 1436356.0000, 1432326.2500, 1425730.1250,
         1406484.3750, 1404791.3750, 1387920.6250, 1382890.7500, 1381145.6250],
        [1360472.3750, 1335026.3750, 1324163.6250, 1291908.8750, 1290182.7500,
         1286224.3750, 1276602.0000, 1275192.8750, 1274258.1250, 1271380.0000],
        [1275790.1250, 1268749.2500, 1230803.8750, 1143887.0000, 1141586.3750,
         1121843.5000, 1117313.1250, 1099487.3750, 1093335.0000, 1089573.1250],
        [1203192.8750, 1024591.5625, 1010481.2500, 1005829.7500,  998326.8750,
          989997.8750,  966671.7500,  962141.1875,  933003.6250,  926473.2500],
        [1145637.0000, 1094420.0000, 1039043.6250, 1020741.1250,  920402.0625,
          881644.8750,  871328.5625,  867968.8750,  862623.9375,  847407.2500],
        [1544612.0000, 1531894.6250, 1530236.0000, 1525109.1250, 1524063.7500,
         1522706.7500, 1519489.2500, 1518276.8750, 1517357.7500, 1517001.7500],
        [1469853.2500, 1393238.5000, 1374659.3750, 1358247.7500, 1329899.1250,
         1311630.3750, 1309161.0000, 1278305.1250, 1276728.6250, 1266024.8750],
        [1556358.3750, 1556137.1250, 1556097.1250, 1555226.2500, 1551593.7500,
         1549610.7500, 1549423.0000, 1548117.3750, 1547885.6250, 1547811.7500],
        [1464607.3750, 1461063.8750, 1419570.5000, 1412851.3750, 1402317.6250,
         1395989.0000, 1394511.8750, 1393708.8750, 1388803.7500, 1374721.1250],
        [1429817.8750, 1404641.2500, 1373831.1250, 1362956.6250, 1329557.8750,
         1325151.5000, 1322289.5000, 1289867.7500, 1287758.6250, 1278650.2500],
        [1565158.1250, 1560964.8750, 1556630.0000, 1556616.6250, 1554443.3750,
         1548425.8750, 1542454.0000, 1542006.8750, 1540755.8750, 1540393.1250],
        [1578503.7500, 1577784.2500, 1576714.7500, 1576659.1250, 1576420.1250,
         1576092.3750, 1575958.6250, 1575586.0000, 1575563.3750, 1574262.6250],
        [1576920.7500, 1574716.2500, 1573657.7500, 1573329.2500, 1572889.6250,
         1572507.1250, 1571307.8750, 1570985.7500, 1569386.5000, 1568780.3750],
        [1524313.7500, 1518979.2500, 1518691.0000, 1514824.6250, 1512145.7500,
         1507088.1250, 1507083.7500, 1501589.0000, 1500126.2500, 1498860.7500],
        [1499272.5000, 1487342.5000, 1482927.8750, 1480757.1250, 1479546.0000,
         1477029.5000, 1475831.2500, 1475679.2500, 1475026.5000, 1474788.6250],
        [1479255.2500, 1468897.5000, 1463366.2500, 1461778.7500, 1458838.8750,
         1456445.2500, 1455385.7500, 1454299.3750, 1454160.7500, 1453443.8750],
        [1556530.5000, 1553420.7500, 1553137.8750, 1551543.3750, 1551473.8750,
         1550463.6250, 1549507.2500, 1548972.5000, 1547558.0000, 1547428.0000],
        [1554035.7500, 1552912.6250, 1551580.3750, 1550919.1250, 1549857.5000,
         1549427.3750, 1546196.2500, 1544501.5000, 1544251.1250, 1543085.1250],
        [1494116.7500, 1482736.7500, 1477177.3750, 1472603.2500, 1469713.0000,
         1464895.1250, 1464540.2500, 1461711.8750, 1442224.0000, 1441869.1250],
        [1575354.6250, 1574165.1250, 1562914.7500, 1562485.5000, 1562440.8750,
         1559343.1250, 1556918.0000, 1555898.2500, 1548346.2500, 1545107.0000],
        [1580150.0000, 1577343.5000, 1575217.8750, 1574932.5000, 1574492.3750,
         1574166.6250, 1574081.1250, 1573374.2500, 1572408.1250, 1571700.5000],
        [1495525.2500, 1493340.3750, 1480631.3750, 1477138.0000, 1475565.2500,
         1473593.7500, 1470229.0000, 1469609.2500, 1467418.8750, 1466704.0000],
        [1577533.0000, 1573842.3750, 1571907.3750, 1570608.2500, 1569826.5000,
         1569052.7500, 1568122.2500, 1566878.6250, 1565561.1250, 1565444.7500],
        [1567095.2500, 1566339.1250, 1563247.1250, 1562880.5000, 1561009.6250,
         1559079.8750, 1556258.8750, 1555201.1250, 1555042.3750, 1552398.8750],
        [1577295.3750, 1576569.0000, 1575880.5000, 1575366.6250, 1574740.2500,
         1574402.3750, 1574393.3750, 1573198.7500, 1572678.1250, 1571361.7500],
        [1580026.3750, 1579951.1250, 1579353.0000, 1576907.3750, 1576758.5000,
         1576714.7500, 1576378.0000, 1576008.2500, 1575963.2500, 1575673.1250],
        [1581484.1250, 1580923.2500, 1576854.7500, 1576599.1250, 1576361.5000,
         1576084.8750, 1576023.2500, 1575553.0000, 1574375.3750, 1574105.1250],
        [1581948.7500, 1581601.8750, 1581146.3750, 1579726.5000, 1579453.8750,
         1579208.3750, 1578719.0000, 1577986.0000, 1577542.0000, 1576805.1250],
        [1581140.3750, 1579103.0000, 1577703.0000, 1577169.0000, 1576970.3750,
         1576800.5000, 1576496.8750, 1576283.3750, 1575882.0000, 1575593.5000],
        [1353272.5000, 1324916.3750, 1166310.1250, 1058555.2500, 1014642.2500,
          996776.2500,  994385.5000,  977512.6875,  958384.7500,  891914.9375],
        [1520245.8750, 1518491.2500, 1512040.3750, 1509166.5000, 1507434.6250,
         1506868.2500, 1505910.0000, 1505638.6250, 1504717.0000, 1501504.6250],
        [1555175.7500, 1554515.8750, 1552459.6250, 1550468.1250, 1549335.8750,
         1547866.3750, 1547605.1250, 1547082.7500, 1547082.7500, 1547048.8750],
        [1527288.0000, 1522523.8750, 1520841.8750, 1520337.2500, 1519753.0000,
         1519676.2500, 1517583.5000, 1515223.2500, 1514163.1250, 1513154.0000],
        [1293796.5000, 1243155.0000, 1183322.8750, 1137610.8750, 1096118.2500,
         1089682.2500, 1061126.5000, 1057601.7500, 1018830.0625, 1013204.4375],
        [1513250.6250, 1501878.3750, 1498199.0000, 1496167.2500, 1494880.7500,
         1494041.3750, 1490590.0000, 1489172.0000, 1488902.2500, 1487268.7500],
        [1439792.8750, 1421845.3750, 1421303.1250, 1412313.8750, 1406746.0000,
         1404924.0000, 1397619.3750, 1394654.2500, 1391423.2500, 1391270.7500],
        [1513191.5000, 1508965.0000, 1505775.0000, 1505645.7500, 1505645.7500,
         1502298.1250, 1501160.8750, 1499589.8750, 1497400.5000, 1496342.7500],
        [1281784.2500, 1281069.3750, 1275065.2500, 1269526.2500, 1242897.8750,
         1219117.1250, 1218575.5000, 1193527.8750, 1180650.2500, 1160207.5000],
        [1565946.3750, 1563542.3750, 1560707.3750, 1560121.0000, 1559606.3750,
         1558929.6250, 1558624.8750, 1558133.0000, 1557218.0000, 1557076.8750],
        [1558330.6250, 1557889.3750, 1556717.5000, 1552051.0000, 1551815.7500,
         1551178.0000, 1550605.6250, 1549695.0000, 1548684.3750, 1547807.2500],
        [1540638.3750, 1537412.3750, 1534160.7500, 1534032.0000, 1533034.5000,
         1531145.3750, 1527882.3750, 1525577.5000, 1524809.6250, 1524777.6250],
        [1380405.6250, 1325023.7500, 1308246.1250, 1295294.1250, 1289722.6250,
         1271302.3750, 1269660.6250, 1263392.0000, 1263235.2500, 1249503.2500],
        [1312103.3750, 1189809.2500, 1189479.1250, 1187056.2500, 1179932.2500,
         1160557.2500, 1157329.8750, 1152815.6250, 1151104.0000, 1134534.8750],
        [1327603.0000, 1294165.5000, 1096569.0000, 1049860.7500,  915933.7500,
          879625.1250,  840265.1875,  832605.8750,  828822.9375,  825686.9375],
        [1086336.0000, 1017005.0625, 1014320.1250,  993557.9375,  978673.0625,
          956690.7500,  937629.3750,  927819.8750,  926308.0625,  815017.3750],
        [1403730.6250, 1387552.6250, 1367872.2500, 1366262.2500, 1359354.3750,
         1349398.6250, 1349160.5000, 1345180.3750, 1338431.5000, 1335889.8750],
        [1475983.2500, 1473832.6250, 1473092.0000, 1470220.5000, 1468607.6250,
         1458036.5000, 1457271.8750, 1455288.6250, 1454654.5000, 1447893.6250],
        [1423043.2500, 1419102.2500, 1409692.5000, 1409434.3750, 1400072.7500,
         1396163.3750, 1393982.7500, 1390592.8750, 1383826.1250, 1380856.0000],
        [1411100.8750, 1408867.2500, 1384915.2500, 1380247.7500, 1365379.0000,
         1361658.7500, 1339126.0000, 1333933.2500, 1329493.3750, 1326882.7500],
        [1464354.5000, 1444706.0000, 1444004.7500, 1427164.0000, 1419627.3750,
         1419328.2500, 1399029.0000, 1384842.6250, 1380884.8750, 1371159.7500],
        [1395520.3750, 1345961.7500, 1334140.6250, 1329858.5000, 1308646.7500,
         1301391.0000, 1299579.0000, 1294512.3750, 1281114.5000, 1266819.5000],
        [1497486.2500, 1497327.6250, 1497327.6250, 1497146.3750, 1496351.2500,
         1491389.2500, 1486280.5000, 1486135.8750, 1485009.5000, 1476864.7500],
        [1506349.6250, 1492997.2500, 1492709.6250, 1491760.5000, 1484307.3750,
         1457702.7500, 1457438.6250, 1455818.8750, 1453905.6250, 1452902.1250],
        [1478275.2500, 1414614.8750, 1392041.8750, 1387776.3750, 1375159.0000,
         1372212.6250, 1366501.8750, 1365050.8750, 1363011.2500, 1355185.2500],
        [1420219.2500, 1409829.6250, 1407366.0000, 1394772.7500, 1325031.5000,
         1324940.5000, 1317679.7500, 1309651.7500, 1302368.0000, 1302282.3750],
        [1426313.5000, 1419500.1250, 1400008.6250, 1392707.1250, 1369667.1250,
         1363541.7500, 1359700.6250, 1335865.7500, 1312605.2500, 1309892.7500],
        [1527950.8750, 1468443.7500, 1444912.6250, 1440836.7500, 1431952.0000,
         1408257.3750, 1357969.2500, 1352522.8750, 1343863.5000, 1343645.6250],
        [1389071.3750, 1363705.5000, 1360250.5000, 1353322.8750, 1351754.2500,
         1341813.2500, 1338727.6250, 1331642.7500, 1327387.7500, 1317448.6250],
        [1421166.1250, 1406359.7500, 1337409.5000, 1296846.5000, 1279152.6250,
         1266996.0000, 1266022.5000, 1261995.1250, 1251779.0000, 1237014.7500],
        [1436831.3750, 1436532.7500, 1430558.3750, 1425197.1250, 1417621.1250,
         1386193.1250, 1321644.1250, 1319319.3750, 1298646.1250, 1285763.2500],
        [1442631.1250, 1437704.5000, 1432640.3750, 1431965.6250, 1431395.0000,
         1422014.8750, 1412250.5000, 1399486.7500, 1388391.8750, 1380360.8750]],
       device='cuda:0')
ONE HOT x EXP(TOP K VALS)
 torch.Size([64, 10, 2])
tensor([[[1518586.7500,       0.0000],
         [1518234.8750,       0.0000],
         [1495300.0000,       0.0000],
         ...,
         [      0.0000, 1484960.0000],
         [1483492.2500,       0.0000],
         [1477580.3750,       0.0000]],

        [[1540347.5000,       0.0000],
         [1527758.5000,       0.0000],
         [1527105.8750,       0.0000],
         ...,
         [1522827.3750,       0.0000],
         [1520308.2500,       0.0000],
         [1520011.1250,       0.0000]],

        [[1133204.8750,       0.0000],
         [1039017.8750,       0.0000],
         [      0.0000, 1032462.1250],
         ...,
         [      0.0000,  960743.8750],
         [      0.0000,  957809.0000],
         [ 954455.2500,       0.0000]],

        ...,

        [[1421166.1250,       0.0000],
         [1406359.7500,       0.0000],
         [1337409.5000,       0.0000],
         ...,
         [1261995.1250,       0.0000],
         [1251779.0000,       0.0000],
         [1237014.7500,       0.0000]],

        [[1436831.3750,       0.0000],
         [1436532.7500,       0.0000],
         [1430558.3750,       0.0000],
         ...,
         [      0.0000, 1319319.3750],
         [1298646.1250,       0.0000],
         [1285763.2500,       0.0000]],

        [[      0.0000, 1442631.1250],
         [      0.0000, 1437704.5000],
         [      0.0000, 1432640.3750],
         ...,
         [      0.0000, 1399486.7500],
         [1388391.8750,       0.0000],
         [      0.0000, 1380360.8750]]], device='cuda:0')
PROBS ARE
 torch.Size([64, 2])
tensor([[13455384.0000,  1484960.0000],
        [15254184.0000,        0.0000],
        [ 4088878.0000,  5877392.0000],
        [12749711.0000,  1406484.3750],
        [10437429.0000,  2547982.0000],
        [ 9341295.0000,  2241073.7500],
        [ 4884548.0000,  5136162.5000],
        [ 8683248.0000,   867968.8750],
        [13731258.0000,  1519489.2500],
        [11974509.0000,  1393238.5000],
        [15518262.0000,        0.0000],
        [12733424.0000,  1374721.1250],
        [13404522.0000,        0.0000],
        [15507850.0000,        0.0000],
        [15763545.0000,        0.0000],
        [15724481.0000,        0.0000],
        [13579388.0000,  1524313.7500],
        [13308928.0000,  1499272.5000],
        [14605872.0000,        0.0000],
        [15510036.0000,        0.0000],
        [15486766.0000,        0.0000],
        [11757116.0000,  2914472.5000],
        [15602974.0000,        0.0000],
        [15747867.0000,        0.0000],
        [10313471.0000,  4456284.5000],
        [15698777.0000,        0.0000],
        [15598554.0000,        0.0000],
        [15745886.0000,        0.0000],
        [15773734.0000,        0.0000],
        [15768364.0000,        0.0000],
        [15794138.0000,        0.0000],
        [15773142.0000,        0.0000],
        [ 2883076.7500,  7853594.0000],
        [ 9054543.0000,  6037474.5000],
        [13951036.0000,  1547605.1250],
        [12152623.0000,  3037920.7500],
        [ 3166924.5000,  8027524.5000],
        [11958431.0000,  2995919.7500],
        [12684273.0000,  1397619.3750],
        [15036016.0000,        0.0000],
        [ 9797739.0000,  2524682.0000],
        [15599906.0000,        0.0000],
        [15524775.0000,        0.0000],
        [13779438.0000,  1534032.0000],
        [ 2512738.5000, 10403047.0000],
        [ 1187056.2500, 10627666.0000],
        [ 5122940.0000,  4768198.0000],
        [ 2680466.5000,  6972891.0000],
        [ 4065658.2500,  9537174.0000],
        [10222961.0000,  4411920.0000],
        [12597332.0000,  1409434.3750],
        [ 1326882.7500, 12314722.0000],
        [ 1371159.7500, 12783942.0000],
        [ 2663999.0000, 10493545.0000],
        [11922443.0000,  2988875.5000],
        [10262238.0000,  4483654.0000],
        [ 2735224.0000, 11134605.0000],
        [ 5254645.5000,  8259496.0000],
        [ 1309892.7500, 12379910.0000],
        [ 2701615.0000, 11418740.0000],
        [10754411.0000,  2720714.0000],
        [11757746.0000,  1266996.0000],
        [11117343.0000,  2640963.5000],
        [ 1388391.8750, 12790450.0000]], device='cuda:0')
PREDICTION IDX/CLASS SORTED
tensor([[0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [1, 0],
        [1, 0],
        [1, 0],
        [1, 0],
        [0, 1],
        [0, 1],
        [0, 1],
        [1, 0]], device='cuda:0')
CORRECT PREDS
tensor([[ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [False],
        [ True],
        [ True],
        [False],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False],
        [False],
        [ True]], device='cuda:0')
Top 1 acc 68.75
Top1 accuracy for validation set is 68.75 size is torch.Size([64, 1])
